### 01

参考文件@/Users/Daglas/dalong.llm/reader3/reader3.py中的代码，实现功能：把一个 EPUB 文件解析成结构化对象 Book，清洗 HTML、提取元数据/目录/正文/图片，并保存到输出目录（含 images 子目录和 book.pkl、各个章节内容文件[每个章节单独一个markdown文件]）。
将该功能的实现代码写入文件/Users/Daglas/dalong.github/dalong.llm-tools/scripts/epub2md.py

继续优化：各个章节的内容清洗为标准的 markdow 纯文本格式，而不是现在的 html 格式内容


---

作用：把一个 EPUB 文件解析成结构化对象 Book，清洗 HTML、提取元数据/目录/正文/图片，并保存到输出目录（含 images 子目录和 book.pkl）。
  - 数据模型：
      - ChapterContent：单个 spine 文件（物理章节）的 id、文件名 href、猜测标题、清洗后 HTML、纯文本、阅读顺序。
      - TOCEntry：导航用的逻辑章节项，含标题、原始 href、文件部分、锚点、子节点。
      - BookMetadata：书名、语言、作者等元数据。
      - Book：汇总 metadata、spine 内容、TOC、图片映射、来源文件名、处理时间、版本。
  - 工具函数：
      - clean_html_content：移除 script/style/iframe/video/nav/form/button/input 和 HTML 注释。
      - extract_plain_text：从 soup 抽取文本并压缩空白，用于搜索/LLM。
      - parse_toc_recursive：递归解析 ebooklib 的 TOC 结构（Link/Section/tuple），拆分 href 得到文件名和锚点。
      - get_fallback_toc：若 TOC 缺失，从文档 items 构建扁平目录，标题用文件名推断。
      - extract_metadata_robust：从 DC 元数据读取 title/language/authors/description/publisher/date/identifier/subject，兼容单值和列表。
  - 主流程 process_epub(epub_path, output_dir)：
      1. 读取 EPUB；2) 提取元数据；3) 清理/重建输出目录并创建 images；4) 遍历 image items，保存为安全文件名，记录内部路径和 basename 到本地
         路径的映射；5) 解析 TOC（为空则用 spine 生成 fallback）；6) 按 spine 顺序处理文档：用 BeautifulSoup 解析，修复 img 的 src（URL 解码
         后按映射替换）、清洗 HTML、提取 body 内部 HTML 和纯文本，构造 ChapterContent（标题默认 “Section N”，TOC 决定展示）；7) 组装 Book，
         记录 source/processed_at。
  - save_to_pickle：将 Book 序列化为 book.pkl。
  - CLI：python reader3.py <file.epub>；输出目录为同名后缀 _data，调用 process_epub + save_to_pickle，并打印标题、作者数、spine 文件数、TOC
    根节点数、提取的图片数。
