### 01

修改文件@scripts/twitter2md.py实现：1.输入的 json 文件路径`json_file = "20250719dataset_twitter-scraper_2025-07-19_10-04-35-572_csl.json"`更改为该项目下的文件@data/20250719dataset_twitter-scraper_2025-07-19_10-04-35-572_csl.json。2.输出的路径`output_dir = "./"`更改为文件夹@data/。3.按时间排序推文之间是`最新在前`，对应的语句为`tweets.sort(key=lambda x: x['issued']['date-parts'][0] if 'issued' in x and 'date-parts' in x['issued'] else [0, 0, 0], reverse=True)`，更改为`最新在后`。

### 02

迭代优化@scripts/twitter2md.py中的`save_yearly_markdown`函数，实现：原来逻辑推文之间用 --- 分割，修改为：推文之间用该元素在数组中的`序号+1`分割

后续我自己又修改成了：推文之间用该元素在数组中的`### 序号+1`分割，继续优化，确保需要始终为 3 位数，比如序号`### 1`优化为`### 001`

### 03

完全参考文件@scripts/word_translate_gemini.py的实现逻辑，在文件@scripts/twitter_translate_gemini.py中实现：1.读取文件`DATA_DIR / "TwitterContentData.json"`，保留原 json 数据结构的基础上新增字段`tranlastedContent`，该字段是翻译 json 数据里的`title`字段内容获得的。2.翻译过程中的结果存在临时性文件`DATA_DIR / "TempTranslatedTwitterContentData.json"`中。3.最后翻译获得的结果存入文件`DATA_DIR / "TranslatedTwitterContentData.json"`。

