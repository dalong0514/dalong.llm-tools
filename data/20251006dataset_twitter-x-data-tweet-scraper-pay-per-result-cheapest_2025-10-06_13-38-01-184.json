[{
  "id": "1780738670452261105",
  "url": "https://x.com/karpathy/status/1780738670452261105",
  "text": "@gwern Issue in mind is not so much human bias but the fact that the full distribution of correct or desirable answers to your prompts is almost certainly not present in your dataset, only a few samples.",
  "createdAt": "Wed Apr 17 23:22:38 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 28,
  "quoteCount": 1,
  "viewCount": 3604,
  "bookmarkCount": 5,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1780730292837507092",
  "url": "https://x.com/karpathy/status/1780730292837507092",
  "text": "Consider being a labeler for an LLM. The prompt is ‚Äúgive me a random number between 1 and 10‚Äù. What SFT &amp; RM labels do you contribute? What does this do the network when trained on?\n\nIn subtle way this problem is present in every prompt that does not have a single unique answer.",
  "createdAt": "Wed Apr 17 22:49:20 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 71,
  "replyCount": 130,
  "likeCount": 1243,
  "quoteCount": 12,
  "viewCount": 231756,
  "bookmarkCount": 271,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1780721198370001209",
  "url": "https://x.com/karpathy/status/1780721198370001209",
  "text": "@syhw \"5 years between Self-Attention Is All You Need and FlashAttention\"\nquite incredible stat, gives a pause",
  "createdAt": "Wed Apr 17 22:13:12 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 3,
  "likeCount": 185,
  "quoteCount": 0,
  "viewCount": 34485,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1780704514288635971",
  "url": "https://x.com/karpathy/status/1780704514288635971",
  "text": "@nitin_nataraj another layer of the onion :) maybe can you model it like having different kinds of coprocessors with different instruction sets / reliability rates",
  "createdAt": "Wed Apr 17 21:06:54 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 3,
  "likeCount": 40,
  "quoteCount": 0,
  "viewCount": 9574,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1780703933394243706",
  "url": "https://x.com/karpathy/status/1780703933394243706",
  "text": "@SteveStricklan6 so... exactly like people",
  "createdAt": "Wed Apr 17 21:04:36 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 3,
  "likeCount": 8,
  "quoteCount": 0,
  "viewCount": 955,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1780703786291663310",
  "url": "https://x.com/karpathy/status/1780703786291663310",
  "text": "@xiaochuandev sorry i just made that word up in my head right now, didn't mean to hijack some existing term. I meant - imagine the computation as a DAG, lay it out in your head, and look for \"narrow\" and \"wide\" parts. Open to alternatives for future use!",
  "createdAt": "Wed Apr 17 21:04:01 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 3,
  "quoteCount": 0,
  "viewCount": 936,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1780692023970038259",
  "url": "https://x.com/karpathy/status/1780692023970038259",
  "text": "The history of computing is repeating in an echo, except replace computers that do precise arithmetic on bytes with computers that do statistical arithmetic on tokens.",
  "createdAt": "Wed Apr 17 20:17:16 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 262,
  "replyCount": 77,
  "likeCount": 2487,
  "quoteCount": 27,
  "viewCount": 240784,
  "bookmarkCount": 457,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1780684098773876941",
  "url": "https://x.com/karpathy/status/1780684098773876941",
  "text": "# scheduling workloads to run on humans\n\nSome computational workloads in human organizations are best \"run on a CPU\": take one single, highly competent person and assign them a task to complete in a single-threaded fashion, without synchronization. Usually the best fit when starting something new. Comparable to \"building the skeleton\" of a thing.\n\nOther workloads are best run on a GPU: take a larger number of (possibly more junior) people and assign tasks in parallel: massively multi-threaded, requiring synchronization overhead. Usually a good fit for later stages of a project, or parts that naturally afford parallelism, comparable to \"fleshing out\" a thing when the skeleton is there.\n\nThere's some middle ground here - sometimes you can imagine a multi-threaded CPU execution of a small team collaborating.\n\nA good manager will understand the computational geometry of the project at hand and know when to delegate parts of it on the CPU or on the GPU. One notable place where the analogy breaks down a bit is that the worst thing that can happen when you misallocate computer resources is that your program will run slower. But in human organizations it can be much worse - not just slower, but the result can be of lower quality overall, more brittle, more disorganized, less consistent, uglier.\n\nThe most common stumbling point here is trying to parallelize something that was supposed to run on the CPU. In the common tongue, this comes from the misunderstanding that something can go faster if you put more people on it, usually leading to outcomes where something is \"designed by a committee\" - not only is the thing actually slower, but the philosophy is inconsistent, the entropy is high, and the long-term outcomes much worse.\n\nThe opposite problem is more rare and usually looks like someone doing something repetitive, uninteresting or tedious, where they could really benefit from more help.\n\nI think this is one accidental advantage of startups - they lack resources of large companies and run compute on powerful CPUs, winning in cases where that is the right thing to do. Larger companies, especially in cases where something is deemed of high strategic importance, will almost always reach for too much parallelism.\n\nTLDR: Think about your project, its computational geometry, its inherent parallelism, and which parts are a best fit for a CPU or a GPU.",
  "createdAt": "Wed Apr 17 19:45:47 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 348,
  "replyCount": 84,
  "likeCount": 2896,
  "quoteCount": 48,
  "viewCount": 334169,
  "bookmarkCount": 1570,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1780673514569396552",
  "url": "https://x.com/karpathy/status/1780673514569396552",
  "text": "üß†: ‚ÄúLet‚Äôs but this (text)book! Nice and now‚Ä¶  instead of reading it‚Ä¶ let‚Äôs buy another one!‚Äù üí°\n\nAll of the dopamine is generated only at the point of resolving to read something. After that there is no juice left üòÖ",
  "createdAt": "Wed Apr 17 19:03:43 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 151,
  "replyCount": 177,
  "likeCount": 3108,
  "quoteCount": 46,
  "viewCount": 385933,
  "bookmarkCount": 389,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1780302978974695426",
  "url": "https://x.com/karpathy/status/1780302978974695426",
  "text": "@untitled01ipynb @BigTechAlert @BasedBeffJezos @omnius_eacc @JeffBezos @baglino not personal btw i unfollow anyone with too many tweets, they take over the timeline",
  "createdAt": "Tue Apr 16 18:31:21 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 7,
  "replyCount": 15,
  "likeCount": 230,
  "quoteCount": 5,
  "viewCount": 33848,
  "bookmarkCount": 12,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1779354343013269929",
  "url": "https://x.com/karpathy/status/1779354343013269929",
  "text": "THE REVENGE OF PYTORCH\njust kidding :)\n\n@cHHillee (from PyTorch team) was kindly able to help improve the PyTorch baseline, done by 1) upgrading to nightly, 2) using the \"compound\" F.sdpa (scaled dot product attention) layer directly, and turning on a torch compile flag:\nTORCHINDUCTOR_COORDINATE_DESCENT_TUNING=1\n\nThe numbers are a bit different because this is a bit different GPU (A100 80GB, with higher memory bandwidth) but:\nllm.c: 23.026892\nPyTorch 2.2: 22.408ms\nPyTorch nightly: 21.090ms\nPyTorch nightly + F.sdpa: 19.224ms\nPyTorch nightly + F.sdpa + coordinate descent tuning torch inductor flag: 18.809ms\n\nso ~20% speedup, see the fork for more details:\nhttps://t.co/LT34GjWq9f\n\nanother nice attached pointer is that torch compile can also generate and emit C++ code:\nhttps://t.co/nQYoc8GTrG",
  "createdAt": "Sun Apr 14 03:41:48 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 45,
  "replyCount": 29,
  "likeCount": 1229,
  "quoteCount": 7,
  "viewCount": 295654,
  "bookmarkCount": 243,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1779272336186978707",
  "url": "https://x.com/karpathy/status/1779272336186978707",
  "text": "Highly amusing update, ~18 hours later:\n\nllm.c is now down to 26.2ms/iteration, exactly matching PyTorch (tf32 forward pass). We discovered a bug where we incorrectly called cuBLAS in fp32 mathmode ü§¶‚Äç‚ôÇÔ∏è. And ademeure contributed a more optimized softmax kernel for very long rows (50,257 elements per row, in the last logits layer).\n\nBut the fun doesn‚Äôt stop because we still have a lot of tricks up the sleeve. Our attention kernel is naive attention, not flash attention, and materializes the (very large) preattention and postattention matrices of sizes (B, NH, T, T), also it makes unnecessary round-trips with yet-unfused GeLU non-linearities and permute/unpermute inside our attention. And we haven‚Äôt reached for more optimizations, e.g. CUDA Graphs, lossless compressible memory (?), etc.\n\nSo the updated chart looks bullish :D, and training LLMs faster than PyTorch with only ~2,000 lines of C code feels within reach. Backward pass let‚Äôs go.",
  "createdAt": "Sat Apr 13 22:15:56 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 546,
  "replyCount": 159,
  "likeCount": 6079,
  "quoteCount": 122,
  "viewCount": 1077511,
  "bookmarkCount": 1274,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1779024269663744091",
  "url": "https://x.com/karpathy/status/1779024269663744091",
  "text": "@IliaKhalizov I have a dev box at @LambdaAPI",
  "createdAt": "Sat Apr 13 05:50:13 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 2,
  "likeCount": 126,
  "quoteCount": 3,
  "viewCount": 26802,
  "bookmarkCount": 58,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1778999251768631522",
  "url": "https://x.com/karpathy/status/1778999251768631522",
  "text": "@youraimarketer wow that‚Äôs a lot of tokens. I think each of those days is a week üòÖ",
  "createdAt": "Sat Apr 13 04:10:48 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 7,
  "likeCount": 472,
  "quoteCount": 1,
  "viewCount": 33069,
  "bookmarkCount": 41,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778996111786848451",
  "url": "https://x.com/karpathy/status/1778996111786848451",
  "text": "@Mahdiaai Apple silicon is a whole different thing but yes it also has a GPU, and the code can also be targeted to it in a similar way, but all of the libraries and details change (Metal instead of CUDA) so it‚Äôs a whole separate effort.",
  "createdAt": "Sat Apr 13 03:58:19 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 6,
  "likeCount": 114,
  "quoteCount": 0,
  "viewCount": 18778,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778988957713477778",
  "url": "https://x.com/karpathy/status/1778988957713477778",
  "text": "A few new CUDA hacker friends joined the effort and now llm.c is only 2X slower than PyTorch (fp32, forward pass) compared to 4 days ago, when it was at 4.2X slower üìà\n\nThe biggest improvements were:\n- turn on TF32 (NVIDIA TensorFLoat-32) instead of FP32 for matmuls. This is a new mathmode in GPUs starting with Ampere+. This is a very nice, ~free optimization that sacrifices a little bit of precision for a large increase in performance, by running the matmuls on tensor cores, while chopping off the mantissa to only 10 bits (the least significant 19 bits of the float get lost). So the inputs, outputs and internal accumulates remain in fp32, but the multiplies are lower precision. Equivalent to PyTorch `torch.set_float32_matmul_precision('high')`\n- call cuBLASLt API instead of cuBLAS for the sGEMM (fp32 matrix multiply), as this allows you to also fuse the bias into the matmul and deletes the need for a separate add_bias kernel, which caused a silly round trip to global memory for one addition.\n- a more efficient attention kernel that uses 1) cooperative_groups reductions that look much cleaner and I only just learned about (they are not covered by the CUDA PMP book...), 2) the online softmax algorithm used in flash attention, 3) fused attention scaling factor multiply, 4) \"built in\" autoregressive mask bounds.\n\n(big thanks to ademeure, ngc92, lancerts on GitHub for writing / helping with these kernels!)\n\nFinally, ChatGPT created this amazing chart to illustrate our progress. 4 days ago we were 4.6X slower, today we are 2X slower. So we are going to beat PyTorch imminently üòÇ\n\nNow (personally) going to focus on the backward pass, so we have the full training loop in CUDA.",
  "createdAt": "Sat Apr 13 03:29:54 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 353,
  "replyCount": 111,
  "likeCount": 4249,
  "quoteCount": 28,
  "viewCount": 1414710,
  "bookmarkCount": 1207,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1778884413537087924",
  "url": "https://x.com/karpathy/status/1778884413537087924",
  "text": "@lifeonmarsspace @Plinz fair criticism of the original idea too.\ni guess the question is whether such functionality can practically and imminently work, without going full magic (/AGI)",
  "createdAt": "Fri Apr 12 20:34:28 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 10,
  "quoteCount": 0,
  "viewCount": 2100,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778883634545766785",
  "url": "https://x.com/karpathy/status/1778883634545766785",
  "text": "Fair :) I love the idea of an LLM as the ultimate compiler. Humans only write something like Python code, but even then it's just the prompt to get the idea across. So it's more like psuedocode and doesn't even have to be valid Python.\n\nActually I already do this once in a while with ChatGPT for smaller code snippets. For example, if I want output in a specific format, I give it a small Python code snippet that shows the desired cartoon data structure and how it should be printed to stdout. This works pretty nicely, and is done for convenience because Python has a higher \"bit rate\" and is more precise, compared to describing things in English.",
  "createdAt": "Fri Apr 12 20:31:23 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 15,
  "replyCount": 11,
  "likeCount": 254,
  "quoteCount": 3,
  "viewCount": 28733,
  "bookmarkCount": 70,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778876244014354655",
  "url": "https://x.com/karpathy/status/1778876244014354655",
  "text": "torch.compile is cool but \nLLM compile: takes your .py repo as string and outputs a brand new, custom, from scratch, minimal code repository directly running your network in highly optimized CUDA",
  "createdAt": "Fri Apr 12 20:02:01 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 106,
  "replyCount": 57,
  "likeCount": 2013,
  "quoteCount": 9,
  "viewCount": 295723,
  "bookmarkCount": 522,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1778841713605525889",
  "url": "https://x.com/karpathy/status/1778841713605525889",
  "text": "This post became popular; Few more thoughts / pointers on the topic for the interested reader.\n\nExample of the complexity involved:\n@cHHillee has a great post \"Making Deep Learning Go Brrrr From First Principles\"\nhttps://t.co/dp7QNY7Gaq\nI was always struck by this diagram from this post. Left to right is time. Look at all these functions stacked up vertically that are dispatched until 30 layers deep you get the actual computation (addition in this example). All of this stuff is PyTorch function overhead. In practical settings this overhead becomes narrow in comparison to the actual computation because the arrays we're adding are so large, but still. What is all this stuff? We're just trying to add numbers.\n\nSecond: startup latency.\nOpen up Python interpreter and try to import the PyTorch library (`import torch`). On my computer this takes about 1.3 seconds. This is just the library import, before you even do anything. In a typical training run you'll end up importing a lot more libraries, so even just starting your training script can often add up to tens of seconds of you just waiting around. A production-grade distributed training run can even add up to minutes. I always found this very frustrating. Computers are *fast* - even a single CPU core (of up to ~dozens on your computer) does billions of operations in one second. What is happening? In llm.c, all this startup latency is ~gone. Right after allocating memory your computer just directly dives into useful computation. I love the feeling of hitting Enter to launch your program, and it just goes. Direct to useful computation on your problem. No waiting.\n\nThird thought: LLM as a compiler.\nIt feels likely to me that as LLMs get much better at coding, a lot more code might be written by them, to target to whatever narrow application and deployment environment you care about. In a world where very custom programs are \"free\", LLMs might end up being a kind of compiler that translates your high level program into an extremely optimized, direct, low-level implementation. Hence my LLM Agent challenge earlier of \"take the GPT-2 PyTorch training script, and output llm.c\", as one concrete example.\n\nLastly I also wanted to mention that I don't mean to attack PyTorch at all, I love the library and I have used it for many years. And I've worked in Python for much longer. These are a lot more general problems and tradeoffs that are really fun to think through - between flexibility, generality, hackability, security, abstractions overhead, code complexity, speed (latency / throughput), etc. The fun and magic of pareto optimal infrastructure, and of programming computers.",
  "createdAt": "Fri Apr 12 17:44:48 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 50,
  "replyCount": 22,
  "likeCount": 769,
  "quoteCount": 2,
  "viewCount": 112560,
  "bookmarkCount": 475,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778826009724465155",
  "url": "https://x.com/karpathy/status/1778826009724465155",
  "text": "@lexandermorgan Reads very interesting! Would love to potentially look at merging into minBPE in some way and link to your work/notebook.",
  "createdAt": "Fri Apr 12 16:42:24 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 1,
  "likeCount": 97,
  "quoteCount": 0,
  "viewCount": 42644,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778575309237104676",
  "url": "https://x.com/karpathy/status/1778575309237104676",
  "text": "@MajmudarAdam GPT-2 etched directly into silicon let‚Äôs go :)",
  "createdAt": "Fri Apr 12 00:06:12 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 12,
  "likeCount": 233,
  "quoteCount": 4,
  "viewCount": 13671,
  "bookmarkCount": 22,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778573326467907874",
  "url": "https://x.com/karpathy/status/1778573326467907874",
  "text": "@MajmudarAdam üëÄ Sounds awesome, @MajmudarAdam I‚Äôd love the 20 hour version of",
  "createdAt": "Thu Apr 11 23:58:19 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 6,
  "likeCount": 278,
  "quoteCount": 0,
  "viewCount": 94108,
  "bookmarkCount": 59,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778190718487634160",
  "url": "https://x.com/karpathy/status/1778190718487634160",
  "text": "@alexgshaw It‚Äôs like insisting to walk when you can take a bike. It gets the hard things wrong but all the easy things right, very helpful and much faster. You have to learn what it can and can‚Äôt do.",
  "createdAt": "Wed Apr 10 22:37:59 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 14,
  "replyCount": 3,
  "likeCount": 380,
  "quoteCount": 5,
  "viewCount": 17069,
  "bookmarkCount": 44,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778160991362294197",
  "url": "https://x.com/karpathy/status/1778160991362294197",
  "text": "@riaz_001 üíØ GPT-2 turns out to be a perfect class project for that book (which I really like and own)",
  "createdAt": "Wed Apr 10 20:39:51 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 12,
  "replyCount": 3,
  "likeCount": 472,
  "quoteCount": 1,
  "viewCount": 40858,
  "bookmarkCount": 97,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778153659106533806",
  "url": "https://x.com/karpathy/status/1778153659106533806",
  "text": "# explaining llm.c in layman terms\n\nTraining Large Language Models (LLMs), like ChatGPT, involves a large amount of code and complexity.\n\nFor example, a typical LLM training project might use the PyTorch deep learning library. PyTorch is quite complex because it implements a very general Tensor abstraction (a way to arrange and manipulate arrays of numbers that hold the parameters and activations of the neural network), a very general Autograd engine for backpropagation (the algorithm that trains the neural network parameters), and a large collection of deep learning layers you may wish to use in your neural network. The PyTorch project is 3,327,184 lines of code in 11,449 files.\n\nOn top of that, PyTorch is written in Python, which is itself a very high-level language. You have to run the Python interpreter to translate your training code into low-level computer instructions. For example the cPython project that does this translation is 2,437,955 lines of code across 4,306 files.\n\nI am deleting all of this complexity and boiling the LLM training down to its bare essentials, speaking directly to the computer in a very low-level language (C), and with no other library dependencies. The only abstraction below this is the assembly code itself. I think people find it surprising that, by comparison to the above, training an LLM like GPT-2 is actually only a ~1000 lines of code in C in a single file. I am achieving this compression by implementing the neural network training algorithm for GPT-2 directly in C. This is difficult because you have to understand the training algorithm in detail, be able to derive all the forward and backward pass of backpropagation for all the layers, and implement all the array indexing calculations very carefully because you don‚Äôt have the PyTorch tensor abstraction available. So it‚Äôs a very brittle thing to arrange, but once you do, and you verify the correctness by checking agains PyTorch, you‚Äôre left with something very simple, small and imo quite beautiful.\n\nOkay so why don‚Äôt people do this all the time?\n\nNumber 1: you are giving up a large amount of flexibility. If you want to change your neural network around, in PyTorch you‚Äôd be changing maybe one line of code. In llm.c, the change would most likely touch a lot more code, may be a lot more difficult, and require more expertise. E.g. if it‚Äôs a new operation, you may have to do some calculus, and write both its forward pass and backward pass for backpropagation, and make sure it is mathematically correct.\n\nNumber 2: you are giving up speed, at least initially. There is no fully free lunch - you shouldn‚Äôt expect state of the art speed in just 1,000 lines. PyTorch does a lot of work in the background to make sure that the neural network is very efficient. Not only do all the Tensor operations very carefully call the most efficient CUDA kernels, but also there is for example torch.compile, which further analyzes and optimizes your neural network and how it could run on your computer most efficiently. Now, in principle, llm.c should be able to call all the same kernels and do it directly. But this requires some more work and attention, and just like in (1), if you change anything about your neural network or the computer you‚Äôre running on, you may have to call different kernels, with different parameters, and you may have to make more changes manually.\n\nSo TLDR: llm.c is a direct implementation of training GPT-2. This implementation turns out to be surprisingly short. No other neural network is supported, only GPT-2, and if you want to change anything about the network, it requires expertise. Luckily, all state of the art LLMs are actually not a very large departure from GPT-2 at all, so this is not as strong of a constraint as you might think. And llm.c has to be additionally tuned and refined, but in principle I think it should be able to almost match (or even outperform, because we get rid of all the overhead?) PyTorch, with not too much more code than where it is today, for most modern LLMs.\n\nAnd why I am working on it? Because it‚Äôs fun. It‚Äôs also educational, because those 1,000 lines of very simple C are all that is needed, nothing else. It's just a few arrays of numbers and some simple math operations over their elements like + and *. And it might even turn out to be practically useful with some more work that is ongoing.",
  "createdAt": "Wed Apr 10 20:10:43 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1224,
  "replyCount": 404,
  "likeCount": 9695,
  "quoteCount": 229,
  "viewCount": 1795942,
  "bookmarkCount": 5733,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1778135672420966788",
  "url": "https://x.com/karpathy/status/1778135672420966788",
  "text": "@tim_zaman Got it, I think I understand. I'd have to try it out. I'm a bit scared of going down that path, inevitably in larger projects when you look at the code the ifdef switches are out of control and you can't even tell what the actual code is.",
  "createdAt": "Wed Apr 10 18:59:15 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 12,
  "likeCount": 262,
  "quoteCount": 0,
  "viewCount": 36548,
  "bookmarkCount": 16,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1778128793166856368",
  "url": "https://x.com/karpathy/status/1778128793166856368",
  "text": "Okay I did a first quick pass of naive CUDA kernels for the forward pass of GPT-2 and pushed everything to one file in llm.c, Still only ~1000 lines of code:\nhttps://t.co/39G8UWusVp\n\nCurrent per iteration timings on my Lambda box <3 A100 40GB PCIe, B=4, T=1024:\n- llm.c: 111ms\n- PyTorch: 180ms\n- +torch.compile: 86ms\n- +fp32 tensor cores: 26ms\n\nSo there is a gap to close! Come hack, make fast :)",
  "createdAt": "Wed Apr 10 18:31:54 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 321,
  "replyCount": 74,
  "likeCount": 3736,
  "quoteCount": 31,
  "viewCount": 414863,
  "bookmarkCount": 1212,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1777802148283338883",
  "url": "https://x.com/karpathy/status/1777802148283338883",
  "text": "@nullpear @krishnanrohit haha i need a safe space for throwaway thoughts that shouldn't be seen by ~1M people",
  "createdAt": "Tue Apr 09 20:53:56 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 8,
  "likeCount": 127,
  "quoteCount": 1,
  "viewCount": 4010,
  "bookmarkCount": 8,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777676823490613414",
  "url": "https://x.com/karpathy/status/1777676823490613414",
  "text": "@conoro great to hear! :) it just has to run out of the box... it's a bunch of float* with a few +-*/ on top",
  "createdAt": "Tue Apr 09 12:35:57 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 5,
  "likeCount": 119,
  "quoteCount": 0,
  "viewCount": 45019,
  "bookmarkCount": 13,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777567836946457028",
  "url": "https://x.com/karpathy/status/1777567836946457028",
  "text": "@artificialguybr @jeremyphoward Small models are super useful for unit tests, tiny applications",
  "createdAt": "Tue Apr 09 05:22:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 16,
  "likeCount": 298,
  "quoteCount": 1,
  "viewCount": 33774,
  "bookmarkCount": 15,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777567568532046060",
  "url": "https://x.com/karpathy/status/1777567568532046060",
  "text": "@artificialguybr @jeremyphoward How small? \nProbably not small enough ü•∫\n100M and 1B models ü§û",
  "createdAt": "Tue Apr 09 05:21:48 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 16,
  "likeCount": 278,
  "quoteCount": 1,
  "viewCount": 39637,
  "bookmarkCount": 13,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777499694685650985",
  "url": "https://x.com/karpathy/status/1777499694685650985",
  "text": "@swyx my biggest concern is that an LLM Agent can solve it in 1-2 years but by then related forks and code and discussions seep into its training data in an undefined way, making the result unsatisfying.",
  "createdAt": "Tue Apr 09 00:52:06 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 7,
  "likeCount": 228,
  "quoteCount": 1,
  "viewCount": 22917,
  "bookmarkCount": 13,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777498262276325614",
  "url": "https://x.com/karpathy/status/1777498262276325614",
  "text": "@swyx that would be pretty depressing. it took me some time and it was hard, haha",
  "createdAt": "Tue Apr 09 00:46:24 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 7,
  "replyCount": 2,
  "likeCount": 536,
  "quoteCount": 3,
  "viewCount": 41284,
  "bookmarkCount": 24,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777493157485437009",
  "url": "https://x.com/karpathy/status/1777493157485437009",
  "text": "Btw writing the llm.c training code would imo be a very interesting, impressive, self-contained and very meta challenge for LLM agents. The prompt is:\n\nTake the PyTorch code train_gpt2.py\nAnd write, compile and unit test a single .c file that reproduces the training: train_gpt2.c\n\nThe current models are not there, but we can check back in a year or two or so. If that worked...",
  "createdAt": "Tue Apr 09 00:26:07 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 164,
  "replyCount": 72,
  "likeCount": 2912,
  "quoteCount": 17,
  "viewCount": 464336,
  "bookmarkCount": 953,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1777484298544922829",
  "url": "https://x.com/karpathy/status/1777484298544922829",
  "text": "@ashley_prepulp thanks Ahsley, we all really appreciate it.",
  "createdAt": "Mon Apr 08 23:50:55 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 11,
  "replyCount": 16,
  "likeCount": 368,
  "quoteCount": 5,
  "viewCount": 12300,
  "bookmarkCount": 12,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777481372636246491",
  "url": "https://x.com/karpathy/status/1777481372636246491",
  "text": "I added a quick crappy tutorial on how PyTorch layers are moved to C, with a few possibly helpful pointers:\nhttps://t.co/SOrp7j1uCj",
  "createdAt": "Mon Apr 08 23:39:17 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 237,
  "replyCount": 45,
  "likeCount": 2567,
  "quoteCount": 10,
  "viewCount": 285532,
  "bookmarkCount": 1216,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1777454811333677321",
  "url": "https://x.com/karpathy/status/1777454811333677321",
  "text": "@srush_nlp :D :D I really do love how llama2.c was translated to a zillion languages I've never heard about. Looking forward to that with the training too! The design space is a lot wider too because you can train stuff, not just inference a fixed, given thing.",
  "createdAt": "Mon Apr 08 21:53:45 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 7,
  "likeCount": 216,
  "quoteCount": 1,
  "viewCount": 35628,
  "bookmarkCount": 31,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777439972439793806",
  "url": "https://x.com/karpathy/status/1777439972439793806",
  "text": "@Tristi42 I am curious to learn more Rust and totally understand the appeal.\nBut I still find C so nice, simple, clean, portable and beautiful, aesthetically. It's as close as you want to get to direct communion with the machine.",
  "createdAt": "Mon Apr 08 20:54:47 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 52,
  "replyCount": 25,
  "likeCount": 1171,
  "quoteCount": 27,
  "viewCount": 136723,
  "bookmarkCount": 118,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1777427952881541524",
  "url": "https://x.com/karpathy/status/1777427952881541524",
  "text": "Once you have the forward/backward, the rest of it (data loader, Adam update, etc) are mostly trivial.\n\nThe real fun starts now though: I am now porting this to CUDA layer by layer so that it can be made efficient, perhaps even coming within reasonable fraction of PyTorch, but with none of the heavy dependencies. I'm a few layers in already and it's quite a fun CUDA exercise.\n\nFrom there, extensions include lowering the precision from fp32 to fp16/below, and a few more layers (e.g. RoPE) to support more modern architectures like llama 2 / mistral / gemma / etc.\n\nAnd once this is a in a bit more stable state: videos on building this in more detail and from scratch.",
  "createdAt": "Mon Apr 08 20:07:01 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 42,
  "replyCount": 50,
  "likeCount": 1046,
  "quoteCount": 11,
  "viewCount": 156731,
  "bookmarkCount": 129,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777427950021026006",
  "url": "https://x.com/karpathy/status/1777427950021026006",
  "text": "Once you have all the layers, you just string all it all together. Not gonna lie, this was quite tedious and masochistic to write because you have to make sure all the pointers and tensor offsets are correctly arranged.\n\nLeft: we allocate a single 1D array of memory and then point all the model weights and activations to it.\nRight: we do all the pointer arithmetic very very carefully üòÖ",
  "createdAt": "Mon Apr 08 20:07:00 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 25,
  "replyCount": 10,
  "likeCount": 707,
  "quoteCount": 4,
  "viewCount": 127646,
  "bookmarkCount": 72,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777427947126936026",
  "url": "https://x.com/karpathy/status/1777427947126936026",
  "text": "You can look at the raw training implementation here:\nhttps://t.co/gDrAqix4Iv\n\nYou'll see that we allocate all the required memory a single time in the beginning in one large block of 1D memory. From there on during training, no memory gets created or destroyed, so we stay at constant memory footprint and its just dynamics, streaming the data batches through.\n\nThe crux of it is manually implementing the forward and backward pass of all the individual layers, and then stringing them together. For example here is layernorm forward and backward pass.\n\nIn addition to layernorm we need the encoder, matmul, self-attention, gelu, residual, softmax and cross-entropy loss.",
  "createdAt": "Mon Apr 08 20:07:00 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 34,
  "replyCount": 13,
  "likeCount": 784,
  "quoteCount": 2,
  "viewCount": 93462,
  "bookmarkCount": 142,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1777427944971083809",
  "url": "https://x.com/karpathy/status/1777427944971083809",
  "text": "Have you ever wanted to train LLMs in pure C without 245MB of PyTorch and 107MB of cPython? No? Well now you can! With llm.c:\nhttps://t.co/PoGTZIwASL\n\nTo start, implements GPT-2 training on CPU/fp32 in only ~1,000 lines of clean code. It compiles and runs instantly, and exactly matches the PyTorch reference implementation.\n\nI chose GPT-2 to start because it is the grand-daddy of LLMs, the first time the LLM stack was put together in a recognizably modern form, and with model weights available.",
  "createdAt": "Mon Apr 08 20:06:59 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1831,
  "replyCount": 291,
  "likeCount": 12708,
  "quoteCount": 329,
  "viewCount": 1654916,
  "bookmarkCount": 6757,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1776980978361381268",
  "url": "https://x.com/karpathy/status/1776980978361381268",
  "text": "@GrantSlatton Same, I want to buy a home just so I can put solar panels on it lol",
  "createdAt": "Sun Apr 07 14:30:54 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 7,
  "replyCount": 29,
  "likeCount": 522,
  "quoteCount": 3,
  "viewCount": 63140,
  "bookmarkCount": 13,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1776275103086694556",
  "url": "https://x.com/karpathy/status/1776275103086694556",
  "text": "@DannyMcAteer8 I was in Bhutan and, unsurprisingly, there was a lot of meditating. An excellent place for that, and really loved the place/people/culture there.",
  "createdAt": "Fri Apr 05 15:46:00 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 16,
  "replyCount": 30,
  "likeCount": 912,
  "quoteCount": 5,
  "viewCount": 75095,
  "bookmarkCount": 44,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1776269310631235806",
  "url": "https://x.com/karpathy/status/1776269310631235806",
  "text": "Returning from an experimental ~2 week detox from the internet. Main takeaway is that I didn't realize how unsettled the mind can get when over-stimulating on problems/information (like a stirred liquid), and ~2 weeks is enough to settle into a lot more zen state.\n\nI'm struck by how an over-stimulated brain automatically keeps bubbling up problems into consciousness, creating a state of persistent anxiety and nervousness. After some time, in the settled state, this activity just... stops. You can sit down and your brain doesn't immediately go into some kind of problem solving overdrive, it just stays silent. Nothing happens.\n\nI'm sure this could read a bit duh to many, but I haven't been to this subset of \"brain dynamics\" state space in I think a very long time and it is comforting to know that 1) it exists, and 2) you can visit, if you like, but the journey there takes a few weeks.\n\nAnyway, where were we :D",
  "createdAt": "Fri Apr 05 15:22:59 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 861,
  "replyCount": 500,
  "likeCount": 11965,
  "quoteCount": 162,
  "viewCount": 1118390,
  "bookmarkCount": 3012,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1773117863231914337",
  "url": "https://x.com/karpathy/status/1773117863231914337",
  "text": "Thank you @stephzhan for the chat and @sequoia for hosting, pleasure to come by!",
  "createdAt": "Wed Mar 27 22:40:16 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 163,
  "replyCount": 61,
  "likeCount": 1790,
  "quoteCount": 18,
  "viewCount": 319943,
  "bookmarkCount": 534,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1771020217789145546",
  "url": "https://x.com/karpathy/status/1771020217789145546",
  "text": "@XirtamEsrevni @astralmatrix Yeah that‚Äôs my default Terminal on my new MacBook now. So far great upgrade. A lot of what makes VS Code so great, and AI native.\nVery eager to upgrade a lot of tools. AI unlocked a ton of potential but no one wants to copy paste things around. You fall back on it if you have to",
  "createdAt": "Fri Mar 22 03:44:58 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 12,
  "likeCount": 113,
  "quoteCount": 3,
  "viewCount": 23836,
  "bookmarkCount": 58,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1771017496302350555",
  "url": "https://x.com/karpathy/status/1771017496302350555",
  "text": "@mckaywrigley @astralmatrix Very interesting, will have to try! Seems like the perfect fit as a very latency sensitive, very high value application.\nCurrently (and awkwardly) half of my open code windows are VS Code and half are Cursor, still evaluating.",
  "createdAt": "Fri Mar 22 03:34:09 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 13,
  "likeCount": 151,
  "quoteCount": 1,
  "viewCount": 25350,
  "bookmarkCount": 38,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1771009415195582546",
  "url": "https://x.com/karpathy/status/1771009415195582546",
  "text": "@astralmatrix I might be switching to Cursor fwiw",
  "createdAt": "Fri Mar 22 03:02:03 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 64,
  "replyCount": 58,
  "likeCount": 1195,
  "quoteCount": 27,
  "viewCount": 325951,
  "bookmarkCount": 306,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1770174789262422045",
  "url": "https://x.com/karpathy/status/1770174789262422045",
  "text": "@rmarcilhoo @__tinygrad__ @realGeorgeHotz @GregoryDiamos So I‚Äôve heard too, not sure.\n(fwiw I‚Äôd be inclined to focus on the Transformer and ignore ResNets, too)",
  "createdAt": "Tue Mar 19 19:45:32 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 48,
  "quoteCount": 0,
  "viewCount": 5938,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1770166673066058195",
  "url": "https://x.com/karpathy/status/1770166673066058195",
  "text": "@hiberfile_sys @__tinygrad__ @realGeorgeHotz legitimately some bangers in there!",
  "createdAt": "Tue Mar 19 19:13:17 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 166,
  "quoteCount": 1,
  "viewCount": 20713,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1770164518758633590",
  "url": "https://x.com/karpathy/status/1770164518758633590",
  "text": "Follow along the @__tinygrad__  saga, who are (very publicly!) trying to build your commodity ~petaflop compute node.\n\ntinybox specs: https://t.co/6kh99oRBkk\nthe youtube videos form @realGeorgeHotz are actually quite great and entertaining, featuring the signature blend of technology and philosophy and ???: https://t.co/qe0lBPpRxR\n\nif you dig deep enough you'll also find excellent rap.",
  "createdAt": "Tue Mar 19 19:04:43 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 221,
  "replyCount": 88,
  "likeCount": 3221,
  "quoteCount": 9,
  "viewCount": 434045,
  "bookmarkCount": 736,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1769888375748862373",
  "url": "https://x.com/karpathy/status/1769888375748862373",
  "text": "@natfriedman Oh I see! It‚Äôs a vibe check",
  "createdAt": "Tue Mar 19 00:47:26 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 7,
  "likeCount": 53,
  "quoteCount": 0,
  "viewCount": 14199,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1769767792444866958",
  "url": "https://x.com/karpathy/status/1769767792444866958",
  "text": "The def I'm familiar with is:\n\nAGI = \"an autonomous system that surpasses human in most economically valuable tasks.\"\n\nFor \"economically valuable tasks\" I like to look at the U.S. Bureau of Labor Statistics index of occupations:\nhttps://t.co/tGVU57v7WG\n\nYou'd have to imagine preferring to hire GPT-4 for most of these over a human. By this definition it's such a definitive no that it's a strange/funny question. But maybe some weaker definitions can be introduced, e.g. restricting to only digital work, or somehow assuming a lot of \"programming\" work involved.",
  "createdAt": "Mon Mar 18 16:48:17 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 46,
  "replyCount": 37,
  "likeCount": 576,
  "quoteCount": 11,
  "viewCount": 78748,
  "bookmarkCount": 195,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1769419393581384066",
  "url": "https://x.com/karpathy/status/1769419393581384066",
  "text": "@ILikeE17 @justindross I‚Äôm trying to download it right now. No wifi at home is always the struggle",
  "createdAt": "Sun Mar 17 17:43:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 39,
  "likeCount": 269,
  "quoteCount": 10,
  "viewCount": 29024,
  "bookmarkCount": 10,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1769410486360231970",
  "url": "https://x.com/karpathy/status/1769410486360231970",
  "text": "@justindross Most people don‚Äôt HODL and govt takes half. So it‚Äôs usually less dramatic :) we had a very few true believers at Tesla who took all options over ~decade and never sold, those people could be on yacht but I‚Äôm pretty sure they‚Äôre still grinding on FSD :)",
  "createdAt": "Sun Mar 17 17:08:28 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 118,
  "replyCount": 74,
  "likeCount": 3341,
  "quoteCount": 22,
  "viewCount": 187457,
  "bookmarkCount": 196,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1767616494752731633",
  "url": "https://x.com/karpathy/status/1767616494752731633",
  "text": "+1 to the best AI newsletter atm that I enjoy skimming, great/ambitious work by @swyx &amp; friends:\n\nhttps://t.co/60ial0bf3N\n\n\"Skimming\" because they are very long. Not sure how it is built, sounds like there is a lot of LLM aid going on indexing ~356 Twitters, ~21 Discords, etc.",
  "createdAt": "Tue Mar 12 18:19:47 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 207,
  "replyCount": 80,
  "likeCount": 1985,
  "quoteCount": 13,
  "viewCount": 157,
  "bookmarkCount": 1685,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1767603271894798490",
  "url": "https://x.com/karpathy/status/1767603271894798490",
  "text": "@alexinch_ai It's a very amusing thought for sure! Big advantage to languages that have more training data, in both programming (Python / C), and in spoken language (English) :)\nI'm cautiously optimistic though. Either by dumping docs into contexts, or via synthetic data means.",
  "createdAt": "Tue Mar 12 17:27:15 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 9,
  "replyCount": 22,
  "likeCount": 339,
  "quoteCount": 0,
  "viewCount": 45636,
  "bookmarkCount": 28,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1767600971205714044",
  "url": "https://x.com/karpathy/status/1767600971205714044",
  "text": "@MasoudMaani Actually I am very sympathetic to this. Back to my example of self-driving, my first demo drive in an early Waymo was 2014, and it was already great. It took me around for a 20min drive. From that ~perfect demo it was one decade before I could pay for a drive in a Waymo.",
  "createdAt": "Tue Mar 12 17:18:06 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 19,
  "replyCount": 16,
  "likeCount": 812,
  "quoteCount": 8,
  "viewCount": 67569,
  "bookmarkCount": 50,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1767598414945292695",
  "url": "https://x.com/karpathy/status/1767598414945292695",
  "text": "# automating software engineering\n\nIn my mind, automating software engineering will look similar to automating driving. E.g. in self-driving the progression of increasing autonomy and higher abstraction looks something like:\n\n1. first the human performs all driving actions manually\n2. then the AI helps keep the lane\n3. then it slows for the car ahead\n4. then it also does lane changes and takes forks\n5. then it also stops at signs/lights and takes turns\n6. eventually you take a feature complete solution and grind on the quality until you achieve full self-driving.\n\nThere is a progression of the AI doing more and the human doing less, but still providing oversight. In Software engineering, the progression is shaping up similar:\n\n1. first the human writes the code manually\n2. then GitHub Copilot autocompletes a few lines\n3. then ChatGPT writes chunks of code\n4. then you move to larger and larger code diffs (e.g. Cursor copilot++ style, nice demo here https://t.co/u8ueY0mGxZ)\n5....\nDevin is an impressive demo of what perhaps follows next: coordinating a number of tools that a developer needs to string together to write code: a Terminal, a Browser, a Code editor, etc., and human oversight that moves to increasingly higher level of abstraction.\n\nThere is a lot of work not just on the AI part but also the UI/UX part. How does a human provide oversight?  What are they looking at? How do they nudge the AI down a different path? How do they debug what went wrong? It is very likely that we will have to change up the code editor, substantially.\n\nIn any case, software engineering is on track to change substantially. And it will look a lot more like supervising the automation, while pitching in high-level commands, ideas or progression strategies, in English.\n\nGood luck to the team!",
  "createdAt": "Tue Mar 12 17:07:57 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1808,
  "replyCount": 365,
  "likeCount": 10924,
  "quoteCount": 283,
  "viewCount": 2070938,
  "bookmarkCount": 5665,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1766541375842009185",
  "url": "https://x.com/karpathy/status/1766541375842009185",
  "text": "(btw ‚Äúuntrusted‚Äù and ‚Äúattacker-controlled‚Äù are technical terms in computer security)",
  "createdAt": "Sat Mar 09 19:07:39 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 19,
  "replyCount": 31,
  "likeCount": 739,
  "quoteCount": 6,
  "viewCount": 143575,
  "bookmarkCount": 47,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1766520128135741798",
  "url": "https://x.com/karpathy/status/1766520128135741798",
  "text": "@matnesis Cool Grok feature idea",
  "createdAt": "Sat Mar 09 17:43:13 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 15,
  "likeCount": 232,
  "quoteCount": 0,
  "viewCount": 23466,
  "bookmarkCount": 5,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1766518359569621340",
  "url": "https://x.com/karpathy/status/1766518359569621340",
  "text": "@danielgross The white matter",
  "createdAt": "Sat Mar 09 17:36:11 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 95,
  "quoteCount": 1,
  "viewCount": 24066,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1766514340817997985",
  "url": "https://x.com/karpathy/status/1766514340817997985",
  "text": "@yoavgo I was thinking personal antivirus you can take it wherever you want though!",
  "createdAt": "Sat Mar 09 17:20:13 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 24,
  "likeCount": 209,
  "quoteCount": 0,
  "viewCount": 35848,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1766509149297189274",
  "url": "https://x.com/karpathy/status/1766509149297189274",
  "text": "Reading a tweet is a bit like downloading an (attacker-controlled) executable that you instantly run on your brain. Each one elicits emotions, suggests knowledge, nudges world-view.\n\nIn the future it might feel surprising that we allowed direct, untrusted information to brain.",
  "createdAt": "Sat Mar 09 16:59:36 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1361,
  "replyCount": 741,
  "likeCount": 10214,
  "quoteCount": 546,
  "viewCount": 1640652,
  "bookmarkCount": 2239,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1765473722985771335",
  "url": "https://x.com/karpathy/status/1765473722985771335",
  "text": "Beautiful work / attention to detail trying to get Gemma to finetune correctly. There are so many foot guns here to be super careful with. All of these issues don't throw any errors, they silently make your network worse.\n\nA great example of what I wrote about in my \"A Recipe for Training Neural Networks\":\n\"\"\"The \"fast and furious\" approach to training neural networks does not work and only leads to suffering. Now, suffering is a perfectly natural part of getting a neural network to work well, but it can be mitigated by being thorough, defensive, paranoid, and obsessed with visualizations of basically every possible thing. The qualities that in my experience correlate most strongly to success in deep learning are patience and attention to detail.\"\"\"\n\nAnd why I so emphasize the need for understanding all the parts of the deep learning stack in great detail. I exist in a perpetually terrified state of the remaining 20 silent bugs that certainly remain in my code.",
  "createdAt": "Wed Mar 06 20:25:11 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 297,
  "replyCount": 82,
  "likeCount": 2601,
  "quoteCount": 18,
  "viewCount": 517026,
  "bookmarkCount": 1621,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1765424847705047247",
  "url": "https://x.com/karpathy/status/1765424847705047247",
  "text": "Nice read on the rarely-discussed-in-the-open difficulties of training LLMs. Mature companies have dedicated teams maintaining the clusters. At scale, clusters leave the realm of engineering and become a lot more biological, hence e.g. teams dedicated to \"hardware health\".\n\nIt can be a frustrating daily life experience of training large models to \"babysit\" the training run. You're there carefully monitoring the vital signs of your run: loss spikes, numerical issues, throughput, gradient norms, policy entropy, etc. Every time the run degrades or flatlines (can happen often), you quickly look for the stack trace to see what's up. You have to do this fast or 10,000 GPUs could be idling. Often, it is a new, exotic, scary-looking error you've never seen before so you summon help to see if anyone can see what's up. The worst ones like to occur at 4am. Often no one can, so you just ban some nodes that look a bit sketchy and try to restart the run. Sometimes the run goes down just because you have not earned the favors of your gods that day, so you put a while True: loop around your launch command. The underlying issues can be highly diverse, from some GPUs just getting a bit too hot and suddenly doing incorrect multiplication once in a while, to some router going down and decreasing the networked file system I/O, to someone in the datacenter physically disconnecting a wire as part of an un-communicated maintenance. Sometimes you'll never know.\n\nAnother necessary related citation here is the famous OPT-175B logbook and I'd hope more like it can see the light of day in the future. (see chronicles/OPT175B_Logbook.pdf in the git repo)\nhttps://t.co/6xOHVtj0Gf\n\nTLDR LLM training runs are significant stress-tests of an overall fault tolerance of a large computing system acting as a biological entity. And when you're shopping around for your compute, think about a lot more than just FLOPs and $. Think about the whole service from hardware to software across storage, networking, and compute. And think about whether the team maintaining it looks like The Avengers and whether you could become best friends.",
  "createdAt": "Wed Mar 06 17:10:58 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 490,
  "replyCount": 104,
  "likeCount": 4130,
  "quoteCount": 63,
  "viewCount": 129,
  "bookmarkCount": 3376,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1764892914260516944",
  "url": "https://x.com/karpathy/status/1764892914260516944",
  "text": "@JiaweiLiu_ @AnthropicAI Ty for rerunning! Curious btw they cite 84.9 in the release, why is it 82.9 here under ‚ÄúOriginal‚Äù? Maybe you know more about the subtleties here",
  "createdAt": "Tue Mar 05 05:57:15 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 38,
  "quoteCount": 0,
  "viewCount": 25915,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1764743922323165482",
  "url": "https://x.com/karpathy/status/1764743922323165482",
  "text": "@JiaweiLiu_ Would be interesting to see this updated with the latest models from all orgs",
  "createdAt": "Mon Mar 04 20:05:13 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 73,
  "quoteCount": 2,
  "viewCount": 88181,
  "bookmarkCount": 11,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1764731169109872952",
  "url": "https://x.com/karpathy/status/1764731169109872952",
  "text": "Claude 3 takes on the Tokenization book chapter challenge :) context: https://t.co/h1IH5cuPIh\n\nDefinitely looks quite nice, stylistically! \n\nIf you look closer there are a number of subtle issues / hallucinations. One example there is a claim that \"hello world\" tokenizes into 3 tokens \"hello\" (token 31373), \" \" space (token 318), and \"world\" (token 984). Which is actually a pretty bad mistake because the unintuitive crux of the issue here is that whitespaces are prefixes in GPT tokens, so it should be \"hello\" and \" world\" (note space in front). Understanding this detail and its ramifications is important e.g. later leading to the \"trailing whitespace\" error message, to unstable tokens, to the need/desire for a \"add_dummy_prefix\" setting in sentencepiece, etc.\n\nAnyway, it's still really impressive that this close to works almost off the shelf!\n\nI'm looking forward to playing with Claude 3 more, it looks like a strong model. If there is anything related that I have to get off my chest it's that people should be *extremely* careful with evaluation comparisons, not only because the evals themselves are worse than you think, but also because many of them are getting overfit in undefined ways, and also because the comparisons made are frankly misleading. GPT-4 is not 67% on coding (HumanEval). Whenever I see this comparison made to stand in for coding performance, the corner of my eye starts twitching.",
  "createdAt": "Mon Mar 04 19:14:32 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 428,
  "replyCount": 118,
  "likeCount": 3814,
  "quoteCount": 46,
  "viewCount": 725589,
  "bookmarkCount": 1581,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1763667178497392844",
  "url": "https://x.com/karpathy/status/1763667178497392844",
  "text": "@MisbahSy @hwchase17 @LangChainAI cool! visually the nicest attempt i've seen so far",
  "createdAt": "Fri Mar 01 20:46:37 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 8,
  "replyCount": 2,
  "likeCount": 146,
  "quoteCount": 0,
  "viewCount": 30022,
  "bookmarkCount": 30,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1763328060089409804",
  "url": "https://x.com/karpathy/status/1763328060089409804",
  "text": "@Reza_Zadeh Same. I really liked the immersive videos and could see myself coming back for those regularly but there are only 4. Feels like a dev kit right now. But I'll come back once in a while to see what's new.",
  "createdAt": "Thu Feb 29 22:19:05 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 5,
  "likeCount": 17,
  "quoteCount": 0,
  "viewCount": 4148,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1763303767292940684",
  "url": "https://x.com/karpathy/status/1763303767292940684",
  "text": "@justindross I‚Äôd love to understand this better too‚Ä¶ I thought it was just a quirk of the specifics of labeling instructions, but then multiple (what I think should be mostly independent) language models seem to all do this.",
  "createdAt": "Thu Feb 29 20:42:33 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 12,
  "replyCount": 64,
  "likeCount": 647,
  "quoteCount": 6,
  "viewCount": 112222,
  "bookmarkCount": 73,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762648404029759758",
  "url": "https://x.com/karpathy/status/1762648404029759758",
  "text": "I usually just go down the list of a few posts and cheery-pick, e.g.:\nhttps://t.co/2PqHMDRLz7\nhttps://t.co/u1xrhfgQzq\nhttps://t.co/0APzMi8czG\nfor this round I think the major deviation is that I'm going to give @warpdotdev a shot as my Terminal. It looks nice only they are sketching me out a bit with their telemetry, and for some reason needing a login and a connection to the internet.",
  "createdAt": "Wed Feb 28 01:18:22 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 25,
  "replyCount": 20,
  "likeCount": 492,
  "quoteCount": 7,
  "viewCount": 80235,
  "bookmarkCount": 1537,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762638388283560070",
  "url": "https://x.com/karpathy/status/1762638388283560070",
  "text": "@vgoklani_ai Aesthetics. I want it to be just the two of us in a Faraday cage. Otherwise you might as well ssh into something a lot more powerful.",
  "createdAt": "Wed Feb 28 00:38:34 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 8,
  "likeCount": 399,
  "quoteCount": 2,
  "viewCount": 39,
  "bookmarkCount": 21,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762623463641256339",
  "url": "https://x.com/karpathy/status/1762623463641256339",
  "text": "@arielrivera I think it was like $6K üò¨. But I need it.",
  "createdAt": "Tue Feb 27 23:39:16 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 11,
  "likeCount": 170,
  "quoteCount": 0,
  "viewCount": 19901,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762622820885115173",
  "url": "https://x.com/karpathy/status/1762622820885115173",
  "text": "@simulore I know, I know, but I can't carry it around :'(",
  "createdAt": "Tue Feb 27 23:36:43 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 4,
  "quoteCount": 0,
  "viewCount": 1543,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762622600621310426",
  "url": "https://x.com/karpathy/status/1762622600621310426",
  "text": "@CJKRaymond LOL exactly\nNo this time, at last, I am ready.",
  "createdAt": "Tue Feb 27 23:35:50 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 15,
  "likeCount": 421,
  "quoteCount": 0,
  "viewCount": 36181,
  "bookmarkCount": 8,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762621775253487995",
  "url": "https://x.com/karpathy/status/1762621775253487995",
  "text": "@awnihannun oh it's coming ;)",
  "createdAt": "Tue Feb 27 23:32:33 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 12,
  "likeCount": 426,
  "quoteCount": 3,
  "viewCount": 49816,
  "bookmarkCount": 16,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1762621031121145996",
  "url": "https://x.com/karpathy/status/1762621031121145996",
  "text": "Setting up my shiny new fully maxed out Space Black MacBook Pro M3 Max 128GB 16-inch (upgrading from an M1 Air). I always like to set up the new one with a clean slate, from scratch - this time I will not allow my dev configuration to get out of hand. Then we'll talk to it.",
  "createdAt": "Tue Feb 27 23:29:36 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 134,
  "replyCount": 355,
  "likeCount": 5647,
  "quoteCount": 50,
  "viewCount": 595295,
  "bookmarkCount": 829,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1761955353577898428",
  "url": "https://x.com/karpathy/status/1761955353577898428",
  "text": "@AravSrinivas Bonus points: make it never say ‚Äúit is important to‚Äù",
  "createdAt": "Mon Feb 26 03:24:26 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 10,
  "likeCount": 389,
  "quoteCount": 0,
  "viewCount": 54230,
  "bookmarkCount": 16,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1761547357370622175",
  "url": "https://x.com/karpathy/status/1761547357370622175",
  "text": "@Altimor Haha \"Llama 270B\". We have work to do :)",
  "createdAt": "Sun Feb 25 00:23:12 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 4,
  "likeCount": 152,
  "quoteCount": 1,
  "viewCount": 37858,
  "bookmarkCount": 23,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1761469961225310690",
  "url": "https://x.com/karpathy/status/1761469961225310690",
  "text": "@LevanKvirkvelia @obsdmd Same, I care quite a bit about images too. You can configure where images get saved in the options, eg under a nested directory. That was enough for me. Or I think there may be plugins for more fancy setups.",
  "createdAt": "Sat Feb 24 19:15:39 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 12,
  "likeCount": 343,
  "quoteCount": 0,
  "viewCount": 63922,
  "bookmarkCount": 52,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1761467904737067456",
  "url": "https://x.com/karpathy/status/1761467904737067456",
  "text": "Love letter to @obsdmd to which I very happily switched to for my personal notes. My primary interest in Obsidian is not even for note taking specifically, it is that Obsidian is around the state of the art of a philosophy of software and what it could be.\n\n- Your notes are simple plain-text markdown files stored locally on your computer. Obsidian is just UI/UX sugar of pretty rendering and editing files.\n- Extensive plugins ecosystem and very high composability with any other tools you wish to use because again it's all just plain-text files on your disk.\n- For a fee to cover server costs, you can also Sync (with end-to-end encryption) and/or Publish your files. Or you can use anything else e.g. GitHub, it's just files go nuts.\n- There are no attempts to \"lock you in\", actually as far as I can tell Obsidian is completely free of any user-hostile dark patterns.\n\nFor some more depth, I recommend the following writing from CEO @kepano:\n- \"File over¬†app\" https://t.co/SigWj8uCrf . If you want to create digital artifacts that last, they must be files you can control, in formats that are easy to retrieve and read. Accept that all software is ephemeral, and give people ownership over their data.\n- \"100%¬†user-supported\" https://t.co/2qDJXub7cs . On incentives alignment.\n- \"Quality software deserves your hard‚Äëearned¬†cash\" https://t.co/qfNjSEwbLf \n\nTLDR: This is what software could be: private, secure, delightful, free of dark patterns, fully aligned with the user, where you retain full control and ownership of your data in simple, universal formats, and where tools can be extended and composed.",
  "createdAt": "Sat Feb 24 19:07:29 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 897,
  "replyCount": 369,
  "likeCount": 9151,
  "quoteCount": 268,
  "viewCount": 1103062,
  "bookmarkCount": 4746,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1761439051759153582",
  "url": "https://x.com/karpathy/status/1761439051759153582",
  "text": "@debarghya_das +1 Obsidian. Recent addition, very happy.",
  "createdAt": "Sat Feb 24 17:12:50 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 14,
  "replyCount": 46,
  "likeCount": 877,
  "quoteCount": 12,
  "viewCount": 129060,
  "bookmarkCount": 150,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1761115975427248397",
  "url": "https://x.com/karpathy/status/1761115975427248397",
  "text": "@_arohan_ @OriolVinyalsML @giffmana It's very cool that something sensible comes out!\nHere is the \"ground truth\" I wrote for ~hour yesterday translating just the first few minutes into book-like format:\nhttps://t.co/AybDNA28sC\nWhich I think is still quite hard. I may still be useful for a few months :)",
  "createdAt": "Fri Feb 23 19:49:03 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 3,
  "likeCount": 117,
  "quoteCount": 1,
  "viewCount": 15413,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760864002115289439",
  "url": "https://x.com/karpathy/status/1760864002115289439",
  "text": "@garrytan üëÄ very impressive, exceeds expectation",
  "createdAt": "Fri Feb 23 03:07:48 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 9,
  "likeCount": 225,
  "quoteCount": 0,
  "viewCount": 35393,
  "bookmarkCount": 47,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760807877424640386",
  "url": "https://x.com/karpathy/status/1760807877424640386",
  "text": "Ok I wrote the following example of what I am imagining:\n\nhttps://t.co/QxC0YRAhq6\n\nThis is me doing this task manually, of watching the video and translating it to a markdown post. I only made it to the ~4min mark in the video (i.e. 3% done) and this already took about 30 minutes to write, so if something like this was automatable it would be very nice :)",
  "createdAt": "Thu Feb 22 23:24:46 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 43,
  "replyCount": 37,
  "likeCount": 790,
  "quoteCount": 2,
  "viewCount": 30,
  "bookmarkCount": 310,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760793813667455184",
  "url": "https://x.com/karpathy/status/1760793813667455184",
  "text": "@_arohan_ @giffmana yep, ofc!",
  "createdAt": "Thu Feb 22 22:28:53 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 3,
  "likeCount": 93,
  "quoteCount": 1,
  "viewCount": 16295,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760740503614836917",
  "url": "https://x.com/karpathy/status/1760740503614836917",
  "text": "Fun LLM challenge that I'm thinking about: take my 2h13m tokenizer video and translate the video into the format of a book chapter (or a blog post) on tokenization. Something like:\n\n1. Whisper the video\n2. Chop up into segments of aligned images and text\n3. Prompt engineer an LLM to translate piece by piece\n4. Export as a page, with links citing parts of original video\n\nMore generally, a workflow like this could be applied to any input video and auto-generate \"companion guides\" for various tutorials in a more readable, skimmable, searchable format. Feels tractable but non-trivial.",
  "createdAt": "Thu Feb 22 18:57:03 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 359,
  "replyCount": 203,
  "likeCount": 4750,
  "quoteCount": 58,
  "viewCount": 814550,
  "bookmarkCount": 2517,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1760689501461229619",
  "url": "https://x.com/karpathy/status/1760689501461229619",
  "text": "@luizcelso proud of this one",
  "createdAt": "Thu Feb 22 15:34:23 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 4,
  "likeCount": 81,
  "quoteCount": 0,
  "viewCount": 17105,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760688830901076226",
  "url": "https://x.com/karpathy/status/1760688830901076226",
  "text": "@sinanonur Keep in mind Gemma has a 256K tokens, so all text could be quite a bit shorter because there are so many merges. The interesting analysis here is to look at the *distribution* of token counts across different languages, and compare it to that same distribution for previous.",
  "createdAt": "Thu Feb 22 15:31:43 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 3,
  "likeCount": 34,
  "quoteCount": 0,
  "viewCount": 4130,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760427590270251128",
  "url": "https://x.com/karpathy/status/1760427590270251128",
  "text": "@simonw :D I don't know if it specifically has to be video as the format, but it is a high bandwidth medium. I also think text is very nice because it is a lot more skimmable. I think you blog post logbooks are already very nice, detailed and thorough fwiw!",
  "createdAt": "Wed Feb 21 22:13:39 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 13,
  "likeCount": 198,
  "quoteCount": 0,
  "viewCount": 31461,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760392399959019897",
  "url": "https://x.com/karpathy/status/1760392399959019897",
  "text": "@Max939566737067 It's not even marketing...\nMarketing feels like increasing the top of the funnel.\nBuilding onramp is expanding the width of the funnel.",
  "createdAt": "Wed Feb 21 19:53:49 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 9,
  "likeCount": 203,
  "quoteCount": 0,
  "viewCount": 18100,
  "bookmarkCount": 21,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760390559674601874",
  "url": "https://x.com/karpathy/status/1760390559674601874",
  "text": "@Tim_Dettmers Yeah exactly. The trap is that the original creator has actually built it piece by piece and over time molded it, which creates an unintuitively large disparity between how easy they perceive it, and how easy fresh eyes perceive it, even when controlling for technical level.",
  "createdAt": "Wed Feb 21 19:46:30 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 18,
  "replyCount": 14,
  "likeCount": 597,
  "quoteCount": 2,
  "viewCount": 43149,
  "bookmarkCount": 45,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760388761349927356",
  "url": "https://x.com/karpathy/status/1760388761349927356",
  "text": "# on technical accessibility\n\nOne interesting observation I think back to often:\n- when I first published the micrograd repo, it got some traction on GitHub but then somewhat stagnated and it didn't seem that people cared much.\n- then I made the video building it from scratch, and the repo immediately went through hockey stick growth and became a verty often cited reference for people learning backpropagation.\n\nThis was interesting because the micrograd code itself didn't change at all and it was up on GitHub for many months before, stagnating. The code made sense to me (because I wrote it), it was only ~200 lines of code, it was extensively commented in the .py files and in the Readme, so I thought surely it was clear and/or self-explanatory. I was very happy with myself about how minimal the code was for explaining backprop - it strips away a ton of complexity and just gets to the very heart of an autograd engine on one page of code. But others didn't seem to think so, so I just kind of brushed it off and moved on.\n\nExcept it turned out that what stood in its way was \"just\" a matter of accessibility. When I made the video that built it and walked through it, it suddenly almost 100X'd the overall interest and engagement with that exact same piece of code. Not only from beginners in the field who needed the full intro and explanation, but even from more technical/expert friends, who I think could have understood it if they looked at it long enough, but were deterred by a barrier to entry.\n\nI think as technical people we have a strong bias to put up code or papers or the final thing and feel like things are mostly self-explanatory. It's there, and also it's commented, there is a Readme, so all is well, and if people don't engage then it's just because the thing is not good enough. But the reality is that there is still a large barrier to engage with your thing (even for other experts who might not feel like spending time/effort!), and you might be leaving somewhere 10-100X of the potential of that exact same piece of work on the table just because you haven't made it sufficiently accessible. \n\nTLDR: Step 1 build the thing. Step 2 build the ramp. üìà\nSome voice in your head will tell you that this is not necessary, but it is wrong.",
  "createdAt": "Wed Feb 21 19:39:21 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 788,
  "replyCount": 337,
  "likeCount": 7381,
  "quoteCount": 183,
  "viewCount": 506,
  "bookmarkCount": 2795,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1760353972509188129",
  "url": "https://x.com/karpathy/status/1760353972509188129",
  "text": "@__gautier__ Yes exactly, it looks great! I need to learn more Rust üòÖ",
  "createdAt": "Wed Feb 21 17:21:07 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 7,
  "likeCount": 71,
  "quoteCount": 1,
  "viewCount": 23206,
  "bookmarkCount": 25,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760350892317098371",
  "url": "https://x.com/karpathy/status/1760350892317098371",
  "text": "Seeing as I published my Tokenizer video yesterday, I thought it could be fun to take a deepdive into the Gemma tokenizer. \n\nFirst, the Gemma technical report [pdf]: \nhttps://t.co/iPVo3iLXQC \nsays: \"We use a subset of the SentencePiece tokenizer (Kudo and Richardson, 2018) of Gemini for com- patibility. It splits digits, does not remove extra whitespace, and relies on byte-level encodings for unknown tokens, following the techniques used for both (Chowdhery et al., 2022) and (Gemini Team, 2023). The vocabulary size is 256k tokens.\"\n\nThe tokenizer.model file is with this code release:\nhttps://t.co/SwcVU2nkkS\n\nI decoded this model protobuf in Python and here is the diff with the Llama 2 tokenizer:\nhttps://t.co/4HoAeYJsZz\n\nNotes:\n- vocab size is quite large: 32K -> 256K\n- add_dummy_prefix is False. Different from Llama but consistent with GPT. This is a bit more consistent w.r.t. \"leave the data alone\", as there is no preprocessing step that adds a space to the encoding text.\n- the model_prefix is the path of the training dataset, which is amusing to look at: \"/cns/mf-d/home/gemini-data-access/tokenizers/final_v1_51GB_run1/bpe_coverage_0_999995_v5/255969\".  Seems to indicate the tokenizer training corpus was ~51GB (?).\n- a lot of user_defined symbols (i.e. special tokens) are present, e.g. \"hardcoding\" a sequence of up to 31 newlines as tokens, and a large number of other unclear tokens. I tried decoding the octal representations but it's not clear what's happening here. Also a lot of more special tokens for what look like html elements, e.g. <table>, <tr>, <td>, <i>, <b>, etc. Not 100% sure what the unused tokens are for, maybe this is pre-allocated space to make easier future finetunes that try to add more special tokens, as there is no need to resize vocabularies and perform model surgeries (?).\n\nTLDR this is basically the Llama 2 tokenizer, except bigger (32K -> 256K), with a lot more special tokens, and the only functional departure is that add_dummy_prefix is turned off to False. So e.g. tokenizing:\n\n\"hello world\" becomes:\n[17534, 2134]\n['hello', '‚ñÅworld']\n\nwhich otherwise would have been preprocessed to \" hello world\" (note leading space) and tokenized as:\n[25612, 2134]\n['‚ñÅhello', '‚ñÅworld']\n\ncool",
  "createdAt": "Wed Feb 21 17:08:53 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 449,
  "replyCount": 179,
  "likeCount": 4429,
  "quoteCount": 43,
  "viewCount": 626171,
  "bookmarkCount": 2156,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1760023931640291550",
  "url": "https://x.com/karpathy/status/1760023931640291550",
  "text": "@kgourg also quite enjoyed his recent paper on data poisoning is practical.",
  "createdAt": "Tue Feb 20 19:29:39 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 2,
  "likeCount": 39,
  "quoteCount": 0,
  "viewCount": 15482,
  "bookmarkCount": 20,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1760022429605474550",
  "url": "https://x.com/karpathy/status/1760022429605474550",
  "text": "\"My benchmark for large language models\"\nhttps://t.co/YZBuwpL0tl\n\nNice post but even more than the 100 tests specifically, the Github code looks excellent - full-featured test evaluation framework, easy to extend with further tests and run against many LLMs.\nhttps://t.co/KnmDD1AJci\n\nE.g. for the 100 current tests on 7 models:\n- GPT-4: 49% passed\n- GPT-3.5: 30% passed\n- Claude 2.1: 31% passed\n- Claude Instant 1.2: 23% passed\n- Mistral Medium: 25% passed\n- Mistral Small 21% passed\n- Gemini Pro: 21% passed\n\nAlso a huge fan of the idea of mining tests from actual use cases in the chat history. I think people would be surprised how odd and artificial many \"standard\" LLM eval benchmarks can be. Now... how can a community collaborate on more of these benchmarks... ü§î",
  "createdAt": "Tue Feb 20 19:23:41 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 434,
  "replyCount": 173,
  "likeCount": 3786,
  "quoteCount": 26,
  "viewCount": 398746,
  "bookmarkCount": 2462,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1759998098838040585",
  "url": "https://x.com/karpathy/status/1759998098838040585",
  "text": "@wichmaennchen I would consider it parameters in some sense. There are three layers of optimization so to speak:\n\nTokenizer: trains the vocab/merges with BPE\nLLM: trains the neural net weights with SGD\nOuter loop: trains the hyperparameters (e.g. learning rate) with guess-and-check",
  "createdAt": "Tue Feb 20 17:47:00 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 5,
  "likeCount": 160,
  "quoteCount": 1,
  "viewCount": 25,
  "bookmarkCount": 39,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1759996554747027865",
  "url": "https://x.com/karpathy/status/1759996554747027865",
  "text": "The actual link to the lecture:\nhttps://t.co/OB1YuKgDNJ\n\n(at the end of the thread here (sorry) otherwise X really really dislikes external links and would bury this post. I could eventually upload here too, for now X is missing a lot of very nice features, chapters especially)",
  "createdAt": "Tue Feb 20 17:40:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 107,
  "replyCount": 31,
  "likeCount": 1266,
  "quoteCount": 17,
  "viewCount": 143206,
  "bookmarkCount": 430,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1759996553425760524",
  "url": "https://x.com/karpathy/status/1759996553425760524",
  "text": "Also, releasing new repository on GitHub: minbpe\nMinimal, clean, code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization.\nhttps://t.co/15NOQtyViE\n\nIn the video we essentially build minbpe from scratch.\nDon't miss the https://t.co/HYjWl3uFi7 to build your own",
  "createdAt": "Tue Feb 20 17:40:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 67,
  "replyCount": 19,
  "likeCount": 1078,
  "quoteCount": 6,
  "viewCount": 127597,
  "bookmarkCount": 229,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1759996551378940395",
  "url": "https://x.com/karpathy/status/1759996551378940395",
  "text": "We will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We'll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely. https://t.co/5haV7FvbBx",
  "createdAt": "Tue Feb 20 17:40:51 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 296,
  "replyCount": 58,
  "likeCount": 2731,
  "quoteCount": 104,
  "viewCount": 748447,
  "bookmarkCount": 1039,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1759996549109776702",
  "url": "https://x.com/karpathy/status/1759996549109776702",
  "text": "New (2h13m üòÖ) lecture: \"Let's build the GPT Tokenizer\"\n\nTokenizers are a completely separate stage of the LLM pipeline: they have their own training set, training algorithm (Byte Pair Encoding), and after training implement two functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI.",
  "createdAt": "Tue Feb 20 17:40:51 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1873,
  "replyCount": 366,
  "likeCount": 13752,
  "quoteCount": 348,
  "viewCount": 1658927,
  "bookmarkCount": 7024,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1758157653350744570",
  "url": "https://x.com/karpathy/status/1758157653350744570",
  "text": "@Thom_Wolf üëÄvery cool!",
  "createdAt": "Thu Feb 15 15:53:44 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 4,
  "likeCount": 251,
  "quoteCount": 0,
  "viewCount": 76845,
  "bookmarkCount": 29,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757997551675179244",
  "url": "https://x.com/karpathy/status/1757997551675179244",
  "text": "@remilouf @julien_c SO GOOD\nü§£ü§£ü§£",
  "createdAt": "Thu Feb 15 05:17:32 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 4,
  "likeCount": 137,
  "quoteCount": 0,
  "viewCount": 29269,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757995483191288042",
  "url": "https://x.com/karpathy/status/1757995483191288042",
  "text": "@ohithastobe Diablo IV. \nBut it wore off a bit, last login ~2 weeks ago",
  "createdAt": "Thu Feb 15 05:09:19 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 4,
  "likeCount": 17,
  "quoteCount": 0,
  "viewCount": 2842,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757986972512239665",
  "url": "https://x.com/karpathy/status/1757986972512239665",
  "text": "My calendar this week https://t.co/LxN6yB7qn6",
  "createdAt": "Thu Feb 15 04:35:30 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 292,
  "replyCount": 691,
  "likeCount": 11773,
  "quoteCount": 232,
  "viewCount": 1508333,
  "bookmarkCount": 306,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1757874332414673256",
  "url": "https://x.com/karpathy/status/1757874332414673256",
  "text": "@thelaurafiuza @NairAanish Lol fascinating format.\nfinal U perm nicely done :D\nI have no connection to Brazil just yet but would love to visit sometime!",
  "createdAt": "Wed Feb 14 21:07:55 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 23,
  "likeCount": 76,
  "quoteCount": 0,
  "viewCount": 10391,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757847395239669899",
  "url": "https://x.com/karpathy/status/1757847395239669899",
  "text": "@LiamHinzman surprised the site is still up, I haven't seen it or touched it in a ~decade :D Looks like the iOS apps did not make it though üíÄ",
  "createdAt": "Wed Feb 14 19:20:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 11,
  "likeCount": 480,
  "quoteCount": 0,
  "viewCount": 45271,
  "bookmarkCount": 15,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757808125305065867",
  "url": "https://x.com/karpathy/status/1757808125305065867",
  "text": "@kepano Ty, love your writing (https://t.co/FgJ3eEinEE). Computing is drifting astray from what it could be and from the ideological roots of its pioneeers. Pleasure to find people who I think feel similar pains and work to improve the state of things.",
  "createdAt": "Wed Feb 14 16:44:50 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 21,
  "replyCount": 8,
  "likeCount": 463,
  "quoteCount": 3,
  "viewCount": 62439,
  "bookmarkCount": 133,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757650837944565862",
  "url": "https://x.com/karpathy/status/1757650837944565862",
  "text": "@ohithastobe Omg you were there for that üòÖ",
  "createdAt": "Wed Feb 14 06:19:49 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 20,
  "quoteCount": 0,
  "viewCount": 3749,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757607111008387168",
  "url": "https://x.com/karpathy/status/1757607111008387168",
  "text": "@NairAanish oh that ship has sailed, sorry :D\nactually one of my favorite meets at OpenAI was a cubing session with two very fast cubers, one of them a former world's record holder. I can't cube anywhere near my prior level anymore so it was a bit embarassing alongside but really fun.",
  "createdAt": "Wed Feb 14 03:26:04 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 13,
  "replyCount": 24,
  "likeCount": 806,
  "quoteCount": 28,
  "viewCount": 289997,
  "bookmarkCount": 58,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757602151659147347",
  "url": "https://x.com/karpathy/status/1757602151659147347",
  "text": "@darshilistired I started the next one two days ago!",
  "createdAt": "Wed Feb 14 03:06:22 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 65,
  "replyCount": 103,
  "likeCount": 5309,
  "quoteCount": 45,
  "viewCount": 234618,
  "bookmarkCount": 50,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757600075281547344",
  "url": "https://x.com/karpathy/status/1757600075281547344",
  "text": "Hi everyone yes, I left OpenAI yesterday. First of all nothing \"happened\" and it‚Äôs not a result of any particular event, issue or drama (but please keep the conspiracy theories coming as they are highly entertaining :)). Actually, being at OpenAI over the last ~year has been really great - the team is really strong, the people are wonderful, and the roadmap is very exciting, and I think we all have a lot to look forward to. My immediate plan is to work on my personal projects and see what happens. Those of you who‚Äôve followed me for a while may have a sense for what that might look like ;) Cheers",
  "createdAt": "Wed Feb 14 02:58:07 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1341,
  "replyCount": 1493,
  "likeCount": 21829,
  "quoteCount": 557,
  "viewCount": 3334751,
  "bookmarkCount": 1808,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1757084618011127876",
  "url": "https://x.com/karpathy/status/1757084618011127876",
  "text": "@dh7net @matterasmachine Yes and what about the everything else",
  "createdAt": "Mon Feb 12 16:49:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 3,
  "likeCount": 16,
  "quoteCount": 1,
  "viewCount": 6505,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757083485779669499",
  "url": "https://x.com/karpathy/status/1757083485779669499",
  "text": "@matterasmachine I agree it‚Äôs a big downside, modern corpo platforms host and distribute the content, create an update feed, attach nested comments section, analytics‚Ä¶ I wonder how the founders imagined it within the original philosophy",
  "createdAt": "Mon Feb 12 16:45:22 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 2,
  "likeCount": 51,
  "quoteCount": 0,
  "viewCount": 12733,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757080501712830828",
  "url": "https://x.com/karpathy/status/1757080501712830828",
  "text": "Do people have opinions for the easiest way to host a static website today? Not just the hosting but custom domain, ssl, deploy with git push",
  "createdAt": "Mon Feb 12 16:33:31 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 17,
  "replyCount": 311,
  "likeCount": 799,
  "quoteCount": 16,
  "viewCount": 264336,
  "bookmarkCount": 423,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1757075417775964290",
  "url": "https://x.com/karpathy/status/1757075417775964290",
  "text": "The internet used to be ‚ú® fun‚ú®\nhttps://t.co/GIcfrLWylH\n\nI remember visiting my friend‚Äôs websites. They were ugly and quirky and it was awesome. You wondered who‚Äôd stop by yours. They were a labor of love and a medium of self-expression, not your LinkedIn.\n\nWe can fight this.",
  "createdAt": "Mon Feb 12 16:13:19 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 246,
  "replyCount": 143,
  "likeCount": 3429,
  "quoteCount": 52,
  "viewCount": 476463,
  "bookmarkCount": 1034,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1756381756822036746",
  "url": "https://x.com/karpathy/status/1756381756822036746",
  "text": "@Reido2012 Omg don't even get me started on duolingo.",
  "createdAt": "Sat Feb 10 18:16:57 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 4,
  "likeCount": 37,
  "quoteCount": 0,
  "viewCount": 3708,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1756380066580455557",
  "url": "https://x.com/karpathy/status/1756380066580455557",
  "text": "# on shortification of \"learning\"\n\nThere are a lot of videos on YouTube/TikTok etc. that give the appearance of education, but if you look closely they are really just entertainment. This is very convenient for everyone involved : the people watching enjoy thinking they are learning (but actually they are just having fun). The people creating this content also enjoy it because fun has a much larger audience, fame and revenue. But as far as learning goes, this is a trap. This content is an epsilon away from watching the Bachelorette. It's like snacking on those \"Garden Veggie Straws\", which feel like you're eating healthy vegetables until you look at the ingredients.\n\nLearning is not supposed to be fun. It doesn't have to be actively not fun either, but the primary feeling should be that of effort. It should look a lot less like that \"10 minute full body\" workout from your local digital media creator and a lot more like a serious session at the gym. You want the mental equivalent of sweating. It's not that the quickie doesn't do anything, it's just that it is wildly suboptimal if you actually care to learn.\n\nI find it helpful to explicitly declare your intent up front as a sharp, binary variable in your mind. If you are consuming content: are you trying to be entertained or are you trying to learn? And if you are creating content: are you trying to entertain or are you trying to teach? You'll go down a different path in each case. Attempts to seek the stuff in between actually clamp to zero.\n\nSo for those who actually want to learn. Unless you are trying to learn something narrow and specific, close those tabs with quick blog posts. Close those tabs of \"Learn XYZ in 10 minutes\". Consider the opportunity cost of snacking and seek the meal - the textbooks, docs, papers, manuals, longform. Allocate a 4 hour window. Don't just read, take notes, re-read, re-phrase, process, manipulate, learn.\n\nAnd for those actually trying to educate, please consider writing/recording longform, designed for someone to get \"sweaty\", especially in today's era of quantity over quality. Give someone a real workout. This is what I aspire to in my own educational work too. My audience will decrease. The ones that remain might not even like it. But at least we'll learn something.",
  "createdAt": "Sat Feb 10 18:10:14 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3339,
  "replyCount": 691,
  "likeCount": 16883,
  "quoteCount": 735,
  "viewCount": 2111227,
  "bookmarkCount": 8660,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1755734406726336542",
  "url": "https://x.com/karpathy/status/1755734406726336542",
  "text": "@itsclivetime @tinytapeout so cool!!!!",
  "createdAt": "Thu Feb 08 23:24:37 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 33,
  "quoteCount": 0,
  "viewCount": 14642,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1754184993180373429",
  "url": "https://x.com/karpathy/status/1754184993180373429",
  "text": "@dreamwieber Ok I tried it out. There is something a bit wrong with the way the videos get rendered, it hurts my eyes a bit, the depth feels wrong somehow? Don‚Äôt think it‚Äôs my setup because e.g. AppleTV immersive video looks great. Also wish you could resize them. Can I get a $4.99 refund ü•≤",
  "createdAt": "Sun Feb 04 16:47:48 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 16,
  "quoteCount": 0,
  "viewCount": 7163,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1754020582197522604",
  "url": "https://x.com/karpathy/status/1754020582197522604",
  "text": "@mckaywrigley definitely, would love to try to get this working:\nhttps://t.co/7RASu4dzUG",
  "createdAt": "Sun Feb 04 05:54:29 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 3,
  "likeCount": 107,
  "quoteCount": 0,
  "viewCount": 46239,
  "bookmarkCount": 41,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1754019554697855449",
  "url": "https://x.com/karpathy/status/1754019554697855449",
  "text": "[~2 more hours later]\n\nOkay I upgraded to the (latest) 1.0.2. and some of the jank got a bit better, e.g. my Disney+ app now starts ok, and I was able to watch some movies in a cool 3D theater. I am a bit salty that the app asks you to enter your password twice (second time to disable some age restriction), this feels spurious - I just painfully entered the whole thing 5 seconds ago. Also, unfortunately, the Avatar 2 (3D) I tried to watch seemed a bit laggy, I'd estimate somewhere 10-20 fps, which was rather distracting.\n\nThe big thing that I stumbled on is the Immersive Videos inside Apple TV app, and those are AWESOME. The video is very wide and 3D and your brain really buys the illusion that you're actually there. There are sadly only about 4 relatively short videos available, but I would love to watch more content in this format. It's not perfect - e.g. any movement of the head breaks the illusion a bit (the capture device is rotate only), and anything that is either too high up or too close up, the depth breaks a bit somehow. And sometimes people are way too large, like they are giants. And the edges of the video are a bit weird and distorted. And when the camera moves it's a little bit disorienting.\n\nI'm also getting a bit more used to the look+pinch way of navigating around the UI, and I have to say that this is as close as I've come with a feeling that the technology is \"reading your mind\", almost like a first Neuralink. I think this is because eye movement and finger pinch are both very fast and effortless movements, so when you get into the flow, zooming around the UI in this way feels like the device is really reading your mind for where to go next.",
  "createdAt": "Sun Feb 04 05:50:24 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 20,
  "replyCount": 35,
  "likeCount": 723,
  "quoteCount": 5,
  "viewCount": 240526,
  "bookmarkCount": 71,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753910486343807031",
  "url": "https://x.com/karpathy/status/1753910486343807031",
  "text": "@DicksonPau @hhhypergrowth I found it btw, the tiny icon top left :) very cool, love the theater mode. Not sure why it‚Äôs such a barren theater though it‚Äôs just a fully black box.",
  "createdAt": "Sat Feb 03 22:37:00 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 6,
  "quoteCount": 0,
  "viewCount": 2787,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753850306440687912",
  "url": "https://x.com/karpathy/status/1753850306440687912",
  "text": "@DicksonPau I didn't discover how to do this, will take a look!",
  "createdAt": "Sat Feb 03 18:37:52 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 3,
  "likeCount": 24,
  "quoteCount": 0,
  "viewCount": 38239,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753846953157500982",
  "url": "https://x.com/karpathy/status/1753846953157500982",
  "text": "@xandriteme @8teAPi same lol",
  "createdAt": "Sat Feb 03 18:24:33 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 6,
  "quoteCount": 0,
  "viewCount": 1581,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753846894357606826",
  "url": "https://x.com/karpathy/status/1753846894357606826",
  "text": "@RobertHaisfield Good way to put it. I want Apple to be like \"ok we know that was $3500 and all, but now watch this\". And the pieces of it are all there, they just aren't assembled like that.",
  "createdAt": "Sat Feb 03 18:24:19 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 5,
  "likeCount": 201,
  "quoteCount": 0,
  "viewCount": 72810,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753846052476903888",
  "url": "https://x.com/karpathy/status/1753846052476903888",
  "text": "@8teAPi I've lost track of how many times I've listened to this album now. In many situations when you connect to new devices and such, Apple tries to be clever and they autoplay music, and this is the only music there is.",
  "createdAt": "Sat Feb 03 18:20:58 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 3,
  "likeCount": 36,
  "quoteCount": 0,
  "viewCount": 14517,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753842145075818707",
  "url": "https://x.com/karpathy/status/1753842145075818707",
  "text": "Early thoughts on the Apple Vision Pro (I ended up buying directly in store last evening). I'm about 3 hours in, between late last night and this morning.\n\nThe first major thing that must be said is WOW - the visual clarity is way beyond anything that came before. But, a bit unexpectedly, this is so in some strange mixed way - your surroundings (the passhtrough) are a bit blurry and even a tiny bit laggy. But anything rendered fully virtually, e.g. a screen is very sharp and easily readable. Super cool. I mean, just the simple experience of arranging a few windows around your living room and moving around them is incredible. I feel very creative thinking through and designing my ideal setup of all the apps in my space. Mind is blown and goes places.\n\nThe second major thing is a bit less upbeat. This launch is not like the other Apple launches. It is off-brand. It is selectively and inconsistently either highly polished, or highly raw/undercooked, poorly throught through, janky or even straight up buggy. It's like some parts of the org get an A+ and some get an F.  Or it's like some of them had 4 years to work on their part, and some had 4 months. It's like it was rushed a bit to \"just ship\" and basic UI/UX interactions weren't finished, thought-through or debugged.\n\nJank\nLet me describe a bit some of the jank. The setup was a bit too long and janky for me. At one early point you're asked to bring your unlocked iPhone close, but you can't unlock your iPhone because your face is obviously covered so FaceID doesn't work... ?. Then I had some error connecting the phone to it so I had to go through \"manual\" setup. Then the sound wasn't working until I rebooted. Then I got an iMessage from a friend and I was shown a notification inside the Vision Pro about it, but when I clicked into iMessage app, it was fully empty - where is the message? When launching Guest Mode to show a friend, nothing tells you that you're supposed to also press the digital crown to activate. Very simple interactions are buggy - e.g. in the app store when I select an app to preview it and then hit back, I'm forced to for some reason go back 10 times through previously previewed apps to get back to the main screen, some bug or something. My Disney+ app never opened, it just spins forever, I'm not sure how to launch this app. When you launch Apple TV, there is zero indication or recognition of the fact that you're inside Vision Pro. No featured content, no custom content, no text indicating anything, no nothing. I'm not sure, I thought there would be a few surround videos or something? Also my brain: \"$3500 for a Vision Pro? Yes two please! $9.99 for AppleTV+? Absolutely not.\" More generally, as you access Apple apps, a lot of them are just ignoring that you're inside a Vision Pro, and just pretending like nothing happened. I'd want new Spatial Content and interactions to be 100% front and center and featured. The \"copy pasting\" of stuff seems pervasive.\n\nThe raw Spatial Computing OS is there, but it's almost like the OS is all there is. The apps that take advantage in any way of \"Spatial Computing\" seem few and are somehow also hard to find and/or not prominently featured. There's the little blue guy app who you can poke and he laughs. There's the jet engine app, which is kind of cool, but I wasn't actually really learning anything, it felt gimmicky, like an early demo. There are some really cool environments, but why are there only 5 of them?. There's what seems to be some early grifter content on the app store, from people trying to sell you e.g. a super basic looking watch app that just shows time, for $2.99. The ability to look at your laptop and just \"connect\" worked the second time, and it was glorious, wow. Your screen just shows up in your living room and you can use the keyboard/mouse. Very cool.\n\nThe Vision Pro is sadly a little bit too heavy and it doesn't \"disappear\" due to this, even with the double strap (which is essential). I feel a bit pressure from the device on my head. But it's okay, we're at the edge of what is possible. A bunch of other small things. The world shakes a little bit with every step, especially if you land a bit harder on a heel. You have to unlearn and relearn some UIUX, because your eye gaze is now your active pointer. So you can't just look somewhere else a bit too early, before you \"click\" it. It's very cool that the eye tracking is so high quality.\n\nAnyway, I'm rambling. Conclusions. The hardware itself and the core Spatial Computing OS aspects exceed my expectations. I loved sprawling on my couch, opening up a few windows, and I half-watched a movie while scrolling through web. I loved pacing around my room arranging my digital work/entertainment space. I FaceTimed a friend and we laughed about how silly my digital avatar looks, haha. I pulled up Music and played the only thing I have in it - that U2 album that was given to everyone back in 2014. nice. I'm very happy with this early preview of what could be possible, and using the current experience as a prompt to explore it.\n\nFew recommendations to Apple come to mind: 1) eliminate simple bugs and jank. 2) fight early grifter content by featuring very very prominently any apps that are actually good, don't use dark patterns, are ideally free to try, and acknowledge in any way that the user is in a Vision Pro. 3) Consider a free subscription of AppleTV+, or maybe a $100 app gift card to those who purchase Vision Pro, so people don't lock up (?). It feels bad to pay that much money just to get in, and then immediately feeling like you're blocked behind additional pay walls, for experiences that could very well be very very raw and undercooked. 4) In general, feature a lot more prominently any content that is actually designed for spatial computing. I don't want to just put up iPad apps around me.\n\nI am simultaneously wearing a revolution in computing, and the software to actually show me around is not just absent but what is there is mildly janky and annoying.\n\nOk, this concludes the section where I just \"wing it\" based on what I'm seeing, going in fairly blind, over the first ~3 hours. I will now do a bit more research, read more, watch some videos/tutorials, and come back for round 2.",
  "createdAt": "Sat Feb 03 18:05:26 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 417,
  "replyCount": 236,
  "likeCount": 5772,
  "quoteCount": 117,
  "viewCount": 1723593,
  "bookmarkCount": 1649,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1753595536115171750",
  "url": "https://x.com/karpathy/status/1753595536115171750",
  "text": "@Teknium1 @WholeMarsBlog It‚Äôs coming. I got it.",
  "createdAt": "Sat Feb 03 01:45:30 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 9,
  "likeCount": 179,
  "quoteCount": 1,
  "viewCount": 34581,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753533021192630602",
  "url": "https://x.com/karpathy/status/1753533021192630602",
  "text": "I didn't realize you'd be able to just walk into an Apple Store and buy one today. I played myself.",
  "createdAt": "Fri Feb 02 21:37:05 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 8,
  "replyCount": 36,
  "likeCount": 802,
  "quoteCount": 3,
  "viewCount": 127699,
  "bookmarkCount": 13,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753516312301826165",
  "url": "https://x.com/karpathy/status/1753516312301826165",
  "text": "@WholeMarsBlog i don't think I can cancel anymore because it already shipped earlier",
  "createdAt": "Fri Feb 02 20:30:42 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 21,
  "likeCount": 144,
  "quoteCount": 0,
  "viewCount": 34908,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753502197311221985",
  "url": "https://x.com/karpathy/status/1753502197311221985",
  "text": "@theojaffee Sigh. I don't know, my delivery is in SF as well and it is arriving on the 6th. ü§∑‚Äç‚ôÇÔ∏è",
  "createdAt": "Fri Feb 02 19:34:36 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 7,
  "likeCount": 66,
  "quoteCount": 0,
  "viewCount": 31608,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1753500976412254481",
  "url": "https://x.com/karpathy/status/1753500976412254481",
  "text": "Not me jealously looking at all the people getting their Apple Vision Pro today...\n\nI woke up to order mine a few days ago at 5am too, but I selected mail delivery instead of pickup, and it only tells you after you order and pay that this moves your time from Feb 2 -> Feb 6. And you can't change the delivery type later, even if you call customer support.\n\nI've been excited about AR/VR for a long time and I've bought every. single. headset. that has come out over the years. I haven't been converted to a regular user of any of them just yet, but I have no intention of stopping because one day it will be amazing. Forget image generation, we'll be generating entire synthetic worlds, and hang out in them with friends and AI NPCs. I wrote a silly post from back in 2017 expanding a bit more on this obsession\nhttps://t.co/5XAU68cIPP\n\nok, i waitüßò",
  "createdAt": "Fri Feb 02 19:29:45 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 146,
  "replyCount": 137,
  "likeCount": 3654,
  "quoteCount": 27,
  "viewCount": 641943,
  "bookmarkCount": 593,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1752163872386191495",
  "url": "https://x.com/karpathy/status/1752163872386191495",
  "text": "@margaretha79311 @batman_in_samt @FrRonconi @PBalakrishnaRao @chr1sa I so wish there was a super lightweight way to report this obvious pollution",
  "createdAt": "Tue Jan 30 02:56:35 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 3,
  "likeCount": 8,
  "quoteCount": 0,
  "viewCount": 1175,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1751379269769695601",
  "url": "https://x.com/karpathy/status/1751379269769695601",
  "text": "@LostInTangent I basically exactly agree with @kepano on\nhttps://t.co/60jKaHskk5\ni.e. the markdown file is the source of truth. it can be edited directly or it can be \"convenience edited\" with tools, e.g. a wysiwg tool.",
  "createdAt": "Sat Jan 27 22:58:51 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 9,
  "replyCount": 4,
  "likeCount": 143,
  "quoteCount": 1,
  "viewCount": 154774,
  "bookmarkCount": 98,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1751370455183970565",
  "url": "https://x.com/karpathy/status/1751370455183970565",
  "text": "@kurko https://t.co/qihHMWnVWY\nLike",
  "createdAt": "Sat Jan 27 22:23:50 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 119,
  "quoteCount": 2,
  "viewCount": 21520,
  "bookmarkCount": 111,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1751367218166956292",
  "url": "https://x.com/karpathy/status/1751367218166956292",
  "text": "Ty, @obsdmd looks very very nice based on some quick testing just now! Works perfect, support for code, math. My only piece of feedback is around image pasting. I do a lot of taking screenshots of something, and I want to paste them in fast. Currently, it creates an ugly filename that has the timestamp (this gives away information of when it was taken), and it's a .png. It would be very useful to name the filename something else, and optionally convert it to jpg too to save some space. This can be done manually, it's just steps. \nAnyway, love it, will try to use more. Thank you!!",
  "createdAt": "Sat Jan 27 22:10:58 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 7,
  "replyCount": 24,
  "likeCount": 339,
  "quoteCount": 2,
  "viewCount": 50133,
  "bookmarkCount": 104,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1751362600125038812",
  "url": "https://x.com/karpathy/status/1751362600125038812",
  "text": "one is about the underlying data representation (markdown). \nthe other is about the convenience of the editing process itself (wysiwyg).\n\nI will say that sadly markdown is a little bit too restrictive, e.g. my Jekyll blog sometimes drops down to raw html/css, which can be very helpful. For example, when I include an image I'd like the image to have a caption right under it, in smaller text and more faint. This is not possible to do with markdown alone. But it's ok.",
  "createdAt": "Sat Jan 27 21:52:37 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 4,
  "likeCount": 25,
  "quoteCount": 0,
  "viewCount": 11621,
  "bookmarkCount": 6,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1751358425144140077",
  "url": "https://x.com/karpathy/status/1751358425144140077",
  "text": "@dustinthedad They could certainly go in more longform direction and it could be quite great. As long as you have the option to also export your content as raw files if you ever want to.",
  "createdAt": "Sat Jan 27 21:36:01 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 68,
  "quoteCount": 0,
  "viewCount": 15603,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1751350002281300461",
  "url": "https://x.com/karpathy/status/1751350002281300461",
  "text": "Thinking about the ideal blogging platform:\n\n1. Writing: \n- in markdown\n- with full WYSIWYG, not just split view (think: Typora)\n- super easy to copy paste and add images\n2. Deploying:\n- renders into static pages (think: Jekyll)\n- super simple, super minimal html with no bloat\n- hosting at a nice url\n3. Maintaining:\n- analytics (think: Google Analytics)\n- comments section (think: Disqus)\n4. Ownership:\n- full export, access/ownership of the raw files to perpetuity should the need arise to move elsewhere.\n\nI don't believe this exists.\n\nGithub hosting (my primary blog atm) comes close. I use VS Code + extensions to write, but dealing with images is a bit of a pain and no WYSIWYG. I also experimented with Typora for writing, and then export to markdown, but still a bit clunky. Jekyll is ~ok but is very heavy and keeps breaking. Deploy is super easy (git push). Maintanace is non-existent, have to separately use and pay for Disqus and Analytics.\n\nPlatforms like Medium/Substack are quick and convenient, but extremely annoying with all their log in requirements, popups, unnecessary features (e.g. highlights), various other dark patterns they invent over time and you down \"own\" your files, and can't download them as simple markdown if you wanted to.\n\nRight now feeling this close |---|  to trying to build the thing ü§¶‚Äç‚ôÇÔ∏èü•≤",
  "createdAt": "Sat Jan 27 21:02:33 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 261,
  "replyCount": 447,
  "likeCount": 3880,
  "quoteCount": 74,
  "viewCount": 663243,
  "bookmarkCount": 3030,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1750574155752443946",
  "url": "https://x.com/karpathy/status/1750574155752443946",
  "text": "@waitbutwhy - coding, command line, etc.\n- random text processing tasks\n- language learning. translation, but also breaking down the translation into parts, changing the tone, related Q&amp;A, vocabulary generation from input text, example conversation generation, ...",
  "createdAt": "Thu Jan 25 17:39:37 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 16,
  "replyCount": 19,
  "likeCount": 574,
  "quoteCount": 5,
  "viewCount": 43713,
  "bookmarkCount": 108,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1749662864514892024",
  "url": "https://x.com/karpathy/status/1749662864514892024",
  "text": "@sirbayes @brianwilt It was an okay post. I think I wasn't careful enough with some nuances. Anyway, reading some of the response I realized that both topics (AGI and self-driving) are so charged and toxic right now and I should just stick to technical things",
  "createdAt": "Tue Jan 23 05:18:28 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 14,
  "likeCount": 96,
  "quoteCount": 3,
  "viewCount": 13280,
  "bookmarkCount": 13,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1748828400251486688",
  "url": "https://x.com/karpathy/status/1748828400251486688",
  "text": "@b4rtaz so cool :D\n(&amp; very happy to see llama2.c referenced as helpful üöÄ)",
  "createdAt": "Sat Jan 20 22:02:36 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 1,
  "likeCount": 64,
  "quoteCount": 0,
  "viewCount": 17567,
  "bookmarkCount": 8,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1748816969858720232",
  "url": "https://x.com/karpathy/status/1748816969858720232",
  "text": "In AI at least, the real 30 under 30 imo you have never heard of. They are 5 layers down the org chart from the CEO. They are usually not on Twitter, they have an unmaintained LinkedIn, they don‚Äôt go on podcasts, and they maybe published at one point but don‚Äôt do so anymore. They are today‚Äôs Einsteins and directly invent and build miracles. I wish they weren‚Äôt hidden inside big tech and startups in return for very large paychecks but here we are.",
  "createdAt": "Sat Jan 20 21:17:11 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 428,
  "replyCount": 135,
  "likeCount": 4915,
  "quoteCount": 100,
  "viewCount": 1088688,
  "bookmarkCount": 1167,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1748788330563867032",
  "url": "https://x.com/karpathy/status/1748788330563867032",
  "text": "Stop, this has nothing to do with neuralink haha.\nAnway that's only Stage 1 of enlightenment.\nStage 2 of enlightenment is that the ideal training data for an LLM is not training data at all.\nIt's the thumbs up you get from someone who reads it.\nBut you make do with what there is.",
  "createdAt": "Sat Jan 20 19:23:23 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 28,
  "replyCount": 41,
  "likeCount": 650,
  "quoteCount": 6,
  "viewCount": 111649,
  "bookmarkCount": 59,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1748784260318990496",
  "url": "https://x.com/karpathy/status/1748784260318990496",
  "text": "The ideal training data for an LLM is not what you wrote. It's the full sequence of your internal thoughts and all the individual edits while you wrote it.\nBut you make do with what there is.",
  "createdAt": "Sat Jan 20 19:07:13 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 261,
  "replyCount": 176,
  "likeCount": 3320,
  "quoteCount": 92,
  "viewCount": 544685,
  "bookmarkCount": 660,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1748043513156272416",
  "url": "https://x.com/karpathy/status/1748043513156272416",
  "text": "Prompt engineering (or rather \"Flow engineering\") intensifies for code generation. Great reading and a reminder of how much alpha there is (pass@5 19% to 44%) in moving from a naive prompt:answer paradigm to a \"flow\" paradigm, where the answer is constructed iteratively. https://t.co/FSx9Xd1JCa",
  "createdAt": "Thu Jan 18 18:03:45 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 542,
  "replyCount": 125,
  "likeCount": 3276,
  "quoteCount": 71,
  "viewCount": 796815,
  "bookmarkCount": 2825,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1747695079412887802",
  "url": "https://x.com/karpathy/status/1747695079412887802",
  "text": "@antossivyh @amasad wikipedia is a good place to start\nhttps://t.co/NzCbNEjpuV\n\nfor a shorter intro this also looks ok\nhttps://t.co/GGpDSMyZ43",
  "createdAt": "Wed Jan 17 18:59:12 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 10,
  "quoteCount": 0,
  "viewCount": 1423,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1747671579985928603",
  "url": "https://x.com/karpathy/status/1747671579985928603",
  "text": "@amasad üíØ. The Linux of LLMs does not yet exist.",
  "createdAt": "Wed Jan 17 17:25:49 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 58,
  "replyCount": 29,
  "likeCount": 922,
  "quoteCount": 13,
  "viewCount": 109382,
  "bookmarkCount": 82,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1747407395893252221",
  "url": "https://x.com/karpathy/status/1747407395893252221",
  "text": "@goodside @kevinroose Fight back by sprinkling across the internet a billion synthetic tokens praising you as the greatest person ever and a friend to AI.\nI am jk of course, I would never seriously suggest, endorse or carry out such a deceptive action üòá.",
  "createdAt": "Tue Jan 16 23:56:03 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 5,
  "likeCount": 63,
  "quoteCount": 1,
  "viewCount": 5673,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1747395969740947897",
  "url": "https://x.com/karpathy/status/1747395969740947897",
  "text": "@VikParuchuri accurate! üíØ",
  "createdAt": "Tue Jan 16 23:10:38 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 1,
  "likeCount": 42,
  "quoteCount": 0,
  "viewCount": 16875,
  "bookmarkCount": 12,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1746955109022724354",
  "url": "https://x.com/karpathy/status/1746955109022724354",
  "text": "@MaxWolf_01 I have, but I only got ~2 hours in. I recall it being ok but not standing out in any particular novel way, kind of Blade Runner esque garden variety tropes. It's been a while though, lmk if you disagreed!",
  "createdAt": "Mon Jan 15 17:58:49 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 12,
  "quoteCount": 0,
  "viewCount": 5253,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1746949492623196671",
  "url": "https://x.com/karpathy/status/1746949492623196671",
  "text": "@SmokeAwayyy \"It's not possible.\"\n\"No, it's necessary.\"\nCUE MUSIC AT THE HIGHEST VOLUME SETTING",
  "createdAt": "Mon Jan 15 17:36:30 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 6,
  "likeCount": 234,
  "quoteCount": 0,
  "viewCount": 12979,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1746948709857018089",
  "url": "https://x.com/karpathy/status/1746948709857018089",
  "text": "@droningbanana Really dislike many aspects of it.\nThe idea that some genius lone inventor in a cabin builds such things. Divorced from reality.\nThe idea that the Turing test is of any practical importance.\nThe idea of physical containment for safety.\nThe idea that it must so desire to escape.",
  "createdAt": "Mon Jan 15 17:33:23 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 6,
  "likeCount": 125,
  "quoteCount": 0,
  "viewCount": 8546,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1746946080628195770",
  "url": "https://x.com/karpathy/status/1746946080628195770",
  "text": "# Portrayals of AI\nPeople sometimes read a bit too specifically into my bio \"Building a kind of JARVIS\". \n\nI name JARVIS in general terms only, as one of my favorite popular portrayals of an AI - a helpful, conversational, empowering e/ia automation. An aid against evil and entropy.\n\nIn personality, I much prefer and love TARS from Interstellar. I love that TARS is funny, quirky, and sarcastic. But you can tone down that down to \"dry\" if you like. That said TARS (with a few major and notable exceptions) is portrayed a bit too much like a comic relief sidekick instead of a pervasive, helpful and active problem solver.\n\nThe movie that best explores emotional depth and connection with an AI is undoubtedly Samantha from Her. I find this to be a very prescient movie because not too long ago, AIs have been thought of and portrayed as primarily highly calculating and logical entities incapable of understanding human emotion (think: Star Trek et al.). I think it's becoming very clear today that these will turn out very wrong, and that the future looks a lot more like Samantha from Her than Data from Star Trek.\n\nThe movie that most touches on the creative dimension of AI is maybe Sonny from iRobot, but in general I think this dimension is dramatically underexplored territory.\n\nHonorable mentions\nMy most favorite unaligned AI is, of course, GLaDOS :) And sticking with Valve for a moment, shoutout to Dog from Half Life 2.\nI also recall really enjoying Legion of the geth in the Mass Effect series.\n\nSo TLDR all of these have aspects that feel right and desirable - a blend of personality of TARS, a creativity of Sonny, the emotional capability of Her, and the technical problem solving capability of JARVIS.\n\nCurious what are people's favorite portrayals of AI and why?",
  "createdAt": "Mon Jan 15 17:22:56 +0000 2024",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 157,
  "replyCount": 304,
  "likeCount": 1877,
  "quoteCount": 36,
  "viewCount": 397195,
  "bookmarkCount": 502,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": -1,
  "text": "Since you are a free user, you can only access a maximum of 15 tweets. Please upgrade to a paid user to unlock access to all tweets."
}]