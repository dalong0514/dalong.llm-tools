# Andrej Karpathy Twitter 2025

æœ¬æ–‡ä»¶åŒ…å«Andrej Karpathyåœ¨2025å¹´çš„æ‰€æœ‰æ¨æ–‡ã€‚

æ€»è®¡æ¨æ–‡æ•°é‡: 113


### 001

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-01
é“¾æ¥: https://x.com/AndrewYNg/status/1874495593827156120
äº’åŠ¨: Likes: 3,050; Retweets: 307; Replies: 98; Quotes: 50; Views: 266,970; Bookmarks: 133; isReply: 0

Happy sum(i**3 for i in range(10)) !

ç¥è´º sumï¼ˆi**3 for i in rangeï¼ˆ10)ï¼‰ï¼

### 002

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-02
é“¾æ¥: https://x.com/AndrewYNg/status/1874922734444236810
äº’åŠ¨: Likes: 3,360; Retweets: 523; Replies: 126; Quotes: 40; Views: 287,241; Bookmarks: 1,916; isReply: 0

Despite having worked on AI since I was a teenager, Iâ€™m now more excited than ever about what we can do with it, especially in building AI applications. Sparks are flying in our field, and 2025 will be a great year for building!

One aspect of AI that Iâ€™m particularly excited about is how easy it is to build software prototypes. AI is lowering the cost of software development and expanding the set of possible applications. While it can help extend or maintain large software systems, it shines particularly in building prototypes and other simple applications quickly.

If you want to build an app to print out flash cards for your kids (I just did this in a couple of hours with o1â€™s help), or write an application that monitors foreign exchange rates to manage international bank accounts (a real example from https://t.co/zpIxRSuky4â€™s finance team), or analyzes user reviews automatically to quickly flag problems with your products (https://t.co/zpIxRSuky4's content team does this), it is now possible to build these applications quickly through AI-assisted coding.

I find AI-assisted coding especially effective for prototyping because (i) stand-alone prototypes require relatively little context and software integration and (ii) prototypes in alpha testing usually donâ€™t have to be reliable. While generative AI also helps with engineering large, mission-critical software systems, the improvements in productivity there aren't as dramatic, because itâ€™s challenging to give the AI system all the context it needs to navigate a large codebase and also to make sure the generated code is reliable (for example, covering all important corner cases).

Until now, a huge friction point for getting a prototype into usersâ€™ hands has been deployment. Platforms like Bolt, Replit Agent, Vercel V0 use generative AI with agentic workflows to improve code quality, but more importantly, they also help deploy generated applications directly. (While I find these systems useful, my own workflow typically uses an LLM to design the system architecture and then generate code, one module at a time if there are multiple large modules. Then I test each module, edit the code further if needed â€” sometimes using an AI-enabled IDE like Cursor â€” and finally assemble the modules.)

Building prototypes quickly is an efficient way to test ideas and get tasks done. Itâ€™s also a great way to learn. Perhaps most importantly, itâ€™s really fun! (At least I think it is. ğŸ˜„)

How can you take advantage of these opportunities in the coming year? As you form new year resolutions, I hope you will:
- Make a learning plan! To be effective builders, we all need to keep up with the exciting changes that continue to unfold. How many short courses a month do you want to take in 2025? If you discuss your learning plan with friends, you can help each other along. For instance, we launched a learning summary page that shows what short courses people have taken. A few https://t.co/zpIxRSuky4 team members have agreed to a friendly competition to see who can take more courses in 2025!
- Go build! If you already know how to code, I encourage you to build prototypes whenever inspiration strikes and you have a spare moment. And if you donâ€™t yet code, it will be well worth your while to learn. Even small wins â€” like the flash cards I printed out, which inspired my daughter to spend an extra 20 minutes practicing her multiplication table â€” make life better. Perhaps youâ€™ll invent something that really takes off. And even if you donâ€™t, youâ€™ll have fun and learn a lot along the way.

[Original text: https://t.co/YgfCpE6FL8 ]

å°½ç®¡æˆ‘ä»å°‘å¹´æ—¶ä»£å°±å¼€å§‹æ¥è§¦äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ï¼Œä½†ç°åœ¨ï¼Œæˆ‘å¯¹ AI èƒ½å¸¦æ¥çš„å¯èƒ½æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ„å»º AI åº”ç”¨ç¨‹åºæ–¹é¢ï¼Œæ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´åŠ å…´å¥‹ã€‚æˆ‘ä»¬çš„é¢†åŸŸæ­£è¿¸å‘å‡ºè€€çœ¼çš„ç«èŠ±ï¼Œ2025 å¹´å¿…å°†æ˜¯å¤§å±•å®å›¾çš„ä¸€å¹´ï¼

AI è®©æˆ‘ç‰¹åˆ«æ¿€åŠ¨çš„ä¸€ä¸ªæ–¹é¢ï¼Œæ˜¯å®ƒèƒ½è®©è½¯ä»¶åŸå‹çš„å¼€å‘å˜å¾—å¦‚æ­¤ä¾¿æ·ã€‚AI æ­£åœ¨æ˜¾è‘—é™ä½è½¯ä»¶å¼€å‘çš„æˆæœ¬ï¼Œå¹¶æå¤§åœ°æ‹“å®½äº†åº”ç”¨ç¨‹åºçš„åº”ç”¨èŒƒå›´ã€‚è™½ç„¶ AI å¯ä»¥å¸®åŠ©æ‰©å±•æˆ–ç»´æŠ¤å¤§å‹è½¯ä»¶ç³»ç»Ÿï¼Œä½†å®ƒåœ¨å¿«é€Ÿæ„å»ºåŸå‹å’Œå…¶ä»–ç®€å•åº”ç”¨æ–¹é¢è¡¨ç°å¾—å°¤ä¸ºå‡ºè‰²ã€‚

å¦‚æœä½ æƒ³å¼€å‘ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œä¸ºä½ çš„å­©å­æ‰“å°æŠ½è®¤å¡ï¼ˆæˆ‘æœ€è¿‘å°±åœ¨ o1 çš„å¸®åŠ©ä¸‹ï¼Œåªç”¨äº†å‡ ä¸ªå°æ—¶å°±åšå¥½äº†ï¼‰ï¼Œæˆ–è€…ç¼–å†™ä¸€ä¸ªç¨‹åºæ¥ç›‘æ§å¤–æ±‡æ±‡ç‡ä»¥ç®¡ç†å›½é™…é“¶è¡Œè´¦æˆ·ï¼ˆè¿™æ˜¯æ¥è‡ª https://t.co/zpIxRSuky4 è´¢åŠ¡å›¢é˜Ÿçš„ä¸€ä¸ªçœŸå®æ¡ˆä¾‹ï¼‰ï¼Œåˆæˆ–æ˜¯è‡ªåŠ¨åˆ†æç”¨æˆ·è¯„è®ºæ¥å¿«é€Ÿå‘ç°äº§å“é—®é¢˜ï¼ˆhttps://t.co/zpIxRSuky4 çš„å†…å®¹å›¢é˜Ÿå°±æ˜¯è¿™æ ·åšçš„ï¼‰ï¼Œç°åœ¨ï¼Œå€ŸåŠ© AI è¾…åŠ©ç¼–ç ï¼Œè¿™äº›åº”ç”¨ç¨‹åºéƒ½å¯ä»¥å¿«é€Ÿæ„å»ºå‡ºæ¥ã€‚

æˆ‘å‘ç° AI è¾…åŠ©ç¼–ç å¯¹åŸå‹å¼€å‘ç‰¹åˆ«æœ‰æ•ˆï¼ŒåŸå› æœ‰äºŒï¼š(iï¼‰ç‹¬ç«‹çš„ï¼ˆæŒ‡ä¸éœ€è¦ä¸ç°æœ‰å¤æ‚ç³»ç»Ÿæ·±åº¦é›†æˆçš„ï¼‰åŸå‹é€šå¸¸åªéœ€è¦ç›¸å¯¹è¾ƒå°‘çš„ä¸Šä¸‹æ–‡å’Œè½¯ä»¶é›†æˆï¼›(iiï¼‰å¤„äºå†…éƒ¨æµ‹è¯•ï¼ˆalpha testingï¼‰é˜¶æ®µçš„åŸå‹é€šå¸¸å¯¹å¯é æ€§è¦æ±‚ä¸é«˜ã€‚è™½ç„¶ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰ä¹Ÿèƒ½è¾…åŠ©å¼€å‘å¤§å‹ã€ä»»åŠ¡å…³é”®å‹è½¯ä»¶ç³»ç»Ÿï¼Œä½†åœ¨è¿™æ–¹é¢çš„ç”Ÿäº§åŠ›æå‡å°±æ²¡æœ‰é‚£ä¹ˆæ˜¾è‘—äº†ã€‚è¿™æ˜¯å› ä¸ºè¦ä¸º AI ç³»ç»Ÿæä¾›å¯¼èˆªåºå¤§ä»£ç åº“æ‰€éœ€çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œå¹¶ç¡®ä¿ç”Ÿæˆä»£ç çš„å¯é æ€§ï¼ˆä¾‹å¦‚ï¼Œè¦†ç›–æ‰€æœ‰é‡è¦çš„è¾¹ç¼˜æƒ…å†µï¼‰ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚

åœ¨æ­¤ä¹‹å‰ï¼Œå°†åŸå‹äº¤ä»˜ç»™ç”¨æˆ·çš„ä¸€å¤§éšœç¢æ˜¯éƒ¨ç½²ã€‚åƒ Boltã€Replit Agentã€Vercel V0 è¿™æ ·çš„å¹³å°ï¼Œæ­£åˆ©ç”¨ç”Ÿæˆå¼ AI ç»“åˆ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰å·¥ä½œæµæ¥æå‡ä»£ç è´¨é‡ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒä»¬è¿˜èƒ½ç›´æ¥éƒ¨ç½²æ‰€ç”Ÿæˆçš„åº”ç”¨ç¨‹åºã€‚ï¼ˆè™½ç„¶æˆ‘å‘ç°è¿™äº›ç³»ç»Ÿå¾ˆæœ‰ç”¨ï¼Œä½†æˆ‘è‡ªå·±çš„å·¥ä½œæµç¨‹é€šå¸¸ä¼šä½¿ç”¨ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è®¾è®¡ç³»ç»Ÿæ¶æ„ï¼Œç„¶åç”Ÿæˆä»£ç  â€”â€” å¦‚æœæ¶‰åŠå¤šä¸ªå¤§å‹æ¨¡å—ï¼Œæˆ‘ä¼šä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªã€‚æ¥ç€ï¼Œæˆ‘é€ä¸ªæµ‹è¯•æ¯ä¸ªæ¨¡å—ï¼Œå¦‚æœéœ€è¦è¿˜ä¼šè¿›ä¸€æ­¥ç¼–è¾‘ä»£ç  â€”â€” æœ‰æ—¶ä¼šå€ŸåŠ©åƒ Cursor è¿™æ ·é›†æˆ AI åŠŸèƒ½çš„é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDE)â€”â€” æœ€åå°†è¿™äº›æ¨¡å—ç»„è£…èµ·æ¥ã€‚ï¼‰

å¿«é€Ÿæ„å»ºåŸå‹æ˜¯éªŒè¯æƒ³æ³•å’Œå®Œæˆä»»åŠ¡çš„æœ‰æ•ˆé€”å¾„ã€‚åŒæ—¶ï¼Œå®ƒä¹Ÿæ˜¯ä¸€ä¸ªç»ä½³çš„å­¦ä¹ æ–¹å¼ã€‚æˆ–è®¸æœ€é‡è¦çš„æ˜¯ï¼Œå®ƒçœŸçš„å¾ˆæœ‰è¶£ï¼ï¼ˆè‡³å°‘æˆ‘ä¸ªäººæ˜¯è¿™ä¹ˆè®¤ä¸ºçš„ã€‚ğŸ˜„ï¼‰

é‚£ä¹ˆï¼Œåœ¨æ–°çš„ä¸€å¹´é‡Œï¼Œä½ è¯¥å¦‚ä½•æŠ“ä½è¿™äº›æœºé‡å‘¢ï¼Ÿå½“ä½ åˆ¶å®šæ–°å¹´è®¡åˆ’æ—¶ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½ï¼š
- ** åˆ¶å®šå­¦ä¹ è®¡åˆ’ï¼** è¦æƒ³æˆä¸ºé«˜æ•ˆçš„æ„å»ºè€…ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ä¸æ–­å­¦ä¹ ï¼Œè·Ÿä¸ŠæŒç»­æ¶Œç°çš„æ¿€åŠ¨äººå¿ƒçš„å˜åŒ–ã€‚ä½ å¸Œæœ›åœ¨ 2025 å¹´æ¯æœˆå‚åŠ å¤šå°‘çŸ­æœŸè¯¾ç¨‹ï¼Ÿå¦‚æœä½ ä¸æœ‹å‹è®¨è®ºå­¦ä¹ è®¡åˆ’ï¼Œä½ ä»¬å¯ä»¥äº’ç›¸ç£ä¿ƒã€å…±åŒè¿›æ­¥ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€é¡¹å­¦ä¹ æ€»ç»“é¡µé¢ï¼Œå±•ç¤ºäº†äººä»¬å‚åŠ è¿‡çš„çŸ­æœŸè¯¾ç¨‹ã€‚ä¸€äº› https://t.co/zpIxRSuky4 å›¢é˜Ÿæˆå‘˜å·²ç»åŒæ„è¿›è¡Œä¸€åœºå‹å¥½çš„æ¯”èµ›ï¼Œçœ‹çœ‹è°èƒ½åœ¨ 2025 å¹´å‚åŠ æ›´å¤šè¯¾ç¨‹ï¼
- ** åŠ¨æ‰‹æ„å»ºï¼** å¦‚æœä½ å·²ç»æ‡‚å¾—ç¼–ç ï¼Œæˆ‘é¼“åŠ±ä½ åœ¨çµæ„Ÿæ¥è¢­ã€æœ‰ç©ºé—²æ—¶é—´æ—¶ï¼Œå°±å»æ„å»ºåŸå‹ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å¼€å§‹ç¼–ç ï¼Œé‚£ä¹ˆå­¦ä¹ å®ƒå°†æ˜¯éå¸¸å€¼å¾—çš„ã€‚å³ä½¿æ˜¯å¾®å°çš„æˆåŠŸ â€”â€” æ¯”å¦‚æˆ‘ä¸ºå¥³å„¿æ‰“å°çš„é‚£äº›æŠ½è®¤å¡ï¼Œå®ƒæ¿€åŠ±å¥¹é¢å¤–èŠ± 20 åˆ†é’Ÿç»ƒä¹ ä¹˜æ³•å£è¯€ â€”â€” ä¹Ÿèƒ½è®©ç”Ÿæ´»å˜å¾—æ›´ç¾å¥½ã€‚ä¹Ÿè®¸ä½ ä¼šå‘æ˜å‡ºä¸€äº›çœŸæ­£é£é¡èµ·æ¥çš„ä¸œè¥¿ã€‚å³ä¾¿æ²¡æœ‰ï¼Œä½ ä¹Ÿä¼šåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æ”¶è·ä¹è¶£å¹¶å­¦åˆ°å¾ˆå¤šä¸œè¥¿ã€‚

[åŸæ–‡ï¼šhttps://t.co/YgfCpE6FL8]

### 003

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-02
é“¾æ¥: https://x.com/AndrewYNg/status/1874923856835772811
äº’åŠ¨: Likes: 40; Retweets: 0; Replies: 3; Quotes: 0; Views: 32,247; Bookmarks: 7; isReply: 1

@nickclegg Thank you for your work championing open source to policymakers @nickclegg -- this has made a real difference!

@nickclegg æ„Ÿè°¢æ‚¨å‘æ”¿ç­–åˆ¶å®šè€…ä»¬å¤§åŠ›æ¨å¹¿å¼€æºçš„å·¥ä½œï¼Œè¿™çœŸçš„å‘æŒ¥äº†å·¨å¤§ä½œç”¨ï¼

### 004

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-06
é“¾æ¥: https://x.com/AndrewYNg/status/1876402210931867825
äº’åŠ¨: Likes: 440; Retweets: 41; Replies: 23; Quotes: 3; Views: 45,532; Bookmarks: 21; isReply: 0

Hanging out â¦â¦with @astrotellerâ© at Google X reminiscing about the early days of Google Brain! https://t.co/2j2QWnHiTz

å’Œ @astroteller åœ¨ Google X èšä¼šï¼Œä¸€èµ·å›å¿† Google Brain çš„æ—©æœŸæ—¶å…‰ï¼https://t.co/2j2QWnHiTz

### 005

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-07
é“¾æ¥: https://x.com/AndrewYNg/status/1876701823840776521
äº’åŠ¨: Likes: 1,158; Retweets: 219; Replies: 57; Quotes: 13; Views: 135,246; Bookmarks: 706; isReply: 0

Where is AI going? Six leaders share their hopes for AI in the coming year, in The Batch:
- Hanno Basse: Generative AI for Artists
- David Ding: Generated Video With Music, Sound Effects, and Dialogue
- Joseph Gonzalez: General Intelligence
- Albert Gu: More Learning, Less Data
- Mustafa Suleyman: Agents of Action
- Audrey Tang: AI That Unites Us

Thank you @BasseHanno , @DavidDingAI, @profjoeyg, @_albertgu, @mustafasuleyman and @audreyt for writing these!  

Read them here: https://t.co/YgfCpE6FL8

AIï¼ˆäººå·¥æ™ºèƒ½ï¼‰å°†èµ°å‘ä½•æ–¹ï¼Ÿå…­ä½ä¸šç•Œé¢†è¢–åœ¨ã€ŠThe Batchã€‹æ‚å¿—ä¸­åˆ†äº«äº†ä»–ä»¬å¯¹æœªæ¥ä¸€å¹´ AI å‘å±•çš„å±•æœ›ï¼š
- Hanno Basseï¼šé¢å‘è‰ºæœ¯å®¶çš„ç”Ÿæˆå¼ AIï¼ˆGenerative AI)
- David Dingï¼šç”Ÿæˆå¼è§†é¢‘ï¼ŒåŒ…å«éŸ³ä¹ã€éŸ³æ•ˆå’Œå¯¹è¯
- Joseph Gonzalezï¼šé€šç”¨æ™ºèƒ½
- Albert Guï¼šæ›´é«˜æ•ˆçš„å­¦ä¹ ï¼Œæ›´å°‘çš„æ•°æ®éœ€æ±‚
- Mustafa Suleymanï¼šAI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰çš„è¡ŒåŠ¨åŠ›
- Audrey Tangï¼šèƒ½å¤Ÿå‡èšäººå¿ƒçš„ AI

æ„Ÿè°¢ Hanno Basseï¼ˆ@BasseHannoï¼‰ã€ David Dingï¼ˆ@DavidDingAIï¼‰ã€ Joseph Gonzalezï¼ˆ@profjoeygï¼‰ã€ Albert Guï¼ˆ@_albertguï¼‰ã€ Mustafa Suleymanï¼ˆ@mustafasuleymanï¼‰å’Œ Audrey Tangï¼ˆ@audreytï¼‰æ’°å†™çš„è¿™äº›æ–‡ç« ï¼

ç‚¹å‡»æ­¤å¤„é˜…è¯»å…¨æ–‡ï¼šhttps://t.co/YgfCpE6FL8

### 006

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-08
é“¾æ¥: https://x.com/AndrewYNg/status/1877075439283482815
äº’åŠ¨: Likes: 803; Retweets: 149; Replies: 45; Quotes: 11; Views: 76,546; Bookmarks: 586; isReply: 0

New short course: Build Long-Context AI Apps with Jamba. Learn about state space models (SSMs), which have emerged as an alternative to transformers!  Specifically, Jamba is a hybrid transformer-Mamba architecture that combines strengths of the transformer with ideas from SSMs. This course is built with  @AI21Labs and taught by @chenwai21 and @AlmagorChen.

The transformer architecture is computationally expensive when handling very long input contexts. But there's an alternative called Mamba, a selective state space model that can process very long contexts with a much lower computational cost. However, researchers found that the pure Mamba architecture underperforms in understanding the context, and gives lower-quality responses. To overcome this, AI21 developed the Jamba model, which combines Mamba's computational efficiency with the transformer's attention mechanism to help with the output quality.

In this course, youâ€™ll learn about how state space models, and Jamba, work. Youâ€™ll also learn how to prompt Jamba, use it to process long documents, and build long-context RAG apps.

- Learn how Jamba combines transformer and state space model architectures to achieve high performance and quality  
- Use the AI21 SDK, with an example of prompting over a large 200k-token annual financial report of Nvidia 
- Use Jamba for tool-calling, with hands-on examples from calling simple arithmetic calculations to a function that returns quarterly company financial reports.
- Learn how training for long context is done, and the metrics used for its evaluation 
- Create a RAG app using the AI21 Conversational RAG tool and build your own RAG pipeline that uses Jamba and LangChain.

By the end of this course, you'll learn how to build applications that can handle context as long as an entire book.

Please sign up here: https://t.co/qc6St7zK9g

æ–°çŸ­æœŸè¯¾ç¨‹ï¼šä½¿ç”¨ Jamba æ„å»ºé•¿ä¸Šä¸‹æ–‡ AI åº”ç”¨ã€‚äº†è§£çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰ï¼Œå®ƒå·²æˆä¸º Transformer çš„ä¸€ç§æ›¿ä»£æ–¹æ¡ˆã€‚å…·ä½“æ¥è¯´ï¼ŒJamba æ˜¯ä¸€ç§æ··åˆå¼çš„ Transformer-Mamba æ¶æ„ï¼Œå®ƒç»“åˆäº† Transformer çš„ä¼˜åŠ¿å’Œ SSMs çš„æ ¸å¿ƒç†å¿µã€‚æœ¬è¯¾ç¨‹ç”± @AI21Labs æ‰“é€ ï¼Œå¹¶ç”± @chenwai21 å’Œ @AlmagorChen æˆè¯¾ã€‚

Transformer æ¶æ„åœ¨å¤„ç†è¶…é•¿è¾“å…¥ä¸Šä¸‹æ–‡æ—¶è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚ä¸è¿‡ï¼Œæœ‰ä¸€ç§åä¸º Mamba çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå®ƒæ˜¯ä¸€ç§é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆselective state space modelï¼‰ï¼Œèƒ½ä»¥ä½å¾—å¤šçš„è®¡ç®—æˆæœ¬å¤„ç†æé•¿çš„ä¸Šä¸‹æ–‡ã€‚ç„¶è€Œï¼Œç ”ç©¶äººå‘˜å‘ç°çº¯ Mamba æ¶æ„åœ¨ç†è§£ä¸Šä¸‹æ–‡æ–¹é¢çš„è¡¨ç°ä¸å°½å¦‚äººæ„ï¼Œå¹¶ä¼šç”Ÿæˆè´¨é‡è¾ƒä½çš„å“åº”ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼ŒAI21 å¼€å‘äº† Jamba æ¨¡å‹ï¼Œå®ƒå°† Mamba çš„è®¡ç®—æ•ˆç‡ä¸ Transformer çš„æ³¨æ„åŠ›æœºåˆ¶ç›¸ç»“åˆï¼Œä»è€Œæé«˜äº†è¾“å‡ºè´¨é‡ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ çŠ¶æ€ç©ºé—´æ¨¡å‹ä»¥åŠ Jamba çš„å·¥ä½œåŸç†ã€‚æ‚¨è¿˜å°†å­¦ä¹ å¦‚ä½•å‘ Jamba æç¤ºï¼ˆpromptï¼‰ã€ä½¿ç”¨å®ƒå¤„ç†é•¿æ–‡æ¡£ï¼Œå¹¶æ„å»ºé•¿ä¸Šä¸‹æ–‡çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨ã€‚

-  å­¦ä¹  Jamba å¦‚ä½•ç»“åˆ Transformer å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„ï¼Œä»¥å®ç°é«˜æ€§èƒ½å’Œé«˜è´¨é‡
-  ä½¿ç”¨ AI21 SDKï¼Œä¾‹å¦‚é€šè¿‡å¯¹ Nvidia åŒ…å« 200k Token çš„å¤§å‹å¹´åº¦è´¢åŠ¡æŠ¥å‘Šè¿›è¡Œæç¤º
-  åˆ©ç”¨ Jamba è¿›è¡Œå·¥å…·è°ƒç”¨ï¼Œä»è°ƒç”¨ç®€å•çš„ç®—æœ¯è®¡ç®—åˆ°è°ƒç”¨è¿”å›å­£åº¦å…¬å¸è´¢åŠ¡æŠ¥å‘Šçš„å‡½æ•°ï¼Œéƒ½æä¾›å®é™…æ“ä½œç¤ºä¾‹
-  äº†è§£é•¿ä¸Šä¸‹æ–‡æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹åŠå…¶è¯„ä¼°æŒ‡æ ‡
-  ä½¿ç”¨ AI21 å¯¹è¯å¼ RAG å·¥å…·åˆ›å»º RAG åº”ç”¨ï¼Œå¹¶æ„å»ºè‡ªå·±çš„åŸºäº Jamba å’Œ LangChain çš„ RAG ç®¡é“åœ¨æœ¬è¯¾ç¨‹ç»“æŸæ—¶ï¼Œæ‚¨å°†å­¦ä¼šå¦‚ä½•æ„å»ºèƒ½å¤Ÿå¤„ç†ç›¸å½“äºä¸€æ•´æœ¬ä¹¦é•¿åº¦çš„ä¸Šä¸‹æ–‡çš„åº”ç”¨ç¨‹åºã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/qc6St7zK9g

### 007

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-09
é“¾æ¥: https://x.com/AndrewYNg/status/1877405010893619238
äº’åŠ¨: Likes: 3,106; Retweets: 453; Replies: 122; Quotes: 47; Views: 290,616; Bookmarks: 3,192; isReply: 0

Using AI-assisted coding to build software prototypes is an important way to quickly explore many ideas and invent new things. In this and future posts, Iâ€™d like to share with you some best practices for prototyping simple web apps. This post will focus on one idea: being opinionated about the software stack.

The software stack I personally use changes every few weeks. There are many good alternatives to these choices, and if you pick a preferred software stack and become familiar with its components, youâ€™ll be able to develop more quickly. But as an illustration, hereâ€™s my current default:
- Python with FastAPI for building web-hosted APIs: I develop primarily in Python, so thatâ€™s a natural choice for me. If youâ€™re a JavaScript/TypeScript developer, youâ€™ll likely make a different choice. Iâ€™ve found FastAPI really easy to use and scalable for deploying web services (APIs) hosted in Python.
- Uvicorn to run the backend application server (to execute code and serve web pages) for local testing on my laptop.
- If deploying on the cloud, then either Heroku for small apps or AWS Elastic Beanstalk for larger ones (disclosure: I serve on Amazonâ€™s board of directors): There are many services for deploying jobs, including HuggingFace Spaces, Railway, Googleâ€™s Firebase, Vercel, and others. Many of these work fine, and becoming familiar with just 1 or 2 will simplify your development process.
- MongoDB for NoSQL database: While traditional SQL databases are amazing feats of engineering that result in highly efficient and reliable data storage, the need to define the database structure (or schema) slows down prototyping. If you really need speed and ease of implementation, then dumping most of your data into a NoSQL (unstructured or semi-structured) database such as MongoDB lets you write code quickly and sort out later exactly what you want to do with the data. This is sometimes called schema-on-write, as opposed to schema-on-read. Mind you, if an application goes to scaled production, there are many use cases where a more structured SQL database is significantly more reliable and scalable.
- OpenAIâ€™s o1 and Anthropicâ€™s Claude 3.5 Sonnet for coding assistance, often by prompting directly (when operating at the conceptual/design level). Also occasionally Cursor (when operating at the code level).  I hope never to have to code again without AI assistance! Claude 3.5 Sonnet is widely regarded as one of the best coding models. And o1 is incredible at planning and building more complex software modules, but you do have to learn to prompt it differently.

On top of all this, of course, I use many AI tools to manage agentic workflows, data ingestion, retrieval augmented generation, and so on. https://t.co/zpIxRSuky4 and our wonderful partners offer courses on many of these tools.

My personal software stack continues to evolve regularly. Components enter or fall out of my default stack every few weeks as I learn new ways to do things. So please donâ€™t feel obliged to use the components I do, but perhaps some of them can be a helpful starting point if you are still deciding what to use. Interestingly, I have found most LLMs not very good at recommending a software stack. I suspect their training sets include too much â€œhypeâ€ on specific choices, so I donâ€™t fully trust them to tell me what to use. And if you can be opinionated and give your LLM directions on the software stack you want it to build on, I think youâ€™ll get better results.

A lot of the software stack is still maturing, and I think many of these components will continue to improve. With my stack, I regularly build prototypes in hours that, without AI assistance, would have taken me days or longer. I hope you, too, will have fun building many prototypes!

[Original text: https://t.co/cfQkXolEJk ]

åˆ©ç”¨ AI è¾…åŠ©ç¼–ç æ¥æ„å»ºè½¯ä»¶åŸå‹ï¼ˆsoftware prototypesï¼‰ï¼Œæ˜¯å¿«é€Ÿæ¢ç´¢å¤§é‡æƒ³æ³•å’Œå®ç°åˆ›æ–°å‘æ˜çš„é‡è¦é€”å¾„ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä»¥åŠæœªæ¥çš„ç³»åˆ—æ–‡ç« ä¸­ï¼Œæˆ‘å°†ä¸å¤§å®¶åˆ†äº«ä¸€äº›æ„å»ºç®€å•ç½‘ç»œåº”ç”¨åŸå‹çš„æœ€ä½³å®è·µã€‚æœ¬æ–‡çš„é‡ç‚¹å°†å›´ç»•ä¸€ä¸ªæ ¸å¿ƒç†å¿µï¼šåœ¨è½¯ä»¶å †æ ˆï¼ˆsoftware stackï¼‰çš„é€‰æ‹©ä¸Šè¦æœ‰è‡ªå·±çš„ä¸»å¼ ã€‚

æˆ‘ä¸ªäººä½¿ç”¨çš„è½¯ä»¶å †æ ˆæ¯éš”å‡ å‘¨å°±ä¼šæ›´æ–°ã€‚å½“ç„¶ï¼Œæˆ‘çš„é€‰æ‹©æœ‰è®¸å¤šä¼˜ç§€çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¦‚æœæ‚¨èƒ½é€‰å®šä¸€å¥—è‡ªå·±åå¥½çš„è½¯ä»¶å †æ ˆå¹¶ç†Ÿæ‚‰å…¶ç»„ä»¶ï¼Œæ‚¨çš„å¼€å‘æ•ˆç‡å°†ä¼šå¤§å¤§æå‡ã€‚ä¸è¿‡ï¼Œä½œä¸ºç¤ºä¾‹ï¼Œä»¥ä¸‹æ˜¯æˆ‘ç›®å‰é»˜è®¤é‡‡ç”¨çš„æŠ€æœ¯æ ˆï¼š
- **Python å’Œ FastAPI ç”¨äºæ„å»ºç½‘ç»œæ‰˜ç®¡ API**ï¼šæˆ‘ä¸»è¦ä½¿ç”¨ Python è¿›è¡Œå¼€å‘ï¼Œæ‰€ä»¥è¿™è‡ªç„¶æ˜¯æˆ‘çš„é¦–é€‰ã€‚å¦‚æœæ‚¨æ˜¯ JavaScript/TypeScript å¼€å‘è€…ï¼Œæ‚¨å¯èƒ½ä¼šåšå‡ºä¸åŒçš„é€‰æ‹©ã€‚æˆ‘å‘ç° FastAPI éå¸¸æ˜“äºä½¿ç”¨ï¼Œå¹¶ä¸”åœ¨éƒ¨ç½²åŸºäº Python çš„ Web æœåŠ¡ï¼ˆAPIï¼‰æ—¶ï¼Œå…¶å¯æ‰©å±•æ€§è¡¨ç°å‡ºè‰²ã€‚
- **Uvicorn ç”¨äºåœ¨æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šè¿›è¡Œæœ¬åœ°æµ‹è¯•æ—¶è¿è¡Œåç«¯åº”ç”¨ç¨‹åºæœåŠ¡å™¨ **ï¼ˆç”¨äºæ‰§è¡Œä»£ç å’Œæä¾›ç½‘é¡µï¼‰ã€‚
- ** äº‘ç«¯éƒ¨ç½²æ–¹æ¡ˆ **ï¼šå°å‹åº”ç”¨å¯é€‰æ‹© Herokuï¼Œå¤§å‹åº”ç”¨åˆ™ä½¿ç”¨ AWS Elastic Beanstalkï¼ˆæŠ«éœ²ï¼šæˆ‘ç›®å‰æ˜¯ Amazon çš„è‘£äº‹ä¼šæˆå‘˜ï¼‰ã€‚å¸‚åœºä¸Šè¿˜æœ‰è®¸å¤šç”¨äºéƒ¨ç½²ä»»åŠ¡çš„æœåŠ¡ï¼ŒåŒ…æ‹¬ HuggingFace Spacesã€Railwayã€Google çš„ Firebaseã€Vercel ç­‰ã€‚å…¶ä¸­å¤§å¤šæ•°éƒ½è¿è¡Œè‰¯å¥½ï¼Œç†Ÿæ‚‰å…¶ä¸­ä¸€ä¸¤ä¸ªå°†èƒ½æ˜¾è‘—ç®€åŒ–æ‚¨çš„å¼€å‘æµç¨‹ã€‚
- **MongoDB ç”¨äº NoSQL æ•°æ®åº“ **ï¼šè™½ç„¶ä¼ ç»Ÿçš„ SQL æ•°æ®åº“æ˜¯å“è¶Šçš„å·¥ç¨‹æˆå°±ï¼Œèƒ½å¤Ÿå®ç°é«˜æ•ˆå¯é çš„æ•°æ®å­˜å‚¨ï¼Œä½†éœ€è¦é¢„å…ˆå®šä¹‰æ•°æ®åº“ç»“æ„ï¼ˆæˆ–æ¨¡å¼ Schemaï¼‰è¿™ä¸€ç‚¹ï¼Œä¼šå‡ç¼“åŸå‹å¼€å‘çš„è¿›ç¨‹ã€‚å¦‚æœæ‚¨ç¡®å®è¿½æ±‚å¼€å‘é€Ÿåº¦å’Œå®ç°ä¾¿æ·æ€§ï¼Œé‚£ä¹ˆå°†å¤§éƒ¨åˆ†æ•°æ®å­˜å‚¨åˆ° NoSQLï¼ˆéç»“æ„åŒ–æˆ–åŠç»“æ„åŒ–ï¼‰æ•°æ®åº“ï¼ˆä¾‹å¦‚ MongoDBï¼‰ä¸­ï¼Œèƒ½è®©æ‚¨å¿«é€Ÿç¼–å†™ä»£ç ï¼Œå¹¶éšåå†è¯¦ç»†è§„åˆ’å¦‚ä½•ä½¿ç”¨è¿™äº›æ•°æ®ã€‚è¿™ç§æ–¹å¼æœ‰æ—¶è¢«ç§°ä¸º ** å†™å…¥æ—¶æ¨¡å¼ **ï¼ˆschema-on-writeï¼‰ï¼Œä¸ ** è¯»å–æ—¶æ¨¡å¼ **ï¼ˆschema-on-readï¼‰ç›¸å¯¹åº”ï¼Œæ„å‘³ç€åœ¨æ•°æ®å†™å…¥æ—¶æ‰ç¡®å®šå…¶ç»“æ„ï¼Œè€Œéæå‰å®šä¹‰ã€‚ä½†è¯·æ³¨æ„ï¼Œå¦‚æœåº”ç”¨ç¨‹åºæŠ•å…¥å¤§è§„æ¨¡ç”Ÿäº§ï¼Œåœ¨è®¸å¤šåœºæ™¯ä¸‹ï¼Œç»“æ„æ›´æ¸…æ™°çš„ SQL æ•°æ®åº“ä¼šè¡¨ç°å¾—æ›´ä¸ºå¯é å’Œå¯æ‰©å±•ã€‚
- **OpenAI çš„ o1 å’Œ Anthropic çš„ Claude 3.5 Sonnet ç”¨äºç¼–ç è¾…åŠ© **ï¼šé€šå¸¸åœ¨æ¦‚å¿µ / è®¾è®¡å±‚é¢é€šè¿‡ç›´æ¥æç¤ºï¼ˆpromptingï¼‰ä½¿ç”¨ï¼Œå¶å°”ä¹Ÿä¼šåœ¨ä»£ç å±‚é¢ä½¿ç”¨ Cursorã€‚æˆ‘çœŸå¿ƒå¸Œæœ›ä»Šå coding éƒ½èƒ½æœ‰ AI æ™ºèƒ½ä½“çš„ååŠ©ï¼Claude 3.5 Sonnet è¢«æ™®éè®¤ä¸ºæ˜¯æœ€å¥½çš„ç¼–ç æ¨¡å‹ä¹‹ä¸€ã€‚è€Œ o1 åœ¨è§„åˆ’å’Œæ„å»ºæ›´å¤æ‚çš„è½¯ä»¶æ¨¡å—æ–¹é¢è¡¨ç°éå‡¡ï¼Œä½†æ‚¨ç¡®å®éœ€è¦å­¦ä¹ å¦‚ä½•ä»¥ä¸åŒçš„æ–¹å¼å¯¹å…¶è¿›è¡Œæç¤ºã€‚

å½“ç„¶ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘è¿˜ä½¿ç”¨äº†è®¸å¤š AI å·¥å…·æ¥ç®¡ç† AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰å·¥ä½œæµã€æ•°æ®æ‘„å…¥ï¼ˆdata ingestionï¼‰ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval Augmented Generationï¼‰ç­‰ç­‰ã€‚https://t.co/zpIxRSuky4 å’Œæˆ‘ä»¬å‡ºè‰²çš„åˆä½œä¼™ä¼´æä¾›äº†è®¸å¤šå…³äºè¿™äº›å·¥å…·çš„è¯¾ç¨‹ã€‚

æˆ‘ä¸ªäººçš„è½¯ä»¶å †æ ˆä¼šå®šæœŸæŒç»­æ¼”è¿›ã€‚æ¯éš”å‡ å‘¨ï¼Œéšç€æˆ‘å­¦ä¹ åˆ°æ–°çš„åšäº‹æ–¹å¼ï¼Œä¸€äº›ç»„ä»¶ä¼šè¿›å…¥æˆ–é€€å‡ºæˆ‘çš„é»˜è®¤æŠ€æœ¯æ ˆã€‚å› æ­¤ï¼Œè¯·å¤§å®¶ä¸å¿…æ‹˜æ³¥äºæˆ‘æ‰€ä½¿ç”¨çš„ç»„ä»¶ï¼Œä½†å¦‚æœæ‚¨ä»åœ¨é€‰æ‹©ï¼Œå…¶ä¸­çš„æŸäº›æˆ–è®¸èƒ½ä¸ºæ‚¨æä¾›ä¸€ä¸ªæœ‰ç›Šçš„èµ·ç‚¹ã€‚æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘å‘ç°å¤§å¤šæ•°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼ŒLLMï¼‰åœ¨æ¨èè½¯ä»¶å †æ ˆæ–¹é¢è¡¨ç°å¹¶ä¸ç†æƒ³ã€‚æˆ‘æ€€ç–‘å®ƒä»¬çš„è®­ç»ƒé›†åŒ…å«äº†å¤ªå¤šå…³äºç‰¹å®šé€‰æ‹©çš„ã€Œè¿‡åº¦å®£ä¼ ã€ï¼Œæ‰€ä»¥æˆ‘å¹¶ä¸å®Œå…¨ä¿¡ä»»å®ƒä»¬ç»™å‡ºçš„å»ºè®®ã€‚è€Œå¦‚æœæ‚¨èƒ½æœ‰è‡ªå·±çš„ä¸»è§ï¼Œå¹¶å‘å¤§è¯­è¨€æ¨¡å‹æ˜ç¡®æŒ‡ç¤ºæ‚¨å¸Œæœ›å®ƒåŸºäºçš„è½¯ä»¶å †æ ˆï¼Œæˆ‘ç›¸ä¿¡æ‚¨ä¼šè·å¾—æ›´å¥½çš„ç»“æœã€‚

è®¸å¤šè½¯ä»¶å †æ ˆä»åœ¨ä¸æ–­æˆç†Ÿï¼Œæˆ‘ç›¸ä¿¡è¿™äº›ç»„ä»¶ä¸­çš„è®¸å¤šéƒ½å°†æŒç»­æ”¹è¿›ã€‚å€ŸåŠ©æˆ‘è¿™å¥—æŠ€æœ¯æ ˆï¼Œæˆ‘ç»å¸¸èƒ½åœ¨å‡ å°æ—¶å†…æ„å»ºå‡ºåŸå‹ï¼Œè€Œå¦‚æœç¼ºå°‘ AI è¾…åŠ©ï¼Œè¿™å¯èƒ½éœ€è¦æ•°å¤©ç”šè‡³æ›´é•¿çš„æ—¶é—´ã€‚æˆ‘ä¹Ÿå¸Œæœ›æ‚¨èƒ½åœ¨æ„å»ºä¼—å¤šåŸå‹çš„è¿‡ç¨‹ä¸­äº«å—ä¹è¶£ï¼

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/cfQkXolEJk]

### 008

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-14
é“¾æ¥: https://x.com/AndrewYNg/status/1879253685232144487
äº’åŠ¨: Likes: 1,853; Retweets: 349; Replies: 166; Quotes: 69; Views: 169,765; Bookmarks: 778; isReply: 0

Just released: New AI Climate Simulator that you can play with. Visualize how geoengineering can slow global warming. 

There is no longer any path to limiting warming to 1.5 degrees Celsius (Paris Agreement), unless we use geoengineering. Reflecting 1% of sunlight away from earth would lead to an extra ~1 degree of cooling.

Our simulator lets you explore how geoengineering via Stratospheric Aerosol Injection (SAI) gives us new paths to keep warming to 1.5 degrees. I think SAI is a promising technology worth serious exploration. Check out the simulator here: https://t.co/OxtaQMyDuL

Big thanks to collaborators @jeremy_irvin16, Jake Dexheimer, @dakotagruener, Charlotte DeWald, @DanVisioni, @DWatsonParris, @DougMacMartin, Joshua Elliott, Juerg Luterbacher, Kion Yaghoobzadeh

æ–°å‘å¸ƒï¼šä½ å¯ä»¥äº²èº«ä½“éªŒçš„æ–° AI æ°”å€™æ¨¡æ‹Ÿå™¨ï¼ç›´è§‚åœ°äº†è§£åœ°çƒå·¥ç¨‹ï¼ˆgeoengineeringï¼‰å¦‚ä½•å‡ç¼“å…¨çƒå˜æš–ã€‚

é™¤éæˆ‘ä»¬é‡‡å–åœ°çƒå·¥ç¨‹æªæ–½ï¼Œå¦åˆ™å·²æ²¡æœ‰ä»»ä½•é€”å¾„èƒ½å°†å…¨çƒå‡æ¸©é™åˆ¶åœ¨ã€Šå·´é»åå®šã€‹è®¾å®šçš„ 1.5 æ‘„æ°åº¦ä»¥å†…ã€‚å¦‚æœèƒ½å°† 1% çš„å¤ªé˜³å…‰åå°„å‡ºåœ°çƒï¼Œå°±èƒ½é¢å¤–å®ç°å¤§çº¦ 1 æ‘„æ°åº¦çš„é™æ¸©ã€‚

æˆ‘ä»¬çš„æ¨¡æ‹Ÿå™¨èƒ½è®©ä½ æ¢ç´¢ï¼Œé€šè¿‡å¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ï¼ˆStratospheric Aerosol Injectionï¼ŒSAIï¼‰è¿™ç§åœ°çƒå·¥ç¨‹æŠ€æœ¯ï¼Œæˆ‘ä»¬å¦‚ä½•æ‰¾åˆ°æ–°çš„è·¯å¾„æ¥å°†å…¨çƒå‡æ¸©æ§åˆ¶åœ¨ 1.5 æ‘„æ°åº¦ã€‚æˆ‘è®¤ä¸º SAI æ˜¯ä¸€é¡¹å‰æ™¯å¹¿é˜”ã€å€¼å¾—è®¤çœŸæ¢ç´¢çš„æŠ€æœ¯ã€‚è¯·åœ¨è¿™é‡ŒæŸ¥çœ‹æ¨¡æ‹Ÿå™¨ï¼šhttps://t.co/OxtaQMyDuL

è¡·å¿ƒæ„Ÿè°¢å„ä½åˆä½œè€…ï¼š@jeremy_irvin16ï¼ŒJake Dexheimerï¼Œ@dakotagruenerï¼ŒCharlotte DeWaldï¼Œ@DanVisioniï¼Œ@DWatsonParrisï¼Œ@DougMacMartinï¼ŒJoshua Elliottï¼ŒJuerg Luterbacherï¼ŒKion Yaghoobzadeh

### 009

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-15
é“¾æ¥: https://x.com/AndrewYNg/status/1879590674561110219
äº’åŠ¨: Likes: 997; Retweets: 158; Replies: 65; Quotes: 22; Views: 107,480; Bookmarks: 491; isReply: 0

Something fun: AI Avatar of me built, by https://t.co/zpIxRSuky4 and @realavatarai. 

Video has details. This is a work in progress, but please come chat with me in avatar form, and let me know what you think!

https://t.co/vMO2CM0xfb

Thank you Jeff Daniel @consciouspilot and team for working with us on this!

ä¸€ä¸ªæœ‰è¶£çš„æ¶ˆæ¯ï¼šæˆ‘çš„ AI å¤´åƒï¼ˆAI Avatarï¼‰å·²ç»ç”± https://t.co/zpIxRSuky4 å’Œ @realavatarai æ‰“é€ å®Œæˆã€‚

è§†é¢‘ä¸­åŒ…å«è¯¦ç»†ä¿¡æ¯ã€‚è¿™é¡¹å·¥ä½œä»åœ¨è¿›è¡Œä¸­ï¼Œæ¬¢è¿å¤§å®¶ä»¥æˆ‘çš„ AI å¤´åƒå½¢å¼ä¸æˆ‘äº¤æµï¼Œå¹¶å‘Šè¯‰æˆ‘ä½ ä»¬çš„æƒ³æ³•ï¼

https://t.co/vMO2CM0xfb

æ„Ÿè°¢ Jeff Daniel @consciouspilot å’Œå›¢é˜Ÿä¸æˆ‘ä»¬åˆä½œå®Œæˆè¿™é¡¹å·¥ä½œï¼

### 010

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-15
é“¾æ¥: https://x.com/AndrewYNg/status/1879641073880076513
äº’åŠ¨: Likes: 13; Retweets: 1; Replies: 1; Quotes: 0; Views: 5,991; Bookmarks: 0; isReply: 1

@dimapyanov @realavatarai It has been great fun working with you on the product  @dimapyanov -- thank you!

@dimapyanov @realavatarai èƒ½ä¸ä½ åœ¨è¿™ä¸ªäº§å“ä¸Šåˆä½œï¼Œæˆ‘æ„Ÿåˆ°éå¸¸æ„‰å¿« @dimapyanov -- è°¢è°¢ä½ ï¼

### 011

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-15
é“¾æ¥: https://x.com/AndrewYNg/status/1879641293401502163
äº’åŠ¨: Likes: 1; Retweets: 0; Replies: 0; Quotes: 0; Views: 1,559; Bookmarks: 0; isReply: 1

@nedteneva @realavatarai @DeepLearningAI I've really enjoyed working with you @nedteneva on the tech powering this -- thank you!

@nedteneva @realavatarai @DeepLearningAI æˆ‘éå¸¸è£å¹¸èƒ½ä¸ä½  @nedteneva ä¸€èµ·ï¼Œä¸ºè¿™é¡¹æŠ€æœ¯æä¾›æ”¯æŒ -- è°¢è°¢ä½ ï¼

### 012

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-16
é“¾æ¥: https://x.com/AndrewYNg/status/1879939058211971420
äº’åŠ¨: Likes: 5,439; Retweets: 1,023; Replies: 187; Quotes: 198; Views: 875,043; Bookmarks: 4,685; isReply: 0

Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!

Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements â€” such as cars (with internal-combustion engines) and gasoline â€” falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build.

This is why Iâ€™m excited about the future of Product Management, the discipline of developing and managing software products. Iâ€™m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products.

Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow.

This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow.

Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires:
- Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.
- Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need be able to manage such a process.
- Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software.
- Skill in managing ambiguity. Because AIâ€™s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it.
- Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into usersâ€™ lives.

Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves.

The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.

The variety of valuable things we can build is nearly unlimited. What a great time to build!

[Original text: https://t.co/OIeAQXpriK ]

å¼€å‘è½¯ä»¶ï¼Œå°¤å…¶æ˜¯åˆ¶ä½œåŸå‹ï¼Œå¦‚ä»Šæˆæœ¬è¶Šæ¥è¶Šä½ã€‚è¿™æ„å‘³ç€å¯¹é‚£äº›èƒ½å†³å®šã€Œåšä»€ä¹ˆäº§å“ã€çš„äººçš„éœ€æ±‚å°†å¤§å¹…å¢åŠ ã€‚å› æ­¤ï¼ŒAI äº§å“ç®¡ç†ï¼ˆAI Product Managementï¼‰çš„æœªæ¥ä¸€ç‰‡å…‰æ˜ï¼

è½¯ä»¶å¼€å‘é€šå¸¸ç”±å›¢é˜Ÿåä½œå®Œæˆï¼Œå…¶ä¸­åŒ…å«äº§å“ç»ç†ï¼ˆPMsï¼‰ï¼Œä»–ä»¬è´Ÿè´£å†³å®šäº§å“æ–¹å‘ï¼ˆæ¯”å¦‚ä¸ºå“ªäº›ç”¨æˆ·å¼€å‘å“ªäº›åŠŸèƒ½ï¼‰ï¼Œä»¥åŠè½¯ä»¶å¼€å‘äººå‘˜ï¼ˆSoftware Developersï¼‰ï¼Œä»–ä»¬ç¼–å†™ä»£ç æ¥å°†äº§å“å˜ä¸ºç°å®ã€‚ç»æµå­¦åŸç†å‘Šè¯‰æˆ‘ä»¬ï¼Œå½“ä¸¤ç§å•†å“æ˜¯äº’è¡¥å“æ—¶ â€”â€” æ¯”å¦‚æ±½è½¦ï¼ˆå†…ç‡ƒæœºï¼‰å’Œæ±½æ²¹ â€”â€” å…¶ä¸­ä¸€ç§å•†å“ä»·æ ¼çš„ä¸‹é™ï¼Œä¼šå¯¼è‡´å¯¹å¦ä¸€ç§å•†å“éœ€æ±‚çš„å¢é•¿ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œéšç€æ±½è½¦ä»·æ ¼å˜å¾—æ›´äº²æ°‘ï¼Œè´­ä¹°æ±½è½¦çš„äººå°±è¶Šå¤šï¼Œè¿™è‡ªç„¶æ¨é«˜äº†å¯¹æ±½æ²¹çš„éœ€æ±‚ã€‚ç±»ä¼¼çš„æƒ…å†µä¹Ÿä¼šå‘ç”Ÿåœ¨è½¯ä»¶é¢†åŸŸã€‚åœ¨æœ‰äº†æ¸…æ™°æ˜ç¡®çš„äº§å“è§„æ ¼åï¼Œäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ­£åœ¨è®©è½¯ä»¶æ„å»ºè¿‡ç¨‹å˜å¾—æ›´å¿«ã€æ›´ä¾¿å®œã€‚è¿™å°†æå¤§åœ°å¢åŠ å¯¹é‚£äº›èƒ½ä¸ºæœ‰ä»·å€¼çš„äº§å“æˆ–åŠŸèƒ½æå‡ºæ¸…æ™°è§„æ ¼çš„äººæ‰çš„éœ€æ±‚ã€‚

æ­£å› å¦‚æ­¤ï¼Œæˆ‘å¯¹äº§å“ç®¡ç†ï¼ˆProduct Managementï¼‰çš„æœªæ¥å……æ»¡æœŸå¾…ï¼Œå®ƒæ˜¯ä¸€é—¨å…³äºå¼€å‘å’Œç®¡ç†è½¯ä»¶äº§å“çš„å­¦é—®ã€‚æˆ‘å°¤å…¶çœ‹å¥½ AI äº§å“ç®¡ç†çš„å‘å±•å‰æ™¯ï¼Œå®ƒä¸“æ³¨äºå¼€å‘å’Œç®¡ç† AI è½¯ä»¶äº§å“ã€‚

è®¸å¤šå…¬å¸å·¥ç¨‹å¸ˆä¸äº§å“ç»ç†çš„æ¯”ä¾‹å¯èƒ½åœ¨ 6:1 å·¦å³ã€‚ï¼ˆè¿™ä¸ªæ¯”ä¾‹å› å…¬å¸å’Œè¡Œä¸šè€Œå¼‚ï¼Œé€šå¸¸åœ¨ 4:1 åˆ° 10:1 ä¹‹é—´ã€‚ï¼‰éšç€ç¼–ç æ•ˆç‡çš„æå‡ï¼Œå›¢é˜Ÿæ‰€éœ€çš„æ€»åŠ³åŠ¨åŠ›ä¸­ï¼Œäº§å“ç®¡ç†å·¥ä½œï¼ˆä»¥åŠè®¾è®¡å·¥ä½œï¼‰æ‰€å çš„æ¯”ä¾‹å°†ä¼šå¢åŠ ã€‚æˆ–è®¸æœ‰äº›å·¥ç¨‹å¸ˆä¼šæ‰¿æ‹…ä¸€éƒ¨åˆ†è¿™ç±»å·¥ä½œï¼Œä½†å¦‚æœè¿™ä»ç„¶æ˜¯ä¸“ä¸šäº§å“ç»ç†çš„èŒè´£èŒƒç•´ï¼Œé‚£ä¹ˆå¯¹è¿™äº›è§’è‰²çš„éœ€æ±‚å°†åªå¢ä¸å‡ã€‚

ç›®å‰ï¼Œè½¯ä»¶å¼€å‘å›¢é˜Ÿæ„æˆä¸Šçš„è¿™ç§è½¬å˜å°šæœªå®Œå…¨åŠ é€Ÿã€‚å‡ç¼“è¿™ä¸€è½¬å˜çš„ä¸€ä¸ªä¸»è¦å› ç´ ï¼Œå°¤å…¶æ˜¯åœ¨ AI äº§å“ç®¡ç†é¢†åŸŸï¼Œæ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆå‡­å€Ÿå…¶æŠ€æœ¯èƒŒæ™¯ï¼Œæ¯”äº§å“ç»ç†æ›´å¿«åœ°ç†è§£å’Œæ¥å— AIã€‚å³ä½¿åœ¨ä»Šå¤©ï¼Œå¤§å¤šæ•°å…¬å¸éƒ½å¾ˆéš¾æ‰¾åˆ°æ—¢æ‡‚å¾—äº§å“å¼€å‘åˆç†è§£ AI çš„äººæ‰ï¼Œæˆ‘é¢„è®¡è¿™ç§äººæ‰çŸ­ç¼ºå°†æ—¥ç›Šä¸¥é‡ã€‚

æ­¤å¤–ï¼ŒAI äº§å“ç®¡ç†éœ€è¦ä¸€å¥—ä¸åŒäºä¼ ç»Ÿè½¯ä»¶äº§å“ç®¡ç†çš„æŠ€èƒ½ã€‚å®ƒè¦æ±‚ï¼š
- **AI æŠ€æœ¯ç†Ÿç»ƒåº¦ ** äº§å“ç»ç†éœ€è¦äº†è§£å“ªäº›äº§å“åœ¨æŠ€æœ¯ä¸Šæ˜¯å¯è¡Œçš„ã€‚ä»–ä»¬è¿˜éœ€è¦ç†Ÿæ‚‰ AI é¡¹ç›®çš„ç”Ÿå‘½å‘¨æœŸï¼Œä¾‹å¦‚æ•°æ®æ”¶é›†ã€æ¨¡å‹æ„å»ºï¼Œä»¥åŠåç»­çš„ AI æ¨¡å‹ï¼ˆAI Modelsï¼‰ç›‘æ§å’Œç»´æŠ¤ã€‚
- ** è¿­ä»£å¼€å‘èƒ½åŠ› ** AI å¼€å‘æ¯”ä¼ ç»Ÿè½¯ä»¶å¼€å‘æ›´å…·è¿­ä»£æ€§ï¼Œè¿‡ç¨‹ä¸­éœ€è¦æ›´å¤šæ¬¡çš„æ–¹å‘è°ƒæ•´ï¼Œå› æ­¤äº§å“ç»ç†éœ€è¦å…·å¤‡ç®¡ç†è¿™ç§æµç¨‹çš„èƒ½åŠ›ã€‚
- ** æ•°æ®ç´ å…» ** AI äº§å“é€šå¸¸ä¾èµ–æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå¹¶ä¸”å¯ä»¥è®¾è®¡æˆç”Ÿæˆæ¯”ä¼ ç»Ÿè½¯ä»¶æ›´ä¸°å¯Œçš„æ•°æ®å½¢å¼ã€‚
- ** ç®¡ç†ä¸ç¡®å®šæ€§çš„æŠ€èƒ½ ** ç”±äº AI æ€§èƒ½éš¾ä»¥æå‰é¢„æµ‹ï¼Œäº§å“ç»ç†éœ€è¦é€‚åº”è¿™ç§ä¸ç¡®å®šæ€§ï¼Œå¹¶æŒæ¡åº”å¯¹ç­–ç•¥ã€‚
- ** æŒç»­å­¦ä¹ ç²¾ç¥ ** AI æŠ€æœ¯æ­£é£é€Ÿå‘å±•ã€‚äº§å“ç»ç†ï¼Œåƒæ‰€æœ‰å¸Œæœ›å……åˆ†åˆ©ç”¨è¿™é¡¹æŠ€æœ¯çš„äººä¸€æ ·ï¼Œéœ€è¦ä¸æ–­è·Ÿè¿›æœ€æ–°çš„æŠ€æœ¯è¿›å±•ã€äº§å“ç†å¿µï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•èå…¥ç”¨æˆ·ç”Ÿæ´»ã€‚

æœ€åï¼ŒAI äº§å“ç»ç†è¿˜éœ€è¦æ‡‚å¾—å¦‚ä½•ç¡®ä¿ AI å¾—åˆ°è´Ÿè´£ä»»çš„å®æ–½ï¼ˆä¾‹å¦‚ï¼Œä½•æ—¶éœ€è¦è®¾ç½®é˜²æŠ¤æªæ–½ä»¥é˜²æ­¢ä¸è‰¯ç»“æœï¼‰ï¼Œå¹¶ä¸”è¦æ“…é•¿å¿«é€Ÿæ”¶é›†åé¦ˆï¼Œä»è€Œæ¨åŠ¨é¡¹ç›®è¿›å±•ã€‚æˆ‘è¶Šæ¥è¶ŠæœŸå¾…ä¼˜ç§€çš„äº§å“ç»ç†ä¹Ÿèƒ½äº²è‡ªåŠ¨æ‰‹æ„å»ºåŸå‹ã€‚

å¸‚åœºå¯¹ä¼˜ç§€çš„ AI äº§å“ç»ç†çš„éœ€æ±‚å°†éå¸¸æ—ºç››ã€‚é™¤äº†å°† AI äº§å“ç®¡ç†ä½œä¸ºä¸€é—¨ç‹¬ç«‹å­¦ç§‘å‘å±•ä¹‹å¤–ï¼Œä¹Ÿè®¸ä¸€äº›å·¥ç¨‹å¸ˆæœ€ç»ˆä¹Ÿå°†æ‰¿æ‹…æ›´å¤šçš„äº§å“ç®¡ç†å·¥ä½œã€‚

æˆ‘ä»¬èƒ½åˆ›é€ çš„æœ‰ä»·å€¼çš„äº‹ç‰©å‡ ä¹æ²¡æœ‰é™åˆ¶ã€‚è¿™æ˜¯ä¸€ä¸ªå¤šä¹ˆæ¿€åŠ¨äººå¿ƒçš„åˆ›é€ æ—¶ä»£å•Šï¼

[åŸå§‹æ–‡æœ¬ï¼šhttps://t.co/OIeAQXpriK]

### 013

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-18
é“¾æ¥: https://x.com/AndrewYNg/status/1880728653329514606
äº’åŠ¨: Likes: 739; Retweets: 55; Replies: 53; Quotes: 6; Views: 68,313; Bookmarks: 51; isReply: 0

Save the date! Pi day (3.14) is coming soon and I'm thinking of organizing something fun and in-person for AI developers in the San Francisco area. More details to come!

æ—¥æœŸå®šå•¦ï¼åœ†å‘¨ç‡æ—¥ï¼ˆ3.14ï¼‰å³å°†åˆ°æ¥ï¼Œæˆ‘æ­£è®¡åˆ’ä¸ºæ—§é‡‘å±±åœ°åŒºçš„ AI å¼€å‘è€…ä¸¾åŠä¸€åœºæœ‰è¶£çš„çº¿ä¸‹æ´»åŠ¨ã€‚æ›´å¤šè¯¦æƒ…å³å°†å…¬å¸ƒï¼Œæ•¬è¯·æœŸå¾…ï¼

### 014

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-22
é“¾æ¥: https://x.com/AndrewYNg/status/1882125891821822398
äº’åŠ¨: Likes: 2,181; Retweets: 321; Replies: 48; Quotes: 17; Views: 168,406; Bookmarks: 1,973; isReply: 0

Our first short course with @AnthropicAI! Building Towards Computer Use with Anthropic. This teaches you to build an LLM-based agent that uses a computer interface by generating mouse clicks and keystrokes. Computer Use is an important, emerging capability for LLMs that will let AI agents do many more tasks than were possible before, since it lets them interact with interfaces designed for humans to use, rather than only tools that provide explicit API access. I hope you will enjoy learning about it!

This course is taught by Anthropic's Head of Curriculum,  @Colt_Steele. You'll learn to apply image reasoning and tool use to "use" a computer as follows: a model processes an image of the screen, analyzes it to understand what's going on, and navigates the computer via mouse clicks and keystrokes.

This course goes through the key building blocks, and culminates in a demo of an AI assistant that uses a web browser to search for a research paper, downloads the PDF, and finally summarizes the paper for you.

In detail, youâ€™ll:
- Learn about Anthropic's family of models, when to use which one, and make API requests to Claude
- Use multi-modal prompts that combine text and image content blocks, and also work with streaming responses
- Improve your prompting by using prompt templates, using XML to structure prompts, and providing examples
- Implement prompt caching to reduce cost and latency
- Apply tool-use to build a chatbot that can call different tools to respond to queries
- See all these building blocks come together in Computer Use demo

Please sign up here: https://t.co/lM3m6zsJ40

æˆ‘ä»¬ä¸ @AnthropicAI è”åˆæ¨å‡ºçš„é¦–ä¸ªçŸ­æœŸè¯¾ç¨‹æ¥å•¦ï¼æœ¬è¯¾ç¨‹åä¸ºã€Œä¸ Anthropic å…±æ¢è®¡ç®—æœºä½¿ç”¨èƒ½åŠ›ã€ã€‚å®ƒå°†æ•™ä½ å¦‚ä½•æ„å»ºä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼ŒLLMï¼‰çš„ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ï¼Œè¯¥æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡æ¨¡æ‹Ÿé¼ æ ‡ç‚¹å‡»å’Œé”®ç›˜è¾“å…¥æ¥æ“ä½œè®¡ç®—æœºç•Œé¢ã€‚å¯¹ LLM æ¥è¯´ï¼Œã€Œè®¡ç®—æœºä½¿ç”¨èƒ½åŠ›ã€æ˜¯ä¸€é¡¹é‡è¦çš„æ–°å…´æŠ€èƒ½ï¼Œå®ƒèƒ½è®© AI æ™ºèƒ½ä½“å®Œæˆè¿œè¶…ä»¥å¾€çš„ä»»åŠ¡ï¼Œå› ä¸ºè¿™ä½¿å¾—å®ƒä»¬å¯ä»¥ä¸ä¸“ä¸ºäººç±»è®¾è®¡çš„ç•Œé¢è¿›è¡Œäº¤äº’ï¼Œè€Œä¸å†å±€é™äºé‚£äº›åªæä¾›æ˜ç¡® APIï¼ˆåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼‰è®¿é—®çš„å·¥å…·ã€‚å¸Œæœ›å¤§å®¶äº«å—å­¦ä¹ è¿‡ç¨‹ï¼

æœ¬è¯¾ç¨‹ç”± Anthropic çš„è¯¾ç¨‹è´Ÿè´£äºº @Colt_Steele äº²è‡ªè®²æˆã€‚ä½ å°†å­¦åˆ°å¦‚ä½•è¿ç”¨å›¾åƒæ¨ç†å’Œå·¥å…·ä½¿ç”¨ï¼ˆTool Useï¼‰æ¥ã€Œæ“ä½œã€è®¡ç®—æœºï¼Œå…·ä½“æµç¨‹æ˜¯ï¼šæ¨¡å‹å¤„ç†å±å¹•å›¾åƒï¼Œå¯¹å…¶è¿›è¡Œåˆ†æä»¥ç†è§£å½“å‰æƒ…å†µï¼Œç„¶åé€šè¿‡æ¨¡æ‹Ÿé¼ æ ‡ç‚¹å‡»å’Œé”®ç›˜è¾“å…¥æ¥å¯¼èˆªè®¡ç®—æœºã€‚

æœ¬è¯¾ç¨‹å°†è¯¦ç»†ä»‹ç»è¿™é¡¹èƒ½åŠ›çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œå¹¶æœ€ç»ˆå±•ç¤ºä¸€ä¸ª AI åŠ©æ‰‹æ¼”ç¤ºï¼Œè¯¥åŠ©æ‰‹èƒ½å¤Ÿåˆ©ç”¨ç½‘ç»œæµè§ˆå™¨æœç´¢ç ”ç©¶è®ºæ–‡ï¼Œä¸‹è½½ PDF æ–‡æ¡£ï¼Œå¹¶æœ€ç»ˆä¸ºä½ æ€»ç»“è®ºæ–‡å†…å®¹ã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- äº†è§£ Anthropic çš„æ¨¡å‹å®¶æ—ï¼Œå­¦ä¹ ä½•æ—¶é€‰æ‹©ä½¿ç”¨å“ªç§æ¨¡å‹ï¼Œå¹¶å‘ Claude å‘å‡º API è¯·æ±‚
- ä½¿ç”¨ç»“åˆæ–‡æœ¬å’Œå›¾åƒå†…å®¹å—çš„å¤šæ¨¡æ€æç¤ºï¼Œå¹¶å­¦ä¹ å¦‚ä½•å¤„ç†æµå¼å“åº”
- é€šè¿‡ä½¿ç”¨æç¤ºæ¨¡æ¿ã€åˆ©ç”¨ XML ç»“æ„åŒ–æç¤ºä»¥åŠæä¾›ç¤ºä¾‹æ¥ä¼˜åŒ–ä½ çš„æç¤ºè¯
- å®ç°æç¤ºç¼“å­˜ï¼ˆPrompt Cachingï¼‰ä»¥é™ä½æˆæœ¬å’Œå»¶è¿Ÿ
- åº”ç”¨å·¥å…·ä½¿ç”¨ï¼ˆTool Useï¼‰æ¥æ„å»ºä¸€ä¸ªèƒ½å¤Ÿè°ƒç”¨ä¸åŒå·¥å…·å“åº”æŸ¥è¯¢çš„èŠå¤©æœºå™¨äºº
- åœ¨ã€Œè®¡ç®—æœºä½¿ç”¨ã€æ¼”ç¤ºä¸­ï¼Œäº²çœ¼è§è¯æ‰€æœ‰è¿™äº›æ„å»ºæ¨¡å—å¦‚ä½•ååŒè¿ä½œè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/lM3m6zsJ40

### 015

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-24
é“¾æ¥: https://x.com/AndrewYNg/status/1882828225979760651
äº’åŠ¨: Likes: 274; Retweets: 57; Replies: 49; Quotes: 7; Views: 75,434; Bookmarks: 106; isReply: 0

Discussion at Davos with @Yoshua_Bengio, @YejinChoinka, @JonathanRoss321, @Thom_Wolf moderated by @nxthompson. We share excitement for the future of AI, the science to be done, and the many things yet to be built. Take a look!

åœ¨è¾¾æ²ƒæ–¯ä¸ @Yoshua_Bengioã€@YejinChoinkaã€@JonathanRoss321ã€@Thom_Wolf è¿›è¡Œäº†è®¨è®ºï¼Œä¼šè®®ç”± @nxthompson ä¸»æŒã€‚æˆ‘ä»¬éƒ½å¯¹äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„æœªæ¥å……æ»¡æœŸå¾…ï¼Œå¯¹éœ€è¦æ·±å…¥è¿›è¡Œçš„ç§‘å­¦ç ”ç©¶æ„Ÿåˆ°å…´å¥‹ï¼Œä¹Ÿå¯¹æœªæ¥æœ‰å¾…æ„å»ºçš„ä¼—å¤šäº‹ç‰©å……æ»¡æ†§æ†¬ã€‚å¿«æ¥çœ‹çœ‹å§ï¼

### 016

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-27
é“¾æ¥: https://x.com/AndrewYNg/status/1883972263177072730
äº’åŠ¨: Likes: 7,160; Retweets: 1,027; Replies: 243; Quotes: 194; Views: 789,390; Bookmarks: 1,230; isReply: 0

Today's "DeepSeek selloff" in the stock market -- attributed to DeepSeek V3/R1 disrupting the tech ecosystem -- is another sign that the application layer is a great place to be. The foundation model layer being  hyper-competitive is great for people building applications.

ä»Šå¤©è‚¡å¸‚ä¸­çš„ã€ŒDeepSeek å¤§è·Œã€ï¼ˆDeepSeek selloffï¼‰â€”â€” è¿™è¢«å½’å› äº DeepSeek V3/R1 æ­£åœ¨é¢ è¦†ï¼ˆdisruptingï¼‰ç§‘æŠ€ç”Ÿæ€ç³»ç»Ÿ â€”â€” å†æ¬¡è¡¨æ˜ï¼Œåº”ç”¨å±‚ï¼ˆapplication layerï¼‰æ˜¯ä¸€ä¸ªæå…·æ½œåŠ›çš„é¢†åŸŸã€‚åŸºç¡€æ¨¡å‹å±‚ï¼ˆfoundation model layerï¼‰çš„è¶…é«˜ç«äº‰åº¦å¯¹äºé‚£äº›å¼€å‘åº”ç”¨ç¨‹åºçš„äººæ¥è¯´ï¼Œåè€Œæ˜¯ä¸€ä»¶å¥½äº‹ã€‚

### 017

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-29
é“¾æ¥: https://x.com/AndrewYNg/status/1884723330839961664
äº’åŠ¨: Likes: 552; Retweets: 41; Replies: 34; Quotes: 2; Views: 61,656; Bookmarks: 41; isReply: 0

Welcome Greg Hart as Courseraâ€™s incoming CEO!

Iâ€™m thrilled to announce that Greg will be joining Coursera as CEO, succeeding Jeff Maggioncalda after seven remarkable years of leadership.

Jeff has been an extraordinary leader. Under his guidance, Coursera has grown into a global platform serving over 160 million learners, expanded our partnerships to over 350 world-class universities and industry leaders, and debuted as a public company. Coursera exists to serve learners, and Jeffâ€™s unwavering commitment to our goal of transforming lives through learning leaves an enduring legacy. Iâ€™m deeply grateful for his leadership, dedication, and partnership throughout this journey.

And, Iâ€™m thrilled to welcome Greg Hart as our next CEO. Greg brings over 25 years of experience in technology-driven innovation and operational excellence, including leading the development and launch of Amazon Alexa and scaling Prime Video globally. At Compass, the leading real estate brokerage in the US, Greg served as Chief Product Officer and later Chief Operating Officer, where he helped take the company public and led the development of its industry-leading technology platform. His ability to combine strategic vision with operational excellence, coupled with his passion for education, makes him the ideal choice to lead Coursera into its next chapter.

Coursera was founded with a mission to provide universal access to world-class learning. Iâ€™m grateful for everyone who has contributed to this journey â€“ learners, educators, our team, and our many partners who have helped us advance this vision in countless ways. Yet, demand for high-quality training continues to grow, and our mission is far from complete. As we enter this next chapter, Iâ€™m excited about Gregâ€™s leadership and what the exceptional Coursera team will do. We will keep working hard to serve learners everywhere!

 https://t.co/chvmwiqVGi

æ¬¢è¿ Greg Hart å‡ºä»» Coursera æ–°ä»»é¦–å¸­æ‰§è¡Œå®˜ï¼

æˆ‘éå¸¸é«˜å…´åœ°å®£å¸ƒï¼ŒGreg å°†åŠ å…¥ Coursera æ‹…ä»»é¦–å¸­æ‰§è¡Œå®˜ï¼Œæ¥æ›¿ Jeff Maggioncalda å“è¶Šé¢†å¯¼ä¸ƒå¹´åçš„èŒä½ã€‚

Jeff æ˜¯ä¸€ä½æ°å‡ºçš„é¢†å¯¼è€…ã€‚åœ¨ä»–çš„æŒ‡å¯¼ä¸‹ï¼ŒCoursera å·²å‘å±•æˆä¸ºä¸€ä¸ªæœåŠ¡å…¨çƒè¶…è¿‡ 1.6 äº¿å­¦ä¹ è€…çš„å¹³å°ï¼Œå°†æˆ‘ä»¬çš„åˆä½œä¼™ä¼´å…³ç³»æ‰©å±•åˆ°è¶…è¿‡ 350 æ‰€ä¸–ç•Œä¸€æµå¤§å­¦å’Œè¡Œä¸šé¢†å¯¼è€…ï¼Œå¹¶æˆåŠŸä¸Šå¸‚ã€‚Coursera è‡´åŠ›äºæœåŠ¡å­¦ä¹ è€…ï¼ŒJeff å§‹ç»ˆåšå®šåœ°è‡´åŠ›äºé€šè¿‡å­¦ä¹ æ”¹å˜ç”Ÿæ´»çš„ç›®æ ‡ï¼Œç•™ä¸‹äº†æ·±è¿œå½±å“ã€‚æˆ‘æ·±åˆ‡æ„Ÿè°¢ä»–åœ¨æ­¤æœŸé—´çš„é¢†å¯¼ã€å¥‰çŒ®ä¸åˆä½œã€‚

åŒæ—¶ï¼Œæˆ‘éå¸¸é«˜å…´åœ°æ¬¢è¿ Greg Hart æ‹…ä»»æˆ‘ä»¬çš„ä¸‹ä¸€ä»»é¦–å¸­æ‰§è¡Œå®˜ã€‚Greg å¸¦æ¥äº†è¶…è¿‡ 25 å¹´çš„æŠ€æœ¯åˆ›æ–°å’Œå“è¶Šè¿è¥ç»éªŒï¼Œå…¶ä¸­åŒ…æ‹¬é¢†å¯¼ Amazon Alexa çš„å¼€å‘ä¸å‘å¸ƒï¼Œä»¥åŠåœ¨å…¨çƒèŒƒå›´å†…æ¨å¹¿ Prime Videoã€‚åœ¨ç¾å›½é¢†å…ˆçš„æˆ¿åœ°äº§ç»çºªå…¬å¸ Compassï¼ŒGreg æ›¾æ‹…ä»»é¦–å¸­äº§å“å®˜ï¼Œéšåå‡ä»»é¦–å¸­è¿è¥å®˜ï¼Œåœ¨æ­¤æœŸé—´ï¼Œä»–å¸®åŠ©å…¬å¸æˆåŠŸä¸Šå¸‚ï¼Œå¹¶ä¸»å¯¼å¼€å‘äº†å…¶è¡Œä¸šé¢†å…ˆçš„æŠ€æœ¯å¹³å°ã€‚ä»–ä¸ä»…èƒ½å°†æˆ˜ç•¥æ„¿æ™¯ä¸å“è¶Šçš„è¿è¥èƒ½åŠ›ç›¸ç»“åˆï¼Œè¿˜å¯¹æ•™è‚²å……æ»¡çƒ­æƒ…ï¼Œè¿™ä½¿ä»–æˆä¸ºå¸¦é¢† Coursera å¼€å¯æ–°ç¯‡ç« çš„ç†æƒ³äººé€‰ã€‚

Coursera çš„åˆ›ç«‹ä½¿å‘½æ˜¯æ™®åŠä¸–ç•Œä¸€æµçš„æ•™è‚²ã€‚æˆ‘æ„Ÿè°¢æ‰€æœ‰ä¸ºè¿™æ®µæ—…ç¨‹åšå‡ºè´¡çŒ®çš„äºº â€”â€” å­¦ä¹ è€…ã€æ•™è‚²å·¥ä½œè€…ã€æˆ‘ä»¬çš„å›¢é˜Ÿï¼Œä»¥åŠæ— æ•°ä»¥å„ç§æ–¹å¼å¸®åŠ©æˆ‘ä»¬æ¨è¿›è¿™ä¸€æ„¿æ™¯çš„åˆä½œä¼™ä¼´ã€‚ç„¶è€Œï¼Œå¯¹é«˜è´¨é‡åŸ¹è®­çš„éœ€æ±‚ä»åœ¨æŒç»­å¢é•¿ï¼Œæˆ‘ä»¬çš„ä½¿å‘½è¿œæœªå®Œæˆã€‚å½“æˆ‘ä»¬è¿ˆå…¥ä¸‹ä¸€ä¸ªç¯‡ç« æ—¶ï¼Œæˆ‘ä¸º Greg çš„é¢†å¯¼ä»¥åŠå“è¶Šçš„ Coursera å›¢é˜Ÿå³å°†åˆ›é€ çš„æˆå°±æ„Ÿåˆ°å…´å¥‹ã€‚æˆ‘ä»¬å°†ç»§ç»­åŠªåŠ›ï¼Œä¸ºä¸–ç•Œå„åœ°çš„å­¦ä¹ è€…æœåŠ¡ï¼

 https://t.co/chvmwiqVGi

### 018

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-01-30
é“¾æ¥: https://x.com/AndrewYNg/status/1885033810552905814
äº’åŠ¨: Likes: 4,405; Retweets: 1,048; Replies: 290; Quotes: 128; Views: 614,217; Bookmarks: 1,983; isReply: 0

The buzz over DeepSeek this week crystallized, for many people, a few important trends that have been happening in plain sight: (i) China is catching up to the U.S. in generative AI, with implications for the AI supply chain. (ii) Open weight models are commoditizing the foundation-model layer, which creates opportunities for application builders. (iii) Scaling up isnâ€™t the only path to AI progress. Despite the massive focus on and hype around processing power, algorithmic innovations are rapidly pushing down training costs.

About a week ago, DeepSeek, a company based in China, released DeepSeek-R1, a remarkable model whose performance on benchmarks is comparable to OpenAIâ€™s o1. Further, it was released as an open weight model with a permissive MIT license. At Davos last week, I got a lot of questions about it from non-technical business leaders. And on Monday, the stock market saw a â€œDeepSeek selloffâ€: The share prices of Nvidia and a number of other U.S. tech companies plunged. (As of the time of writing, some have recovered somewhat.)

Hereâ€™s what I think DeepSeek has caused many people to realize:

China is catching up to the U.S. in generative AI. When ChatGPT was launched in November 2022, the U.S. was significantly ahead of China in generative AI. Impressions change slowly, and so even recently I heard friends in both the U.S. and China say they thought China was behind. But in reality, this gap has rapidly eroded over the past two years. With models from China such as Qwen (which my teams have used for months), Kimi, InternVL, and DeepSeek, China had clearly been closing the gap, and in areas such as video generation there were already moments where China seemed to be in the lead.

Iâ€™m thrilled that DeepSeek-R1 was released as an open weight model, with a technical report that shares many details. In contrast, a number of U.S. companies have pushed for regulation to stifle open source by hyping up hypothetical AI dangers such as human extinction. It is now clear that open source/open weight models are a key part of the AI supply chain: Many companies will use them. If the U.S. continues to stymie open source, China will come to dominate this part of the supply chain and many businesses will end up using models that reflect Chinaâ€™s values much more than Americaâ€™s.

Open weight models are commoditizing the foundation-model layer. As I wrote previously, LLM token prices have been falling rapidly, and open weights have contributed to this trend and given developers more choice. OpenAIâ€™s o1 costs $60 per million output tokens; DeepSeek R1 costs $2.19. This nearly 30x difference brought the trend of falling prices to the attention of many people.

The business of training foundation models and selling API access is tough. Many companies in this area are still looking for a path to recouping the massive cost of model training. Sequoiaâ€™s article â€œAIâ€™s $600B Questionâ€ lays out the challenge well (but, to be clear, I think the foundation model companies are doing great work, and I hope they succeed). In contrast, building applications on top of foundation models presents many great business opportunities. Now that others have spent billions training such models, you can access these models for mere dollars to build customer service chatbots, email summarizers, AI doctors, legal document assistants, and much more.

Scaling up isnâ€™t the only path to AI progress. Thereâ€™s been a lot of hype around scaling up models as a way to drive progress. To be fair, I was an early proponent of scaling up models. A number of companies raised billions of dollars by generating buzz around the narrative that, with more capital, they could (i) scale up and (ii) predictably drive improvements. Consequently, there has been a huge focus on scaling up, as opposed to a more nuanced view that gives due attention to the many different ways we can make progress. Driven in part by the U.S. AI chip embargo, the DeepSeek team had to innovate on many optimizations to run on less-capable H800 GPUs rather than H100s, leading ultimately to a model trained (omitting research costs) for under $6M of compute.

It remains to be seen if this will actually reduce demand for compute. Sometimes making each unit of a good cheaper can result in more dollars in total going to buy that good. I think the demand for intelligence and compute has practically no ceiling over the long term, so I remain bullish that humanity will use more intelligence even as it gets cheaper.

I saw many different interpretations of DeepSeekâ€™s progress here in X, as if it was a Rorschach test that allowed many people to project their own meaning onto it. I think DeepSeek-R1 has geopolitical implications that are yet to be worked out. And itâ€™s also great for AI application builders. My team has already been brainstorming ideas that are newly possible only because we have easy access to an open advanced reasoning model. This continues to be a great time to build!

[Original text: https://t.co/yiOHeGJgLZ ]

æœ¬å‘¨å›´ç»• DeepSeek äº§ç”Ÿçš„çƒ­è®®ï¼Œè®©è®¸å¤šäººæ¸…æ¥šåœ°è®¤è¯†åˆ°å‡ ä¸ªä¸€ç›´åœ¨æ‚„ç„¶å‘ç”Ÿçš„é‡è¦è¶‹åŠ¿ï¼š(iï¼‰ä¸­å›½åœ¨ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰æ–¹é¢æ­£åœ¨è¿½èµ¶ç¾å›½ï¼Œè¿™å¯¹ AI ä¾›åº”é“¾æœ‰ç€æ·±è¿œå½±å“ã€‚(iiï¼‰å¼€æ”¾æƒé‡æ¨¡å‹ï¼ˆOpen weight modelsï¼‰æ­£åœ¨è®©åŸºç¡€æ¨¡å‹å±‚å•†å“åŒ–ï¼Œè¿™ä¸ºåº”ç”¨ç¨‹åºå¼€å‘è€…åˆ›é€ äº†æ–°çš„æœºé‡ã€‚(iiiï¼‰ä¸€å‘³è¿½æ±‚è§„æ¨¡åŒ–å¹¶é AI è¿›æ­¥çš„å”¯ä¸€é€”å¾„ã€‚å°½ç®¡ç®—åŠ›å¤‡å—å…³æ³¨å¹¶è¢«å¤§è‚†ç‚’ä½œï¼Œä½†ç®—æ³•åˆ›æ–°æ­£åœ¨è¿…é€Ÿé™ä½æ¨¡å‹è®­ç»ƒæˆæœ¬ã€‚

å¤§çº¦ä¸€å‘¨å‰ï¼Œä¸€å®¶ä¸­å›½å…¬å¸ DeepSeek å‘å¸ƒäº† DeepSeek-R1ï¼Œè¿™æ˜¯ä¸€æ¬¾å“è¶Šçš„æ¨¡å‹ï¼Œå…¶åœ¨åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°è¶³ä»¥ä¸ OpenAI çš„ o1 ç›¸åª²ç¾ã€‚æ›´ä»¤äººæŒ¯å¥‹çš„æ˜¯ï¼Œå®ƒä»¥å¼€æ”¾æƒé‡æ¨¡å‹å½¢å¼å‘å¸ƒï¼Œå¹¶é‡‡ç”¨äº†å®½æ¾çš„ MIT è®¸å¯è¯ã€‚ä¸Šå‘¨åœ¨è¾¾æ²ƒæ–¯ï¼Œæˆ‘æ”¶åˆ°äº†è®¸å¤šéæŠ€æœ¯å•†ä¸šé¢†è¢–å…³äºå®ƒçš„æé—®ã€‚æœ¬å‘¨ä¸€ï¼Œè‚¡å¸‚ç”šè‡³å‡ºç°äº†ã€ŒDeepSeek æŠ›å”®ã€ï¼šNvidia å’Œè®¸å¤šå…¶ä»–ç¾å›½ç§‘æŠ€å…¬å¸çš„è‚¡ä»·åº”å£°æš´è·Œã€‚ï¼ˆæˆªè‡³æœ¬æ–‡æ’°å†™æ—¶ï¼Œéƒ¨åˆ†è‚¡ä»·å·²æœ‰æ‰€å›å‡ã€‚ï¼‰

ä»¥ä¸‹æ˜¯æˆ‘è®¤ä¸º DeepSeek è®©è®¸å¤šäººæ„è¯†åˆ°çš„å‡ ç‚¹ï¼š

ä¸­å›½åœ¨ç”Ÿæˆå¼ AI æ–¹é¢æ­£åœ¨è¿½èµ¶ç¾å›½ã€‚å½“ ChatGPT äº 2022 å¹´ 11 æœˆé—®ä¸–æ—¶ï¼Œç¾å›½åœ¨ç”Ÿæˆå¼ AI é¢†åŸŸç¡®å®æ˜¾è‘—é¢†å…ˆäºä¸­å›½ã€‚äººä»¬çš„å›ºæœ‰å°è±¡æ”¹å˜ç¼“æ…¢ï¼Œå› æ­¤å³ä½¿æœ€è¿‘ï¼Œæˆ‘ä»å¬åˆ°ç¾å›½å’Œä¸­å›½çš„æœ‹å‹è¯´ä»–ä»¬è®¤ä¸ºä¸­å›½åœ¨è¿™æ–¹é¢ä»å¤„äºåŠ£åŠ¿ã€‚ä½†å®é™…ä¸Šï¼Œè¿™ä¸ªå·®è·åœ¨è¿‡å»ä¸¤å¹´ä¸­å·²è¿…é€Ÿå¼¥åˆã€‚éšç€æ¥è‡ªä¸­å›½çš„ Qwenï¼ˆæˆ‘çš„å›¢é˜Ÿå·²ä½¿ç”¨æ•°æœˆï¼‰ã€Kimiã€InternVL å’Œ DeepSeek ç­‰æ¨¡å‹çš„ç›¸ç»§é—®ä¸–ï¼Œä¸­å›½æ˜¾ç„¶ä¸€ç›´åœ¨æ‹‰è¿‘ä¸ç¾å›½çš„è·ç¦»ï¼Œåœ¨è§†é¢‘ç”Ÿæˆç­‰æŸäº›é¢†åŸŸï¼Œä¸­å›½ç”šè‡³ä¸€åº¦å±•ç°å‡ºé¢†å…ˆçš„æ€åŠ¿ã€‚

æˆ‘å¾ˆé«˜å…´ DeepSeek-R1 èƒ½ä»¥å¼€æ”¾æƒé‡æ¨¡å‹å½¢å¼å‘å¸ƒï¼ŒåŒæ—¶è¿˜é™„å¸¦äº†ä¸€ä»½è¯¦å°½çš„æŠ€æœ¯æŠ¥å‘Šã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¸€äº›ç¾å›½å…¬å¸å´é€šè¿‡å¤¸å¤§ã€Œäººç±»ç­ç»ã€ç­‰å‡è®¾çš„ AI å±é™©ï¼Œæ¥æ¨åŠ¨ç›‘ç®¡ä»¥æ‰“å‹å¼€æºã€‚å¦‚ä»Šï¼Œå¼€æº / å¼€æ”¾æƒé‡æ¨¡å‹å·²æ˜ç¡®æˆä¸º AI ä¾›åº”é“¾çš„å…³é”®ä¸€ç¯ï¼šæœªæ¥ä¼šæœ‰å¤§é‡å…¬å¸ä½¿ç”¨å®ƒä»¬ã€‚å¦‚æœç¾å›½ç»§ç»­é˜»ç¢å¼€æºå‘å±•ï¼Œä¸­å›½å°†ä¸»å¯¼è¿™éƒ¨åˆ†ä¾›åº”é“¾ï¼Œå±Šæ—¶è®¸å¤šä¼ä¸šæœ€ç»ˆå°†ä¸å¾—ä¸ä½¿ç”¨é‚£äº›æ›´åæ˜ ä¸­å›½ä»·å€¼è§‚è€Œéç¾å›½ä»·å€¼è§‚çš„æ¨¡å‹ã€‚

å¼€æ”¾æƒé‡æ¨¡å‹æ­£åœ¨è®©åŸºç¡€æ¨¡å‹å±‚å•†å“åŒ–ã€‚æ­£å¦‚æˆ‘ä¹‹å‰æ‰€å†™ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰tokenï¼ˆTokenï¼‰çš„ä»·æ ¼ä¸€ç›´åœ¨è¿…é€Ÿä¸‹è·Œï¼Œå¼€æ”¾æƒé‡æ¨¡å‹å¯¹æ­¤è¶‹åŠ¿èµ·åˆ°äº†æ¨åŠ¨ä½œç”¨ï¼Œå¹¶ä¸ºå¼€å‘è€…æä¾›äº†æ›´å¤šé€‰æ‹©ã€‚OpenAI çš„ o1 æ¯ç™¾ä¸‡è¾“å‡º token æˆæœ¬ä¸º 60 ç¾å…ƒï¼›è€Œ DeepSeek R1 ä»…ä¸º 2.19 ç¾å…ƒã€‚è¿™è¿‘ 30 å€çš„å·¨å¤§å·®å¼‚ï¼Œè®©ä»·æ ¼æŒç»­ä¸‹é™çš„è¶‹åŠ¿å—åˆ°äº†æ›´å¤šäººçš„å…³æ³¨ã€‚

è®­ç»ƒåŸºç¡€æ¨¡å‹å¹¶é”€å”® API è®¿é—®å¹¶éæ˜“äº‹ã€‚è®¸å¤šèº«å¤„è¿™ä¸ªé¢†åŸŸçš„å…¬å¸ä»åœ¨æ¢ç´¢å¦‚ä½•æ”¶å›å·¨é¢çš„æ¨¡å‹è®­ç»ƒæˆæœ¬ã€‚Sequoia çš„æ–‡ç« ã€ŒAI çš„ 6000 äº¿ç¾å…ƒé—®é¢˜ã€å¾ˆå¥½åœ°é˜è¿°äº†è¿™ä¸€æŒ‘æˆ˜ï¼ˆä½†éœ€è¦æ¾„æ¸…çš„æ˜¯ï¼Œæˆ‘è®¤ä¸ºåŸºç¡€æ¨¡å‹å…¬å¸æ­£åœ¨åšç€äº†ä¸èµ·çš„å·¥ä½œï¼Œæˆ‘å¸Œæœ›å®ƒä»¬èƒ½æˆåŠŸï¼‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨åŸºç¡€æ¨¡å‹ä¹‹ä¸Šæ„å»ºåº”ç”¨ç¨‹åºåˆ™å¸¦æ¥äº†è®¸å¤šå·¨å¤§çš„å•†ä¸šæœºé‡ã€‚æ—¢ç„¶å·²æœ‰å…¬å¸æŠ•å…¥æ•°åäº¿ç¾å…ƒè®­ç»ƒå‡ºè¿™äº›æ¨¡å‹ï¼Œä½ ç°åœ¨åªéœ€èŠ±è´¹åŒºåŒºå‡ ç¾å…ƒï¼Œå°±èƒ½è®¿é—®è¿™äº›æ¨¡å‹ï¼Œä»è€Œæ„å»ºå®¢æˆ·æœåŠ¡èŠå¤©æœºå™¨äººã€ç”µå­é‚®ä»¶æ‘˜è¦å™¨ã€AI åŒ»ç”Ÿã€æ³•å¾‹æ–‡æ¡£åŠ©æ‰‹ç­‰ç­‰ã€‚

è§„æ¨¡åŒ–å¹¶é AI è¿›æ­¥çš„å”¯ä¸€é€”å¾„ã€‚æ­¤å‰ï¼Œå°†æ¨¡å‹è§„æ¨¡åŒ–ä½œä¸ºæ¨åŠ¨ AI è¿›æ­¥çš„å”¯ä¸€é€”å¾„è¢«å¤§è‚†ç‚’ä½œã€‚å¹³å¿ƒè€Œè®ºï¼Œæˆ‘æ›¾æ˜¯æ¨¡å‹è§„æ¨¡åŒ–çš„æ—©æœŸå€¡å¯¼è€…ã€‚ä¸€äº›å…¬å¸é€šè¿‡å®£æ‰¬è¿™æ ·çš„è®ºè°ƒ â€”â€” åªè¦æœ‰æ›´å¤šèµ„é‡‘ï¼Œå°±èƒ½ï¼ˆiï¼‰æ‰©å¤§è§„æ¨¡å¹¶ï¼ˆiiï¼‰æŒç»­å®ç°å¯é¢„æµ‹çš„æ”¹è¿› â€”â€” ä»è€Œåˆ¶é€ è½°åŠ¨æ•ˆåº”ï¼Œç­¹é›†äº†æ•°åäº¿ç¾å…ƒã€‚å› æ­¤ï¼Œäººä»¬å¯¹è§„æ¨¡åŒ–ç»™äºˆäº†å·¨å¤§å…³æ³¨ï¼Œè€Œå¿½è§†äº†å¯¹å–å¾—è¿›æ­¥çš„å¤šç§ä¸åŒé€”å¾„çš„æ›´ç»†è‡´è€ƒé‡ã€‚éƒ¨åˆ†å—ç¾å›½ AI èŠ¯ç‰‡ç¦è¿çš„å½±å“ï¼ŒDeepSeek å›¢é˜Ÿä¸å¾—ä¸è¿›è¡Œå¤§é‡ä¼˜åŒ–åˆ›æ–°ï¼Œä»¥ä½¿æ¨¡å‹èƒ½åœ¨æ€§èƒ½ç›¸å¯¹è¾ƒä½çš„ H800 GPU è€Œé H100 ä¸Šè¿è¡Œï¼Œæœ€ç»ˆä½¿å¾—è¯¥æ¨¡å‹çš„è®­ç»ƒè®¡ç®—æˆæœ¬ï¼ˆä¸åŒ…æ‹¬ç ”ç©¶æˆæœ¬ï¼‰ä½äº 600 ä¸‡ç¾å…ƒã€‚

è¿™æ˜¯å¦çœŸçš„ä¼šå‡å°‘å¯¹ç®—åŠ›çš„éœ€æ±‚ï¼Œè¿˜æœ‰å¾…è§‚å¯Ÿã€‚æœ‰æ—¶ï¼Œå•†å“å•ä½ä»·æ ¼çš„é™ä½åè€Œä¼šä¿ƒä½¿äººä»¬è´­ä¹°æ›´å¤šï¼Œä»è€Œå¢åŠ æ€»æ”¯å‡ºã€‚æˆ‘è®¤ä¸ºä»é•¿è¿œæ¥çœ‹ï¼Œå¯¹æ™ºèƒ½å’Œç®—åŠ›çš„éœ€æ±‚å‡ ä¹æ²¡æœ‰ä¸Šé™ï¼Œæ‰€ä»¥æˆ‘ä»ç„¶ä¹è§‚åœ°è®¤ä¸ºï¼Œå³ä½¿æ™ºèƒ½å˜å¾—æ›´ä¾¿å®œï¼Œäººç±»ä¹Ÿä¼šä½¿ç”¨æ›´å¤šçš„æ™ºèƒ½ã€‚

æˆ‘åœ¨è¿™é‡Œçš„ X ä¸Šçœ‹åˆ°äº†è®¸å¤šå¯¹ DeepSeek è¿›å±•çš„ä¸åŒè§£è¯»ï¼Œå°±å¥½åƒå®ƒæ˜¯ä¸€é¢ç½—å¤æµ‹è¯•ï¼ˆRorschach testï¼‰çš„é•œå­ï¼Œè®©è®¸å¤šäººå°†è‡ªå·±çš„æ„ä¹‰æŠ•å°„åˆ°ä¸Šé¢ã€‚æˆ‘è®¤ä¸º DeepSeek-R1 å…·æœ‰å°šæœªæ˜æœ—çš„åœ°ç¼˜æ”¿æ²»å½±å“ã€‚åŒæ—¶ï¼Œå®ƒå¯¹ AI åº”ç”¨ç¨‹åºå¼€å‘è€…ä¹Ÿæ˜¯ä¸€ä¸ªé‡å¤§åˆ©å¥½ã€‚æˆ‘çš„å›¢é˜Ÿå·²ç»å¼€å§‹é›†æ€å¹¿ç›Šï¼Œæå‡ºäº†è®¸å¤šä»¥å‰æ— æ³•å®ç°ï¼Œç°åœ¨å› æˆ‘ä»¬èƒ½è½»æ¾è®¿é—®ä¸€ä¸ªå¼€æ”¾çš„é«˜çº§æ¨ç†æ¨¡å‹è€Œå˜ä¸ºå¯èƒ½çš„æ–°æƒ³æ³•ã€‚è¿™ä»ç„¶æ˜¯åˆ›é€ çš„ç»ä½³æ—¶æœºï¼

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/yiOHeGJgLZ]

### 019

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-01
é“¾æ¥: https://x.com/AndrewYNg/status/1885522069301211562
äº’åŠ¨: Likes: 14; Retweets: 1; Replies: 4; Quotes: 0; Views: 6,579; Bookmarks: 3; isReply: 1

@StanfordHAI @landay @erikbryn @alex_pentland @YejinChoinka Fun event, and great to see @StanfordHAI have such a strong presence at WEF. Thank you @landay for organizing this!

@StanfordHAI @landay @erikbryn @alex_pentland @YejinChoinka è¿™æ¬¡æ´»åŠ¨å¾ˆæœ‰è¶£ï¼Œå¾ˆé«˜å…´çœ‹åˆ° @StanfordHAI åœ¨ WEF æœ‰å¦‚æ­¤å¼ºå¤§çš„å½±å“åŠ›ã€‚æ„Ÿè°¢ @landay çš„ç»„ç»‡ï¼

### 020

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-04
é“¾æ¥: https://x.com/AndrewYNg/status/1886833904235241753
äº’åŠ¨: Likes: 630; Retweets: 94; Replies: 160; Quotes: 14; Views: 72,526; Bookmarks: 148; isReply: 0

Announcing AI Dev 25: A conference for AI developers, this Pi day (3/14/2025)!

There're great AI academic conferences for researchers (NeurIPS, ICLR, ICML, etc.) and some companies hold great meetings around their products (Google I/O, OpenAI DevDay, etc.). But we need more vendor-neutral meetings for AI developers, so I decided to organize this. 

This is a technical meeting, and we'll have >400 developers gathering in-person in San Francisco to build, share ideas, and network.

This will be fun! https://t.co/i4bQevDG4i

éš†é‡å®£å¸ƒ AI Dev 25ï¼šä¸€åœºä¸“ä¸º AI å¼€å‘è€…ä¸¾åŠçš„ä¼šè®®ï¼Œå®šäºä»Šå¹´çš„åœ†å‘¨ç‡æ—¥ï¼ˆ3/14/2025ï¼‰ä¸¾è¡Œï¼

ç›®å‰ï¼Œæˆ‘ä»¬æœ‰å¾ˆå¤šé¢å‘ç ”ç©¶äººå‘˜çš„ä¼˜ç§€ AI å­¦æœ¯ä¼šè®®ï¼ˆä¾‹å¦‚ NeurIPSï¼ŒICLRï¼ŒICML ç­‰ï¼‰ï¼Œä¹Ÿæœ‰ä¸€äº›å…¬å¸å›´ç»•å…¶äº§å“ä¸¾åŠçš„ç²¾å½©æ´»åŠ¨ï¼ˆå¦‚ Google I/Oï¼ŒOpenAI DevDay ç­‰ï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ›´å¤šé¢å‘ AI å¼€å‘è€…ã€ä¸”ã€Œä¾›åº”å•†ä¸­ç«‹ã€çš„èšä¼šï¼Œå› æ­¤æˆ‘å†³å®šç»„ç»‡æ­¤æ¬¡ç››ä¼šã€‚

è¿™å°†æ˜¯ä¸€åœºçº¯æŠ€æœ¯æ€§çš„ä¼šè®®ï¼Œå±Šæ—¶å°†æœ‰è¶…è¿‡ 400 åå¼€å‘è€…é½èšæ—§é‡‘å±±ï¼Œå¤§å®¶å°†é¢å¯¹é¢åœ°èšåœ¨ä¸€èµ·ï¼Œå…±åŒæ„å»ºã€åˆ†äº«åˆ›æ„å¹¶è¿›è¡Œäº¤æµã€‚

è¿™åœºæ´»åŠ¨ä¸€å®šä¼šéå¸¸æœ‰è¶£ï¼https://t.co/i4bQevDG4i

### 021

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-04
é“¾æ¥: https://x.com/AndrewYNg/status/1886871011578273818
äº’åŠ¨: Likes: 1,083; Retweets: 43; Replies: 24; Quotes: 3; Views: 70,298; Bookmarks: 37; isReply: 0

Thank you @NYSE for highlighting Coursera on your trading floor to help us celebrate Greg Hart joining as our CEO! ğŸ‰ https://t.co/JNe3wvPyNY

æ„Ÿè°¢ @NYSE åœ¨ä½ ä»¬çš„äº¤æ˜“å¤§å…å®£ä¼  Courseraï¼Œå’Œæˆ‘ä»¬ä¸€åŒåº†ç¥ Greg Hart å‡ºä»»å…¬å¸é¦–å¸­æ‰§è¡Œå®˜ï¼ğŸ‰ https://t.co/JNe3wvPyNY

### 022

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-05
é“¾æ¥: https://x.com/AndrewYNg/status/1887184924165492940
äº’åŠ¨: Likes: 1,594; Retweets: 258; Replies: 44; Quotes: 19; Views: 236,843; Bookmarks: 1,308; isReply: 0

Announcing How Transformer LLMs Work, created with @JayAlammar and @MaartenGr, co-authors of the beautifully illustrated book, â€œHands-On Large Language Models.â€

This course offers a deep dive into the inner workings of the transformer architecture that powers large language models (LLMs).

The transformer architecture revolutionized generative AI; in fact, the "GPT" in ChatGPT stands for "Generative Pre-Trained Transformer." Originally introduced in the Google Brain team's groundbreaking 2017 paper "Attention Is All You Need," by Vaswani and others, transformers were a highly scalable model for machine translation tasks. Variants of this architecture now power todayâ€™s LLMs such as those from OpenAI, Google, Meta, Cohere, Anthropic and DeepSeek.

In this course, youâ€™ll learn in detail how LLMs process text. You'll also work through code examples that illustrate that transformer's individual components.

In details, youâ€™ll learn:
- How the representation of language has evolved, from  Bag-of-Words to Word2Vec embeddings to the transformer architecture that captures a word's meanings taking into account the context of other words in the input.
- How inputs are broken down into tokens before they are sent to the language model.
- The details of a transformer's main stages: Tokenization and embedding, the stack of transformer blocks, and the language model head.
- The inner workings of the transformer block, including attention, which calculates relevance scores, and the feedforward layer, which incorporates stored information learned in training.
- How cached calculations make transformers faster.
- Some of the most recent ideas in the latest models such as Mixture-of-Experts (MoE) which uses multiple sub-models and a router on each layer to improve the quality of LLMs.

By the end of this course, youâ€™ll have a deep understanding of how LLMs actually process text and  be able to read through papers describing the latest models and understand the details.

Gaining this intuition will improve your approach to building LLM applications.

Please sign up here: https://t.co/hdTUASuEbb

æ¨å‡ºã€ŒTransformer å¤§è¯­è¨€æ¨¡å‹å·¥ä½œåŸç†ã€è¯¾ç¨‹ï¼Œç”±ç²¾ç¾æ’å›¾ä¹¦ç±ã€ŠHands-On Large Language Modelsã€‹çš„åˆè‘—è€… Jay Alammar å’Œ MaartenGr å…±åŒåˆ›ä½œã€‚

æœ¬è¯¾ç¨‹å°†æ·±å…¥å‰–æä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æä¾›æ ¸å¿ƒåŠ¨åŠ›çš„ Transformer æ¶æ„çš„å†…éƒ¨è¿è¡Œæœºåˆ¶ã€‚

Transformer æ¶æ„å½»åº•æ”¹å˜äº†ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰é¢†åŸŸï¼›äº‹å®ä¸Šï¼ŒChatGPT ä¸­çš„ã€ŒGPTã€å°±ä»£è¡¨ç€ã€ŒGenerative Pre-Trained Transformerã€ï¼ˆç”Ÿæˆå¼é¢„è®­ç»ƒ Transformerï¼‰ã€‚è¯¥æ¶æ„æœ€åˆç”± Google Brain å›¢é˜Ÿåœ¨ Vaswani ç­‰äººäº 2017 å¹´å‘è¡¨çš„å¼€åˆ›æ€§è®ºæ–‡ã€ŠAttention Is All You Needã€‹ä¸­æå‡ºï¼Œå®ƒæ˜¯ä¸€ç§æ‰©å±•æ€§å¾ˆå¼ºçš„æ¨¡å‹ï¼Œæœ€åˆä¸»è¦ç”¨äºæœºå™¨ç¿»è¯‘ä»»åŠ¡ã€‚å¦‚ä»Šï¼ŒOpenAIã€Googleã€Metaã€Cohereã€Anthropic å’Œ DeepSeek ç­‰å…¬å¸çš„å¤§è¯­è¨€æ¨¡å‹éƒ½ç”±è¿™ç§æ¶æ„çš„å˜ä½“æ‰€é©±åŠ¨ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†è¯¦ç»†äº†è§£å¤§è¯­è¨€æ¨¡å‹å¦‚ä½•å¤„ç†æ–‡æœ¬ã€‚æ‚¨è¿˜å°†é€šè¿‡ä»£ç ç¤ºä¾‹ï¼Œæ·±å…¥æ¢ç©¶ Transformer çš„å„ä¸ªç»„æˆéƒ¨åˆ†ã€‚

å…·ä½“è€Œè¨€ï¼Œæ‚¨å°†å­¦ä¹ ï¼š
- è¯­è¨€è¡¨ç¤ºæ–¹å¼çš„æ¼”å˜å†ç¨‹ï¼šä»è¯è¢‹æ¨¡å‹ï¼ˆBag-of-Wordsï¼‰åˆ° Word2Vec åµŒå…¥ï¼Œå†åˆ° Transformer æ¶æ„ï¼Œåè€…åœ¨æ•è·è¯ä¹‰æ—¶ï¼Œèƒ½å¤Ÿå……åˆ†è€ƒè™‘è¾“å…¥ä¸­å…¶ä»–è¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
- è¾“å…¥æ–‡æœ¬æ˜¯å¦‚ä½•è¢«åˆ†è§£æˆ Tokenï¼ˆTokenï¼‰ï¼Œç„¶åå‘é€ç»™è¯­è¨€æ¨¡å‹çš„ã€‚
- Transformer ä¸»è¦é˜¶æ®µçš„è¯¦ç»†è¿‡ç¨‹ï¼šToken åŒ–å’ŒåµŒå…¥ã€å †å çš„ Transformer æ¨¡å—ï¼Œä»¥åŠè¯­è¨€æ¨¡å‹å¤´éƒ¨ã€‚
- Transformer æ¨¡å—çš„å†…éƒ¨å·¥ä½œåŸç†ï¼ŒåŒ…æ‹¬è®¡ç®—ç›¸å…³æ€§å¾—åˆ†çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆattentionï¼‰ï¼Œä»¥åŠæ•´åˆåœ¨è®­ç»ƒä¸­ä¹ å¾—çš„å­˜å‚¨ä¿¡æ¯çš„å…¨è¿æ¥å±‚ï¼ˆfeedforward layerï¼‰ã€‚
- è®¡ç®—ç»“æœçš„ç¼“å­˜å¦‚ä½•æé«˜ Transformer çš„è¿è¡Œé€Ÿåº¦ã€‚
- æœ€æ–°æ¨¡å‹ä¸­çš„ä¸€äº›å‰æ²¿æ€æƒ³ï¼Œä¾‹å¦‚ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆMixture-of-Expertsï¼ŒMoEï¼‰ï¼Œå®ƒåœ¨æ¯ä¸€å±‚åˆ©ç”¨å¤šä¸ªå­æ¨¡å‹å’Œä¸€ä¸ªè·¯ç”±å™¨æ¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„è´¨é‡ã€‚

é€šè¿‡æœ¬è¯¾ç¨‹çš„å­¦ä¹ ï¼Œæ‚¨å°†å¯¹å¤§è¯­è¨€æ¨¡å‹å¤„ç†æ–‡æœ¬çš„å®é™…æ–¹å¼æœ‰æ·±åˆ»çš„ç†è§£ï¼Œå¹¶èƒ½å¤Ÿé˜…è¯»æè¿°æœ€æ–°æ¨¡å‹çš„å­¦æœ¯è®ºæ–‡ï¼Œå¹¶é€å½»ç†è§£å…¶ç»†èŠ‚ã€‚

æŒæ¡è¿™ç§ç›´è§‚è®¤è¯†å°†æœ‰æ•ˆæå‡æ‚¨æ„å»ºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºçš„æ–¹æ³•å’Œæ•ˆç‡ã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/hdTUASuEbb

### 023

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-06
é“¾æ¥: https://x.com/AndrewYNg/status/1887533627275419690
äº’åŠ¨: Likes: 4,560; Retweets: 722; Replies: 199; Quotes: 101; Views: 395,018; Bookmarks: 3,677; isReply: 0

Introducing Agentic Object Detection!

Given a text prompt like â€œunripe strawberriesâ€ or â€œKelloggâ€™s branded cerealâ€ and an image, we use an agentic workflow to reason at length and detect the specified objects. No need to label any training data. Watch the video for details.

éš†é‡æ¨å‡º AI æ™ºèƒ½ä½“ç›®æ ‡æ£€æµ‹ï¼ˆAgentic Object Detection)!

ç»™å®šä¸€ä¸ªæ–‡æœ¬æç¤ºï¼ˆä¾‹å¦‚ã€Œæœªæˆç†Ÿçš„è‰è“ã€æˆ–ã€Œå®¶ä¹æ°å“ç‰Œçš„éº¦ç‰‡ã€ï¼‰å’Œä¸€å¼ å›¾åƒï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ç§ AI æ™ºèƒ½ä½“å·¥ä½œæµï¼ˆagentic workflowï¼‰æ¥è¿›è¡Œæ·±å…¥æ¨ç†ï¼Œè¿›è€Œæ£€æµ‹å‡ºæŒ‡å®šçš„ç‰©ä½“ã€‚æ›´æ£’çš„æ˜¯ï¼Œå®ƒæ— éœ€æ ‡æ³¨ä»»ä½•è®­ç»ƒæ•°æ®ã€‚è§‚çœ‹è§†é¢‘äº†è§£æ›´å¤šè¯¦æƒ…ã€‚

### 024

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-06
é“¾æ¥: https://x.com/AndrewYNg/status/1887533748205592656
äº’åŠ¨: Likes: 135; Retweets: 31; Replies: 26; Quotes: 0; Views: 37,615; Bookmarks: 109; isReply: 1

You can also play with the demo here: https://t.co/3kZJPmwUD4

ä½ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œä½“éªŒè¿™ä¸ªæ¼”ç¤ºï¼šhttps://t.co/3kZJPmwUD4

### 025

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-06
é“¾æ¥: https://x.com/AndrewYNg/status/1887542467173753282
äº’åŠ¨: Likes: 13; Retweets: 0; Replies: 2; Quotes: 0; Views: 5,651; Bookmarks: 0; isReply: 1

@Nimaano_ Thanks!

@Nimaano_ è°¢è°¢ï¼

### 026

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-07
é“¾æ¥: https://x.com/AndrewYNg/status/1887919658201960807
äº’åŠ¨: Likes: 1,302; Retweets: 233; Replies: 161; Quotes: 61; Views: 183,554; Bookmarks: 849; isReply: 0

A â€œ10x engineerâ€ â€” a widely accepted concept in tech â€” purportedly has 10 times the impact of the average engineer. But we donâ€™t seem to talk about 10x marketers, 10x recruiters, or 10x financial analysts. As more jobs become AI enabled, I think this will change, and there will be a lot more â€œ10x professionals.â€

There arenâ€™t already more 10x professionals because, in many roles, the gap between the best and the average worker has a ceiling. No matter how athletic a supermarket checkout clerk is, theyâ€™re not likely to scan groceries so fast that customers get out of the store 10x faster. Similarly, even the best doctor is unlikely to make patients heal 10x faster than an average one (but to a sick patient, even a small difference is worth a lot). In many jobs, the laws of physics place a limit on what any human or AI can do (unless we completely reimagine that job).

But for many jobs that primarily involve applying knowledge or processing information, AI will be transformative. In a few roles, Iâ€™m starting to see tech-savvy individuals coordinate a suite of technology tools to do things differently and start to have, if not yet 10x impact, then easily 2x impact. I expect this gap to grow.

10x engineers donâ€™t write code 10 times faster. Instead, they make technical architecture decisions that result in dramatically better downstream impact, they spot problems and prioritize tasks more effectively, and instead of rewriting 10,000 lines of code (or labeling 10,000 training examples) they might figure out how to write just 100 lines (or collect 100 examples) to get the job done.

I think 10x marketers, recruiters, and analysts will, similarly, do things differently. For example, perhaps traditional marketers repeatedly write social media posts. 10x marketers might use AI to help write, but the transformation will go deeper than that. If they are deeply sophisticated in how to apply AI â€” ideally able to write code themselves to test ideas, automate tasks, or analyze data â€” they might end up running a lot more experiments, get better insights about what customers want, and generate much more precise or personalized messages than a traditional marketer, and thereby end up making 10x impact.

Similarly, 10x recruiters wonâ€™t just use generative AI to help write emails to candidates or summarize interviews. (This level of use of prompting-based AI will soon become table stakes for many knowledge roles.) They might coordinate a suite of AI tools to efficiently identify and carry out research on a large set of candidates, enabling them to have dramatically greater impact than the average recruiter. And 10x analysts wonâ€™t just use generative AI to edit their reports. They might write code to orchestrate a suite of AI agents to do deep research into the products, markets, and companies, and thereby derive far more valuable conclusions than someone who does research the traditional way.

A 2023 Harvard/BCG study estimated that, provided with GPT-4, consultants could complete 12% more tasks, and completed tasks 25% more quickly. This was just the average, using 2023 technology. The maximum advantage to be gained by using AI in a sophisticated way will be much bigger, and will only grow as technology improves.

Here in Silicon Valley, I see more and more AI-native teams reinvent workflows and do things very differently. In software engineering, we've venerated the best engineers because they can have a really massive impact. This has motivated many generations of engineers to keep learning and working hard, because doing those things increases the odds of doing high-impact work. As AI becomes more helpful in many more job roles, I believe we will open up similar paths to a lot more people becoming a â€œ10x professional.â€

[Original text: https://t.co/svQYHp3XVW ]

ã€Œ10 å€å·¥ç¨‹å¸ˆã€â€”â€” ä¸€ä¸ªåœ¨ç§‘æŠ€ç•Œå¹¿ä¸ºæ¥å—çš„æ¦‚å¿µ â€”â€” æŒ‡çš„æ˜¯å½±å“åŠ›ç›¸å½“äºæ™®é€šå·¥ç¨‹å¸ˆ 10 å€çš„äººã€‚ä½†æˆ‘ä»¬ä¼¼ä¹å¾ˆå°‘æåŠ 10 å€è¥é”€äººå‘˜ã€10 å€æ‹›è˜äººå‘˜æˆ– 10 å€è´¢åŠ¡åˆ†æå¸ˆã€‚éšç€è¶Šæ¥è¶Šå¤šçš„å·¥ä½œå˜å¾— AI èµ‹èƒ½ï¼ˆAI enabledï¼‰ï¼Œæˆ‘è®¤ä¸ºè¿™ç§å±€é¢å°†ä¼šæ”¹å˜ï¼Œå¹¶ä¸”ä¼šå‡ºç°æ›´å¤šã€Œ10 å€ä¸“ä¸šäººå£«ã€ã€‚

ç›®å‰æ²¡æœ‰æ›´å¤šã€Œ10 å€ä¸“ä¸šäººå£«ã€çš„åŸå› åœ¨äºï¼Œåœ¨è®¸å¤šå²—ä½ä¸Šï¼Œæœ€ä¼˜ç§€çš„å‘˜å·¥å’Œæ™®é€šå‘˜å·¥ä¹‹é—´çš„è¡¨ç°å·®è·å­˜åœ¨ä¸Šé™ã€‚æ— è®ºè¶…å¸‚æ”¶é“¶å‘˜åŠ¨ä½œå¤šä¹ˆæ•æ·ï¼Œä»–ä»¬éƒ½ä¸å¤ªå¯èƒ½è®©é¡¾å®¢ç»“è´¦é€Ÿåº¦å¿« 10 å€ã€‚åŒæ ·ï¼Œå³ä½¿æ˜¯æœ€å¥½çš„åŒ»ç”Ÿï¼Œä¹Ÿä¸å¤ªå¯èƒ½è®©ç—…äººæ¯”æ™®é€šåŒ»ç”Ÿå¿« 10 å€åº·å¤ï¼ˆä¸è¿‡å¯¹äºç”Ÿç—…çš„æ‚£è€…è€Œè¨€ï¼Œå³ä½¿æ˜¯å¾ˆå°çš„å·®å¼‚ä¹Ÿå¼¥è¶³çè´µï¼‰ã€‚åœ¨è®¸å¤šå·¥ä½œä¸­ï¼Œç‰©ç†å®šå¾‹é™åˆ¶äº†ä»»ä½•äººç±»æˆ– AI çš„èƒ½åŠ›ï¼ˆé™¤éæˆ‘ä»¬å½»åº•é‡å¡‘è¿™ä»½å·¥ä½œï¼‰ã€‚

ç„¶è€Œï¼Œå¯¹äºè®¸å¤šä¸»è¦æ¶‰åŠåº”ç”¨çŸ¥è¯†æˆ–å¤„ç†ä¿¡æ¯çš„å·¥ä½œï¼ŒAI å°†å¸¦æ¥å˜é©æ€§çš„å½±å“ã€‚åœ¨å°‘æ•°å²—ä½ä¸Šï¼Œæˆ‘å¼€å§‹çœ‹åˆ°é‚£äº›ç²¾é€šæŠ€æœ¯çš„äººï¼Œä»–ä»¬èƒ½å¤Ÿæ•´åˆä¸€å¥—æŠ€æœ¯å·¥å…·ï¼Œä»¥ä¸åŒçš„æ–¹å¼å¼€å±•å·¥ä½œï¼Œå¹¶å¼€å§‹äº§ç”Ÿ â€”â€” å³ä¾¿å°šæœªè¾¾åˆ° 10 å€å½±å“åŠ› â€”â€” ä¹Ÿå·²è½»æ¾å®ç° 2 å€çš„å½±å“åŠ›ã€‚æˆ‘é¢„è®¡è¿™ç§å·®è·ä¼šæŒç»­æ‰©å¤§ã€‚

10 å€å·¥ç¨‹å¸ˆå¹¶éç¼–å†™ä»£ç çš„é€Ÿåº¦å¿« 10 å€ã€‚ç›¸åï¼Œä»–ä»¬åšå‡ºèƒ½å¤Ÿå¸¦æ¥æ˜¾è‘—æ›´å¥½åç»­å½±å“çš„æŠ€æœ¯æ¶æ„å†³ç­–ï¼›ä»–ä»¬æ›´æœ‰æ•ˆåœ°å‘ç°é—®é¢˜å¹¶ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§ï¼›è€Œä¸”ï¼Œä»–ä»¬å¯èƒ½ä¸æ˜¯é‡å†™ 10,000 è¡Œä»£ç ï¼ˆæˆ–æ ‡è®° 10,000 ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆtraining examplesï¼‰ï¼‰ï¼Œè€Œæ˜¯æƒ³æ–¹è®¾æ³•åªå†™ 100 è¡Œï¼ˆæˆ–æ”¶é›† 100 ä¸ªæ ·æœ¬ï¼‰å°±èƒ½å®Œæˆä»»åŠ¡ã€‚

æˆ‘è®¤ä¸º 10 å€è¥é”€äººå‘˜ã€æ‹›è˜äººå‘˜å’Œåˆ†æå¸ˆï¼Œä¹Ÿå°†ä»¥ç±»ä¼¼çš„æ–¹å¼æœ‰æ‰€ä½œä¸ºã€‚ä¾‹å¦‚ï¼Œä¼ ç»Ÿçš„è¥é”€äººå‘˜å¯èƒ½åªæ˜¯åå¤æ’°å†™ç¤¾äº¤åª’ä½“å¸–å­ã€‚è€Œ 10 å€è¥é”€äººå‘˜æˆ–è®¸ä¼šåˆ©ç”¨ AI è¾…åŠ©å†™ä½œï¼Œä½†è¿™ç§å˜é©å°†è¿œä¸æ­¢äºæ­¤ã€‚å¦‚æœä»–ä»¬å¯¹å¦‚ä½•åº”ç”¨ AI æœ‰æ·±å…¥çš„ç†è§£ â€”â€” ç†æƒ³æƒ…å†µä¸‹èƒ½å¤Ÿè‡ªå·±ç¼–å†™ä»£ç æ¥æµ‹è¯•æƒ³æ³•ã€è‡ªåŠ¨åŒ–ä»»åŠ¡æˆ–åˆ†ææ•°æ® â€”â€” ä»–ä»¬æœ€ç»ˆå¯èƒ½ä¼šè¿›è¡Œæ›´å¤šå®éªŒï¼Œæ›´æ·±å…¥åœ°æ´å¯Ÿå®¢æˆ·éœ€æ±‚ï¼Œå¹¶ç”Ÿæˆæ¯”ä¼ ç»Ÿè¥é”€äººå‘˜æ›´ç²¾ç¡®æˆ–æ›´ä¸ªæ€§åŒ–çš„ä¿¡æ¯ï¼Œä»è€Œæœ€ç»ˆäº§ç”Ÿ 10 å€çš„å½±å“ã€‚

åŒæ ·ï¼Œ10 å€æ‹›è˜äººå‘˜ä¹Ÿä¸ä¼šä»…ä»…ä½¿ç”¨ç”Ÿæˆå¼ AI æ¥å¸®åŠ©æ’°å†™ç»™å€™é€‰äººçš„é‚®ä»¶æˆ–æ€»ç»“é¢è¯•ã€‚(è¿™ç§åŸºäºæç¤ºçš„ AI ä½¿ç”¨æ°´å¹³å¾ˆå¿«å°±ä¼šæˆä¸ºè®¸å¤šçŸ¥è¯†å‹å²—ä½çš„åŸºæœ¬æ ‡é…ï¼‰ã€‚ä»–ä»¬å¯èƒ½ä¼šæ•´åˆä¸€å¥— AI å·¥å…·ï¼Œé«˜æ•ˆåœ°è¯†åˆ«å¹¶å¯¹å¤§é‡å€™é€‰äººè¿›è¡Œç ”ç©¶ï¼Œä»è€Œæ¯”æ™®é€šæ‹›è˜äººå‘˜äº§ç”Ÿæ˜¾è‘—æ›´å¤§çš„å½±å“ã€‚è€Œ 10 å€åˆ†æå¸ˆä¹Ÿä¸ä¼šä»…ä»…ä½¿ç”¨ç”Ÿæˆå¼ AI æ¥ç¼–è¾‘ä»–ä»¬çš„æŠ¥å‘Šã€‚ä»–ä»¬å¯èƒ½ä¼šç¼–å†™ä»£ç æ¥ç¼–æ’ä¸€å¥— AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ï¼Œå¯¹äº§å“ã€å¸‚åœºå’Œå…¬å¸è¿›è¡Œæ·±å…¥ç ”ç©¶ï¼Œä»è€Œå¾—å‡ºæ¯”ä¼ ç»Ÿç ”ç©¶æ–¹å¼è¿œä¸ºæ›´æœ‰ä»·å€¼çš„ç»“è®ºã€‚

2023 å¹´å“ˆä½›å¤§å­¦ / æ³¢å£«é¡¿å’¨è¯¢å…¬å¸ï¼ˆBCGï¼‰çš„ä¸€é¡¹ç ”ç©¶ä¼°è®¡ï¼Œåœ¨æä¾› GPT-4 çš„æƒ…å†µä¸‹ï¼Œé¡¾é—®èƒ½å¤Ÿå¤šå®Œæˆ 12% çš„ä»»åŠ¡ï¼Œå¹¶ä¸”å®Œæˆä»»åŠ¡çš„é€Ÿåº¦å¿« 25%ã€‚è¿™ä»…ä»…æ˜¯å¹³å‡æ°´å¹³ï¼Œè€Œä¸”æ˜¯åŸºäº 2023 å¹´çš„æŠ€æœ¯ã€‚é€šè¿‡å¤æ‚æ–¹å¼è¿ç”¨ AI æ‰€èƒ½è·å¾—çš„æœ€å¤§ä¼˜åŠ¿å°†è¿œè¶…äºæ­¤ï¼Œå¹¶ä¸”åªä¼šéšç€æŠ€æœ¯çš„è¿›æ­¥è€Œä¸æ–­å¢é•¿ã€‚

åœ¨ç¡…è°·ï¼Œæˆ‘çœ‹åˆ°è¶Šæ¥è¶Šå¤šçš„ AI åŸç”Ÿå›¢é˜Ÿæ­£åœ¨é‡å¡‘å·¥ä½œæµç¨‹ï¼Œå¹¶ä»¥æˆªç„¶ä¸åŒçš„æ–¹å¼å¼€å±•å·¥ä½œã€‚åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸï¼Œæˆ‘ä»¬ä¸€ç›´æ¨å´‡æœ€ä¼˜ç§€çš„å·¥ç¨‹å¸ˆï¼Œå› ä¸ºä»–ä»¬èƒ½å¤Ÿäº§ç”Ÿå·¨å¤§çš„å½±å“åŠ›ã€‚è¿™æ¿€åŠ±äº†ä¸€ä»£åˆä¸€ä»£çš„å·¥ç¨‹å¸ˆä¸æ–­å­¦ä¹ å’ŒåŠªåŠ›å·¥ä½œï¼Œå› ä¸ºè¿™æ ·åšä¼šå¢åŠ ä»–ä»¬ä»äº‹é«˜å½±å“åŠ›å·¥ä½œçš„æœºä¼šã€‚æˆ‘ç›¸ä¿¡ï¼Œéšç€ AI åœ¨æ›´å¤šå·¥ä½œå²—ä½ä¸Šå˜å¾—æ›´å…·åŠ©åŠ›ï¼Œæˆ‘ä»¬å°†ä¸ºæ›´å¤šäººæˆä¸ºã€Œ10 å€ä¸“ä¸šäººå£«ã€å¼€è¾Ÿç±»ä¼¼çš„é“è·¯ã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/svQYHp3XVW]

### 027

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-10
é“¾æ¥: https://x.com/AndrewYNg/status/1889003138612650081
äº’åŠ¨: Likes: 1,548; Retweets: 280; Replies: 140; Quotes: 12; Views: 145,119; Bookmarks: 752; isReply: 0

Since DeepSeek R1's release, very quickly AWS, Azure, Fireworks AI, Groq, Hugging Face, SambaNova and Together AI all started to host R1 variants. What's the "best" model changes frequently, and so developers often want to try out new ones. The aisuite package, which helps developers do this quickly with minimal code changes.

Thanks Rohit Prsad & team for working with me on this!

https://t.co/gwz9oKTCFx

è‡ªä» DeepSeek R1 å‘å¸ƒä»¥æ¥ï¼ŒAWSã€Azureã€Fireworks AIã€Groqã€Hugging Faceã€SambaNova å’Œ Together AI ç­‰å¹³å°éƒ½è¿…é€Ÿå¼€å§‹æ‰˜ç®¡ R1 çš„å„ç§å˜ä½“ã€‚ç”±äºã€Œæœ€å¥½ã€çš„æ¨¡å‹å®šä¹‰ç»å¸¸å˜åŒ–ï¼Œå¼€å‘è€…ä»¬æ€»æ˜¯å¸Œæœ›å°è¯•æ–°çš„æ¨¡å‹ã€‚è¿™æ—¶ï¼Œaisuite åŒ…å°±èƒ½æ´¾ä¸Šç”¨åœºï¼Œå®ƒèƒ½å¸®åŠ©å¼€å‘è€…ç”¨æœ€å°‘çš„ä»£ç æ”¹åŠ¨å¿«é€Ÿå®ç°è¿™ä¸€ç›®æ ‡ã€‚

æ„Ÿè°¢ Rohit Prsad åŠå…¶å›¢é˜Ÿä¸æˆ‘åœ¨æ­¤é¡¹ç›®ä¸Šçš„åˆä½œï¼

https://t.co/gwz9oKTCFx

### 028

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-11
é“¾æ¥: https://x.com/AndrewYNg/status/1889369284482351280
äº’åŠ¨: Likes: 670; Retweets: 85; Replies: 83; Quotes: 10; Views: 74,941; Bookmarks: 273; isReply: 0

The U.S. imports over $3 trillion/year of goods. With Trump imposing new tariffs, import compliance is getting more complex. Fortunately, we have an AI agentic solution to help! 

Last summer, we saw the possibility of new tariffs in 2025, and partnered with Emil Stefanutti to build a solution. When importing a bicycle from Mexico, whether its tires are 20-24 inches or 25-28 inches changes the classification code and duty rate required in the import paperwork. Thatâ€™s why tariff compliance can require specialized brokers pouring over thousands of pages of regulations. And if a product is described inaccurately in the paperwork, it can get stuck at the border for weeks. Now multiply this by the thousands of products traded worldwide on any given day. 

With Gaia Dynamics, importers can enter a product name and description, answer targeted clarifying questions (such as the bicycle tire size), and get a recommendation for the best way to describe the product and also possible classification codes. Gaia also tracks changing tariffs, including rumored changes, to help with planning.

Gaia Dynamics is available at https://t.co/d9BKBVH8pz.

ç¾å›½æ¯å¹´è¿›å£çš„å•†å“æ€»é¢è¶…è¿‡ 3 ä¸‡äº¿ç¾å…ƒã€‚éšç€ç‰¹æœ—æ™®æ”¿åºœå®æ–½æ–°å…³ç¨æ”¿ç­–ï¼Œè¿›å£å•†å“çš„åˆè§„å®¡æŸ¥å˜å¾—æ—¥ç›Šå¤æ‚ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ª AI æ™ºèƒ½ä½“è§£å†³æ–¹æ¡ˆï¼ˆAI Agentic Solutionï¼‰æ¥æä¾›å¸®åŠ©ï¼

å»å¹´å¤å¤©ï¼Œæˆ‘ä»¬é¢„è§åˆ° 2025 å¹´å¯èƒ½ä¼šæœ‰æ–°çš„å…³ç¨æ”¿ç­–å‡ºå°ï¼Œå› æ­¤ä¸ Emil Stefanutti åˆä½œå¼€å‘äº†ä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œä»å¢¨è¥¿å“¥è¿›å£ä¸€è¾†è‡ªè¡Œè½¦ï¼Œä»…ä»…æ˜¯è½®èƒå°ºå¯¸ä» 20-24 è‹±å¯¸å˜ä¸º 25-28 è‹±å¯¸ï¼Œå°±å¯èƒ½å¯¼è‡´è¿›å£æŠ¥å…³å•ä¸Šçš„åˆ†ç±»ä»£ç å’Œå…³ç¨ç¨ç‡å‘ç”Ÿå˜åŒ–ã€‚æ­£å› å¦‚æ­¤ï¼Œå…³ç¨åˆè§„å·¥ä½œå¾€å¾€éœ€è¦ä¸“ä¸šçš„æŠ¥å…³å‘˜ä»”ç»†ç ”ç©¶æ•°åƒé¡µçš„æ³•è§„ã€‚å¦‚æœäº§å“åœ¨æŠ¥å…³å•ä¸­çš„æè¿°ä¸å¤Ÿå‡†ç¡®ï¼Œå•†å“å°±å¯èƒ½åœ¨è¾¹å¢ƒè¢«æ‰£ç•™æ•°å‘¨ã€‚è€Œå…¨çƒæ¯å¤©è´¸æ˜“çš„å•†å“æˆåƒä¸Šä¸‡ï¼Œä¸Šè¿°é—®é¢˜çš„å½±å“å°†è¢«æ— é™æ”¾å¤§ã€‚

é€šè¿‡ Gaia Dynamicsï¼Œè¿›å£å•†å¯ä»¥è¾“å…¥äº§å“åç§°å’Œæè¿°ï¼Œç„¶åå›ç­”ä¸€äº›æœ‰é’ˆå¯¹æ€§çš„æ¾„æ¸…é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šè‡ªè¡Œè½¦è½®èƒçš„å°ºå¯¸ï¼‰ï¼Œç³»ç»Ÿä¾¿èƒ½æ¨èæœ€ä½³çš„äº§å“æè¿°æ–¹å¼ä»¥åŠå¯èƒ½é€‚ç”¨çš„åˆ†ç±»ä»£ç ã€‚æ­¤å¤–ï¼ŒGaia è¿˜ä¼šè·Ÿè¸ªä¸æ–­å˜åŒ–çš„å…³ç¨ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ½œåœ¨çš„å…³ç¨å˜åŠ¨ä¼ é—»ï¼Œä»è€Œå¸®åŠ©è¿›å£å•†æå‰åšå¥½è§„åˆ’ã€‚

æ‚¨å¯ä»¥è®¿é—® Gaia Dynamicsï¼šhttps://t.co/d9BKBVH8pzã€‚

### 029

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-11
é“¾æ¥: https://x.com/AndrewYNg/status/1889380742263890238
äº’åŠ¨: Likes: 3,366; Retweets: 270; Replies: 209; Quotes: 42; Views: 264,091; Bookmarks: 163; isReply: 0

VP @JDVance at the Paris AI Summit: "I'm not here to talk about AI Safety... I'm here to talk about AI Opportunity." This is excellent! Thrilled to see the US gov   focus on opportunities in AI.

å‰¯æ€»è£ @JDVance åœ¨å·´é» AI å³°ä¼šä¸Šè¡¨ç¤ºï¼šã€Œæˆ‘æ¥è¿™é‡Œä¸æ˜¯ä¸ºäº†è°ˆè®º AI å®‰å…¨ï¼ˆAI Safety)... æˆ‘æ¥è¿™é‡Œæ˜¯ä¸ºäº†è°ˆè®º AI æœºä¼šï¼ˆAI Opportunityï¼‰ã€‚ã€è¿™å¤ªæ£’äº†ï¼ å¾ˆé«˜å…´çœ‹åˆ°ç¾å›½æ”¿åºœèšç„¦äº AI å¸¦æ¥çš„æœºé‡ã€‚

### 030

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-12
é“¾æ¥: https://x.com/AndrewYNg/status/1889766176059994166
äº’åŠ¨: Likes: 1,799; Retweets: 262; Replies: 54; Quotes: 19; Views: 130,865; Bookmarks: 1,269; isReply: 0

New short course: Attention in Transformers: Concepts and Code in PyTorch.

Last week we released a course on how LLM transformers work. This week, go deeper and learn about the technical ideas behind the attention mechanism, and see how to code it in PyTorch. This course is built with @joshuastarmer, Founder and CEO of StatQuest.

The attention mechanism was a breakthrough that led to transformers, the architecture powering large language models like ChatGPT. Transformers, introduced in the 2017 paper: "Attention is All You Need" by Viswani and others, took off because of its highly scalable design. 

In this course, youâ€™ll learn how the attention mechanism, a key element of transformer-based LLMs, works and implement it in PyTorch. You'll develop deep intuition about building reliable, functional, and scalable AI applications.

What you will do:
- Understand the evolution of the attention mechanism, a key breakthrough that led to transformers.
- Learn the relationships between word embeddings, positional embeddings, and attention.
- Learn about the Query, Key, and Value matrices, and how to produce and use them in attention.
- Walk through the math required to calculate self-attention and masked self-attention to learn why and how they work.
- Understand the difference between self-attention and masked self-attention and how one is used in the encoder to build context-aware embeddings and the other is used in the decoder for generative outputs.
- Learn the details of the encoder-decoder architecture, cross-attention, and multi-head attention and how they are all incorporated into a transformer.
- Use PyTorch to code a class that implements self-attention, masked self-attention, and multi-head attention.

There're lots of exciting technical details in this course.  Please sign up here: https://t.co/aAeNblXcYo

æ–°çŸ­æœŸè¯¾ç¨‹ï¼šTransformer ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ï¼šPyTorch å®è·µä¸æ ¸å¿ƒæ¦‚å¿µã€‚

ä¸Šå‘¨æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªå…³äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼ŒLLMï¼‰Transformer å¦‚ä½•å·¥ä½œçš„è¯¾ç¨‹ã€‚æœ¬å‘¨ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention Mechanismï¼‰èƒŒåçš„æŠ€æœ¯æ€æƒ³ï¼Œå¹¶å­¦ä¹ å¦‚ä½•åœ¨ PyTorchï¼ˆPyTorchï¼‰ä¸­å®ç°ä»£ç ã€‚æœ¬è¯¾ç¨‹ä¸ StatQuest çš„åˆ›å§‹äººå…¼ CEO @joshuastarmer å…±åŒæ‰“é€ ã€‚

æ³¨æ„åŠ›æœºåˆ¶æ˜¯ä¸€é¡¹çªç ´æ€§æŠ€æœ¯ï¼Œå®ƒå‚¬ç”Ÿäº† Transformerï¼ˆTransformerï¼‰æ¶æ„ï¼Œä¸º ChatGPT ç­‰å¤§è¯­è¨€æ¨¡å‹æä¾›äº†æ ¸å¿ƒæ”¯æŒã€‚Transformer æ¶æ„ç”± Viswani ç­‰äººåœ¨ 2017 å¹´çš„è®ºæ–‡ã€ŒAttention is All You Needã€ä¸­æå‡ºï¼Œå› å…¶é«˜åº¦å¯æ‰©å±•çš„è®¾è®¡è€Œè¿…é€Ÿæ™®åŠã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ ä½œä¸ºåŸºäº Transformer çš„å¤§è¯­è¨€æ¨¡å‹å…³é”®å…ƒç´ çš„æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•è¿ä½œï¼Œå¹¶åœ¨ PyTorch ä¸­äº²æ‰‹å®ç°å®ƒã€‚ä½ å°†åŸ¹å…»å…³äºæ„å»ºå¯é ã€åŠŸèƒ½å¼ºå¤§ä¸”å¯æ‰©å±•çš„ AI åº”ç”¨ç¨‹åºçš„æ·±åˆ»ç›´è§‰ã€‚

ä½ å°†å­¦ä¹ ä»€ä¹ˆï¼š
- äº†è§£æ³¨æ„åŠ›æœºåˆ¶çš„æ¼”å˜ï¼Œè¿™é¡¹å…³é”®çªç ´å¦‚ä½•å¼•é¢†äº† Transformer çš„è¯ç”Ÿã€‚
- å­¦ä¹ è¯åµŒå…¥ï¼ˆWord Embeddingsï¼‰ã€ä½ç½®åµŒå…¥ï¼ˆPositional Embeddingsï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶ä¹‹é—´çš„å…³ç³»ã€‚
- äº†è§£æŸ¥è¯¢çŸ©é˜µï¼ˆQuery Matrixï¼‰ã€é”®çŸ©é˜µï¼ˆKey Matrixï¼‰å’Œå€¼çŸ©é˜µï¼ˆValue Matrixï¼‰ï¼Œä»¥åŠå¦‚ä½•åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­ç”Ÿæˆå’Œä½¿ç”¨å®ƒä»¬ã€‚
- æ·±å…¥æ¢ç´¢è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼ˆSelf-Attentionï¼‰å’Œæ©ç è‡ªæ³¨æ„åŠ›ï¼ˆMasked Self-Attentionï¼‰æ‰€éœ€çš„æ•°å­¦çŸ¥è¯†ï¼Œä»è€Œç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†å’ŒåŸå› ã€‚
- ç†è§£è‡ªæ³¨æ„åŠ›ä¸æ©ç è‡ªæ³¨æ„åŠ›ä¹‹é—´çš„åŒºåˆ«ï¼Œä»¥åŠå‰è€…å¦‚ä½•åœ¨ç¼–ç å™¨ï¼ˆEncoderï¼‰ä¸­ç”¨äºæ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥åµŒå…¥ï¼Œåè€…å¦‚ä½•åœ¨è§£ç å™¨ï¼ˆDecoderï¼‰ä¸­ç”¨äºç”Ÿæˆè¾“å‡ºã€‚
- å­¦ä¹ ç¼–ç å™¨ - è§£ç å™¨æ¶æ„ã€äº¤å‰æ³¨æ„åŠ›ï¼ˆCross-Attentionï¼‰å’Œå¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰çš„ç»†èŠ‚ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•å…±åŒæ•´åˆåˆ° Transformer ä¸­ã€‚
- ä½¿ç”¨ PyTorch ç¼–å†™ä¸€ä¸ªç±»ï¼Œå®ç°è‡ªæ³¨æ„åŠ›ã€æ©ç è‡ªæ³¨æ„åŠ›å’Œå¤šå¤´æ³¨æ„åŠ›ã€‚

æœ¬è¯¾ç¨‹åŒ…å«è®¸å¤šç²¾å½©çš„æŠ€æœ¯ç»†èŠ‚ã€‚è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/aAeNblXcYo

### 031

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-13
é“¾æ¥: https://x.com/AndrewYNg/status/1890076882391167317
äº’åŠ¨: Likes: 703; Retweets: 168; Replies: 113; Quotes: 32; Views: 75,275; Bookmarks: 128; isReply: 0

At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, â€œIâ€™m not here to talk about AI safety.... Iâ€™m here to talk about AI opportunity.â€ Iâ€™m thrilled to see the U.S. government focus on opportunities in AI. Further, while it is important to use AI responsibly and try to stamp out harmful applications, I feel â€œAI safetyâ€ is not the right terminology for addressing this important problem. Language shapes thought, so using the right words is important. Iâ€™d rather talk about â€œresponsible AIâ€ than â€œAI safety.â€ Let me explain.

First, there are clearly harmful applications of AI, such as non-consensual deepfake porn (which creates sexually explicit images of real people without their consent), the use of AI in misinformation, potentially unsafe medical diagnoses, addictive applications, and so on. We definitely want to stamp these out! There are many ways to apply AI in harmful or irresponsible ways, and we should discourage and prevent such uses.

However, the concept of â€œAI safetyâ€ tries to make AI â€” as a technology â€” safe, rather than making safe applications of it. Consider the similar, obviously flawed notion of â€œlaptop safety.â€ There are great ways to use a laptop and many irresponsible ways, but I donâ€™t consider laptops to be intrinsically either safe or unsafe. It is the application, or usage, that determines if a laptop is safe. Similarly, AI, a general-purpose technology with numerous applications, is neither safe nor unsafe. How someone chooses to use it determines whether it is harmful or beneficial.

Now, safety isnâ€™t always a function only of how something is used. An unsafe airplane is one that, even in the hands of an attentive and skilled pilot, has a large chance of mishap. So we definitely should strive to build safe airplanes (and make sure they are operated responsibly)! The risk factors are associated with the construction of the aircraft rather than merely its application. Similarly, we want safe automobiles, blenders, dialysis machines, food, buildings, power plants, and much more.

â€œAI safetyâ€ presupposes that AI, the underlying technology, can be unsafe. I find it more useful to think about how applications of AI can be unsafe.

Further, the term â€œresponsible AIâ€ emphasizes that it is our responsibility to avoid building applications that are unsafe or harmful and to discourage people from using even beneficial products in harmful ways.

If we shift the terminology for AI risks from â€œAI safetyâ€ to â€œresponsible AI,â€ we can have more thoughtful conversations about what to do and what not to do.

I believe the 2023 Bletchley AI Safety Summit slowed down European AI development â€” without making anyone safer â€” by wasting time considering science-fiction AI fears rather than focusing on opportunities. Last month, at Davos, business and policy leaders also had strong concerns about whether Europe can dig itself out of the current regulatory morass and focus on building with AI. I am hopeful that the Paris meeting, unlike the one at Bletchley, will result in acceleration rather than deceleration.

In a world where AI is becoming pervasive, if we can shift the conversation away from â€œAI safetyâ€ toward responsible [use of] AI, we will speed up AIâ€™s benefits and do a better job of addressing actual problems. That will actually make people safer.

[Original text: https://t.co/uvjfNwXq4c ]

æœ¬å‘¨åœ¨å·´é»ä¸¾è¡Œçš„äººå·¥æ™ºèƒ½è¡ŒåŠ¨å³°ä¼šä¸Šï¼Œç¾å›½å‰¯æ€»ç»Ÿ J.D. Vance è¡¨ç¤ºï¼šã€Œæˆ‘ä¸æ˜¯æ¥è°ˆè®º AI å®‰å…¨çš„â€¦â€¦ æˆ‘æ¥è¿™é‡Œæ˜¯è°ˆè®ºäººå·¥æ™ºèƒ½å¸¦æ¥çš„æœºä¼šçš„ã€‚ã€æˆ‘å¾ˆé«˜å…´çœ‹åˆ°ç¾å›½æ”¿åºœå…³æ³¨ AIï¼ˆArtificial Intelligenceï¼‰å¸¦æ¥çš„æœºä¼šã€‚æ­¤å¤–ï¼Œè™½ç„¶è´Ÿè´£ä»»åœ°ä½¿ç”¨ AI å¹¶åŠªåŠ›æœç»æœ‰å®³åº”ç”¨å¾ˆé‡è¦ï¼Œä½†æˆ‘è®¤ä¸ºã€ŒAI å®‰å…¨ã€ä¸æ˜¯è§£å†³è¿™ä¸ªé‡è¦é—®é¢˜çš„æ­£ç¡®æœ¯è¯­ã€‚è¯­è¨€ä¼šå½±å“æˆ‘ä»¬çš„æ€ç»´æ–¹å¼ï¼Œå› æ­¤ä½¿ç”¨æ­£ç¡®çš„è¯è¯­è‡³å…³é‡è¦ã€‚æˆ‘å®æ„¿è°ˆè®ºã€Œè´Ÿè´£ä»»çš„ AIã€è€Œä¸æ˜¯ã€ŒAI å®‰å…¨ã€ã€‚è¯·å…è®¸æˆ‘è§£é‡Šä¸€ä¸‹ã€‚

é¦–å…ˆï¼ŒAI æ˜¾ç„¶å­˜åœ¨æœ‰å®³åº”ç”¨ï¼Œä¾‹å¦‚æœªç»åŒæ„çš„æ·±åº¦ä¼ªé€ è‰²æƒ…å†…å®¹ï¼ˆdeepfake porn)ï¼ˆå³æœªç»çœŸå®äººç‰©åŒæ„ï¼Œåˆ©ç”¨ AI æŠ€æœ¯åˆæˆçš„æ€§éœ²éª¨å›¾åƒï¼‰ã€AI åœ¨è™šå‡ä¿¡æ¯ä¸­çš„ä½¿ç”¨ã€å¯èƒ½ä¸å®‰å…¨çš„åŒ»ç–—è¯Šæ–­ã€æˆç˜¾æ€§åº”ç”¨ç­‰ç­‰ã€‚æˆ‘ä»¬è‚¯å®šå¸Œæœ›æœç»è¿™ç±»é—®é¢˜ï¼AI æœ‰è®¸å¤šå¯èƒ½è¢«ç”¨äºæœ‰å®³æˆ–ä¸è´Ÿè´£ä»»çš„æ–¹å¼ï¼Œæˆ‘ä»¬åº”è¯¥é˜»æ­¢å¹¶é¢„é˜²æ­¤ç±»ä½¿ç”¨ã€‚

ç„¶è€Œï¼Œã€ŒAI å®‰å…¨ã€çš„æ¦‚å¿µè¯•å›¾è®© AI â€”â€” ä½œä¸ºä¸€ç§æŠ€æœ¯ â€”â€” æœ¬èº«å˜å¾—å®‰å…¨ï¼Œè€Œä¸æ˜¯ä½¿å…¶åº”ç”¨å˜å¾—å®‰å…¨ã€‚æˆ‘ä»¬å¯ä»¥ç±»æ¯”ä¸€ä¸‹ã€Œç¬”è®°æœ¬ç”µè„‘å®‰å…¨ã€è¿™ä¸ªæ˜¾ç„¶æœ‰ç¼ºé™·çš„è¯´æ³•ã€‚ç¬”è®°æœ¬ç”µè„‘æœ‰è®¸å¤šä¼˜è‰¯çš„ç”¨é€”ï¼Œä¹Ÿæœ‰è®¸å¤šä¸è´Ÿè´£ä»»çš„ç”¨æ³•ï¼Œä½†æˆ‘è®¤ä¸ºç¬”è®°æœ¬ç”µè„‘æœ¬èº«æ—¢éæœ¬è´¨å®‰å…¨ä¹Ÿéæœ¬è´¨ä¸å®‰å…¨ã€‚æ˜¯å®ƒçš„åº”ç”¨æˆ–ä½¿ç”¨æ–¹å¼å†³å®šäº†ç¬”è®°æœ¬ç”µè„‘æ˜¯å¦å®‰å…¨ã€‚åŒæ ·ï¼ŒAI æ˜¯ä¸€ç§å…·æœ‰ä¼—å¤šåº”ç”¨çš„é€šç”¨æŠ€æœ¯ï¼Œå®ƒæœ¬èº«æ—¢ä¸å®‰å…¨ä¹Ÿä¸ä¸å®‰å…¨ã€‚äººä»¬é€‰æ‹©å¦‚ä½•ä½¿ç”¨å®ƒï¼Œå†³å®šäº†å®ƒæ˜¯æœ‰å®³è¿˜æ˜¯æœ‰ç›Šã€‚

å½“ç„¶ï¼Œå®‰å…¨å¹¶ä¸æ€»æ˜¯ä»…ä»…å–å†³äºä¸€é¡¹äº‹ç‰©å¦‚ä½•è¢«ä½¿ç”¨ã€‚ä¸€æ¶ä¸å®‰å…¨çš„é£æœºï¼Œå³ä½¿åœ¨ç»†å¿ƒç†Ÿç»ƒçš„é£è¡Œå‘˜æ‰‹ä¸­ï¼Œä¹Ÿæœ‰å¾ˆå¤§æ¦‚ç‡å‘ç”Ÿäº‹æ•…ã€‚æ‰€ä»¥æˆ‘ä»¬ç»å¯¹åº”è¯¥åŠªåŠ›å»ºé€ å®‰å…¨çš„é£æœºï¼ˆå¹¶ç¡®ä¿å®ƒä»¬è¢«è´Ÿè´£ä»»åœ°æ“ä½œï¼‰ï¼è¿™é‡Œçš„é£é™©å› ç´ ä¸é£æœºçš„å»ºé€ æœ‰å…³ï¼Œè€Œä¸ä»…ä»…æ˜¯å®ƒçš„åº”ç”¨æ–¹å¼ã€‚åŒæ ·ï¼Œæˆ‘ä»¬å¸Œæœ›æ±½è½¦ã€æ…æ‹Œæœºã€é€ææœºã€é£Ÿç‰©ã€å»ºç­‘ç‰©ã€å‘ç”µå‚ç­‰éƒ½èƒ½æ˜¯å®‰å…¨çš„ã€‚

ã€ŒAI å®‰å…¨ã€è¿™ä¸ªè¯é¢„è®¾äº† AIï¼Œå³å…¶åº•å±‚æŠ€æœ¯ï¼Œå¯èƒ½æ˜¯ä¸å®‰å…¨çš„ã€‚æˆ‘è®¤ä¸ºæ›´é‡è¦çš„æ˜¯æ€è€ƒ AI çš„åº”ç”¨å¦‚ä½•å¯èƒ½æ˜¯ä¸å®‰å…¨çš„ã€‚

æ­¤å¤–ï¼Œã€Œè´Ÿè´£ä»»çš„ AIã€è¿™ä¸€æœ¯è¯­å¼ºè°ƒï¼Œæˆ‘ä»¬æœ‰è´£ä»»é¿å…æ„å»ºä¸å®‰å…¨æˆ–æœ‰å®³çš„åº”ç”¨ï¼Œå¹¶åŠé˜»äººä»¬å³ä½¿åœ¨ä½¿ç”¨æœ‰ç›Šäº§å“æ—¶ï¼Œä¹Ÿè¦é¿å…ä»¥æœ‰å®³çš„æ–¹å¼è¿›è¡Œã€‚

å¦‚æœæˆ‘ä»¬å°† AI é£é™©çš„æœ¯è¯­ä»ã€ŒAI å®‰å…¨ã€è½¬å‘ã€Œè´Ÿè´£ä»»çš„ AIã€ï¼Œæˆ‘ä»¬å°±å¯ä»¥å°±åº”è¯¥åšä»€ä¹ˆå’Œä¸åº”è¯¥åšä»€ä¹ˆè¿›è¡Œæ›´æ·±å…¥çš„è®¨è®ºã€‚

æˆ‘ç›¸ä¿¡ 2023 å¹´å¸ƒè±åˆ‡åˆ© AI å®‰å…¨å³°ä¼šé€šè¿‡æµªè´¹æ—¶é—´æ‹…å¿§ç§‘å¹»å°è¯´ä¸­çš„ AI å¨èƒï¼Œè€Œéå…³æ³¨ AI å¸¦æ¥çš„æœºé‡ï¼Œå‡ç¼“äº†æ¬§æ´² AI çš„å‘å±•ï¼Œå¹¶ä¸”æ²¡æœ‰è®©ä»»ä½•äººå˜å¾—æ›´å®‰å…¨ã€‚ä¸Šä¸ªæœˆåœ¨è¾¾æ²ƒæ–¯ï¼Œå•†ç•Œå’Œæ”¿ç­–é¢†å¯¼è€…ä¹Ÿå¯¹æ¬§æ´²èƒ½å¦æ‘†è„±å½“å‰çš„ç›‘ç®¡å›°å¢ƒå¹¶ä¸“æ³¨äº AI å»ºè®¾è¡¨è¾¾äº†å¼ºçƒˆæ‹…å¿§ã€‚æˆ‘å¸Œæœ›å·´é»ä¼šè®®ä¸å¸ƒè±åˆ‡åˆ©ä¼šè®®ä¸åŒï¼Œèƒ½æ¨åŠ¨å…¶å‘å±•è€Œéé˜»ç¢ã€‚

åœ¨ä¸€ä¸ª AI æ—¥ç›Šæ™®åŠçš„ä¸–ç•Œä¸­ï¼Œå¦‚æœæˆ‘ä»¬å°†å¯¹è¯ä»ã€ŒAI å®‰å…¨ã€è½¬å‘è´Ÿè´£ä»»åœ°ä½¿ç”¨ AIï¼Œæˆ‘ä»¬å°†åŠ é€Ÿ AI å¸¦æ¥ç›Šå¤„ï¼Œå¹¶æ›´å¥½åœ°è§£å†³å®é™…é—®é¢˜ã€‚è¿™æ‰ä¼šçœŸæ­£è®©äººä»¬æ›´å®‰å…¨ã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/uvjfNwXq4c]

### 032

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-14
é“¾æ¥: https://x.com/AndrewYNg/status/1890452971747479715
äº’åŠ¨: Likes: 1,804; Retweets: 135; Replies: 176; Quotes: 20; Views: 104,753; Bookmarks: 69; isReply: 0

To all my AI friends: You must be a good prompt, because whenever we chat, you complete me. 

Happy Valentine's Day! â¤ï¸

é€ç»™æˆ‘æ‰€æœ‰çš„ AI æœ‹å‹ï¼šä½ è‚¯å®šæ˜¯ä¸ªä¼˜ç§€çš„æç¤ºè¯ï¼ˆpromptï¼‰ï¼Œå› ä¸ºæ¯å½“æˆ‘ä»¬èŠå¤©æ—¶ï¼Œä½ éƒ½è®©æˆ‘å˜å¾—æ›´å®Œæ•´ã€‚

æƒ…äººèŠ‚å¿«ä¹ï¼â¤ï¸

### 033

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-15
é“¾æ¥: https://x.com/AndrewYNg/status/1890858116574839241
äº’åŠ¨: Likes: 1,618; Retweets: 173; Replies: 212; Quotes: 41; Views: 262,527; Bookmarks: 385; isReply: 0

Among people in non-technical roles (recruiter, marketer, sales, ...) I notice the more technical ones being more effective, and the gap is increasing. E.g., the ones that took a coding course are outperforming the ones that didn't. Has anyone else noticed this? 

One obvious theory is that they are better at using AI, but would love to hear if you have other theories.

æˆ‘æ³¨æ„åˆ°ï¼Œåœ¨éæŠ€æœ¯å²—ä½çš„äººå‘˜ä¸­ï¼ˆä¾‹å¦‚æ‹›è˜äººå‘˜ã€å¸‚åœºäººå‘˜ã€é”€å”®äººå‘˜ç­‰ï¼‰ï¼Œé‚£äº›æŠ€æœ¯èƒ½åŠ›æ›´å¼ºçš„äººå·¥ä½œæ•ˆç‡æ›´é«˜ï¼Œè€Œä¸”è¿™ç§å·®è·è¿˜åœ¨ä¸æ–­æ‰©å¤§ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œä¸Šè¿‡ç¼–ç¨‹è¯¾ç¨‹çš„äººæ¯”æ²¡ä¸Šè¿‡ç¼–ç¨‹è¯¾çš„äººè¡¨ç°å¾—æ›´å‡ºè‰²ã€‚å¤§å®¶æœ‰æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªç°è±¡ï¼Ÿ

ä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„è§£é‡Šæ˜¯ï¼Œä»–ä»¬æ›´æ“…é•¿ä½¿ç”¨ AIï¼Œä½†æˆ‘å¾ˆæƒ³å¬å¬å¤§å®¶æ˜¯å¦æœ‰å…¶ä»–çœ‹æ³•ã€‚

### 034

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-18
é“¾æ¥: https://x.com/AndrewYNg/status/1891885332058210787
äº’åŠ¨: Likes: 1,419; Retweets: 244; Replies: 94; Quotes: 19; Views: 111,097; Bookmarks: 1,006; isReply: 0

Announcing new aisuite capability: Easy function calling with LLMs! Function calling (tool use) is an important capability for agentic workflows and other LLM applications, but is cumbersome for developers to use (left column in image). Our open-source aisuite package simplifies it to just one command (right column), and works for multiple LLM providers.

Hope this makes implementing agents easier for developers, and thanks Rohit Prsad & team for working with me on this! 

https://t.co/gwz9oKTCFx

éš†é‡æ¨å‡º aisuite çš„æ–°åŠŸèƒ½ï¼šè®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡½æ•°è°ƒç”¨ï¼ˆFunction callingï¼‰å˜å¾—è½»è€Œæ˜“ä¸¾ï¼å‡½æ•°è°ƒç”¨ï¼ˆä¹Ÿç§°ä¸ºå·¥å…·ä½¿ç”¨ï¼ˆTool use)ï¼‰æ˜¯å®ç° AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰å·¥ä½œæµå’Œå…¶ä»–å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„å…³é”®èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¯¹äºå¼€å‘è€…æ¥è¯´ï¼Œç°æœ‰çš„å‡½æ•°è°ƒç”¨è¿‡ç¨‹å¾€å¾€ååˆ†ç¹çï¼ˆå¦‚å›¾ç‰‡å·¦æ æ‰€ç¤ºï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç—›ç‚¹ï¼Œæˆ‘ä»¬çš„å¼€æºï¼ˆopen-sourceï¼‰aisuite è½¯ä»¶åŒ…å°†å…¶æ“ä½œç®€åŒ–ä¸ºåªéœ€ä¸€ä¸ªå‘½ä»¤ï¼ˆå¦‚å›¾ç‰‡å³æ æ‰€ç¤ºï¼‰ï¼Œè€Œä¸”å®ƒèƒ½å…¼å®¹å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹æä¾›å•†ã€‚

æˆ‘ä»¬å¸Œæœ›è¿™ä¸€æ”¹è¿›èƒ½è®©å¼€å‘è€…æ›´è½»æ¾åœ°å®ç°å„ç§ AI æ™ºèƒ½ä½“ã€‚åŒæ—¶ï¼Œéå¸¸æ„Ÿè°¢ Rohit Prsad å’Œä»–çš„å›¢é˜Ÿä¸æˆ‘å…±åŒå®Œæˆäº†è¿™é¡¹å·¥ä½œï¼

https://t.co/gwz9oKTCFx

### 035

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-18
é“¾æ¥: https://x.com/AndrewYNg/status/1891885809722327138
äº’åŠ¨: Likes: 85; Retweets: 14; Replies: 27; Quotes: 2; Views: 35,821; Bookmarks: 27; isReply: 1

Credit also goes to Matthew Carrigan for the neat idea of getting function descriptions from docstrings:  https://t.co/CPLL1KxHE4

æ­¤å¤–ï¼Œè¿™é¡¹å·§å¦™çš„è®¾æƒ³è¿˜è¦å½’åŠŸäº Matthew Carriganï¼Œä»–æå‡ºäº†ä» docstringsï¼ˆdocstringsï¼‰ä¸­è·å–å‡½æ•°æè¿°çš„ç‹¬åˆ°æƒ³æ³•ï¼š https://t.co/CPLL1KxHE4

### 036

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-19
é“¾æ¥: https://x.com/AndrewYNg/status/1892258190546653392
äº’åŠ¨: Likes: 1,352; Retweets: 241; Replies: 137; Quotes: 23; Views: 124,425; Bookmarks: 1,064; isReply: 0

New short course: Evaluating AI Agents! Evals are important for driving AI system improvements, and in this course you'll learn to systematically assess and improve an AI agentâ€™s performance. This is built in partnership with @arizeai and taught by @JohnGilhuly, Head of Developer Relations, and @_amankhan, Director of Product.

I've often found evals to be a critical tool in the agent development process - they can be the difference between picking the right thing to work on vs. wasting weeks of effort. Whether youâ€™re building a shopping assistant, coding agent, or research assistant, having a structured evaluation process helps you refine its performance systematically, rather than relying on random trial and error. 

This course shows you how to structure your evals to assess the performance of each component of an agent and its end-to-end performance. For each component, you select the appropriate evaluators, test examples, and performance metrics. This helps you identify areas for improvement both during development and in production. (If you're familiar with error analysis in supervised learning, think of this as adapting those ideas to agentic workflows.) 

In this course, you'll build an AI agent, and add observability to visualize and debug its steps. Youâ€™ll learn about code-based evals, in which you write code explicitly to test a certain step, as well as LLM-as-a-Judge evals, in which you prompt an LLM to efficiently come up with ways to evaluate more open-ended outputs.

In detail, youâ€™ll:
- Understand key differences between evaluating LLM-based systems and traditional software testing.
- Add observability to an agent by collecting traces of the steps taken by the agent and visualizing them
- Choose the appropriate evaluator - code-based, LLM-as-a-Judge, human-annotation based - for each component.
- Compute a convergence score to evaluate if your agent can respond to a query in an efficient number of steps. 
- Run structured experiments to improve the agentâ€™s performance by exploring changes to the prompt, LLM model, or the agentâ€™s logic.
- Understand how to deploy these evaluation techniques to monitor the agentâ€™s performance in production.

By the end of this course, youâ€™ll know how to trace AI agents, systematically evaluate them, and improve their performance.

Please sign up here: https://t.co/hTNCM8xuYn

æ–°è¯¾ç¨‹ä¸Šçº¿ï¼šè¯„ä¼° AI æ™ºèƒ½ä½“ï¼ˆAI Agents)ï¼è¯„ä¼°ï¼ˆEvaluationï¼‰å¯¹äºæ¨åŠ¨äººå·¥æ™ºèƒ½ç³»ç»Ÿè¿›æ­¥è‡³å…³é‡è¦ï¼Œåœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ç³»ç»Ÿåœ°è¯„ä¼°å’Œæå‡ AI æ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚æœ¬è¯¾ç¨‹ç”± @arizeai åˆä½œå¼€å‘ï¼Œå¹¶ç”±å¼€å‘è€…å…³ç³»è´Ÿè´£äºº @JohnGilhuly å’Œäº§å“æ€»ç›‘ @_amankhan å…±åŒæˆè¯¾ã€‚

æˆ‘å¸¸å¸¸å‘ç°è¯„ä¼°æ˜¯æ™ºèƒ½ä½“å¼€å‘è¿‡ç¨‹ä¸­çš„ä¸€é¡¹å…³é”®å·¥å…· â€”â€” å®ƒå¯èƒ½å†³å®šæ‚¨çš„å›¢é˜Ÿæ˜¯é€‰å¯¹äº†å·¥ä½œæ–¹å‘ï¼Œè¿˜æ˜¯ç™½ç™½æµªè´¹æ•°å‘¨ç²¾åŠ›ã€‚æ— è®ºæ‚¨æ­£åœ¨æ„å»ºè´­ç‰©åŠ©æ‰‹ã€ç¼–ç¨‹æ™ºèƒ½ä½“ï¼Œè¿˜æ˜¯ç ”ç©¶åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä¸€ä¸ªç»“æ„åŒ–çš„è¯„ä¼°æµç¨‹éƒ½èƒ½å¸®åŠ©æ‚¨ç³»ç»Ÿåœ°ä¼˜åŒ–å…¶æ€§èƒ½ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾é ç›²ç›®çš„è¯•é”™ã€‚

æœ¬è¯¾ç¨‹å°†æŒ‡å¯¼æ‚¨å¦‚ä½•æ„å»ºè¯„ä¼°ä½“ç³»ï¼Œä»¥ä¾¿åŒæ—¶è¯„ä¼°æ™ºèƒ½ä½“çš„å„ä¸ªç»„ä»¶å’Œå…¶ç«¯åˆ°ç«¯ï¼ˆend-to-endï¼‰çš„æ•´ä½“æ€§èƒ½ã€‚å¯¹äºæ¯ä¸ªç»„ä»¶ï¼Œæ‚¨å°†å­¦ä¼šé€‰æ‹©åˆé€‚çš„è¯„ä¼°å™¨ã€æµ‹è¯•ç”¨ä¾‹å’Œæ€§èƒ½æŒ‡æ ‡ã€‚è¿™èƒ½å¸®åŠ©æ‚¨åœ¨å¼€å‘é˜¶æ®µå’Œå®é™…ç”Ÿäº§ç¯å¢ƒä¸­ç²¾å‡†å®šä½æ”¹è¿›ç‚¹ã€‚(å¦‚æœæ‚¨ç†Ÿæ‚‰ç›‘ç£å­¦ä¹ ä¸­çš„é”™è¯¯åˆ†æï¼Œå¯ä»¥æŠŠè¿™é—¨è¯¾çœ‹ä½œæ˜¯å°†é‚£äº›æ€è·¯å·§å¦™åœ°åº”ç”¨åˆ°æ™ºèƒ½ä½“å·¥ä½œæµç¨‹ä¸­ã€‚)

åœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†äº²æ‰‹æ­å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼Œå¹¶ä¸ºå…¶æ·»åŠ å¯è§‚æµ‹æ€§ï¼ˆobservabilityï¼‰åŠŸèƒ½ï¼Œä»è€Œå®ç°å…¶è¿è¡Œæ­¥éª¤çš„å¯è§†åŒ–å’Œè°ƒè¯•ã€‚æ‚¨å°†äº†è§£åŸºäºä»£ç çš„è¯„ä¼°æ–¹æ³• â€”â€” å³é€šè¿‡ç¼–å†™ä»£ç æ¥æ˜ç¡®æµ‹è¯•æŸä¸ªæ­¥éª¤ï¼›ä»¥åŠå¤§è¯­è¨€æ¨¡å‹å³æ³•å®˜ï¼ˆLLM-as-a-Judgeï¼‰è¯„ä¼°æ–¹æ³• â€”â€” å³é€šè¿‡å‘å¤§è¯­è¨€æ¨¡å‹æé—®ï¼Œæ¥é«˜æ•ˆåœ°è¯„ä¼°é‚£äº›æ›´å¼€æ”¾å¼çš„è¾“å‡ºç»“æœã€‚

å…·ä½“æ¥è¯´ï¼Œæ‚¨å°†ï¼š
- ç†è§£è¯„ä¼°åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç³»ç»Ÿä¸ä¼ ç»Ÿè½¯ä»¶æµ‹è¯•ä¹‹é—´çš„ä¸»è¦åŒºåˆ«ã€‚
- é€šè¿‡æ”¶é›†å¹¶å¯è§†åŒ–æ™ºèƒ½ä½“æ‰§è¡Œæ­¥éª¤çš„è½¨è¿¹ï¼Œä¸ºæ™ºèƒ½ä½“æ·»åŠ å¯è§‚æµ‹æ€§ã€‚
- ä¸ºæ¯ä¸ªç»„ä»¶é€‰æ‹©æœ€åˆé€‚çš„è¯„ä¼°å™¨ â€”â€” åŒ…æ‹¬åŸºäºä»£ç çš„ã€ å¤§è¯­è¨€æ¨¡å‹å³æ³•å®˜ï¼Œä»¥åŠåŸºäºäººå·¥æ ‡æ³¨çš„æ–¹æ³•ã€‚
- è®¡ç®—æ”¶æ•›åˆ†æ•°ï¼ˆconvergence scoreï¼‰ï¼Œä»¥è¯„ä¼°æ‚¨çš„æ™ºèƒ½ä½“èƒ½å¦ä»¥é«˜æ•ˆçš„æ­¥æ•°å“åº”æŸ¥è¯¢ã€‚
- è¿è¡Œç»“æ„åŒ–å®éªŒï¼Œé€šè¿‡è°ƒæ•´æç¤ºï¼ˆpromptï¼‰ã€æ›´æ¢å¤§è¯­è¨€æ¨¡å‹æ¨¡å‹æˆ–ä¿®æ”¹æ™ºèƒ½ä½“é€»è¾‘ï¼Œæ¥æå‡æ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚
- æŒæ¡å¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”ç”¨è¿™äº›è¯„ä¼°æŠ€æœ¯ï¼ŒæŒç»­ç›‘æ§æ™ºèƒ½ä½“çš„è¡¨ç°ã€‚

å­¦å®Œæœ¬è¯¾ç¨‹ï¼Œæ‚¨å°†èƒ½å¤Ÿè¿½è¸ª AI æ™ºèƒ½ä½“çš„è¿è¡Œè¿‡ç¨‹ï¼Œç³»ç»Ÿåœ°è¯„ä¼°å®ƒä»¬ï¼Œå¹¶æœ‰æ•ˆæå‡å®ƒä»¬çš„æ€§èƒ½ã€‚

è¯·ç‚¹å‡»æ­¤å¤„æŠ¥åï¼šhttps://t.co/hTNCM8xuYn

### 037

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-20
é“¾æ¥: https://x.com/AndrewYNg/status/1892628887856939236
äº’åŠ¨: Likes: 591; Retweets: 107; Replies: 167; Quotes: 10; Views: 64,457; Bookmarks: 122; isReply: 0

Last month, a drone from Skyfire AI was credited with saving a police officerâ€™s life after a dramatic 2 a.m. traffic stop. Many statistics show that AI impacts billions of lives, but sometimes a story still hits me emotionally. Let me share what happened.

Skyfire AI, an AI Fund portfolio company led by CEO Don Mathis, operates a public safety program in which drones function as first responders to 911 calls. Particularly when a police department is personnel-constrained, drones can save officersâ€™ time while enhancing their situational awareness. For example, many burglar alarms are false alarms, maybe set off by moisture or an animal. Rather than sending a patrol officer to drive over to discover this, a drone can get there faster and determine if an officer is required at all. If the alarm is real, the drone can help officers understand the situation, the locations of any perpetrators, and how best to respond.

In January, a Skyfire AI drone was returning to base after responding to a false alarm when the police dispatcher asked us to reroute it to help locate a patrol officer. The officer had radioed a few minutes earlier that he had pulled over a suspicious vehicle and had not been heard from since. The officer had stopped where two major highways intersect in a complex cloverleaf, and dispatch was unsure exactly where they were located.

From the air, the drone rapidly located the officer and the driver of the vehicle he had pulled over, who it turned out had escaped from a local detention facility. Neither would have been visible from the road â€” they were fighting in a drainage ditch below the highway. Because of the complexity of the cloverleafâ€™s geometry, the watch officer (who coordinates police activities for the shift) later estimated it would have taken 5-7 minutes for an officer in a patrol car to find  them.

From the aerial footage, it appeared that the officer still had his radio, but  was losing the fight and unable to reach it to call for help. Further, it looked like the assailant might gain control of his service weapon and use it against him. This was a dire and dangerous situation.

Fortunately, because the drone had pinpointed the location of the officer and his assailant, dispatch was able to direct additional units to assist. The first arrived not in 5-7 minutes but in 45 seconds. Four more units arrived within minutes.

The officers were able to take control of the situation and apprehend the driver, resulting in an arrest and, more important, a safe outcome for the officer. Subsequently, the watch officer said weâ€™d probably saved the officerâ€™s life.

Democratic nations still have a lot of work to do on drone technology, and we must build this technology with guardrails to make sure we enhance civil liberties and human rights. But I am encouraged by the progress weâ€™re making. In the aftermath of Hurricane Helene last year, Skyfire AIâ€™s drones supported search-and-rescue operations under the direction of the North Carolina Office of Emergency Management, responding to specific requests to help locate missing persons and direct rescue assets (e.g., helicopters and boats) to their location, and was credited with saving 13 lives.

Itâ€™s not every day that AI directly saves someone's life. But as our technology advances, I think there will be more and more stories like these.

[Original text: https://t.co/xtBdJgqIqc ]

ä¸Šä¸ªæœˆï¼ŒSkyfire AI çš„ä¸€æ¶æ— äººæœºåœ¨ä¸€æ¬¡æƒŠå¿ƒåŠ¨é­„çš„å‡Œæ™¨ä¸¤ç‚¹äº¤é€šæ‹¦æˆªä¸­ï¼ŒæˆåŠŸæŒ½æ•‘äº†ä¸€åè­¦å®˜çš„ç”Ÿå‘½ã€‚è®¸å¤šç»Ÿè®¡æ•°æ®éƒ½è¡¨æ˜ï¼ŒAIï¼ˆäººå·¥æ™ºèƒ½ï¼‰æ­£å½±å“ç€æ•°åäº¿äººçš„ç”Ÿæ´»ï¼Œä½†æœ‰æ—¶ä¸€äº›çœŸå®çš„æ•…äº‹ä¾ç„¶ä¼šæ·±æ·±è§¦åŠ¨æˆ‘çš„å†…å¿ƒã€‚ä¸‹é¢æˆ‘å°±æ¥åˆ†äº«ä¸€ä¸‹è¿™ä¸ªäº‹ä»¶çš„å§‹æœ«ã€‚

Skyfire AI æ˜¯ä¸€å®¶ç”± CEO Don Mathis é¢†å¯¼çš„ AI Fund æŠ•èµ„ç»„åˆå…¬å¸ï¼Œå…¶è¿è¥ç€ä¸€é¡¹å…¬å…±å®‰å…¨è®¡åˆ’ï¼Œè®©æ— äººæœºä½œä¸º 911 ç´§æ€¥å‘¼å«çš„ç¬¬ä¸€å“åº”è€…ã€‚å°¤å…¶æ˜¯åœ¨è­¦åŠ›å—é™çš„éƒ¨é—¨ï¼Œæ— äººæœºä¸ä»…èƒ½ä¸ºè­¦å®˜èŠ‚çœå®è´µæ—¶é—´ï¼Œè¿˜èƒ½æ˜¾è‘—å¢å¼ºä»–ä»¬çš„æ€åŠ¿æ„ŸçŸ¥ï¼ˆSituational Awarenessï¼‰èƒ½åŠ›ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œè®¸å¤šé˜²ç›—è­¦æŠ¥éƒ½å±äºè¯¯æŠ¥ï¼Œå¯èƒ½åªæ˜¯ç”±æ½®æ¹¿æˆ–å°åŠ¨ç‰©è§¦å‘çš„ã€‚è¿™æ—¶ï¼Œä¸å…¶æ´¾å·¡é€»è­¦å®˜å¼€è½¦å‰å¾€ç°åœºç¡®è®¤ï¼Œæ— äººæœºèƒ½æ›´å¿«æŠµè¾¾ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦çœŸçš„éœ€è¦è­¦å®˜ä»‹å…¥ã€‚å¦‚æœè­¦æŠ¥å±å®ï¼Œæ— äººæœºè¿˜èƒ½å¸®åŠ©è­¦å®˜äº†è§£ç°åœºæƒ…å†µã€å«Œç–‘äººçš„ä½ç½®ä»¥åŠæœ€ä½³çš„åº”å¯¹ç­–ç•¥ã€‚

ä»Šå¹´ä¸€æœˆï¼Œä¸€æ¶ Skyfire AI æ— äººæœºåœ¨å“åº”äº†ä¸€æ¬¡è¯¯æŠ¥åæ­£å‡†å¤‡è¿”èˆªåŸºåœ°ï¼Œè¿™æ—¶è­¦æ–¹è°ƒåº¦å‘˜è¯·æ±‚æˆ‘ä»¬æ”¹å˜èˆªçº¿ï¼ŒååŠ©å®šä½ä¸€åå·¡é€»è­¦å®˜ã€‚è¿™åè­¦å®˜åœ¨å‡ åˆ†é’Ÿå‰æ›¾é€šè¿‡æ— çº¿ç”µæŠ¥å‘Šï¼Œä»–æ‹¦ä¸‹äº†ä¸€è¾†å¯ç–‘è½¦è¾†ï¼Œä½†æ­¤åä¾¿å¤±å»äº†è”ç³»ã€‚è­¦å®˜åœè½¦çš„ä½ç½®æ˜¯ä¸¤æ¡ä¸»è¦é«˜é€Ÿå…¬è·¯åœ¨ä¸€ä¸ªå¤æ‚çš„è‹œè“¿å¶å½¢ç«‹äº¤æ¡¥å¤„äº¤æ±‡ï¼Œè°ƒåº¦ä¸­å¿ƒä¸ç¡®å®šä»–ä»¬çš„ç¡®åˆ‡ä½ç½®ã€‚

ä»ç©ºä¸­ä¿¯ç°ï¼Œæ— äººæœºè¿…é€Ÿé”å®šäº†è­¦å®˜ä»¥åŠä»–æ‰€æ‹¦æˆªè½¦è¾†çš„å¸æœºã€‚åŸæ¥ï¼Œè¿™åå¸æœºæ˜¯ä»å½“åœ°ä¸€æ‰€çœ‹å®ˆæ‰€è¶Šç‹±çš„é€ƒçŠ¯ã€‚ä»åœ°é¢ä¸Šçœ‹ï¼Œä¸¤äººéƒ½æ— æ³•è¢«å‘ç° â€”â€” ä»–ä»¬æ­£åœ¨é«˜é€Ÿå…¬è·¯ä¸‹æ–¹çš„ä¸€ä¸ªæ’æ°´æ²Ÿé‡Œæ¿€çƒˆææ–—ã€‚ç”±äºè‹œè“¿å¶å½¢ç«‹äº¤æ¡¥çš„å¤æ‚å‡ ä½•ç»“æ„ï¼Œå€¼ç­è­¦å®˜ï¼ˆè´Ÿè´£åè°ƒå½“ç­è­¦åŠ¡æ´»åŠ¨ï¼‰åæ¥ä¼°è®¡ï¼Œå¦‚æœç”±è­¦è½¦å†…çš„è­¦å®˜é©¾è½¦å¯»æ‰¾ï¼Œè‡³å°‘éœ€è¦ 5 åˆ° 7 åˆ†é’Ÿæ‰èƒ½æ‰¾åˆ°ä»–ä»¬ã€‚

ä»æ— äººæœºä¼ å›çš„ç©ºä¸­ç”»é¢æ˜¾ç¤ºï¼Œè­¦å®˜çš„æ— çº¿ç”µè™½ç„¶ä»åœ¨èº«è¾¹ï¼Œä½†ä»–åœ¨è¿™åœºææ–—ä¸­æ­£å¤„äºåŠ£åŠ¿ï¼Œæ ¹æœ¬æ— æš‡é¡¾åŠå»å‘¼å«æ”¯æ´ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œçœ‹èµ·æ¥è¢­å‡»è€…ä¼¼ä¹æœ‰å¯èƒ½å¤ºèµ°ä»–çš„é…æªï¼Œå¹¶ç”¨æ¥æ”»å‡»è­¦å®˜ã€‚è¿™æ— ç–‘æ˜¯ä¸€ä¸ªæå…¶å±æ€¥å’Œå±é™©çš„å±€é¢ã€‚

å¹¸è¿çš„æ˜¯ï¼Œç”±äºæ— äººæœºç²¾ç¡®é”å®šäº†è­¦å®˜å’Œè¢­å‡»è€…çš„ä½ç½®ï¼Œè°ƒåº¦ä¸­å¿ƒèƒ½å¤Ÿç«‹å³æŒ‡ç¤ºå¢æ´è­¦åŠ›å‰å¾€ååŠ©ã€‚ç¬¬ä¸€æ‰¹æ”¯æ´å•ä½ä¸æ˜¯åœ¨ 5 åˆ° 7 åˆ†é’Ÿååˆ°è¾¾ï¼Œè€Œæ˜¯åœ¨ä»…ä»… 45 ç§’å†…ä¾¿èµ¶åˆ°ç°åœºã€‚éšåçš„å››è¾†è­¦è½¦ä¹Ÿåœ¨å‡ åˆ†é’Ÿå†…é™†ç»­æŠµè¾¾ã€‚

åœ¨å¢æ´è­¦åŠ›çš„å¸®åŠ©ä¸‹ï¼Œè­¦å®˜ä»¬æˆåŠŸæ§åˆ¶äº†å±€é¢å¹¶é€®æ•äº†å¸æœºã€‚æœ€ç»ˆï¼Œè¿™åé€ƒçŠ¯è¢«æ•ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œè­¦å®˜æœ¬äººå®‰ç„¶æ— æ™ã€‚äº‹åï¼Œå€¼ç­è­¦å®˜è¡¨ç¤ºï¼Œæˆ‘ä»¬å¾ˆå¯èƒ½æŒ½æ•‘äº†è¿™åè­¦å®˜çš„ç”Ÿå‘½ã€‚

æ°‘ä¸»å›½å®¶åœ¨æ— äººæœºæŠ€æœ¯æ–¹é¢ä»æœ‰è®¸å¤šå·¥ä½œè¦åšï¼Œæˆ‘ä»¬å¿…é¡»åœ¨å¼€å‘è¿™é¡¹æŠ€æœ¯æ—¶ï¼ŒåŒæ­¥å»ºç«‹å®Œå–„çš„ä¿éšœæœºåˆ¶ï¼Œä»¥ç¡®ä¿å…¬æ°‘è‡ªç”±å’Œäººæƒå¾—åˆ°å……åˆ†ç»´æŠ¤ã€‚ä½†æˆ‘å¯¹æˆ‘ä»¬ç›®å‰æ‰€å–å¾—çš„è¿›å±•æ„Ÿåˆ°éå¸¸é¼“èˆã€‚å»å¹´é£“é£ Helene å¸­å·ä¹‹åï¼ŒSkyfire AI çš„æ— äººæœºå°±åœ¨åŒ—å¡ç½—æ¥çº³å·åº”æ€¥ç®¡ç†åŠå…¬å®¤çš„æŒ‡æŒ¥ä¸‹ï¼Œå‚ä¸äº†æœæ•‘è¡ŒåŠ¨ã€‚å®ƒä»¬å“åº”å…·ä½“è¯·æ±‚ï¼Œå¸®åŠ©å®šä½å¤±è¸ªäººå‘˜ï¼Œå¹¶å¼•å¯¼æ•‘æ´èµ„æºï¼ˆä¾‹å¦‚ç›´å‡æœºå’Œèˆ¹åªï¼‰å‰å¾€æŒ‡å®šä½ç½®ï¼Œæœ€ç»ˆæˆåŠŸæŒ½æ•‘äº† 13 æ¡ç”Ÿå‘½ã€‚

AI å¹¶éæ¯å¤©éƒ½èƒ½ç›´æ¥æŒ½æ•‘ç”Ÿå‘½ã€‚ä½†éšç€æˆ‘ä»¬æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥ï¼Œæˆ‘ç›¸ä¿¡è¿™æ ·çš„æ•…äº‹å°†ä¼šè¶Šæ¥è¶Šå¤šã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/xtBdJgqIqc]

### 038

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-26
é“¾æ¥: https://x.com/AndrewYNg/status/1894796562829844873
äº’åŠ¨: Likes: 1,565; Retweets: 271; Replies: 143; Quotes: 24; Views: 138,836; Bookmarks: 1,267; isReply: 0

New course to bring you up to state-of-the-art at using AI to help you code: Build Apps with Windsurf's AI Coding Agents, built in partnership with WIndsurf (@codeiumdev) and taught by @_anshulr!

AI-assisted IDEs (Integrated Development Environments) make developersâ€™ workflows faster, more efficient, and much more fun. Agentic tools like Windsurf are more than just code autocompleteâ€”they are collaborative coding agents that help you break down complex applications, iterate efficiently, and generate code that spans multiple files.

Although a lot of coding assistants share the same underlying large language models for planning and reasoning, a major point of distinction is how they handle tools, keep track of context, and stay aligned with your intent as a developer.

For instance, if you make modifications to a class definition in your code and make the same modifications to other classes in the same directory, you might tell the AI agent "Do the same thing in similar places in this directory." Here, tracking your intent means understanding that â€œthe same thing" refers to that recent edit you just made, which must be followed by appropriate search and tool-calling to implement the changes.

In this course, you'll learn the inner workings of coding agents, their strengths and limitations, and how to use Windsurf to quickly build several applications.

In detail, you'll:
- Build a mental model of how agents work by combining human-action tracking, tool integration, and context awareness to carry out an agentic coding workflow.
- Learn the challenges of code search and discovery and how a multi-step retrieval approach helps coding agents address them.
- Use Windsurf to analyze and understand a large, old codebase and update it to the latest versions of the frameworks and packages it uses.
- Build a Wikipedia data analysis app that retrieves, parses, and analyzes word frequencies.
- Enhance the performance of your Wikipedia analysis app by adding caching, and through this, also learn how to course-correct when the AI agent produces unexpected results.
- Learn tips and tricks such as keyboard shortcuts, autocomplete, and @ mentions to quickly call on agentic capabilities.
- Use image/multimodal capabilities of the AI agent to increase your development velocity; you'll see an example of uploading a mockup with sketched-out UI features, and ask the agent to use that to build new functionality to an app.

By the end of this course, youâ€™ll understand agentic coding in-depth and know how to use it to make your development process much faster, more efficient, and enjoyable.

Please sign up here! https://t.co/IhFB3IwHAh

å…¨æ–°è¯¾ç¨‹ï¼ŒåŠ©æ‚¨æŒæ¡åˆ©ç”¨ AI è¾…åŠ©ç¼–ç¨‹çš„æœ€æ–°å‰æ²¿æŠ€æœ¯ï¼šå­¦ä¹ ä½¿ç”¨ Windsurf çš„ AI ç¼–ç æ™ºèƒ½ä½“æ„å»ºåº”ç”¨ç¨‹åºï¼æœ¬è¯¾ç¨‹ç”± Windsurfï¼ˆ@codeiumdevï¼‰åˆä½œå¼€å‘ï¼Œå¹¶ç”± @_anshulr äº²è‡ªè®²æˆã€‚

AI è¾…åŠ©çš„é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEs - Integrated Development Environmentsï¼‰èƒ½è®©å¼€å‘è€…çš„å·¥ä½œæµç¨‹æ›´å¿«é€Ÿã€æ›´é«˜æ•ˆï¼Œä¹Ÿæ›´æœ‰è¶£ã€‚åƒ Windsurf è¿™æ ·çš„æ™ºèƒ½ä½“ï¼ˆAgenticï¼‰å·¥å…·ä¸ä»…ä»…æ˜¯ç®€å•çš„ä»£ç è‡ªåŠ¨è¡¥å…¨ â€”â€” å®ƒä»¬æ˜¯çœŸæ­£çš„åä½œå¼ç¼–ç¨‹æ™ºèƒ½ä½“ï¼Œèƒ½å¸®åŠ©ä½ æ‹†è§£å¤æ‚çš„åº”ç”¨ç¨‹åºã€é«˜æ•ˆè¿­ä»£ï¼Œå¹¶ç”Ÿæˆè·¨å¤šä¸ªæ–‡ä»¶çš„ä»£ç ã€‚

å°½ç®¡è®¸å¤šç¼–ç¨‹åŠ©æ‰‹åœ¨è§„åˆ’å’Œæ¨ç†æ—¶éƒ½ä¾èµ–ç›¸åŒçš„åº•å±‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼‰ï¼Œä½†å®ƒä»¬ä¹‹é—´çš„ä¸€ä¸ªä¸»è¦åŒºåˆ«åœ¨äºï¼šå®ƒä»¬å¦‚ä½•å¤„ç†å·¥å…·ã€è·Ÿè¸ªä¸Šä¸‹æ–‡ï¼Œä»¥åŠå¦‚ä½•ä¸ä½ ä½œä¸ºå¼€å‘è€…çš„æ„å›¾ä¿æŒä¸€è‡´ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœä½ åœ¨ä»£ç ä¸­ä¿®æ”¹äº†ä¸€ä¸ªç±»å®šä¹‰ï¼Œå¹¶æƒ³åœ¨åŒä¸€ç›®å½•çš„å…¶ä»–ç±»ä¸­ä¹Ÿè¿›è¡Œç›¸åŒçš„ä¿®æ”¹ï¼Œä½ å¯èƒ½ä¼šå‘Šè¯‰ AI æ™ºèƒ½ä½“ã€Œåœ¨è¿™ä¸ªç›®å½•é‡Œç±»ä¼¼çš„åœ°æ–¹ä¹ŸåšåŒæ ·çš„äº‹æƒ…ã€‚ã€åœ¨è¿™é‡Œï¼Œè·Ÿè¸ªä½ çš„æ„å›¾å°±æ„å‘³ç€è¦ç†è§£ã€ŒåŒæ ·çš„äº‹æƒ…ã€æŒ‡çš„å°±æ˜¯ä½ åˆšåˆšåšå‡ºçš„é‚£ä¸ªç¼–è¾‘ã€‚AI æ™ºèƒ½ä½“ä¼šæ®æ­¤è¿›è¡Œé€‚å½“çš„æœç´¢å’Œå·¥å…·è°ƒç”¨ï¼Œä»è€Œå¸®ä½ å®ç°è¿™äº›æ›´æ”¹ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†æ·±å…¥å­¦ä¹ ç¼–ç¨‹æ™ºèƒ½ä½“çš„å·¥ä½œåŸç†ã€å®ƒä»¬çš„ä¼˜åŠ¿ä¸å±€é™æ€§ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨ Windsurf å¿«é€Ÿæ„å»ºå¤šä¸ªåº”ç”¨ç¨‹åºã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- ç»“åˆäººå·¥æ“ä½œè·Ÿè¸ªã€å·¥å…·é›†æˆå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œæ„å»ºä¸€ä¸ªå…³äºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰å·¥ä½œåŸç†çš„å¿ƒæ™ºæ¨¡å‹ï¼Œä»è€ŒæŒæ¡æ™ºèƒ½ä½“é©±åŠ¨çš„ç¼–ç¨‹å·¥ä½œæµç¨‹ã€‚
- äº†è§£ä»£ç æœç´¢å’Œå‘ç°çš„æŒ‘æˆ˜ï¼Œä»¥åŠå¤šæ­¥æ£€ç´¢æ–¹æ³•å¦‚ä½•å¸®åŠ©ç¼–ç¨‹æ™ºèƒ½ä½“æœ‰æ•ˆåº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚
- ä½¿ç”¨ Windsurf åˆ†æå¹¶ç†è§£ä¸€ä¸ªåºå¤§ä¸”é™ˆæ—§çš„ä»£ç åº“ï¼Œå¹¶å°†å…¶æ›´æ–°åˆ°æ‰€ç”¨æ¡†æ¶å’Œè½¯ä»¶åŒ…çš„æœ€æ–°ç‰ˆæœ¬ã€‚
- æ„å»ºä¸€ä¸ªç»´åŸºç™¾ç§‘æ•°æ®åˆ†æåº”ç”¨ç¨‹åºï¼Œç”¨äºæ£€ç´¢ã€è§£æå’Œåˆ†æè¯é¢‘ã€‚
- é€šè¿‡æ·»åŠ ç¼“å­˜ï¼ˆCachingï¼‰æ¥æå‡ç»´åŸºç™¾ç§‘åˆ†æåº”ç”¨ç¨‹åºçš„æ€§èƒ½ï¼›åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä½ è¿˜å°†å­¦ä¹ å½“ AI æ™ºèƒ½ä½“äº§ç”Ÿæ„å¤–ç»“æœæ—¶å¦‚ä½•è¿›è¡Œä¿®æ­£ã€‚
- å­¦ä¹ å„ç§å®ç”¨æŠ€å·§ï¼Œå¦‚é”®ç›˜å¿«æ·é”®ã€è‡ªåŠ¨è¡¥å…¨ä»¥åŠ @ æåŠï¼ˆMentionsï¼‰åŠŸèƒ½ï¼Œä»¥ä¾¿å¿«é€Ÿè°ƒç”¨æ™ºèƒ½ä½“çš„å¼ºå¤§èƒ½åŠ›ã€‚
- åˆ©ç”¨ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰çš„å›¾åƒ / å¤šæ¨¡æ€ï¼ˆMultimodalï¼‰èƒ½åŠ›æ¥åŠ é€Ÿå¼€å‘è¿›ç¨‹ï¼›ä½ å°†çœ‹åˆ°ä¸€ä¸ªç¤ºä¾‹ï¼Œæ¼”ç¤ºå¦‚ä½•ä¸Šä¼ å¸¦æœ‰æ‰‹ç»˜ UI åŠŸèƒ½çš„åŸå‹å›¾ï¼Œå¹¶è¦æ±‚æ™ºèƒ½ä½“åˆ©ç”¨å®ƒæ¥ä¸ºåº”ç”¨ç¨‹åºæ·»åŠ æ–°åŠŸèƒ½ã€‚

é€šè¿‡æœ¬è¯¾ç¨‹çš„å­¦ä¹ ï¼Œä½ å°†æ·±å…¥ç†è§£æ™ºèƒ½ä½“é©±åŠ¨çš„ç¼–ç¨‹ï¼ˆAgentic Codingï¼‰ï¼Œå¹¶æŒæ¡å¦‚ä½•è¿ç”¨å®ƒæ¥è®©ä½ çš„å¼€å‘è¿‡ç¨‹å˜å¾—æ›´å¿«ã€æ›´é«˜æ•ˆã€æ›´ä»¤äººæ„‰å¿«ã€‚

è¯·ç‚¹å‡»è¿™é‡ŒæŠ¥åï¼https://t.co/IhFB3IwHAh

### 039

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-27
é“¾æ¥: https://x.com/AndrewYNg/status/1894979731726180765
äº’åŠ¨: Likes: 1,858; Retweets: 281; Replies: 94; Quotes: 13; Views: 159,066; Bookmarks: 537; isReply: 0

Transformers have dominated LLM text generation, and generate tokens sequentially. This is a cool attempt to explore diffusion models as an alternative, by generating the entire text at the same time using a coarse-to-fine process. Congrats @StefanoErmon &amp; team!

åœ¨è¿‡å»ï¼ŒTransformer æ¨¡å‹åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–‡æœ¬ç”Ÿæˆé¢†åŸŸä¸€ç›´å æ®ä¸»å¯¼åœ°ä½ï¼Œå®ƒä»¬é€šå¸¸ä»¥é¡ºåºæ–¹å¼ç”Ÿæˆ Tokenã€‚ç°åœ¨ï¼Œæœ‰ä¸€é¡¹å¼•äººæ³¨ç›®çš„å°è¯•ï¼Œæ¢ç´¢å°†æ‰©æ•£æ¨¡å‹ï¼ˆdiffusion modelsï¼‰ä½œä¸ºä¸€ç§æ›¿ä»£æ–¹æ³•ï¼Œå…¶åˆ›æ–°ä¹‹å¤„åœ¨äºåˆ©ç”¨ä¸€ç§ä»ç²—åˆ°ç²¾ï¼ˆcoarse-to-fineï¼‰çš„è¿‡ç¨‹æ¥åŒæ—¶ç”Ÿæˆæ•´ä¸ªæ–‡æœ¬ã€‚ç¥è´º @StefanoErmon åŠå›¢é˜Ÿï¼

### 040

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-27
é“¾æ¥: https://x.com/AndrewYNg/status/1895146310296379419
äº’åŠ¨: Likes: 661; Retweets: 142; Replies: 132; Quotes: 23; Views: 76,927; Bookmarks: 346; isReply: 0

The Voice Stack is improving rapidly. Systems that interact with users via speaking and listening will drive many new applications. Over the past year, Iâ€™ve been working closely with https://t.co/zpIxRSuky4, AI Fund, and several collaborators on voice-based applications, and I will share best practices Iâ€™ve learned in this and future posts.

Foundation models that are trained to directly input, and often also directly generate, audio have contributed to this growth, but they are only part of the story. OpenAIâ€™s RealTime API makes it easy for developers to write prompts to develop systems that deliver voice-in, voice-out experiences. This is great for building quick-and-dirty prototypes, and it also works well for low-stakes conversations where making an occasional mistake is okay. I encourage you to try it!

However, compared to text-based generation, it is still hard to control the output of voice-in voice-out models. In contrast to directly generating audio, when we use an LLM to generate text, we have many tools for building guardrails, and we can double-check the output before showing it to users. We can also use sophisticated agentic reasoning workflows to compute high-quality outputs. Before a customer-service agent shows a user the message, â€œSure, Iâ€™m happy to issue a refund,â€ we can make sure that (i) issuing the refund is consistent with our business policy and (ii) we will call the API to issue the refund (and not just promise a refund without issuing it).

In contrast, the tools to prevent a voice-in, voice-out model from making such mistakes are much less mature.

In my experience, the reasoning capability of voice models also seems inferior to text-based models, and they give less sophisticated answers. (Perhaps this is because voice responses have to be more brief, leaving less room for chain-of-thought reasoning to get to a more thoughtful answer.)

When building applications where I need a high degree of control over the output, I use agentic workflows to reason at length about the userâ€™s input. In voice applications, this means I end up using a pipeline that includes speech-to-text (STT, also known as ASR, or automatic speech recognition) to transcribe the userâ€™s words, then processes the text using one or more LLM calls, and finally returns an audio response to the user via TTS (text-to-speech). This STT â†’ LLM/Agentic workflow â†’ TTS pipeline, where the reasoning is done in text, allows for more accurate responses.

However, this process introduces latency, and users of voice applications are very sensitive to latency. When https://t.co/zpIxRSuky4 worked with RealAvatar (an AI Fund portfolio company led by Jeff Daniel) to build an avatar of me, we found that getting TTS to generate a voice that sounded like me was not very hard, but getting it to respond to questions using words similar to those I would choose was. Even after a year of tuning our system â€” starting with iterating on multiple, long, mega-prompts and eventually developing complex agentic workflows â€” it remains a work in progress. You can play with it at https://t.co/vMO2CM0xfb

Initially, this agentic workflow incurred 5-9 seconds of latency, and having users wait that long for responses led to a bad experience. To address this, we came up with the following latency reduction technique. The system quickly generates a pre-response (short for preliminary response) that can be uttered quickly, which buys time for an agentic workflow to generate a more thoughtful, full response. (Weâ€™re grateful to LiveKitâ€™s CEO Russ dâ€™Sa and team for helping us get this working.) This is similar to how, if you were to ask me a complicated question, I might say â€œHmm, let me think about thatâ€ or â€œSure, I can help with thatâ€ â€” thatâ€™s the pre-response â€” while thinking about what my full response might be.

I think generating a pre-response followed by a full response, to quickly acknowledge the userâ€™s query and also reduce the perceived latency, will be an important technique, and I hope many teams will find this useful. Our goal was to approach human face-to-face conversational latency, which is around 0.3-1 seconds. RealAvatar and https://t.co/zpIxRSuky4, through our efforts on the pre-response and other optimizations, have reduced the systemâ€™s latency to around 0.5-1 seconds.

Months ago, sitting in a coffee shop, I was able to buy a phone number on Twilio and hook it up to an STT â†’ LLM â†’ TTS pipeline in just hours. This enabled me to talk to my own LLM using custom prompts. Prototyping voice applications is much easier than most people realize!

Building reliable, scaled production applications takes longer, of course, but if you have a voice application in mind, I hope youâ€™ll start building prototypes and see how far you can get! Iâ€™ll keep building voice applications and sharing best practices and voice-related technology trends in future posts.

[Original letter: https://t.co/M38Ud0UhdT ]

è¯­éŸ³æŠ€æœ¯æ ˆï¼ˆVoice Stackï¼‰æ­£åœ¨å¿«é€Ÿå‘å±•ã€‚é‚£äº›é€šè¿‡è¯­éŸ³äº¤äº’ä¸ç”¨æˆ·æ²Ÿé€šçš„ç³»ç»Ÿï¼Œå°†å‚¬ç”Ÿå‡ºè®¸å¤šå…¨æ–°çš„åº”ç”¨ã€‚åœ¨è¿‡å»ä¸€å¹´é‡Œï¼Œæˆ‘ä¸€ç›´ä¸ https://t.co/zpIxRSuky4ã€AI Fund ä»¥åŠå¤šä½åˆä½œä¼™ä¼´ç´§å¯†åä½œï¼Œè‡´åŠ›äºå¼€å‘åŸºäºè¯­éŸ³çš„åº”ç”¨ã€‚æˆ‘å°†åœ¨æœ¬æ–‡åŠåç»­æ–‡ç« ä¸­ï¼Œåˆ†äº«æˆ‘æ‰€å­¦åˆ°çš„æœ€ä½³å®è·µã€‚

ç»è¿‡è®­ç»ƒå¯ä»¥ç›´æ¥æ¥æ”¶å¹¶é€šå¸¸ä¹Ÿç›´æ¥ç”ŸæˆéŸ³é¢‘çš„åŸºç¡€æ¨¡å‹ï¼ˆFoundation modelsï¼‰ï¼Œå¯¹è¿™ä¸€å‘å±•èµ·åˆ°äº†æ¨åŠ¨ä½œç”¨ï¼Œä½†è¿™åªæ˜¯å…¶ä¸­çš„ä¸€éƒ¨åˆ†ã€‚OpenAI çš„ RealTime API è®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾ç¼–å†™æç¤ºï¼ˆpromptsï¼‰ï¼Œä»è€Œå¼€å‘å‡ºæ”¯æŒè¯­éŸ³è¾“å…¥ã€è¯­éŸ³è¾“å‡ºï¼ˆvoice-inï¼Œvoice-outï¼‰ä½“éªŒçš„ç³»ç»Ÿã€‚è¿™å¯¹äºå¿«é€Ÿæ­å»ºåŸå‹éå¸¸æœ‰ç”¨ï¼Œä¹Ÿé€‚ç”¨äºé‚£äº›å¶å°”å‡ºé”™ä¹Ÿæ— å…³ç´§è¦çš„ä½é£é™©å¯¹è¯ã€‚æˆ‘é¼“åŠ±å¤§å®¶äº²è‡ªä½“éªŒä¸€ä¸‹ï¼

ç„¶è€Œï¼Œä¸åŸºäºæ–‡æœ¬çš„ç”Ÿæˆç›¸æ¯”ï¼Œç›®å‰ä»ç„¶å¾ˆéš¾ç²¾ç¡®æ§åˆ¶è¯­éŸ³åˆ°è¯­éŸ³æ¨¡å‹çš„è¾“å‡ºã€‚ä¸ç›´æ¥ç”ŸæˆéŸ³é¢‘ä¸åŒï¼Œå½“æˆ‘ä»¬ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œæˆ‘ä»¬æœ‰è®¸å¤šå·¥å…·æ¥æ„å»ºã€ŒæŠ¤æ ã€(guardrailsï¼‰ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‘ç”¨æˆ·å±•ç¤ºè¾“å‡ºä¹‹å‰è¿›è¡ŒäºŒæ¬¡æ£€æŸ¥ã€‚æˆ‘ä»¬è¿˜å¯ä»¥è¿ç”¨å¤æ‚çš„ AI æ™ºèƒ½ä½“ï¼ˆagenticï¼‰å·¥ä½œæµæ¥ç”Ÿæˆé«˜è´¨é‡çš„è¾“å‡ºã€‚ä¾‹å¦‚ï¼Œåœ¨å®¢æˆ·æœåŠ¡ AI æ™ºèƒ½ä½“å‘ç”¨æˆ·å‘é€ã€Œå½“ç„¶ï¼Œæˆ‘å¾ˆä¹æ„ä¸ºæ‚¨åŠç†é€€æ¬¾ã€è¿™æ¡æ¶ˆæ¯ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿ï¼ˆiï¼‰åŠç†é€€æ¬¾ç¬¦åˆæˆ‘ä»¬çš„ä¸šåŠ¡æ”¿ç­–ï¼Œå¹¶ä¸”ï¼ˆiiï¼‰æˆ‘ä»¬ä¼šè°ƒç”¨ç›¸åº”çš„ API æ¥å®é™…æ‰§è¡Œé€€æ¬¾æ“ä½œï¼ˆè€Œä¸ä»…ä»…æ˜¯å£å¤´æ‰¿è¯ºï¼‰ã€‚

ç›¸æ¯”ä¹‹ä¸‹ï¼Œç›®å‰é˜²æ­¢è¯­éŸ³åˆ°è¯­éŸ³æ¨¡å‹çŠ¯è¿™ç±»é”™è¯¯çš„å·¥å…·è¿˜è¿œä¸å¤Ÿæˆç†Ÿã€‚

æ ¹æ®æˆ‘çš„ç»éªŒï¼Œè¯­éŸ³æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¼¼ä¹ä¹Ÿæ¯”åŸºäºæ–‡æœ¬çš„æ¨¡å‹é€Šè‰²ï¼Œå®ƒä»¬ç»™å‡ºçš„ç­”æ¡ˆå¾€å¾€ä¸å¤Ÿç²¾å¦™ã€‚(è¿™å¯èƒ½æ˜¯å› ä¸ºè¯­éŸ³å›å¤å¿…é¡»æ›´ç®€æ´ï¼Œç•™ç»™æ€ç»´é“¾ï¼ˆchain-of-thoughtï¼‰æ¨ç†çš„ç©ºé—´è¾ƒå°‘ï¼Œä»è€Œéš¾ä»¥å¾—å‡ºæ›´æ·±æ€ç†Ÿè™‘çš„ç­”æ¡ˆã€‚)

åœ¨æ„å»ºéœ€è¦é«˜åº¦æ§åˆ¶è¾“å‡ºçš„åº”ç”¨æ—¶ï¼Œæˆ‘é€šå¸¸ä¼šé‡‡ç”¨ AI æ™ºèƒ½ä½“å·¥ä½œæµï¼Œå¯¹ç”¨æˆ·çš„è¾“å…¥è¿›è¡Œæ·±å…¥æ¨ç†ã€‚åœ¨è¯­éŸ³åº”ç”¨ä¸­ï¼Œè¿™æ„å‘³ç€æˆ‘æœ€ç»ˆä¼šä½¿ç”¨ä¸€ä¸ªåŒ…å«ä»¥ä¸‹ç¯èŠ‚çš„ç®¡é“ï¼šé¦–å…ˆæ˜¯è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSTTï¼Œä¹Ÿç§°ä¸º ASR æˆ–è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ï¼Œå°†ç”¨æˆ·çš„è¯­éŸ³è½¬å½•æˆæ–‡æœ¬ï¼›ç„¶åä½¿ç”¨ä¸€ä¸ªæˆ–å¤šä¸ª LLM è°ƒç”¨æ¥å¤„ç†è¿™äº›æ–‡æœ¬ï¼›æœ€åé€šè¿‡æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ï¼Œå°†éŸ³é¢‘å›å¤è¿”å›ç»™ç”¨æˆ·ã€‚è¿™ç§ STT â†’ LLM/AI æ™ºèƒ½ä½“å·¥ä½œæµ â†’ TTS çš„ç®¡é“ï¼Œå°†æ¨ç†è¿‡ç¨‹æ”¾åœ¨æ–‡æœ¬å±‚é¢è¿›è¡Œï¼Œå¯ä»¥å®ç°æ›´å‡†ç¡®çš„å›å¤ã€‚

ç„¶è€Œï¼Œè¿™ä¸ªè¿‡ç¨‹ä¼šå¼•å…¥å»¶è¿Ÿï¼Œè€Œè¯­éŸ³åº”ç”¨çš„ç”¨æˆ·å¯¹å»¶è¿Ÿéå¸¸æ•æ„Ÿã€‚å½“ https://t.co/zpIxRSuky4 ä¸ RealAvatarï¼ˆä¸€å®¶ç”± Jeff Daniel é¢†å¯¼çš„ AI Fund æŠ•èµ„ç»„åˆå…¬å¸ï¼‰åˆä½œæ‰“é€ æˆ‘çš„è™šæ‹Ÿå½¢è±¡ï¼ˆavatarï¼‰æ—¶ï¼Œæˆ‘ä»¬å‘ç°è®© TTS ç”Ÿæˆå¬èµ·æ¥åƒæˆ‘çš„å£°éŸ³å¹¶ä¸å¤ªéš¾ï¼Œä½†è¦è®©å®ƒç”¨æˆ‘å¯èƒ½é€‰æ‹©çš„è¯è¯­æ¥å›åº”é—®é¢˜ï¼Œå´éå¸¸å›°éš¾ã€‚å³ä½¿ç»è¿‡ä¸€å¹´çš„ç³»ç»Ÿè°ƒä¼˜ â€”â€” æˆ‘ä»¬ä»è¿­ä»£å¤šä¸ªå†—é•¿çš„å¤§å‹æç¤ºï¼ˆmega-promptsï¼‰å¼€å§‹ï¼Œæœ€ç»ˆå¼€å‘å‡ºå¤æ‚çš„ AI æ™ºèƒ½ä½“å·¥ä½œæµ â€”â€” è¿™é¡¹å·¥ä½œä»åœ¨è¿›è¡Œä¸­ã€‚æ‚¨å¯ä»¥åœ¨ https://t.co/vMO2CM0xfb ä½“éªŒå®ƒã€‚

æœ€åˆï¼Œè¿™ä¸ª AI æ™ºèƒ½ä½“å·¥ä½œæµä¼šäº§ç”Ÿ 5-9 ç§’çš„å»¶è¿Ÿï¼Œè®©ç”¨æˆ·ç­‰å¾…è¿™ä¹ˆä¹…æ‰èƒ½å¾—åˆ°å›å¤ï¼Œä¼šä¸¥é‡å½±å“ç”¨æˆ·ä½“éªŒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å»¶è¿Ÿé™ä½æŠ€æœ¯ï¼šç³»ç»Ÿä¼šå¿«é€Ÿç”Ÿæˆä¸€ä¸ªé¢„å›åº”ï¼ˆpre-responseï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€çŸ­çš„åˆæ­¥å›å¤ï¼Œå¯ä»¥è¿…é€Ÿå‘å‡ºï¼Œä»è€Œä¸º AI æ™ºèƒ½ä½“å·¥ä½œæµäº‰å–æ—¶é—´ï¼Œå»ç”Ÿæˆä¸€ä¸ªæ›´å‘¨åˆ°ã€æ›´å®Œæ•´çš„å›å¤ã€‚(æˆ‘ä»¬éå¸¸æ„Ÿè°¢ LiveKit çš„ CEO Russ d'Sa åŠå…¶å›¢é˜Ÿå¸®åŠ©æˆ‘ä»¬å®ç°äº†è¿™ä¸€ç‚¹ã€‚ï¼‰è¿™ç±»ä¼¼äºï¼Œå¦‚æœæ‚¨é—®æˆ‘ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼Œæˆ‘å¯èƒ½ä¼šå…ˆè¯´ã€Œå—¯ï¼Œè®©æˆ‘è€ƒè™‘ä¸€ä¸‹ã€æˆ–ã€Œå½“ç„¶ï¼Œæˆ‘èƒ½å¸®ä½ ã€â€”â€” è¿™å°±æ˜¯é¢„å›åº” â€”â€” åŒæ—¶æˆ‘åœ¨æ€è€ƒæˆ‘çš„å®Œæ•´å›å¤å¯èƒ½æ˜¯ä»€ä¹ˆã€‚

æˆ‘è®¤ä¸ºï¼Œå…ˆç”Ÿæˆä¸€ä¸ªé¢„å›åº”ï¼Œå†ç»™å‡ºå®Œæ•´å›å¤ï¼Œèƒ½å¤Ÿè¿…é€Ÿç¡®è®¤ç”¨æˆ·çš„æŸ¥è¯¢å¹¶é™ä½æ„ŸçŸ¥å»¶è¿Ÿï¼Œè¿™å°†æ˜¯ä¸€é¡¹é‡è¦çš„æŠ€æœ¯ï¼Œå¸Œæœ›å¾ˆå¤šå›¢é˜Ÿéƒ½èƒ½ä»ä¸­å—ç›Šã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¾¾åˆ°äººé¢å¯¹é¢äº¤è°ˆçš„å»¶è¿Ÿæ°´å¹³ï¼Œå¤§çº¦åœ¨ 0.3-1 ç§’ä¹‹é—´ã€‚é€šè¿‡åœ¨é¢„å›åº”å’Œå…¶ä»–ä¼˜åŒ–æ–¹é¢çš„åŠªåŠ›ï¼ŒRealAvatar å’Œ https://t.co/zpIxRSuky4 å·²å°†ç³»ç»Ÿçš„å»¶è¿Ÿé™ä½åˆ°å¤§çº¦ 0.5-1 ç§’ã€‚

å‡ ä¸ªæœˆå‰ï¼Œæˆ‘ååœ¨ä¸€å®¶å’–å•¡åº—é‡Œï¼Œåªç”¨äº†å‡ ä¸ªå°æ—¶å°±æˆåŠŸåœ¨ Twilio ä¸Šè´­ä¹°äº†ä¸€ä¸ªç”µè¯å·ç ï¼Œå¹¶å°†å…¶è¿æ¥åˆ° STT â†’ LLM â†’ TTS ç®¡é“ã€‚è¿™è®©æˆ‘èƒ½å¤Ÿä½¿ç”¨è‡ªå®šä¹‰æç¤ºä¸æˆ‘è‡ªå·±çš„ LLM å¯¹è¯ã€‚å¼€å‘è¯­éŸ³åº”ç”¨åŸå‹æ¯”å¤§å¤šæ•°äººæƒ³è±¡çš„è¦å®¹æ˜“å¾—å¤šï¼

å½“ç„¶ï¼Œæ„å»ºå¯é ã€å¯æ‰©å±•çš„ç”Ÿäº§çº§åº”ç”¨éœ€è¦æ›´é•¿æ—¶é—´ï¼Œä½†å¦‚æœæ‚¨å¿ƒä¸­å·²ç»æœ‰ä¸€ä¸ªè¯­éŸ³åº”ç”¨çš„æ„æƒ³ï¼Œæˆ‘å¸Œæœ›æ‚¨èƒ½å¼€å§‹æ„å»ºåŸå‹ï¼Œçœ‹çœ‹æ‚¨èƒ½èµ°å¤šè¿œï¼æˆ‘å°†ç»§ç»­æ„å»ºè¯­éŸ³åº”ç”¨ï¼Œå¹¶åœ¨æœªæ¥çš„æ–‡ç« ä¸­åˆ†äº«æœ€ä½³å®è·µå’Œè¯­éŸ³ç›¸å…³çš„æŠ€æœ¯è¶‹åŠ¿ã€‚

[åŸå§‹æ–‡ç« ï¼šhttps://t.co/M38Ud0UhdT]

### 041

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-02-27
é“¾æ¥: https://x.com/AndrewYNg/status/1895183929977843970
äº’åŠ¨: Likes: 6,301; Retweets: 894; Replies: 273; Quotes: 89; Views: 683,093; Bookmarks: 7,114; isReply: 0

Announcing: Agentic Document Extraction! 

PDF files represent information visually - via layout, charts, graphs, etc. - and are more than just text. Unlike  traditional OCR and most PDF-to-text approaches, which focus on extracting the text, an agentic approach lets us break a document down into components and reason about them, resulting in more accurate extraction of the underlying meaning for RAG and other applications. Watch the video for details.

å‘å¸ƒï¼šæ™ºèƒ½ä½“æ–‡æ¡£æå–ï¼ˆAgentic Document Extraction)ï¼

PDF æ–‡ä»¶é€šè¿‡å¸ƒå±€ã€å›¾è¡¨ã€å›¾å½¢ç­‰æ–¹å¼ä»¥è§†è§‰å½¢å¼å‘ˆç°ä¿¡æ¯ï¼Œå®ƒä»¬ä¸åªæ˜¯ç®€å•çš„æ–‡æœ¬ã€‚ä¸ä¼ ç»Ÿçš„ OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰å’Œå¤§å¤šæ•° PDF è½¬æ–‡æœ¬æ–¹æ³•ä¸åŒï¼Œè¿™äº›æ–¹æ³•é€šå¸¸åªä¾§é‡äºæå–æ–‡æœ¬ï¼Œè€Œæ™ºèƒ½ä½“ï¼ˆAgenticï¼‰æ–¹æ³•èƒ½å¤Ÿå°†æ–‡æ¡£åˆ†è§£æˆæ›´å°çš„ç»„ä»¶ï¼Œå¹¶å¯¹è¿™äº›ç»„ä»¶è¿›è¡Œæ¨ç†ï¼Œä»è€Œä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œå…¶ä»–åº”ç”¨æ›´å‡†ç¡®åœ°ç†è§£æ–‡æ¡£çš„æ·±å±‚å«ä¹‰ã€‚è§‚çœ‹è§†é¢‘äº†è§£è¯¦æƒ…ã€‚

### 042

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-05
é“¾æ¥: https://x.com/AndrewYNg/status/1897389514034688313
äº’åŠ¨: Likes: 1,556; Retweets: 244; Replies: 136; Quotes: 12; Views: 150,897; Bookmarks: 1,345; isReply: 0

New short course: Event-Driven Agentic Document Workflows. Event-driven workflows are a key design pattern in which many pieces of work (LLM calls, tool use, etc.) can be carried out asynchronously and in parallel, and completion of specific steps generate events that trigger other work to begin. In this course, created in partnership with @llama_index and @seldo, VP of Developer Relations, you'll learn to apply this technique to document workflows.

Filling out complex forms can be tedious, time-consuming, and error-prone. Agentic workflows can automate this. This course teaches you how to build an agentic document workflow using an event-driven architecture.

You'll design an event-driven agentic workflow that fills out a PDF form based on information from a source document. The agent will use RAG to retrieve relevant data from the source document, parse the form to identify the required fields, convert the blank spaces into questions, and send those questions to the RAG system to fill the form. You'll collaborate with the agent using a human-in-the-loop feedback approach through text and with your voice.

In detail, youâ€™ll:
- Understand the basic concepts of event-driven workflows.
- Build a series of LlamaIndexâ€™s workflows that increase in complexity from branching and looping logic to concurrent executions.
- Set up the agentâ€™s RAG capability by parsing the source document, loading the extracted information into a vector store, and building a query engine on top of the store.
- Implement workflow steps that enable the agent to parse the form to be filled, turn the parsed information into simple questions, and use the questions to query the RAG pipeline.
- Incorporate human-in-the-loop into the workflow and ask the agent to re-answer when necessary to produce more accurate form responses.
- Add multimodal capability to the agent, allowing it to process spoken feedback.

By the end of this course, you will have built an event-driven agentic workflow that fills out a document and responds to human feedback to complete the form more accurately.

Please sign up here: https://t.co/GZSZ9lXMKC

æ–°è¯¾ç¨‹ä¸Šçº¿ï¼šäº‹ä»¶é©±åŠ¨çš„ AI æ™ºèƒ½ä½“æ–‡æ¡£å·¥ä½œæµã€‚äº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµæ˜¯ä¸€ç§å…³é”®è®¾è®¡æ¨¡å¼ï¼Œå®ƒå…è®¸è®¸å¤šä»»åŠ¡ï¼ˆå¦‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è°ƒç”¨ã€å·¥å…·ä½¿ç”¨ç­‰ï¼‰å¼‚æ­¥å¹¶è¡Œåœ°æ‰§è¡Œã€‚å½“ç‰¹å®šæ­¥éª¤å®Œæˆåï¼Œä¼šç”Ÿæˆäº‹ä»¶æ¥è§¦å‘åç»­å·¥ä½œçš„å¯åŠ¨ã€‚æœ¬è¯¾ç¨‹æ˜¯ä¸ LlamaIndex å’Œå¼€å‘è€…å…³ç³»å‰¯æ€»è£ Seldo åˆä½œå¼€å‘çš„ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°†è¿™é¡¹æŠ€æœ¯åº”ç”¨åˆ°æ–‡æ¡£å¤„ç†å·¥ä½œä¸­ã€‚

å¡«å†™å¤æ‚çš„è¡¨æ ¼å¯èƒ½æ—¢ç¹çåˆè€—æ—¶ï¼Œè¿˜å®¹æ˜“å‡ºé”™ã€‚è€Œ AI æ™ºèƒ½ä½“å·¥ä½œæµèƒ½å¤Ÿå°†è¿™ä¸€è¿‡ç¨‹è‡ªåŠ¨åŒ–ã€‚æœ¬è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•åˆ©ç”¨äº‹ä»¶é©±åŠ¨æ¶æ„æ¥æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“æ–‡æ¡£å·¥ä½œæµã€‚

ä½ å°†è®¾è®¡ä¸€ä¸ªäº‹ä»¶é©±åŠ¨çš„ AI æ™ºèƒ½ä½“å·¥ä½œæµï¼Œæ ¹æ®æºæ–‡æ¡£ä¸­çš„ä¿¡æ¯æ¥å¡«å†™ PDF è¡¨æ ¼ã€‚è¿™ä¸ªæ™ºèƒ½ä½“å°†è¿ç”¨ RAG æŠ€æœ¯ä»æºæ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³æ•°æ®ï¼Œè§£æè¡¨æ ¼ä»¥è¯†åˆ«å¿…å¡«å­—æ®µï¼Œç„¶åå°†ç©ºç™½åŒºåŸŸè½¬åŒ–ä¸ºå…·ä½“é—®é¢˜ï¼Œå¹¶å°†è¿™äº›é—®é¢˜å‘é€ç»™ RAG ç³»ç»Ÿä»¥å®Œæˆè¡¨æ ¼å¡«å†™ã€‚ä½ è¿˜å°†é€šè¿‡æ–‡æœ¬å’Œè¯­éŸ³ï¼Œé‡‡ç”¨äººæœºåä½œï¼ˆhuman-in-the-loopï¼‰çš„åé¦ˆæ–¹å¼ä¸æ™ºèƒ½ä½“å…±åŒå®Œæˆä»»åŠ¡ã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- ç†è§£äº‹ä»¶é©±åŠ¨å·¥ä½œæµçš„åŸºæœ¬æ¦‚å¿µã€‚
- æ„å»ºä¸€ç³»åˆ—åŸºäº LlamaIndex çš„å·¥ä½œæµï¼Œå…¶å¤æ‚ç¨‹åº¦å°†ä»åˆ†æ”¯å’Œå¾ªç¯é€»è¾‘é€æ­¥æå‡è‡³å¹¶å‘æ‰§è¡Œã€‚
- æ­å»ºæ™ºèƒ½ä½“çš„ RAG èƒ½åŠ›ï¼šåŒ…æ‹¬è§£ææºæ–‡æ¡£ã€å°†æå–çš„ä¿¡æ¯åŠ è½½åˆ°å‘é‡å­˜å‚¨ä¸­ï¼Œå¹¶åœ¨æ­¤å­˜å‚¨ä¹‹ä¸Šæ„å»ºä¸€ä¸ªæŸ¥è¯¢å¼•æ“ã€‚
- å®ç°å·¥ä½œæµæ­¥éª¤ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè§£æå¾…å¡«å†™çš„è¡¨æ ¼ï¼Œå°†è§£æå‡ºçš„ä¿¡æ¯è½¬åŒ–ä¸ºç®€å•é—®é¢˜ï¼Œå¹¶åˆ©ç”¨è¿™äº›é—®é¢˜æŸ¥è¯¢ RAG ç®¡é“ã€‚
- å°†äººæœºåä½œæ•´åˆåˆ°å·¥ä½œæµä¸­ï¼Œå¹¶åœ¨å¿…è¦æ—¶è¦æ±‚æ™ºèƒ½ä½“é‡æ–°å›ç­”ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®çš„è¡¨æ ¼å“åº”ã€‚
- ä¸ºæ™ºèƒ½ä½“æ·»åŠ å¤šæ¨¡æ€èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å£å¤´åé¦ˆã€‚

åœ¨æœ¬è¯¾ç¨‹ç»“æŸæ—¶ï¼Œä½ å°†æˆåŠŸæ„å»ºä¸€ä¸ªäº‹ä»¶é©±åŠ¨çš„ AI æ™ºèƒ½ä½“å·¥ä½œæµã€‚å®ƒä¸ä»…èƒ½å¡«å†™æ–‡æ¡£ï¼Œè¿˜èƒ½å“åº”äººç±»åé¦ˆï¼Œä»è€Œæ›´å‡†ç¡®åœ°å®Œæˆè¡¨æ ¼å¡«å†™ã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/GZSZ9lXMKC

### 043

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-06
é“¾æ¥: https://x.com/AndrewYNg/status/1897776017873465635
äº’åŠ¨: Likes: 385; Retweets: 85; Replies: 38; Quotes: 9; Views: 68,182; Bookmarks: 155; isReply: 0

Continuing from last weekâ€™s post on the rise of the Voice Stack, thereâ€™s an area that todayâ€™s voice-based systems often struggle with: Voice Activity Detection (VAD) and the turn-taking paradigm of communication.

When communicating with a text-based chatbot, the turns are clear: You write something, then the bot does, then you do, and so on. The success of text-based chatbots with clear turn-taking has influenced the design of voice-based bots, most of which also use the turn-taking paradigm.

A key part of building such a system is a VAD component to detect when the user is talking. This allows our software to take the parts of the audio stream in which the user is saying something and pass that to the model for the userâ€™s turn. It also supports interruption in a limited way, whereby if a user insistently interrupts the AI system while it is talking, eventually the VAD system will realize the user is talking, shut off the AIâ€™s output, and let the user take a turn. This works reasonably well in quiet environments.

However, VAD systems today struggle with noisy environments, particularly when the background noise is from other human speech. For example, if you are in a noisy cafe speaking with a voice chatbot, VAD â€” which is usually trained to detect human speech â€” tends to be inaccurate at figuring out when you, or someone else, is talking. (In comparison, it works much better if you are in a noisy vehicle, since the background noise is more clearly not human speech.) It might think you are interrupting when it was merely someone in the background speaking, or fail to recognize that youâ€™ve stopped talking. This is why todayâ€™s speech applications often struggle in noisy environments.

Intriguingly, last year, Kyutai Labs published Moshi, a model that had many technical innovations. An important one was enabling persistent bi-direction audio streams from the user to Moshi and from Moshi to the user.

If you and I were speaking in person or on the phone, we would constantly be streaming audio to each other (through the air or the phone system), and weâ€™d use social cues to know when to listen and how to politely interrupt if one of us felt the need. Thus, the streams would not need to explicitly model turn-taking. Moshi works like this. Itâ€™s listening all the time, and itâ€™s up to the model to decide when to stay silent and when to talk. This means an explicit VAD step is no longer necessary. (Moshi also included other innovations, such as an â€œinner monologueâ€ that simultaneously generates text alongside the audio to improve the quality of responses as well as audio encoding.)

Just as the architecture of text-only transformers has gone through many evolutions (such as encoder-decoder models, decoder-only models, and reasoning models that generate a lot of â€œreasoning tokensâ€ before the final output), voice models are going through a lot of architecture explorations. Given the importance of foundation models with voice-in and voice-out capabilities, many large companies right now are investing in developing better voice models. Iâ€™m confident weâ€™ll see many more good voice models released this year.

It feels like the space of potential innovation for voice remains large. Hard technical problems, like the one of latency that I described last week and VAD errors, remain to be solved. As solutions get better, voice-to-voice will continue to be a promising category to build applications in.

[Original text: https://t.co/vwLlAnTJZT ]

æ¥ç»­ä¸Šå‘¨å…³äºè¯­éŸ³æŠ€æœ¯æ ˆï¼ˆVoice Stackï¼‰å…´èµ·çš„æ–‡ç« ï¼Œä»Šå¤©çš„è¯­éŸ³ç³»ç»Ÿåœ¨æŸäº›æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå…¶ä¸­ä¹‹ä¸€ä¾¿æ˜¯è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVoice Activity Detectionï¼ŒVADï¼‰æŠ€æœ¯ä»¥åŠå¯¹è¯ä¸­ã€Œè½®æµã€æ²Ÿé€šçš„æ¨¡å¼ã€‚

å½“æˆ‘ä»¬ä¸æ–‡æœ¬èŠå¤©æœºå™¨äººäº¤æµæ—¶ï¼Œå¯¹è¯çš„è½®æ¬¡éå¸¸æ˜ç¡®ï¼šä½ å…ˆè¾“å…¥å†…å®¹ï¼Œç„¶åæœºå™¨äººå›å¤ï¼Œæ¥ç€ä½ å†å‘è¨€ï¼Œå¦‚æ­¤å¾ªç¯ã€‚è¿™ç§æ¸…æ™°çš„è½®æµæ²Ÿé€šæ¨¡å¼åœ¨æ–‡æœ¬èŠå¤©æœºå™¨äººä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä¹Ÿå› æ­¤å½±å“äº†è¯­éŸ³æœºå™¨äººçš„è®¾è®¡ï¼Œç›®å‰å¤§å¤šæ•°è¯­éŸ³æœºå™¨äººä¹Ÿæ²¿ç”¨äº†è¿™ç§è½®æµå¯¹è¯çš„èŒƒå¼ã€‚

è¦æ„å»ºä¸€ä¸ªè¿™æ ·çš„ç³»ç»Ÿï¼Œä¸€ä¸ªæ ¸å¿ƒç»„ä»¶å°±æ˜¯ VADï¼Œå®ƒçš„ä½œç”¨æ˜¯è¯†åˆ«ç”¨æˆ·ä½•æ—¶æ­£åœ¨è¯´è¯ã€‚é€šè¿‡ VADï¼Œæˆ‘ä»¬çš„è½¯ä»¶èƒ½å¤Ÿä»éŸ³é¢‘æµä¸­æˆªå–å‡ºç”¨æˆ·è¯´è¯çš„éƒ¨åˆ†ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æ¨¡å‹è¿›è¡Œå¤„ç†ï¼Œä»è€Œå®Œæˆç”¨æˆ·çš„è¿™ä¸€è½®å¯¹è¯ã€‚å®ƒè¿˜åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ”¯æŒæ‰“æ–­åŠŸèƒ½ï¼šå¦‚æœç”¨æˆ·åœ¨ AI ç³»ç»Ÿè®²è¯æ—¶æŒç»­æ‰“æ–­ï¼ŒVAD ç³»ç»Ÿæœ€ç»ˆä¼šæ£€æµ‹åˆ°ç”¨æˆ·æ­£åœ¨è¯´è¯ï¼Œéšå³åœæ­¢ AI çš„è¾“å‡ºï¼Œè®©ç”¨æˆ·æ¥ç®¡å¯¹è¯ã€‚åœ¨å®‰é™çš„ç¯å¢ƒä¸­ï¼Œè¿™å¥—æœºåˆ¶é€šå¸¸è¿ä½œè‰¯å¥½ã€‚

ç„¶è€Œï¼Œå½“å‰çš„ VAD ç³»ç»Ÿåœ¨å˜ˆæ‚ç¯å¢ƒä¸‹ï¼Œå°¤å…¶æ˜¯å½“èƒŒæ™¯å™ªéŸ³æ˜¯å…¶ä»–äººå£°æ—¶ï¼Œå°±ä¼šæ˜¾å¾—åŠ›ä¸ä»å¿ƒã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœä½ åœ¨ä¸€ä¸ªå–§é—¹çš„å’–å•¡é¦†é‡Œä¸è¯­éŸ³èŠå¤©æœºå™¨äººå¯¹è¯ï¼ŒVADï¼ˆå®ƒé€šå¸¸è¢«è®­ç»ƒæ¥æ£€æµ‹äººå£°ï¼‰å°±å¾ˆéš¾å‡†ç¡®åˆ¤æ–­ç©¶ç«Ÿæ˜¯ä½ è¿˜æ˜¯æ—è¾¹çš„äººåœ¨è¯´è¯ã€‚ï¼ˆç›¸æ¯”ä¹‹ä¸‹ï¼Œå¦‚æœä½ åœ¨ä¸€è¾†å˜ˆæ‚çš„æ±½è½¦é‡Œï¼Œå®ƒçš„æ•ˆæœä¼šå¥½å¾—å¤šï¼Œå› ä¸ºèƒŒæ™¯å™ªéŸ³æ˜æ˜¾ä¸æ˜¯äººå£°ã€‚ï¼‰VAD å¯èƒ½ä¼šè¯¯ä»¥ä¸ºä½ åœ¨æ‰“æ–­ï¼Œè€Œé‚£å…¶å®åªæ˜¯èƒŒæ™¯ä¸­æœ‰äººåœ¨è®²è¯ï¼›æˆ–è€…å®ƒå¯èƒ½æ²¡æœ‰è¯†åˆ«å‡ºä½ å·²ç»åœæ­¢è¯´è¯ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“ä»Šè®¸å¤šè¯­éŸ³åº”ç”¨åœ¨å˜ˆæ‚ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³çš„åŸå› ã€‚

æœ‰è¶£çš„æ˜¯ï¼Œå»å¹´ Kyutai Labs å‘å¸ƒäº† Moshi æ¨¡å‹ï¼Œå…¶ä¸­åŒ…å«äº†å¤šé¡¹æŠ€æœ¯åˆ›æ–°ã€‚ä¸€ä¸ªé‡è¦çš„çªç ´æ˜¯å®ƒå®ç°äº†ä»ç”¨æˆ·åˆ° Moshiï¼Œä»¥åŠä» Moshi åˆ°ç”¨æˆ·çš„æŒç»­åŒå‘éŸ³é¢‘æµã€‚

å¦‚æœä½ æˆ‘é¢å¯¹é¢æˆ–é€šè¿‡ç”µè¯äº¤è°ˆï¼Œæˆ‘ä»¬ä¼šä¸æ–­åœ°å‘å¯¹æ–¹ä¼ è¾“éŸ³é¢‘ï¼ˆé€šè¿‡ç©ºæ°”æˆ–ç”µè¯ç³»ç»Ÿï¼‰ï¼Œå¹¶åˆ©ç”¨ç¤¾äº¤çº¿ç´¢æ¥åˆ¤æ–­ä½•æ—¶å€¾å¬ï¼Œä»¥åŠåœ¨æœ‰éœ€è¦æ—¶å¦‚ä½•ç¤¼è²Œåœ°æ‰“æ–­å¯¹æ–¹ã€‚å› æ­¤ï¼ŒéŸ³é¢‘æµæœ¬èº«ä¸éœ€è¦æ˜ç¡®åœ°è®¾å®šè½®æµæ¨¡å¼ã€‚Moshi æ­£æ˜¯è¿™æ ·è¿ä½œçš„ã€‚å®ƒä¸€ç›´åœ¨æŒç»­ç›‘å¬ï¼Œå¹¶ç”±æ¨¡å‹è‡ªèº«æ¥å†³å®šä½•æ—¶ä¿æŒæ²‰é»˜ã€ä½•æ—¶è¿›è¡Œå›åº”ã€‚è¿™æ„å‘³ç€ä¸å†éœ€è¦ç‹¬ç«‹çš„ VAD æ­¥éª¤ã€‚ï¼ˆMoshi è¿˜åŒ…å«äº†å…¶ä»–åˆ›æ–°ï¼Œæ¯”å¦‚ä¸€ä¸ªã€Œå†…å¿ƒç‹¬ç™½ã€åŠŸèƒ½ï¼Œå®ƒåœ¨ç”ŸæˆéŸ³é¢‘çš„åŒæ—¶åŒæ­¥ç”Ÿæˆæ–‡æœ¬ï¼Œä»¥æé«˜å“åº”è´¨é‡ï¼Œå¹¶ä¼˜åŒ–äº†éŸ³é¢‘ç¼–ç æŠ€æœ¯ã€‚ï¼‰

æ­£å¦‚çº¯æ–‡æœ¬ Transformer çš„æ¶æ„ç»å†äº†å¤šæ¬¡æ¼”è¿›ï¼ˆä¾‹å¦‚ç¼–ç å™¨ - è§£ç å™¨æ¨¡å‹ã€ä»…è§£ç å™¨æ¨¡å‹ï¼Œä»¥åŠåœ¨æœ€ç»ˆè¾“å‡ºå‰ç”Ÿæˆå¤§é‡ã€Œæ¨ç† Tokenã€çš„æ¨ç†æ¨¡å‹ï¼‰ï¼Œè¯­éŸ³æ¨¡å‹ç›®å‰ä¹Ÿæ­£å¤„äºå¹¿æ³›çš„æ¶æ„æ¢ç´¢é˜¶æ®µã€‚é‰´äºå…·å¤‡è¯­éŸ³è¾“å…¥å’Œè¯­éŸ³è¾“å‡ºèƒ½åŠ›çš„åŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰çš„é‡è¦æ€§ï¼Œè®¸å¤šå¤§å‹å…¬å¸æ­£åœ¨å¤§åŠ›æŠ•èµ„å¼€å‘æ›´ä¼˜ç§€çš„è¯­éŸ³æ¨¡å‹ã€‚æˆ‘ç¡®ä¿¡ä»Šå¹´æˆ‘ä»¬ä¼šçœ‹åˆ°æ›´å¤šå‡ºè‰²çš„è¯­éŸ³æ¨¡å‹é—®ä¸–ã€‚

è¯­éŸ³æŠ€æœ¯é¢†åŸŸçš„æ½œåœ¨åˆ›æ–°ç©ºé—´ä¾ç„¶å¹¿é˜”ã€‚ä¸€äº›æ£˜æ‰‹çš„æŠ€æœ¯éš¾é¢˜ï¼Œæ¯”å¦‚æˆ‘ä¸Šå‘¨æåˆ°çš„å»¶è¿Ÿé—®é¢˜å’Œ VAD é”™è¯¯ï¼Œä»æœ‰å¾…æ”»å…‹ã€‚éšç€è¿™äº›è§£å†³æ–¹æ¡ˆçš„ä¸æ–­å®Œå–„ï¼Œè¯­éŸ³åˆ°è¯­éŸ³çš„äº¤äº’æ¨¡å¼å°†ç»§ç»­æˆä¸ºæ„å»ºå„ç±»åº”ç”¨çš„ä¸€ä¸ªæå…·å‰æ™¯çš„é¢†åŸŸã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/vwLlAnTJZT]

### 044

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-13
é“¾æ¥: https://x.com/AndrewYNg/status/1900219116822102116
äº’åŠ¨: Likes: 12,179; Retweets: 2,866; Replies: 524; Quotes: 514; Views: 2,121,039; Bookmarks: 5,550; isReply: 0

Some people today are discouraging others from learning programming on the grounds AI will automate it. This advice will be seen as some of the worst career advice ever given. I disagree with the Turing Award and Nobel prize winner who wrote, â€œIt is far more likely that the programming occupation will become extinct [...] than that it will become all-powerful. More and more, computers will program themselves.â€â€‹ Statements discouraging people from learning to code are harmful!

In the 1960s, when programming moved from punchcards (where a programmer had to laboriously make holes in physical cards to write code character by character) to keyboards with terminals, programming became easier. And that made it a better time than before to begin programming. Yet it was in this era that Nobel laureate Herb Simon wrote the words quoted in the first paragraph. Todayâ€™s arguments not to learn to code continue to echo his comment.

As coding becomes easier, more people should code, not fewer!

Over the past few decades, as programming has moved from assembly language to higher-level languages like C, from desktop to cloud, from raw text editors to IDEs to AI assisted coding where sometimes one barely even looks at the generated code (which some coders recently started to call vibe coding), it is getting easier with each step.

I wrote previously that I see tech-savvy people coordinating AI tools to move toward being 10x professionals â€” individuals who have 10 times the impact of the average person in their field. I am increasingly convinced that the best way for many people to accomplish this is not to be just consumers of AI applications, but to learn enough coding to use AI-assisted coding tools effectively.

One question Iâ€™m asked most often is what someone should do who is worried about job displacement by AI. My answer is: Learn about AI and take control of it, because one of the most important skills in the future will be the ability to tell a computer exactly what you want, so it can do that for you. Coding (or getting AI to code for you) is a great way to do that.

When I was working on the course Generative AI for Everyone and needed to generate AI artwork for the background images, I worked with a collaborator who had studied art history and knew the language of art. He prompted Midjourney with terminology based on the historical style, palette, artist inspiration and so on â€” using the language of art â€” to get the result he wanted. I didnâ€™t know this language, and my paltry attempts at prompting could not deliver as effective a result.

Similarly, scientists, analysts, marketers, recruiters, and people of a wide range of professions who understand the language of software through their knowledge of coding can tell an LLM or an AI-enabled IDE what they want much more precisely, and get much better results. As these tools are continuing to make coding easier, this is the best time yet to learn to code, to learn the language of software, and learn to make computers do exactly what you want them to do.

[Original text: https://t.co/HdI3Jb9HmF ]

å¦‚ä»Šï¼Œæœ‰äº›äººä»¥äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å°†è‡ªåŠ¨åŒ–ç¼–ç¨‹å·¥ä½œä¸ºç”±ï¼ŒåŠé˜»ä»–äººå­¦ä¹ ç¼–ç¨‹ã€‚è¿™æ¡å»ºè®®æœªæ¥å¾ˆå¯èƒ½ä¼šè¢«è®¤ä¸ºæ˜¯å²ä¸Šæœ€ç³Ÿç³•çš„èŒä¸šå»ºè®®ä¹‹ä¸€ã€‚æˆ‘ä¸åŒæ„æŸä½å›¾çµå¥–å’Œè¯ºè´å°”å¥–å¾—ä¸»æ‰€å†™çš„è¯ï¼šã€Œç¼–ç¨‹èŒä¸šä¸å…¶å˜å¾—æ— æ‰€ä¸èƒ½ï¼Œæ›´æœ‰å¯èƒ½èµ°å‘æ¶ˆäº¡ [...]ã€‚è®¡ç®—æœºå°†è¶Šæ¥è¶Šå¤šåœ°è‡ªè¡Œç¼–ç¨‹ã€‚ã€åŠé˜»äººä»¬å­¦ä¹ ç¼–ç¨‹çš„è¨€è®ºæ˜¯ååˆ†æœ‰å®³çš„ï¼

åœ¨ 20 ä¸–çºª 60 å¹´ä»£ï¼Œç¼–ç¨‹ä»ç©¿å­”å¡ç‰‡ï¼ˆç¨‹åºå‘˜å¿…é¡»è´¹åŠ›åœ°åœ¨ç‰©ç†å¡ç‰‡ä¸Šé€å­—ç¬¦æ‰“å­”æ¥ç¼–å†™ä»£ç ï¼‰è½¬å‘äº†å¸¦ç»ˆç«¯çš„é”®ç›˜ï¼Œç¼–ç¨‹å˜å¾—æ›´åŠ å®¹æ˜“ã€‚è¿™ä½¿å¾—é‚£æ®µæ—¶é—´æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´é€‚åˆå¼€å§‹ç¼–ç¨‹ã€‚ç„¶è€Œï¼Œæ­£æ˜¯åœ¨è¿™ä¸ªæ—¶ä»£ï¼Œè¯ºè´å°”å¥–å¾—ä¸»èµ«ä¼¯Â·è¥¿è’™å†™ä¸‹äº†ç¬¬ä¸€æ®µå¼•ç”¨çš„é‚£äº›è¯ã€‚å¦‚ä»Šï¼Œé‚£äº›åŠé€€äººä»¬å­¦ä¹ ç¼–ç¨‹çš„è®ºç‚¹ä¾ç„¶åœ¨å‘¼åº”ä»–çš„è¯„è®ºã€‚

éšç€ç¼–ç¨‹å˜å¾—è¶Šæ¥è¶Šå®¹æ˜“ï¼Œåº”è¯¥æœ‰æ›´å¤šçš„äººå»å­¦ä¹ ç¼–ç¨‹ï¼Œè€Œä¸æ˜¯æ›´å°‘ï¼

åœ¨è¿‡å»çš„å‡ åå¹´é‡Œï¼Œç¼–ç¨‹ä»æ±‡ç¼–è¯­è¨€ï¼ˆassembly languageï¼‰è½¬å‘äº†åƒ C è¿™æ ·çš„é«˜çº§è¯­è¨€ï¼Œä»æ¡Œé¢ç¯å¢ƒè½¬å‘äº†äº‘ç«¯ï¼Œä»åŸå§‹æ–‡æœ¬ç¼–è¾‘å™¨å‘å±•åˆ°é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEï¼‰ï¼Œå†åˆ°äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰è¾…åŠ©ç¼–ç¨‹ â€”â€” æœ‰æ—¶äººä»¬ç”šè‡³å‡ ä¹ä¸ç”¨çœ‹ç”Ÿæˆçš„ä»£ç ï¼ˆä¸€äº›ç¨‹åºå‘˜æœ€è¿‘å¼€å§‹ç§°ä¹‹ä¸ºã€Œvibe codingã€ï¼‰ï¼Œæ¯ä¸€æ­¥éƒ½è®©ç¼–ç¨‹å˜å¾—æ›´åŠ ç®€å•ã€‚

æˆ‘ä¹‹å‰æ›¾å†™é“ï¼Œæˆ‘çœ‹åˆ°é‚£äº›ç²¾é€šæŠ€æœ¯çš„äººæ­£é€šè¿‡åè°ƒ AI å·¥å…·ï¼Œé€æ­¥æˆä¸ºã€Œ10 å€ä¸“ä¸šäººå£«ã€â€”â€” å³åœ¨å„è‡ªé¢†åŸŸä¸­ï¼Œèƒ½å‘æŒ¥å‡ºç›¸å½“äºæ™®é€šäºº 10 å€å½±å“åŠ›çš„ä¸ªä½“ã€‚æˆ‘è¶Šæ¥è¶Šåšä¿¡ï¼Œå¯¹è®¸å¤šäººæ¥è¯´ï¼Œå®ç°è¿™ä¸€ç›®æ ‡çš„æœ€ä½³é€”å¾„ä¸æ˜¯ä»…ä»…ä½œä¸º AI åº”ç”¨ç¨‹åºçš„æ¶ˆè´¹è€…ï¼Œè€Œæ˜¯è¦å­¦ä¹ è¶³å¤Ÿçš„ç¼–ç¨‹çŸ¥è¯†ï¼Œä»¥ä¾¿èƒ½æœ‰æ•ˆåœ°ä½¿ç”¨ AI è¾…åŠ©ç¼–ç¨‹å·¥å…·ã€‚

æˆ‘æœ€å¸¸è¢«é—®åˆ°çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œé‚£äº›æ‹…å¿ƒ AI å¯¼è‡´å¤±ä¸šçš„äººåº”è¯¥æ€ä¹ˆåŠã€‚æˆ‘çš„ç­”æ¡ˆæ˜¯ï¼šäº†è§£ AI å¹¶æŒæ§å®ƒï¼Œå› ä¸ºæœªæ¥æœ€é‡è¦çš„æŠ€èƒ½ä¹‹ä¸€å°†æ˜¯èƒ½å¤Ÿå‡†ç¡®åœ°å‘Šè¯‰è®¡ç®—æœºä½ æƒ³è¦ä»€ä¹ˆï¼Œè¿™æ ·å®ƒå°±èƒ½ä¸ºä½ å®Œæˆã€‚ç¼–ç¨‹ï¼ˆæˆ–è€…è®© AI ä¸ºä½ ç¼–ç¨‹ï¼‰æ˜¯å®ç°è¿™ä¸€ç›®æ ‡çš„ç»ä½³æ–¹å¼ã€‚

å½“æˆ‘æ­£åœ¨åˆ¶ä½œã€Œäººäººå¯ç”¨çš„ç”Ÿæˆå¼ AIï¼ˆGenerative AI for Everyoneï¼‰ã€è¯¾ç¨‹å¹¶éœ€è¦ä¸ºèƒŒæ™¯å›¾åƒç”Ÿæˆ AI è‰ºæœ¯å“æ—¶ï¼Œæˆ‘ä¸ä¸€ä½ç ”ç©¶è¿‡è‰ºæœ¯å²å¹¶äº†è§£è‰ºæœ¯è¯­è¨€çš„åˆä½œè€…ä¸€èµ·å·¥ä½œã€‚ä»–ä½¿ç”¨åŸºäºå†å²é£æ ¼ã€è°ƒè‰²æ¿ã€è‰ºæœ¯å®¶çµæ„Ÿç­‰æœ¯è¯­ â€”â€” è¿ç”¨è‰ºæœ¯è¯­è¨€ â€”â€” å‘ Midjourney è¿›è¡Œæç¤ºï¼Œä»¥è·å¾—ä»–æƒ³è¦çš„ç»“æœã€‚æˆ‘ä¸æ‡‚è¿™ç§è¯­è¨€ï¼Œæˆ‘é‚£äº›å¾®ä¸è¶³é“çš„æç¤ºå°è¯•æ— æ³•äº§ç”Ÿå¦‚æ­¤æœ‰æ•ˆçš„ç»“æœã€‚

åŒæ ·ï¼Œç§‘å­¦å®¶ã€åˆ†æå¸ˆã€è¥é”€äººå‘˜ã€æ‹›è˜äººå‘˜ä»¥åŠå„è¡Œå„ä¸šçš„ä¸“ä¸šäººå£«ï¼Œé€šè¿‡ä»–ä»¬çš„ç¼–ç¨‹çŸ¥è¯†ç†è§£è½¯ä»¶è¯­è¨€ï¼Œå¯ä»¥æ›´ç²¾ç¡®åœ°å‘Šè¯‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æˆ–æ”¯æŒ AI çš„é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEï¼‰ä»–ä»¬æƒ³è¦ä»€ä¹ˆï¼Œå¹¶è·å¾—æ›´å¥½çš„ç»“æœã€‚ç”±äºè¿™äº›å·¥å…·æ­£åœ¨æŒç»­ä½¿ç¼–ç¨‹å˜å¾—æ›´å®¹æ˜“ï¼Œç°åœ¨æ˜¯å­¦ä¹ ç¼–ç¨‹ã€æŒæ¡è½¯ä»¶è¯­è¨€ã€å¹¶å­¦ä¼šè®©è®¡ç®—æœºå®Œå…¨æŒ‰ç…§ä½ çš„æ„æ„¿è¡Œäº‹çš„æœ€ä½³æ—¶æœºã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/HdI3Jb9HmF]

### 045

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900594063516254299
äº’åŠ¨: Likes: 656; Retweets: 74; Replies: 120; Quotes: 6; Views: 61,303; Bookmarks: 49; isReply: 0

Itâ€™s starting - just kicked off AI Dev 25, the AI developer conference, in San Francisco! Happy Pi day! https://t.co/tlJvBFee0F

æ­£å¼å¼€å§‹äº†ï¼AI Dev 25ï¼Œè¿™åœº AIï¼ˆäººå·¥æ™ºèƒ½ï¼‰å¼€å‘è€…å¤§ä¼šï¼Œåˆšåˆšåœ¨æ—§é‡‘å±±æ‹‰å¼€å¸·å¹•ï¼ç¥å¤§å®¶åœ†å‘¨ç‡æ—¥å¿«ä¹ï¼ https://t.co/tlJvBFee0F

### 046

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900595885970780360
äº’åŠ¨: Likes: 66; Retweets: 10; Replies: 9; Quotes: 1; Views: 23,236; Bookmarks: 6; isReply: 1

From audience poll the topic AI developers are most excited about is Agents! https://t.co/WqMCyR07H4

æ ¹æ®è§‚ä¼—æŠ•ç¥¨ç»“æœæ˜¾ç¤ºï¼ŒAI å¼€å‘è€…æœ€æ„Ÿå…´è¶£çš„è¯é¢˜æ˜¯ AI æ™ºèƒ½ä½“ï¼ˆAI Agent)ï¼ https://t.co/WqMCyR07H4

### 047

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900596396140671194
äº’åŠ¨: Likes: 78; Retweets: 8; Replies: 12; Quotes: 1; Views: 32,914; Bookmarks: 11; isReply: 1

Great talk by Googleâ€™s Bill Jia on their GenAI work, including Astra and Deep Research agents (both of which I think are very cool). https://t.co/1yhNIQGxII

Google çš„ Bill Jia å‘è¡¨äº†ä¸€åœºç²¾å½©çš„æ¼”è®²ï¼Œåˆ†äº«äº†ä»–ä»¬åœ¨ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰æ–¹é¢çš„å·¥ä½œï¼Œå…¶ä¸­åŒ…æ‹¬ Astra å’Œ Deep Research AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ï¼ˆæˆ‘ä¸ªäººè®¤ä¸ºè¿™ä¸¤è€…éƒ½éå¸¸é…·ï¼‰ã€‚https://t.co/1yhNIQGxII

### 048

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900599467822510154
äº’åŠ¨: Likes: 66; Retweets: 18; Replies: 6; Quotes: 0; Views: 18,052; Bookmarks: 10; isReply: 1

Metaâ€™s Chaya Nayak talking about the open Llama models and Llama Stack, and best practices for using them. Great tips and I saw lots of people pulling out phones to take pictures of her slides! https://t.co/OGixvLRyPO

Meta çš„ Chaya Nayak ä»‹ç»äº†å¼€æ”¾çš„ Llama æ¨¡å‹å’Œ Llama Stackï¼Œå¹¶åˆ†äº«äº†å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨å®ƒä»¬çš„æœ€ä½³å®è·µã€‚è¿™äº›å»ºè®®éå¸¸æ£’ï¼Œæˆ‘çœ‹åˆ°è®¸å¤šäººéƒ½çº·çº·æ‹¿å‡ºæ‰‹æœºæ‹æ‘„å¥¹çš„æ¼”ç¤ºå¹»ç¯ç‰‡ï¼https://t.co/OGixvLRyPO

### 049

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900610468747899142
äº’åŠ¨: Likes: 58; Retweets: 8; Replies: 10; Quotes: 0; Views: 33,935; Bookmarks: 11; isReply: 1

Panel with Replitâ€™s Michele Catasta, Stanfordâ€™s @percyliang , Nebiusâ€™ Roman Chernin and Hugging Faceâ€™s @Thom_Wolf, moderated by @lmoroney, on application building. Lots of tips on infra, open source, agentic workflows, benchmarking and code gen. Particular interest in how to take stochastic LLMs that hallucinate and nonetheless build reliable agents.

@lmoroney ä¸»æŒäº†ä¸€åœºå…³äºåº”ç”¨æ„å»ºçš„å°ç»„è®¨è®ºã€‚å‚ä¸è€…åŒ…æ‹¬ Replit çš„ Michele Catastaã€æ–¯å¦ç¦å¤§å­¦çš„ @percyliang ã€Nebius çš„ Roman Chernin ä»¥åŠ Hugging Face çš„ @Thom_Wolfã€‚è®¨è®ºåˆ†äº«äº†è®¸å¤šå…³äºåŸºç¡€è®¾æ–½ã€å¼€æºã€AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰å·¥ä½œæµã€åŸºå‡†æµ‹è¯•ï¼ˆbenchmarkingï¼‰å’Œä»£ç ç”Ÿæˆï¼ˆcode generationï¼‰çš„å®ç”¨æŠ€å·§ã€‚å…¶ä¸­ä¸€ä¸ªç‰¹åˆ«å¼•äººå…³æ³¨çš„è®®é¢˜æ˜¯ï¼Œå¦‚ä½•åˆ©ç”¨é‚£äº›å®¹æ˜“å‡ºç°ã€Œå¹»è§‰ã€ï¼ˆå³è¾“å‡ºä¸å‡†ç¡®ä¿¡æ¯ï¼‰çš„ã€å…·å¤‡ä¸ç¡®å®šæ€§ï¼ˆstochasticï¼‰çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼‰ï¼Œå»æ„å»ºå¯é çš„ AI æ™ºèƒ½ä½“ã€‚

### 050

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900617330906067136
äº’åŠ¨: Likes: 468; Retweets: 77; Replies: 38; Quotes: 15; Views: 105,433; Bookmarks: 200; isReply: 0

Good tip from Replitâ€™s @mattppal at AI Dev 25 on debugging while vibe coding: Large part of it is looking at outputs to figure out what context you have that LLM does not, so that you can give it that context and help it get unstuck. Sometimes pasting in the error messages is enough, but also sometimes not.

åœ¨ AI Dev 25 å¤§ä¼šä¸Šï¼ŒReplit å…¬å¸çš„ @mattppal åˆ†äº«äº†ä¸€ä¸ªåœ¨ã€Œéšæ€§ç¼–ç ã€æˆ–ã€Œå‡­æ„Ÿè§‰ç¼–ç ã€(vibe codingï¼‰æ—¶è¿›è¡Œè°ƒè¯•çš„å®ç”¨æŠ€å·§ï¼šå¾ˆå¤§ç¨‹åº¦ä¸Šï¼Œè°ƒè¯•è¿‡ç¨‹å°±æ˜¯è¦æŸ¥çœ‹ç¨‹åºçš„è¾“å‡ºï¼Œä»è€Œå‘ç°ä½ äº†è§£è€Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å´ä¸å…·å¤‡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚è¿™æ ·ä¸€æ¥ï¼Œä½ å°±èƒ½å°†è¿™äº›å…³é”®ä¸Šä¸‹æ–‡æä¾›ç»™ LLMï¼Œå¸®åŠ©å®ƒè§£å†³é‡åˆ°çš„éš¾é¢˜ã€‚æœ‰æ—¶ï¼Œç®€å•åœ°ç²˜è´´é”™è¯¯æ¶ˆæ¯å°±è¶³ä»¥è§£å†³é—®é¢˜ï¼Œä½†æœ‰æ—¶è¿™è¿˜è¿œè¿œä¸å¤Ÿã€‚

### 051

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-14
é“¾æ¥: https://x.com/AndrewYNg/status/1900639477279977618
äº’åŠ¨: Likes: 472; Retweets: 78; Replies: 51; Quotes: 3; Views: 75,035; Bookmarks: 192; isReply: 0

OpenAIâ€™s Justin Uberti at AI Dev 25 showing how to build a voice agent using the Realtime API. Building on the voice stack is easier than most realize - worth trying out if you have a voice idea! https://t.co/GOTyw7Vftl

åœ¨ AI Dev 25 å¤§ä¼šä¸Šï¼ŒOpenAI çš„ Justin Uberti å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Realtime API æ¥æ„å»ºä¸€ä¸ªè¯­éŸ³ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ã€‚å…¶å®ï¼Œåœ¨è¯­éŸ³æŠ€æœ¯æ ˆï¼ˆvoice stackï¼‰ä¸Šå¼€å‘è¯­éŸ³åº”ç”¨è¿œæ¯”å¤§å¤šæ•°äººæƒ³è±¡çš„è¦ç®€å• â€”â€” å¦‚æœä½ æœ‰ä»»ä½•ä¸è¯­éŸ³ç›¸å…³çš„æƒ³æ³•ï¼Œéƒ½éå¸¸å€¼å¾—ä¸€è¯•ï¼https://t.co/GOTyw7Vftl

### 052

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-19
é“¾æ¥: https://x.com/AndrewYNg/status/1902395485601853941
äº’åŠ¨: Likes: 1,619; Retweets: 267; Replies: 50; Quotes: 18; Views: 129,706; Bookmarks: 1,188; isReply: 0

New short course: Long-Term Agentic Memory with LangGraph. Learn to build an agent with long-term memory in this course developed in collaboration with @LangChainAI taught by its Co-Founder and CEO, @hwchase17! 

Personal assistance and productivity tasks have become important use cases for agents. An important feature of an AI assistant, such as a coding or calendar assistant, is its ability to keep improving over time from its experience. Agent memory is the key capability that enables this.

To add memory to an agent, you must first figure out what to store and what to retrieve when it is time to use the information. Additionally, youâ€™ll have to decide when to update the stored information. For example, you might update in each iteration loop of the agent or perform updates in the background, with a helper agent.

In this course, you will learn a mental framework to build agents with long-term memory. You'll create a useful email assistant that can respond, ignore, and notify using writing, scheduling, and memory-management tools. Youâ€™ll develop your agent's memory by adding facts to its memory store, provide examples to learn the user's preferences, and optimize system prompts to evolve instructions based on previous responses.

In detail, youâ€™ll:
- Learn how the three types of memory--semantic, episodic, and proceduralâ€“and the two update mechanismsâ€“via hot path and in the backgroundâ€“apply to your agents.
- Build an email agent with writing, scheduling, and availability tools, along with a router that triages incoming email and handles it accordingly by ignoring, responding, or notifying the user.
- Add tools to your email agent that allow it to operate on semantic memory by learning facts about the user, storing them in a long-term memory store, and searching over them in future interactions.
- Incorporate episodic memory, in the form of few-shot examples, in the triage step of your agents to help them learn and update user preferences.
- Add procedural memory as system prompts, optimized with feedback to improve the instructions the agent follows.

Learn how to approach memory in agents, and start building agents with long-term memory with LangGraph!

Please sign up here: https://t.co/9E02gQDdiM

æ–°çŸ­æœŸè¯¾ç¨‹ï¼šLangGraph ä¸­çš„ AI æ™ºèƒ½ä½“é•¿æ•ˆè®°å¿†ã€‚åœ¨è¿™ä¸ªä¸ @LangChainAI åˆä½œå¼€å‘ï¼Œç”±å…¶è”åˆåˆ›å§‹äººå…¼é¦–å¸­æ‰§è¡Œå®˜ @hwchase17 æ•™æˆçš„è¯¾ç¨‹ä¸­ï¼Œå­¦ä¹ å¦‚ä½•æ„å»ºä¸€ä¸ªå…·æœ‰é•¿æœŸè®°å¿†çš„ AI æ™ºèƒ½ä½“ï¼ˆAI Agent)ï¼

ä¸ªäººååŠ©å’Œç”Ÿäº§åŠ›ä»»åŠ¡å·²æˆä¸º AI æ™ºèƒ½ä½“çš„é‡è¦åº”ç”¨åœºæ™¯ã€‚ä¸€ä¸ª AI åŠ©æ‰‹ï¼Œä¾‹å¦‚ç¼–ç æˆ–æ—¥å†åŠ©æ‰‹ï¼Œå…¶ä¸€ä¸ªé‡è¦ç‰¹ç‚¹å°±æ˜¯èƒ½å¤Ÿéšç€æ—¶é—´çš„æ¨ç§»ï¼Œé€šè¿‡å­¦ä¹ ç»éªŒä¸æ–­æ”¹è¿›ã€‚AI æ™ºèƒ½ä½“çš„è®°å¿†èƒ½åŠ›æ˜¯å®ç°è¿™ä¸€åŠŸèƒ½çš„å…³é”®ã€‚

è¦ä¸º AI æ™ºèƒ½ä½“æ·»åŠ è®°å¿†ï¼Œä½ é¦–å…ˆå¿…é¡»æ˜ç¡®è¦å­˜å‚¨ä»€ä¹ˆï¼Œä»¥åŠå½“éœ€è¦ä½¿ç”¨ä¿¡æ¯æ—¶ï¼Œåº”è¯¥æ£€ç´¢ä»€ä¹ˆã€‚æ­¤å¤–ï¼Œä½ è¿˜éœ€è¦å†³å®šä½•æ—¶æ›´æ–°å­˜å‚¨çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥åœ¨ AI æ™ºèƒ½ä½“çš„æ¯ä¸ªè¿­ä»£å¾ªç¯ä¸­è¿›è¡Œæ›´æ–°ï¼Œæˆ–è€…åœ¨åå°é€šè¿‡ä¸€ä¸ªè¾…åŠ© AI æ™ºèƒ½ä½“æ‰§è¡Œæ›´æ–°ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸€ä¸ªæ„å»ºå…·æœ‰é•¿æœŸè®°å¿†çš„ AI æ™ºèƒ½ä½“çš„æ€ç»´æ¡†æ¶ã€‚ä½ å°†åˆ›å»ºä¸€ä¸ªå®ç”¨çš„ç”µå­é‚®ä»¶åŠ©æ‰‹ï¼Œå®ƒèƒ½åˆ©ç”¨å†™ä½œã€æ—¥ç¨‹å®‰æ’å’Œè®°å¿†ç®¡ç†å·¥å…·æ¥å“åº”ã€å¿½ç•¥æˆ–é€šçŸ¥ã€‚ä½ å°†é€šè¿‡å‘å…¶è®°å¿†å­˜å‚¨æ·»åŠ äº‹å®ã€æä¾›ç¤ºä¾‹æ¥å­¦ä¹ ç”¨æˆ·çš„åå¥½ï¼Œå¹¶ä¼˜åŒ–ç³»ç»Ÿæç¤ºï¼ˆsystem promptsï¼‰ä»¥æ ¹æ®ä¹‹å‰çš„å“åº”è°ƒæ•´æŒ‡ä»¤ï¼Œä»è€Œä¸æ–­å‘å±•ä½ çš„ AI æ™ºèƒ½ä½“çš„è®°å¿†èƒ½åŠ›ã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- å­¦ä¹ ä¸‰ç§è®°å¿†ç±»å‹ â€”â€” è¯­ä¹‰è®°å¿†ï¼ˆsemantic memoryï¼‰ã€æƒ…æ™¯è®°å¿†ï¼ˆepisodic memoryï¼‰å’Œç¨‹åºè®°å¿†ï¼ˆprocedural memory)â€”â€” ä»¥åŠä¸¤ç§æ›´æ–°æœºåˆ¶ â€”â€” å³æ—¶æ›´æ–°ï¼ˆvia hot pathï¼‰å’Œåå°æ›´æ–°ï¼ˆin the background)â€”â€” å¦‚ä½•åº”ç”¨äºä½ çš„ AI æ™ºèƒ½ä½“ã€‚
- æ„å»ºä¸€ä¸ªç”µå­é‚®ä»¶ AI æ™ºèƒ½ä½“ï¼Œå®ƒé…å¤‡å†™ä½œã€æ—¥ç¨‹å®‰æ’å’Œå¯ç”¨æ€§å·¥å…·ï¼Œä»¥åŠä¸€ä¸ªè·¯ç”±å™¨ï¼ˆrouterï¼‰ï¼Œç”¨äºåˆ†ç±»ä¼ å…¥çš„ç”µå­é‚®ä»¶å¹¶ç›¸åº”åœ°å¤„ç†ï¼Œå¦‚å¿½ç•¥ã€å›å¤æˆ–é€šçŸ¥ç”¨æˆ·ã€‚
- ä¸ºä½ çš„ç”µå­é‚®ä»¶ AI æ™ºèƒ½ä½“æ·»åŠ å·¥å…·ï¼Œä½¿å…¶èƒ½å¤Ÿé€šè¿‡å­¦ä¹ å…³äºç”¨æˆ·çš„äº‹å®ã€å°†å®ƒä»¬å­˜å‚¨åœ¨é•¿æœŸè®°å¿†åº“ä¸­ï¼Œå¹¶åœ¨æœªæ¥çš„äº¤äº’ä¸­æœç´¢è¿™äº›äº‹å®ï¼Œä»¥æ­¤æ¥ç®¡ç†è¯­ä¹‰è®°å¿†ã€‚
- åœ¨ä½ çš„ AI æ™ºèƒ½ä½“çš„åˆ†ç±»æ­¥éª¤ä¸­ï¼Œä»¥å°‘æ ·æœ¬ï¼ˆFew-shotï¼‰ç¤ºä¾‹çš„å½¢å¼èå…¥æƒ…æ™¯è®°å¿†ï¼Œå¸®åŠ©å®ƒä»¬å­¦ä¹ å¹¶æ›´æ–°ç”¨æˆ·åå¥½ã€‚
- å°†ç¨‹åºè®°å¿†ä½œä¸ºç³»ç»Ÿæç¤ºæ·»åŠ è¿›å»ï¼Œå¹¶é€šè¿‡åé¦ˆè¿›è¡Œä¼˜åŒ–ï¼Œä»¥æ”¹è¿› AI æ™ºèƒ½ä½“éµå¾ªæŒ‡ä»¤çš„æ–¹å¼ã€‚

å­¦ä¹ å¦‚ä½•å¤„ç† AI æ™ºèƒ½ä½“ä¸­çš„è®°å¿†ï¼Œå¹¶å¼€å§‹ä½¿ç”¨ LangGraph æ„å»ºå…·æœ‰é•¿æœŸè®°å¿†çš„ AI æ™ºèƒ½ä½“å§ï¼

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/9E02gQDdiM

### 053

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-21
é“¾æ¥: https://x.com/AndrewYNg/status/1903147778097983709
äº’åŠ¨: Likes: 268; Retweets: 47; Replies: 33; Quotes: 7; Views: 45,778; Bookmarks: 63; isReply: 0

Last Friday on Pi Day, we held AI Dev 25, a new conference for AI Developers. Tickets had (unfortunately) sold out shortly after we announced their availability, but I came away energized by the day of coding and technical discussions with fellow AI Builders! Let me share here my observations from the event.

I'd decided to start AI Dev because while there're great academic AI conferences that disseminate research work (such as NeurIPS, ICML and ICLR) and also great meetings held by individual companies, often focused on each company's product offerings, there were few vendor-neutral conferences for AI developers. With the wide range of AI tools now available, there is a rich set of opportunities for developers to build new things (and to share ideas on how to build things!), but also a need for a neutral forum that helps developers do so.

Based on an informal poll, about half the attendees had traveled to San Francisco from outside the Bay Area for this meeting, including many who had come from overseas. I was thrilled by the enthusiasm to be part of this AI Builder community. To everyone who came, thank you!

Other aspects of the event that struck me:
- First, agentic AI continues to be a strong theme. The topic attendees most wanted to hear about (based on free text responses to our in-person survey at the start of the event) was agents!
- Google's Paige Bailey talked about embedding AI in everything and using a wide range of models to do so. I also particularly enjoyed her demos of Astra and Deep Research agents.
- Meta's Amit Sangani talked compellingly as usual about open models. Specifically, he described developers fine-tuning smaller models on specific data, resulting in superior performance than with large general purpose models. While there're still many companies using fine-tuning that should really just be prompting, I'm also seeing continued growth of fine-tuning in applications that are reaching scale and that are becoming valuable.
- Many speakers also spoke about the importance of being pragmatic about what problems we are solving, as opposed to buying into the AGI hype. For example, Nebius' Roman Chernin put it simply: Focusing on solving real problems is important!
- Lastly, I was excited to hear continued enthusiasm for the Voice Stack. Justin Uberti gave a talk about OpenAIâ€™s realtime audio API to a packed room, with many people pulling out laptops to try things out themselves in code!

https://t.co/zpIxRSuky4 has a strong â€œLearner Firstâ€ mentality; our foremost goal is always to help learners. I was thrilled that a few attendees told me they enjoyed how technical the sessions were, and said they learned many things that they're sure they will use. (In fact, I, too, came away with a few ideas from the sessions!) I was also struck that, both during the talks and at the technical demo booths, the rooms were packed with attendees who were highly engaged throughout the whole day. I'm glad that we were able to have a meeting filled with technical and engineering discussions.

I'm delighted that AI Dev 25 went off so well, and am grateful to all the attendees, volunteers, speakers, sponsors, partners, and team members that made the event possible. I regretted only that the physical size of the event space prevented us from admitting more attendees this time. There is something magical about bringing people together physically to share ideas, make friends, and to learn from and help each other. I hope we'll be able to bring even more people together in the future.

[Original text: https://t.co/iNUywKfGRx ]

ä¸Šå‘¨äº”çš„åœ†å‘¨ç‡æ—¥ï¼Œæˆ‘ä»¬æˆåŠŸä¸¾åŠäº†é¢å‘ AI å¼€å‘è€…çš„æ–°ä¼šè®® â€”â€”AI Dev 25ã€‚å°½ç®¡é—¨ç¥¨åœ¨å…¬å¸ƒå‘å”®ä¸ä¹…åå°±ï¼ˆå¾ˆé—æ†¾åœ°ï¼‰ä¸€æŠ¢è€Œç©ºï¼Œä½†è¿™ä¸€å¤©ä¸ä¼—å¤š AI å¼€å‘è€…ä¸€èµ·ç¼–ç å’Œè¿›è¡ŒæŠ€æœ¯äº¤æµï¼Œè®©æˆ‘å€æ„ŸæŒ¯å¥‹ï¼ç°åœ¨ï¼Œæˆ‘æ¥åˆ†äº«ä¸€ä¸‹è¿™æ¬¡æ´»åŠ¨çš„ä¸€äº›è§‚å¯Ÿã€‚

æˆ‘å†³å®šå‘èµ· AI Dev ä¼šè®®ï¼Œæ˜¯å› ä¸ºè™½ç„¶æœ‰è®¸å¤šä¼˜ç§€çš„å­¦æœ¯ AI ä¼šè®®ï¼Œä¸“æ³¨äºä¼ æ’­ç ”ç©¶æˆæœï¼ˆä¾‹å¦‚ NeurIPSã€ICML å’Œ ICLRï¼‰ï¼Œä¹Ÿæœ‰ä¸å°‘ç”±å¤§å…¬å¸ä¸»åŠçš„æ´»åŠ¨ï¼Œé€šå¸¸ä¾§é‡äºè‡ªå®¶äº§å“ï¼Œä½†é¢å‘ AI å¼€å‘è€…ã€ä¸”ä¿æŒå‚å•†ä¸­ç«‹çš„ä¼šè®®å´å¯¥å¯¥æ— å‡ ã€‚å¦‚ä»Šï¼Œéšç€ AI å·¥å…·çš„æ—¥ç›Šä¸°å¯Œï¼Œå¼€å‘è€…ä»¬æ‹¥æœ‰æ— æ•°æœºä¼šå»åˆ›é€ æ–°äº‹ç‰©ï¼ˆå¹¶äº¤æµåˆ›é€ çš„ç»éªŒï¼ï¼‰ï¼Œå› æ­¤ï¼Œä¸€ä¸ªä¸­ç«‹çš„äº¤æµå¹³å°æ¥å¸®åŠ©ä»–ä»¬å®ç°è¿™äº›å°±æ˜¾å¾—å°¤ä¸ºå¿…è¦ã€‚

æ ¹æ®ä¸€é¡¹éæ­£å¼è°ƒæŸ¥ï¼Œå¤§çº¦ä¸€åŠçš„ä¸ä¼šè€…ä¸è¿œä¸‡é‡Œï¼Œä»æ—§é‡‘å±±æ¹¾åŒºä»¥å¤–çš„åœ°æ–¹èµ¶æ¥å‚åŠ è¿™æ¬¡ç››ä¼šï¼Œå…¶ä¸­è®¸å¤šäººç”šè‡³æ¥è‡ªæµ·å¤–ã€‚çœ‹åˆ°å¤§å®¶å¯¹èå…¥è¿™ä¸ª AI å¼€å‘è€…ç¤¾åŒºæ‰€å±•ç°å‡ºçš„çƒ­æƒ…ï¼Œæˆ‘æ„Ÿåˆ°éå¸¸æ¿€åŠ¨ã€‚åœ¨æ­¤ï¼Œå‘æ‰€æœ‰åˆ°åœºçš„åŒä»ä»¬è¡¨ç¤ºè¡·å¿ƒçš„æ„Ÿè°¢ï¼

æœ¬æ¬¡æ´»åŠ¨ä¸­ï¼Œè¿˜æœ‰å…¶ä»–ä¸€äº›æ–¹é¢ç»™æˆ‘ç•™ä¸‹äº†æ·±åˆ»å°è±¡ï¼š
- é¦–å…ˆï¼ŒAI æ™ºèƒ½ä½“ï¼ˆagentic AIï¼‰ä¾æ—§æ˜¯å¤§ä¼šçš„çƒ­é—¨ä¸»é¢˜ã€‚æ ¹æ®æ´»åŠ¨å¼€å§‹æ—¶æˆ‘ä»¬ç°åœºè°ƒæŸ¥çš„è‡ªç”±æ–‡æœ¬å›å¤ï¼Œä¸ä¼šè€…æœ€æƒ³å¬åˆ°çš„å°±æ˜¯å…³äºæ™ºèƒ½ä½“çš„è¯é¢˜ï¼
- Google çš„ Paige Bailey æ¢è®¨äº†å¦‚ä½•å°† AI èå…¥ä¸‡ç‰©ï¼Œå¹¶åˆ©ç”¨å„ç§æ¨¡å‹æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚æˆ‘å°¤å…¶å–œæ¬¢å¥¹å¯¹ Astra å’Œ Deep Research æ™ºèƒ½ä½“è¿›è¡Œçš„æ¼”ç¤ºã€‚
- Meta çš„ Amit Sangani ä¸€å¦‚æ—¢å¾€åœ°ï¼Œç”ŸåŠ¨åœ°è®²è¿°äº†å¼€æºæ¨¡å‹ã€‚ä»–å…·ä½“æè¿°äº†å¼€å‘è€…å¦‚ä½•é€šè¿‡åœ¨ç‰¹å®šæ•°æ®ä¸Šå¯¹å°å‹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»è€Œè·å¾—æ¯”å¤§å‹é€šç”¨æ¨¡å‹æ›´å‡ºè‰²çš„æ€§èƒ½ã€‚è™½ç„¶ç›®å‰ä»æœ‰ä¸å°‘å…¬å¸åœ¨ä½¿ç”¨å¾®è°ƒï¼Œè€Œä»–ä»¬å¯èƒ½æ›´é€‚åˆä½¿ç”¨æç¤ºè¯å·¥ç¨‹ï¼Œä½†æˆ‘è§‚å¯Ÿåˆ°å¾®è°ƒåœ¨é‚£äº›å·²å…·è§„æ¨¡ä¸”æ—¥ç›Šé‡è¦çš„åº”ç”¨ä¸­ï¼Œå‘ˆç°å‡ºæŒç»­å¢é•¿çš„æ€åŠ¿ã€‚
- è®¸å¤šæ¼”è®²è€…è¿˜å¼ºè°ƒäº†åœ¨è§£å†³é—®é¢˜æ—¶ä¿æŒåŠ¡å®çš„é‡è¦æ€§ï¼Œè€Œéç›²ç›®è¿½é€é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„ç‚’ä½œã€‚ä¾‹å¦‚ï¼ŒNebius çš„ Roman Chernin è§‚ç‚¹æ˜ç¡®ï¼šä¸“æ³¨äºè§£å†³å®é™…é—®é¢˜è‡³å…³é‡è¦ï¼
- æœ€åï¼Œæˆ‘å¾ˆé«˜å…´åœ°çœ‹åˆ°å¤§å®¶å¯¹ Voice Stack æŒç»­é¥±æ»¡çš„çƒ­æƒ…ã€‚Justin Uberti åœ¨ä¸€ä¸ªåº§æ— è™šå¸­çš„ä¼šåœºé‡Œï¼Œå°± OpenAI çš„å®æ—¶éŸ³é¢‘ API è¿›è¡Œäº†æ¼”è®²ï¼Œè®¸å¤šäººçº·çº·æ‹¿å‡ºç¬”è®°æœ¬ç”µè„‘ï¼Œäº²è‡ªåŠ¨æ‰‹åœ¨ä»£ç ä¸­å®è·µï¼

https://t.co/zpIxRSuky4 ç§‰æŒç€å¼ºçƒˆçš„ã€Œå­¦ä¹ è€…ä¼˜å…ˆã€ç†å¿µï¼›æˆ‘ä»¬çš„é¦–è¦ç›®æ ‡å§‹ç»ˆæ˜¯å¸®åŠ©å­¦ä¹ è€…ã€‚æˆ‘å¾ˆé«˜å…´æœ‰å‡ ä½ä¸ä¼šè€…å‘Šè¯‰æˆ‘ï¼Œä»–ä»¬éå¸¸å–œæ¬¢ä¼šè®®çš„æŠ€æœ¯æ·±åº¦ï¼Œå¹¶è¡¨ç¤ºå­¦åˆ°äº†è®¸å¤šèƒ½ç›´æ¥åº”ç”¨åˆ°å®è·µä¸­çš„çŸ¥è¯†ã€‚(äº‹å®ä¸Šï¼Œæˆ‘è‡ªå·±ä¹Ÿä»è¿™äº›ç¯èŠ‚ä¸­è·å¾—äº†ä¸€äº›æ–°æƒ³æ³•ï¼ï¼‰åŒæ ·ä»¤æˆ‘æƒŠè®¶çš„æ˜¯ï¼Œæ— è®ºæ˜¯æ¼”è®²ç¯èŠ‚è¿˜æ˜¯æŠ€æœ¯æ¼”ç¤ºå±•ä½ï¼Œä¼šåœºéƒ½åº§æ— è™šå¸­ï¼Œä¸ä¼šè€…æ•´å¤©éƒ½ä¿æŒç€é«˜åº¦çš„ä¸“æ³¨å’ŒæŠ•å…¥ã€‚æˆ‘å¾ˆé«˜å…´æˆ‘ä»¬èƒ½å¤Ÿä¸¾åŠä¸€åœºå……æ»¡æŠ€æœ¯å’Œå·¥ç¨‹è®¨è®ºçš„ç››ä¼šã€‚

æˆ‘éå¸¸æ¬£å–œ AI Dev 25 å–å¾—äº†åœ†æ»¡æˆåŠŸï¼Œå¹¶è¡·å¿ƒæ„Ÿè°¢æ‰€æœ‰ä½¿è¿™æ¬¡æ´»åŠ¨æˆä¸ºå¯èƒ½çš„ä¸ä¼šè€…ã€å¿—æ„¿è€…ã€æ¼”è®²è€…ã€èµåŠ©å•†ã€åˆä½œä¼™ä¼´ä»¥åŠå›¢é˜Ÿæˆå‘˜ã€‚æˆ‘å”¯ä¸€çš„é—æ†¾æ˜¯ï¼Œç”±äºæ´»åŠ¨ç©ºé—´çš„ç‰©ç†é™åˆ¶ï¼Œæˆ‘ä»¬è¿™æ¬¡æœªèƒ½æ¥çº³æ›´å¤šçš„ä¸ä¼šè€…ã€‚é¢å¯¹é¢åœ°å°†äººä»¬èšé›†åœ¨ä¸€èµ·ï¼Œåˆ†äº«æƒ³æ³•ã€ç»“äº¤æœ‹å‹ã€äº’ç›¸å­¦ä¹ å’Œå¸®åŠ©ï¼Œè¿™æœ¬èº«å°±æ˜¯ä¸€ä»¶å……æ»¡é­”åŠ›çš„äº‹æƒ…ã€‚æˆ‘å¸Œæœ›æœªæ¥æˆ‘ä»¬èƒ½å¤Ÿæ±‡èšæ›´å¤šçš„äººã€‚

[Original textï¼šhttps://t.co/iNUywKfGRx]

### 054

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-03-26
é“¾æ¥: https://x.com/AndrewYNg/status/1904929635043074478
äº’åŠ¨: Likes: 4,227; Retweets: 691; Replies: 110; Quotes: 136; Views: 743,254; Bookmarks: 5,174; isReply: 0

New short course: Vibe Coding 101 with Replit! Learn to build and host applications with an AI agent in this course, built in partnership with @Replit and taught by its President @pirroh and Head of Developer Relations @mattppal.

Coding agents are changing how we write code. "Vibe coding" refers to a growing practice where you might barely look at the generated code, and instead focus on the architecture and features of your application. However, contrary to popular belief, effectively coding this way isn't done by just prompting, accepting all recommendations, and hoping for the best. It requires structuring your work, refining your prompts, and having a systematic process that lead to a more efficient and effective workflow.

I code frequently using LLMs, and asking an LLM to do everything in one shot usually does not work. I'll typically take a problem, partition it into manageable modules, spend time creating prompts to specify each module, and use the model to produce the code one module at a time, and test/debug each module before moving on. A process like this is making me and many other developers faster and more efficient.

In this video-only course, youâ€™ll learn how to use Replitâ€™s cloud environment--with an integrated code editor, package manager, and deployment tools--to build and deploy web applications. Along the way, youâ€™ll learn strategies for working effectively with agents and improve your development skills.

In detail, youâ€™ll:
- Understand principles of agentic code development such as being precise, giving agents one task at a time, making prompts specific, keeping projects tidy, starting with fresh sessions for each new feature, and how to approach debugging.
- Learn how to get started with Replit, and key skills for vibe coding: Thinking, using frameworks, checkpoints, debugging, and providing context.
- Create a product requirement document (PRD) and wireframe for your agent to build a prototype of a website performance analyzer.
- See how to use an agent to make your prototype more visually appealing, and deploy it application others to access .
- Learn to build a head-to-head national park ranking app, from a sample dataset, with voting capabilities and persistent data storage, and refine further ask the assistant to recap and explain what it built to find room for improvement and reinforce your learning.

By the end of this course, youâ€™ll have a solid foundation in building with coding agents, and a process you can use to keep vibe coding effectively.

Please sign up here: https://t.co/yDbX1QFTI7

æ–°çŸ­è¯¾ç¨‹ï¼šReplitã€ŒVibe Coding 101ã€å¼€è¯¾å•¦ï¼è¿™é—¨è¯¾ç¨‹ä¸ @Replit åˆä½œæ¨å‡ºï¼Œç”±å…¶æ€»è£ @pirroh å’Œå¼€å‘è€…å…³ç³»ä¸»ç®¡ @mattppal äº²è‡ªæˆè¯¾ï¼Œå°†æ•™ä½ å¦‚ä½•ä½¿ç”¨ AI æ™ºèƒ½ä½“ï¼ˆAI agentï¼‰æ¥æ„å»ºå’Œæ‰˜ç®¡åº”ç”¨ç¨‹åºã€‚

ç¼–ç æ™ºèƒ½ä½“ï¼ˆCoding agentsï¼‰æ­£åœ¨æ”¹å˜æˆ‘ä»¬ç¼–å†™ä»£ç çš„æ–¹å¼ã€‚ã€ŒVibe codingã€æŒ‡çš„æ˜¯ä¸€ç§æ—¥ç›Šå…´ç››çš„å®è·µï¼Œåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œä½ å¯èƒ½å‡ ä¹ä¸ç”¨æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç ï¼Œè€Œæ˜¯å°†é‡å¿ƒæ”¾åœ¨åº”ç”¨ç¨‹åºçš„æ¶æ„å’ŒåŠŸèƒ½è®¾è®¡ä¸Šã€‚ç„¶è€Œï¼Œä¸æ™®éçš„çœ‹æ³•ä¸åŒï¼Œé«˜æ•ˆåœ°è¿›è¡Œ Vibe coding å¹¶éç®€å•åœ°é€šè¿‡ç»™å‡ºæç¤ºã€æ¥å—æ‰€æœ‰å»ºè®®å¹¶å¯„å¸Œæœ›äºæœ€å¥½çš„ç»“æœå°±èƒ½å®ç°ã€‚å®ƒè¦æ±‚ä½ ç»“æ„åŒ–å·¥ä½œã€ä¼˜åŒ–æç¤ºï¼Œå¹¶éµå¾ªç³»ç»ŸåŒ–çš„æµç¨‹ï¼Œæ‰èƒ½å¸¦æ¥æ›´é«˜æ•ˆã€æ›´æœ‰æ•ˆçš„å·¥ä½œæµã€‚

æˆ‘ä¸ªäººç»å¸¸ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œç¼–ç ï¼Œè€Œè®© LLM ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰ä»»åŠ¡é€šå¸¸æ˜¯è¡Œä¸é€šçš„ã€‚æˆ‘çš„åšæ³•æ˜¯ï¼Œå…ˆå°†é—®é¢˜åˆ†è§£æˆæ˜“äºç®¡ç†çš„æ¨¡å—ï¼Œç„¶åèŠ±æ—¶é—´ä¸ºæ¯ä¸ªæ¨¡å—åˆ›å»ºå…·ä½“çš„æç¤ºï¼Œå¹¶åˆ©ç”¨æ¨¡å‹é€ä¸ªç”Ÿæˆæ¨¡å—ä»£ç ï¼Œåœ¨è¿›å…¥ä¸‹ä¸€ä¸ªæ¨¡å—ä¹‹å‰ï¼Œå¯¹æ¯ä¸ªæ¨¡å—è¿›è¡Œæµ‹è¯•å’Œè°ƒè¯•ã€‚è¿™æ ·çš„æµç¨‹æ˜¾è‘—æå‡äº†æˆ‘å’Œè®¸å¤šå…¶ä»–å¼€å‘è€…çš„æ•ˆç‡ã€‚

åœ¨è¿™ä¸ªçº¯è§†é¢‘è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨ Replit çš„äº‘ç¯å¢ƒ â€”â€” å®ƒå†…ç½®äº†é›†æˆä»£ç ç¼–è¾‘å™¨ã€åŒ…ç®¡ç†å™¨å’Œéƒ¨ç½²å·¥å…· â€”â€” æ¥æ„å»ºå’Œéƒ¨ç½² Web åº”ç”¨ç¨‹åºã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä½ å°†æŒæ¡ä¸ AI æ™ºèƒ½ä½“æœ‰æ•ˆåä½œçš„ç­–ç•¥ï¼Œå¹¶å…¨é¢æå‡ä½ çš„å¼€å‘æŠ€èƒ½ã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- ç†è§£æ™ºèƒ½ä½“è¾…åŠ©ä»£ç å¼€å‘ï¼ˆagentic code developmentï¼‰çš„æ ¸å¿ƒåŸåˆ™ï¼Œä¾‹å¦‚ä¿æŒç²¾ç¡®æ€§ã€æ¯æ¬¡åªåˆ†é…ä¸€ä¸ªä»»åŠ¡ç»™æ™ºèƒ½ä½“ã€ä½¿æç¤ºå…·ä½“åŒ–ã€ä¿æŒé¡¹ç›®æ•´æ´ã€ä¸ºæ¯ä¸ªæ–°åŠŸèƒ½å¼€å¯ä¸€ä¸ªå…¨æ–°çš„ä¼šè¯ï¼Œä»¥åŠå¦‚ä½•ç€æ‰‹è°ƒè¯•ã€‚
- å­¦ä¹ å¦‚ä½•å¼€å§‹ä½¿ç”¨ Replitï¼Œä»¥åŠ Vibe coding çš„å…³é”®æŠ€èƒ½ï¼šæ€è€ƒã€è¿ç”¨æ¡†æ¶ã€è®¾ç½®æ£€æŸ¥ç‚¹ã€è°ƒè¯•å’Œæä¾›ä¸Šä¸‹æ–‡ã€‚
- ä¸ºä½ çš„æ™ºèƒ½ä½“åˆ›å»ºä¸€ä¸ªäº§å“éœ€æ±‚æ–‡æ¡£ï¼ˆPRDï¼‰å’Œçº¿æ¡†å›¾ï¼Œä»¥æ„å»ºä¸€ä¸ªç½‘ç«™æ€§èƒ½åˆ†æå™¨çš„åŸå‹ã€‚
- äº†è§£å¦‚ä½•ä½¿ç”¨æ™ºèƒ½ä½“è®©ä½ çš„åŸå‹æ›´å…·è§†è§‰å¸å¼•åŠ›ï¼Œå¹¶éƒ¨ç½²åº”ç”¨ä¾›ä»–äººè®¿é—®ã€‚
- å­¦ä¹ å¦‚ä½•ä»æ ·æœ¬æ•°æ®é›†ä¸­æ„å»ºä¸€ä¸ªå›½å®¶å…¬å›­ã€Œå¯¹æˆ˜ã€æ’ååº”ç”¨ï¼Œå®ƒå°†å…·å¤‡æŠ•ç¥¨åŠŸèƒ½å’ŒæŒä¹…æ•°æ®å­˜å‚¨ã€‚ä½ è¿˜å°†è¿›ä¸€æ­¥ä¼˜åŒ–åº”ç”¨ï¼Œå¹¶è¯· AI åŠ©æ‰‹æ€»ç»“å’Œè§£é‡Šå®ƒæ‰€æ„å»ºçš„å†…å®¹ï¼Œä»¥å‘ç°æ”¹è¿›ç©ºé—´å¹¶å·©å›ºå­¦ä¹ æˆæœã€‚

å­¦å®Œæœ¬è¯¾ç¨‹åï¼Œä½ å°†ä¸ºä½¿ç”¨ç¼–ç æ™ºèƒ½ä½“è¿›è¡Œå¼€å‘æ‰“ä¸‹åšå®åŸºç¡€ï¼Œå¹¶æŒæ¡ä¸€å¥—èƒ½è®©ä½ æŒç»­é«˜æ•ˆè¿›è¡Œ Vibe coding çš„æµç¨‹ã€‚

è¯·ç‚¹å‡»æ­¤å¤„æŠ¥åï¼šhttps://t.co/yDbX1QFTI7

### 055

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-01
é“¾æ¥: https://x.com/AndrewYNg/status/1907132637963260223
äº’åŠ¨: Likes: 849; Retweets: 165; Replies: 54; Quotes: 3; Views: 83,413; Bookmarks: 758; isReply: 0

Major program launch: Data Analytics Professional Certificate! This large, five-course sequence takes you all the way to being job-ready as a data analyst, and shows how to use Generative AI as a thought partner to enhance your work in this role.

Offered by https://t.co/zpIxRSuky4 on Coursera, this is taught by Sean Barnes, Ph.D., a Data Science & Engineering Leader at Netflix.

Analyzing data remains one of the most important skills in where the world is going with AI. This comprehensive certificate takes you all the way to being job-ready. 

Each course comes with practical projects demonstrated in real-world contexts, such as analyzing sales data for a Korean bakery, video game sales trends across different regions, or identifying factors impacting customer retention for a communications company. You'll also work on estimating fire distribution for forest fire prevention, analyzing how a diamond's properties affect its market value, and developing predictive models for retail sales analysis, carbon emissions, and coral reef conservation.

Here's some of what you'll learn:
- How to define data and categorize it into its many types such as discrete & continuous numerical, structured & unstructured, time series, categorical, and know what insights can be derived from the different types of data categories.
- How to differentiate between data-related job roles and their responsibilities, and how data flows through an organization from the moment of capture to decision-making.
- How to perform data processing functions and apply conditional formatting in spreadsheets to extract business value from your data using statistical calculations and best practices for visualizing and interpreting data.
- How to use LLMs for stakeholder analysis, data exploration, and data visualization.
- Best practices for using LLMs for as a thought partner to data analysis work

By the end of this professional certificate program, you will have learned core statistical concepts, analysis techniques, and visualization methodologies that will serve as the foundation for working as a data analyst.

The world needs more data analysts, especially ones who know how to use modern generative AI. With data science roles projected to grow 36% by 2033, the skills taught in this program create new professional opportunities in data.

Sign up here! https://t.co/R2ZiJQCn5g

<font color="#FF0000"> é‡ç£…é¡¹ç›®ä¸Šçº¿ </font>ï¼šæ•°æ®åˆ†æä¸“ä¸šè¯ä¹¦ï¼è¿™ä¸ªåŒ…å«äº”é—¨è¯¾ç¨‹çš„å¤§å‹ç³»åˆ—ï¼Œå°†å¸¦æ‚¨ä¸€æ­¥æ­¥æˆä¸º <font color="#FF0000"> ä¸€åèƒ½å¤Ÿèƒœä»»å·¥ä½œ </font> çš„æ•°æ®åˆ†æå¸ˆï¼Œå¹¶å±•ç¤ºå¦‚ä½•åˆ©ç”¨ <font color="#FF0000"> ç”Ÿæˆå¼ AIï¼ˆGenerative AI)</font> ä½œä¸ºæ€æƒ³ä¼™ä¼´æ¥æå‡æ‚¨åœ¨è¯¥é¢†åŸŸçš„å·¥ä½œè¡¨ç°ã€‚

æœ¬è¯¾ç¨‹ç”± https://t.co/zpIxRSuky4 åœ¨ Coursera å¹³å°æä¾›ï¼Œç”± Netflix çš„æ•°æ®ç§‘å­¦ä¸å·¥ç¨‹ä¸»ç®¡ Sean Barnes åšå£«äº²è‡ªæˆè¯¾ã€‚

åˆ†ææ•°æ®ä¾ç„¶æ˜¯ <font color="#FF0000"> åœ¨ AI é©±åŠ¨çš„ä¸–ç•Œä¸­ </font> æœ€é‡è¦çš„æŠ€èƒ½ä¹‹ä¸€ã€‚è¿™ä¸ªå…¨é¢çš„è¯ä¹¦è¯¾ç¨‹å°†åŠ©æ‚¨ <font color="#FF0000"> å…·å¤‡æ•°æ®åˆ†æå¸ˆçš„å·¥ä½œèƒ½åŠ› </font>ã€‚

æ¯é—¨è¯¾ç¨‹éƒ½åŒ…å«åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­æ¼”ç¤ºçš„å®è·µé¡¹ç›®ï¼Œä¾‹å¦‚åˆ†æä¸€å®¶éŸ©å›½é¢åŒ…åº—çš„é”€å”®æ•°æ®ã€æ¢ç©¶ä¸åŒåœ°åŒºè§†é¢‘æ¸¸æˆçš„é”€å”®è¶‹åŠ¿ï¼Œæˆ–è€…è¯†åˆ«å½±å“æŸé€šä¿¡å…¬å¸ <font color="#FF0000"> å®¢æˆ·ç•™å­˜ </font> çš„å› ç´ ã€‚æ‚¨è¿˜å°†å­¦ä¹ ä¼°ç®—æ£®æ—ç«ç¾çš„åˆ†å¸ƒæƒ…å†µä»¥è¿›è¡Œç«ç¾é¢„é˜²ã€åˆ†æé’»çŸ³çš„ç‰¹æ€§å¦‚ä½•å½±å“å…¶å¸‚åœºä»·å€¼ï¼Œä»¥åŠå¼€å‘ç”¨äºé›¶å”®é”€å”®åˆ†æã€ç¢³æ’æ”¾å’ŒçŠç‘šç¤ä¿æŠ¤çš„é¢„æµ‹æ¨¡å‹ã€‚

ä»¥ä¸‹æ˜¯æ‚¨å°†å­¦åˆ°çš„ä¸€äº›æ ¸å¿ƒå†…å®¹:
- å¦‚ä½•å®šä¹‰æ•°æ®å¹¶å°†å…¶å½’ç±»ä¸ºå¤šç§ç±»å‹ï¼Œä¾‹å¦‚ <font color="#FF0000"> ç¦»æ•£å‹ï¼ˆdiscreteï¼‰å’Œè¿ç»­å‹ï¼ˆcontinuousï¼‰æ•°å€¼æ•°æ®ã€ç»“æ„åŒ–ï¼ˆstructuredï¼‰å’Œéç»“æ„åŒ–ï¼ˆunstructuredï¼‰æ•°æ®ã€æ—¶é—´åºåˆ—ï¼ˆtime seriesï¼‰æ•°æ®ã€åˆ†ç±»å‹ï¼ˆcategoricalï¼‰æ•°æ® </font>ï¼Œå¹¶äº†è§£å¦‚ä½•ä»ä¸åŒç±»å‹çš„æ•°æ®ä¸­è·å¾— <font color="#FF0000"> æ´å¯Ÿ </font>ã€‚
- å¦‚ä½•åŒºåˆ†ä¸æ•°æ®ç›¸å…³çš„å·¥ä½œè§’è‰²åŠå…¶èŒè´£ï¼Œä»¥åŠæ•°æ®ä» <font color="#FF0000"> è·å– </font> åˆ°å†³ç­–åˆ¶å®šåœ¨ç»„ç»‡å†…éƒ¨çš„æµåŠ¨æ–¹å¼ã€‚
- å¦‚ä½•æ‰§è¡Œæ•°æ®å¤„ç†åŠŸèƒ½ï¼Œå¹¶åœ¨ç”µå­è¡¨æ ¼ä¸­åº”ç”¨æ¡ä»¶æ ¼å¼ï¼Œé€šè¿‡ç»Ÿè®¡è®¡ç®—å’Œæ•°æ®å¯è§†åŒ–ä¸è§£è¯»çš„æœ€ä½³å®è·µï¼Œä»æ•°æ®ä¸­æå–å•†ä¸šä»·å€¼ã€‚
- å¦‚ä½•ä½¿ç”¨ <font color="#FF0000"> å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM)</font> è¿›è¡Œåˆ©ç›Šç›¸å…³è€…åˆ†æã€æ•°æ®æ¢ç´¢å’Œæ•°æ®å¯è§†åŒ–ã€‚
- å°† LLM ä½œä¸ºæ•°æ®åˆ†æå·¥ä½œçš„æ€æƒ³ä¼™ä¼´çš„æœ€ä½³å®è·µã€‚

å®Œæˆæœ¬ä¸“ä¸šè¯ä¹¦è¯¾ç¨‹åï¼Œæ‚¨å°†æŒæ¡æ ¸å¿ƒç»Ÿè®¡æ¦‚å¿µã€åˆ†ææŠ€æœ¯å’Œ <font color="#FF0000"> å¯è§†åŒ–æ–¹æ³•è®º </font>ï¼Œè¿™äº›éƒ½å°†ä¸ºæ‚¨æˆä¸ºæ•°æ®åˆ†æå¸ˆ <font color="#FF0000"> å¥ å®šåšå®åŸºç¡€ </font>ã€‚

ä¸–ç•Œéœ€è¦æ›´å¤šçš„æ•°æ®åˆ†æå¸ˆï¼Œå°¤å…¶æ˜¯é‚£äº›æ‡‚å¾—å¦‚ä½•è¿ç”¨ç°ä»£ç”Ÿæˆå¼ AI çš„ä¸“ä¸šäººæ‰ã€‚éšç€æ•°æ®ç§‘å­¦èŒä½çš„é¢„è®¡åˆ° 2033 å¹´å¢é•¿ 36%ï¼Œæœ¬è¯¾ç¨‹ä¸­æ•™æˆçš„æŠ€èƒ½å°†åœ¨æ•°æ®é¢†åŸŸä¸ºæ‚¨åˆ›é€ å…¨æ–°çš„èŒä¸šæœºé‡ã€‚

ç‚¹å‡»è¿™é‡Œæ³¨å†Œï¼https://t.co/R2ZiJQCn5g

### 056

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-02
é“¾æ¥: https://x.com/AndrewYNg/status/1907471607314133126
äº’åŠ¨: Likes: 1,267; Retweets: 186; Replies: 32; Quotes: 21; Views: 88,725; Bookmarks: 860; isReply: 0

New Short Course: Getting Structured LLM Output!

Learn how to get structured outputs from your LLM applications in this course, built in partnership with @dottxtai, and taught by @willkurt, a Founding Engineer, and @cameron_pfiffer , Developer Relations Engineer.

It's challenging for software to automatically parse through an LLM's freeform text outputs. Structured outputsâ€”like JSONâ€”solve this by converting natural language into consistent, clear, data that a machine can read and process. This course teaches you how to generate structured outputs while building several use cases, including a social media analysis agent.

Youâ€™ll learn about structured outputs and efficient ways to generate outputs in your defined schema or format. Youâ€™ll begin by using structured output APIs, then use re-prompting libraries like â€œinstructorâ€ to generate structured output. Finally, youâ€™ll learn how constrained decoding works; this is a very clever technique in which constraints are applied on each subsequent token generated, blocking any tokens that donâ€™t fit your defined schema.

In detail, youâ€™ll:
- Learn why structured outputs are important, how they allow for scalable software development, and the different approaches to generate them, including vendor-provided APIs, re-prompting libraries, and structured generation.
- Build a simple social media agent using OpenAIâ€™s structured output API, learn how to define a model's desired structured output using Pydantic, and perform basic programming with your outputs, such as importing structured data into a data frame using pandas.
- Learn how to use the open-source library "instructor," which checks the structured output of the model and re-prompts the model until it validates the desired output, and explore the limitations of this approach.
- Understand how structured generation by the â€œoutlinesâ€ library works by modifying LLM logits, on a per-generated-token basis based on the desired format, to give a particular output structure.
- Learn how regular expressions, which outlines works with, are represented as finite-state machines, and how they can be used to develop a range of structured outputs beyond JSON.

By the end of this course, youâ€™ll have broadened your knowledge of the approaches you can use to get structured outputs from your LLM applications.

Please sign up here: https://t.co/3k53vgEFj3

æ–°è¯¾ç¨‹ï¼šæŒæ¡å¤§è¯­è¨€æ¨¡å‹ç»“æ„åŒ–è¾“å‡ºï¼

æœ¬è¯¾ç¨‹å°†æ•™æ‚¨å¦‚ä½•ä»å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨ç¨‹åºä¸­è·å–ç»“æ„åŒ–è¾“å‡ºã€‚è¿™é—¨è¯¾ç¨‹æ˜¯ä¸ @dottxtai åˆä½œå¼€å‘çš„ï¼Œç”±åˆ›å§‹å·¥ç¨‹å¸ˆ @willkurt å’Œå¼€å‘è€…å…³ç³»å·¥ç¨‹å¸ˆ @cameron_pfiffer å…±åŒæˆè¯¾ã€‚

è®©è½¯ä»¶è‡ªåŠ¨è§£æå¤§è¯­è¨€æ¨¡å‹çš„è‡ªç”±æ–‡æœ¬è¾“å‡ºæ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚ç»“æ„åŒ–è¾“å‡º â€”â€” ä¾‹å¦‚ JSONâ€”â€” é€šè¿‡å°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºæœºå™¨å¯è¯»å’Œå¤„ç†çš„ä¸€è‡´ã€æ¸…æ™°çš„æ•°æ®ï¼Œæœ‰æ•ˆè§£å†³äº†è¿™ä¸€éš¾é¢˜ã€‚æœ¬è¯¾ç¨‹å°†æ•™æ‚¨å¦‚ä½•ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼ŒåŒæ—¶è¿˜ä¼šé€šè¿‡æ„å»ºå¤šä¸ªå®é™…ç”¨ä¾‹è¿›è¡Œæ¼”ç¤ºï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªç¤¾äº¤åª’ä½“åˆ†æ AI æ™ºèƒ½ä½“ï¼ˆAI agentï¼‰ã€‚

æ‚¨å°†å­¦ä¹ ä»€ä¹ˆæ˜¯ç»“æ„åŒ–è¾“å‡ºï¼Œä»¥åŠå¦‚ä½•é«˜æ•ˆåœ°æŒ‰ç…§æ‚¨å®šä¹‰çš„æ¨¡å¼æˆ–æ ¼å¼ç”Ÿæˆè¾“å‡ºã€‚è¯¾ç¨‹å°†ä»ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º API å¼€å§‹ï¼Œç„¶åæ•™æ‚¨å¦‚ä½•åˆ©ç”¨åƒã€Œinstructorã€è¿™æ ·çš„é‡æ–°æç¤ºï¼ˆre-promptingï¼‰åº“æ¥ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºã€‚æœ€åï¼Œæ‚¨å°†æ·±å…¥äº†è§£å—é™è§£ç ï¼ˆconstrained decodingï¼‰çš„å·¥ä½œåŸç†ï¼›è¿™æ˜¯ä¸€é¡¹éå¸¸å·§å¦™çš„æŠ€æœ¯ï¼Œå®ƒå¯¹æ¯ä¸ªåç»­ç”Ÿæˆçš„ Token æ–½åŠ çº¦æŸï¼Œä»è€Œé˜»æ­¢ä»»ä½•ä¸ç¬¦åˆæ‚¨é¢„è®¾æ¨¡å¼çš„ Token è¢«ç”Ÿæˆã€‚

å…·ä½“æ¥è¯´ï¼Œæ‚¨å°†ï¼š
- äº†è§£ç»“æ„åŒ–è¾“å‡ºçš„é‡è¦æ€§ï¼Œå®ƒä»¬å¦‚ä½•ä¿ƒè¿›å¯æ‰©å±•çš„è½¯ä»¶å¼€å‘ï¼Œä»¥åŠç”Ÿæˆç»“æ„åŒ–è¾“å‡ºçš„å„ç§æ–¹æ³•ï¼ŒåŒ…æ‹¬ç”±å‚å•†æä¾›çš„ APIã€é‡æ–°æç¤ºåº“å’Œç»“æ„åŒ–ç”ŸæˆæŠ€æœ¯ã€‚
- ä½¿ç”¨ OpenAI çš„ç»“æ„åŒ–è¾“å‡º API æ„å»ºä¸€ä¸ªç®€å•çš„ç¤¾äº¤åª’ä½“ AI æ™ºèƒ½ä½“ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨ Pydantic å®šä¹‰æ¨¡å‹æ‰€éœ€çš„ç»“æ„åŒ–è¾“å‡ºï¼Œå¹¶åˆ©ç”¨è¿™äº›è¾“å‡ºè¿›è¡ŒåŸºç¡€ç¼–ç¨‹ï¼Œä¾‹å¦‚ä½¿ç”¨ pandas å°†ç»“æ„åŒ–æ•°æ®å¯¼å…¥æ•°æ®æ¡†ï¼ˆdata frameï¼‰ã€‚
- å­¦ä¹ å¦‚ä½•ä½¿ç”¨å¼€æºåº“ã€Œinstructorã€ï¼Œè¯¥åº“ä¼šæ£€æŸ¥æ¨¡å‹çš„ç»“æ„åŒ–è¾“å‡ºï¼Œå¹¶åœ¨å¿…è¦æ—¶é‡æ–°æç¤ºæ¨¡å‹ï¼Œç›´åˆ°è¾“å‡ºç¬¦åˆé¢„æœŸï¼ŒåŒæ—¶ä¹Ÿä¼šæ¢è®¨è¿™ç§æ–¹æ³•çš„å±€é™æ€§ã€‚
- ç†è§£ã€Œoutlinesã€åº“çš„ç»“æ„åŒ–ç”ŸæˆåŸç†ï¼šå®ƒå¦‚ä½•é€šè¿‡æ ¹æ®æ‰€éœ€æ ¼å¼ï¼Œå¯¹å¤§è¯­è¨€æ¨¡å‹æ¯ä¸ªç”Ÿæˆçš„ Token çš„ logits è¿›è¡Œä¿®æ”¹ï¼Œä»è€Œå®ç°ç‰¹å®šçš„è¾“å‡ºç»“æ„ã€‚
- å­¦ä¹ æ­£åˆ™è¡¨è¾¾å¼ï¼ˆã€Œoutlinesã€åº“ä½¿ç”¨çš„æ ¸å¿ƒæŠ€æœ¯ï¼‰å¦‚ä½•è¡¨ç¤ºä¸ºæœ‰é™çŠ¶æ€æœºï¼ˆfinite-state machinesï¼‰ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨å®ƒä»¬æ¥å¼€å‘é™¤ JSON ä¹‹å¤–çš„æ›´å¹¿æ³›çš„ç»“æ„åŒ–è¾“å‡ºã€‚

å®Œæˆæœ¬è¯¾ç¨‹åï¼Œæ‚¨å°†æŒæ¡æ›´å¤šä»å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºè·å–ç»“æ„åŒ–è¾“å‡ºçš„æ–¹æ³•ã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/3k53vgEFj3

### 057

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-03
é“¾æ¥: https://x.com/AndrewYNg/status/1907843984158036137
äº’åŠ¨: Likes: 1,419; Retweets: 167; Replies: 77; Quotes: 38; Views: 146,030; Bookmarks: 733; isReply: 0

Contrary to standard prompting advice that you should give LLMs the context they need to succeed, I find itâ€™s sometimes faster to be lazy and dash off a quick, imprecise prompt and see what happens. The key to whether this is a good idea is whether you can quickly assess the output quality, so you can decide whether to provide more context. In this post, Iâ€™d like to share when and how I use â€œlazy prompting.â€

When debugging code, many developers copy-paste error messages â€” sometimes pages of them â€” into an LLM without further instructions. Most LLMs are smart enough to figure out that you want them to help understand and propose fixes, so you donâ€™t need to explicitly tell them. With brief instructions like â€œEdit this: â€¦â€ or â€œsample dotenv codeâ€ (to remind you how to write code to use Python's dotenv package), an LLM will often generate a good response. Further, if the response is flawed, hopefully you can spot any problems and refine the prompt, for example to steer how the LLM edits your text.

At the other end of the spectrum, sometimes  I spend 30 minutes carefully writing a 2-page prompt to get an AI system to help me solve a problem (for example to write many pages of code) that otherwise would have taken me much longer.

I donâ€™t try a lazy prompt if (i) I feel confident thereâ€™s no chance the LLM will provide a good solution without additional context. For example, given a partial program spec, does even a skilled human developer have a chance of understanding what you want? If I absolutely want to use a particular piece of pdf-to-text conversion software (like my team LandingAIâ€™s Agentic Doc Extraction!), I should say so in the prompt, since otherwise itâ€™s very hard for the LLM to guess my preference. I also wouldnâ€™t use a lazy prompt if (ii) a buggy implementation would take a long time to detect. For example, if the only way for me to figure out if the output is incorrect is to laboriously run the code to check its functionality, it would be better to spend the time up-front to give context that would increase the odds of the LLM generating what I want.

By the way, lazy prompting is an advanced technique. On average, I see more people giving too little context to LLMs than too much. Laziness is a good technique only when youâ€™ve learned how to provide enough context, and then deliberately step back to see how little context you can get away with and still have it work. Also, lazy prompting applies only when you can iterate quickly using an LLMâ€™s web or app interface. It doesnâ€™t apply to prompts written in code for the purpose of repeatedly calling an API, since presumably you wonâ€™t be examining every output to clarify and iterate if the output is poor.

Thank you to Rohit Prsad, who has been collaborating with me on the open-source package aisuite, for suggesting the term lazy prompting. There is an analogy to lazy evaluation in computer science, where you call a function at the latest possible moment and only when a specific result is needed. In lazy prompting, we add details to the prompt only when they are needed.

Original text: https://t.co/Doh0TdJpO3

ä¸æ ‡å‡†æç¤ºå»ºè®® â€”â€” å³ä½ åº”è¯¥ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›å®ƒä»¬æˆåŠŸæ‰€éœ€çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ â€”â€” ä¸åŒçš„æ˜¯ï¼Œæˆ‘å‘ç°æœ‰æ—¶å·æ‡’åè€Œæ›´å¿«ï¼šåªéœ€å¿«é€Ÿè‰æ‹Ÿä¸€ä¸ªä¸ç²¾ç¡®çš„æç¤ºï¼Œç„¶åè§‚å¯Ÿç»“æœã€‚åˆ¤æ–­è¿™ç§åšæ³•æ˜¯å¦æ˜æ™ºçš„å…³é”®åœ¨äºä½ èƒ½å¦è¿…é€Ÿè¯„ä¼°è¾“å‡ºè´¨é‡ï¼Œä»è€Œå†³å®šæ˜¯å¦éœ€è¦æä¾›æ›´å¤šä¸Šä¸‹æ–‡ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†åˆ†äº«æˆ‘ä½•æ—¶ä»¥åŠå¦‚ä½•ä½¿ç”¨ã€Œæƒ°æ€§æç¤ºï¼ˆlazy promptingï¼‰ã€ã€‚

åœ¨è°ƒè¯•ä»£ç æ—¶ï¼Œè®¸å¤šå¼€å‘è€…å¸¸å¸¸ç›´æ¥å°†é”™è¯¯ä¿¡æ¯ â€”â€” æœ‰æ—¶å¤šè¾¾å¥½å‡ é¡µ â€”â€” å¤åˆ¶ç²˜è´´åˆ°å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œè€Œä¸é™„å¸¦ä»»ä½•é¢å¤–æŒ‡ä»¤ã€‚å¤§å¤šæ•°å¤§è¯­è¨€æ¨¡å‹éƒ½è¶³å¤Ÿæ™ºèƒ½ï¼Œèƒ½ç†è§£ä½ å¸Œæœ›å®ƒä»¬å¸®åŠ©ç†è§£é—®é¢˜å¹¶æå‡ºä¿®å¤æ–¹æ¡ˆï¼Œå› æ­¤ä½ æ— éœ€æ˜ç¡®å‘ŠçŸ¥ã€‚åªéœ€åƒã€Œç¼–è¾‘æ­¤å†…å®¹ï¼š...ã€æˆ–ã€Œç¤ºä¾‹ dotenv ä»£ç ã€ï¼ˆç”¨æ¥æé†’ä½ å¦‚ä½•ç¼–å†™ä»£ç ä»¥ä½¿ç”¨ Python çš„ dotenv åŒ…ï¼‰è¿™æ ·ç®€çŸ­çš„æŒ‡ä»¤ï¼Œå¤§è¯­è¨€æ¨¡å‹é€šå¸¸å°±èƒ½ç”Ÿæˆä»¤äººæ»¡æ„çš„å“åº”ã€‚æ­¤å¤–ï¼Œå¦‚æœå“åº”å­˜åœ¨ç¼ºé™·ï¼Œä½ ä¹Ÿèƒ½åŠæ—¶å‘ç°é—®é¢˜å¹¶ä¼˜åŒ–æç¤ºï¼Œä¾‹å¦‚å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹å¦‚ä½•ä¿®æ”¹ä½ çš„æ–‡æœ¬ã€‚

å½“ç„¶ï¼Œåœ¨å¦ä¸€æ–¹é¢ï¼Œæœ‰æ—¶æˆ‘ä¹Ÿä¼šèŠ±è´¹ 30 åˆ†é’Ÿä»”ç»†æ’°å†™ä¸€ä»½é•¿è¾¾ 2 é¡µçš„æç¤ºï¼Œä»¥å€ŸåŠ© AI ç³»ç»Ÿè§£å†³ä¸€ä¸ªå¤æ‚é—®é¢˜ï¼ˆä¾‹å¦‚ç¼–å†™å¤šé¡µä»£ç ï¼‰ï¼Œè€Œè¿™åœ¨æ²¡æœ‰ AI å¸®åŠ©çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¼šèŠ±è´¹æˆ‘æ›´é•¿çš„æ—¶é—´ã€‚

æˆ‘ä¸ä¼šåœ¨ä»¥ä¸‹ä¸¤ç§æƒ…å†µä¸‹å°è¯•æƒ°æ€§æç¤ºï¼šï¼ˆiï¼‰æˆ‘ç¡®ä¿¡ï¼Œå¦‚æœæ²¡æœ‰é¢å¤–ä¸Šä¸‹æ–‡ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¸å¯èƒ½æä¾›ä¸€ä¸ªå¥½çš„è§£å†³æ–¹æ¡ˆã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªä¸å®Œæ•´çš„ç¨‹åºè§„æ ¼ï¼Œå³ä½¿æ˜¯ç»éªŒä¸°å¯Œçš„äººç±»å¼€å‘è€…ï¼Œä¹Ÿå¾ˆéš¾ç†è§£ä½ åˆ°åº•æƒ³è¦ä»€ä¹ˆã€‚å¦‚æœæˆ‘ç»å¯¹æƒ³ä½¿ç”¨æŸä¸ªç‰¹å®šçš„ PDF è½¬æ–‡æœ¬è½¬æ¢è½¯ä»¶ï¼ˆæ¯”å¦‚æˆ‘å›¢é˜Ÿ LandingAI çš„ Agentic Doc Extraction!ï¼‰ï¼Œæˆ‘å°±åº”è¯¥åœ¨æç¤ºä¸­æ˜ç¡®è¯´æ˜ï¼Œå¦åˆ™å¤§è¯­è¨€æ¨¡å‹å°†å¾ˆéš¾çŒœåˆ°æˆ‘çš„åå¥½ã€‚(iiï¼‰å½“ä¸€ä¸ªæœ‰ç¼ºé™·çš„å®ç°éœ€è¦å¾ˆé•¿æ—¶é—´æ‰èƒ½è¢«å‘ç°æ—¶ï¼Œæˆ‘ä¹Ÿä¸ä¼šä½¿ç”¨æƒ°æ€§æç¤ºã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œå¦‚æœæˆ‘åˆ¤æ–­è¾“å‡ºæ˜¯å¦æ­£ç¡®çš„å”¯ä¸€æ–¹æ³•æ˜¯è´¹åŠ›åœ°è¿è¡Œä»£ç æ¥æ£€æŸ¥å…¶åŠŸèƒ½ï¼Œé‚£ä¹ˆæœ€å¥½é¢„å…ˆèŠ±æ—¶é—´æä¾›ä¸Šä¸‹æ–‡ï¼Œè¿™æ ·èƒ½å¤§å¤§å¢åŠ å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæˆ‘æ‰€éœ€å†…å®¹çš„å¯èƒ½æ€§ã€‚

é¡ºå¸¦ä¸€æï¼Œæƒ°æ€§æç¤ºæ˜¯ä¸€ç§é«˜çº§æŠ€å·§ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘å‘ç°å¤§å¤šæ•°äººåœ¨ç»™å¤§è¯­è¨€æ¨¡å‹æä¾›ä¸Šä¸‹æ–‡æ—¶ï¼Œå¸¸å¸¸æ˜¯ç»™å¾—å¤ªå°‘è€Œéå¤ªå¤šã€‚æƒ°æ€§åªæœ‰åœ¨ä½ å·²ç»å­¦ä¼šå¦‚ä½•æä¾›è¶³å¤Ÿä¸Šä¸‹æ–‡çš„åŸºç¡€ä¸Šï¼Œå†æœ‰æ„è¯†åœ°å°è¯•ã€Œé€€ä¸€æ­¥ã€ï¼Œçœ‹çœ‹åœ¨æä¾›æœ€å°‘ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹æ˜¯å¦ä¾ç„¶èƒ½å¥æ•ˆæ—¶ï¼Œæ‰æ˜¯ä¸€ç§æœ‰æ•ˆçš„æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæƒ°æ€§æç¤ºä»…é€‚ç”¨äºä½ èƒ½é€šè¿‡å¤§è¯­è¨€æ¨¡å‹çš„ç½‘é¡µæˆ–åº”ç”¨ç•Œé¢è¿›è¡Œå¿«é€Ÿè¿­ä»£çš„æƒ…å¢ƒã€‚å®ƒä¸é€‚ç”¨äºé‚£äº›ä¸ºåå¤è°ƒç”¨ API è€Œç¼–å†™åœ¨ä»£ç ä¸­çš„æç¤ºï¼Œå› ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœè¾“å‡ºè´¨é‡ä¸ä½³ï¼Œä½ å¯èƒ½ä¸ä¼šé€ä¸€æ£€æŸ¥æ¯ä¸ªè¾“å‡ºå¹¶è¿›è¡Œæ¾„æ¸…å’Œè¿­ä»£ã€‚

æ„Ÿè°¢ Rohit Prsad æå‡ºäº†ã€Œæƒ°æ€§æç¤ºã€è¿™ä¸ªæœ¯è¯­ï¼Œä»–ä¸€ç›´ä¸æˆ‘åˆä½œå¼€å‘å¼€æºè½¯ä»¶åŒ… aisuiteã€‚è¿™ä¸è®¡ç®—æœºç§‘å­¦ä¸­çš„æƒ°æ€§æ±‚å€¼ï¼ˆlazy evaluationï¼‰æœ‰å¼‚æ›²åŒå·¥ä¹‹å¦™ï¼Œæƒ°æ€§æ±‚å€¼æŒ‡çš„æ˜¯åœ¨æœ€æ™šçš„æ—¶åˆ»ï¼Œå¹¶ä¸”ä»…å½“ç‰¹å®šç»“æœè¢«éœ€è¦æ—¶æ‰è°ƒç”¨å‡½æ•°ã€‚åœ¨æƒ°æ€§æç¤ºä¸­ï¼Œæˆ‘ä»¬ä¹Ÿæ˜¯åªåœ¨éœ€è¦æ—¶æ‰å‘æç¤ºä¸­æ·»åŠ ç»†èŠ‚ã€‚

åŸæ–‡é“¾æ¥ï¼šhttps://t.co/Doh0TdJpO3

### 058

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-10
é“¾æ¥: https://x.com/AndrewYNg/status/1910388768487727535
äº’åŠ¨: Likes: 2,978; Retweets: 364; Replies: 198; Quotes: 50; Views: 333,496; Bookmarks: 627; isReply: 0

I am so sorry that the U.S. is letting down our friends and allies. Broad tariffs, implemented not just against adversaries but also steadfast allies, will damage the livelihoods of billions of people, create inflation, make the world more fragmented, and leave the U.S. and the world poorer. AI isnâ€™t the solution to everything, but even amidst this challenging environment, I hope our community can hold together, keep building friendships across borders, keep sharing ideas, and keep supporting each other.

Much has been written about why high, widespread taxes on imports are harmful. In this letter, Iâ€™d like to focus on its possible effects on AI. One silver lining of the new tariffs is that they focus on physical imports, rather than digital goods and services, including intellectual property (IP) such as AI research inventions and software. IP is difficult to tax, because each piece of IP is unique and thus hard to value, and it moves across borders with little friction via the internet. Many international AI teams collaborate across borders and timezones, and software, including specifically open source software, is an important mechanism for sharing ideas. I hope that this free flow of ideas remains unhampered, even if the flow of physical goods is.

However, AI relies on hardware, and tariffs will slow down AI progress by restricting access to it. Even though a last-minute exception was made for semiconductors, taxing imports of solar panels, wind turbines, and other power-generation and -distribution equipment will diminish the ability to provide power to U.S. data centers. Taxing imports of servers, cooling hardware, networking hardware, and the like will also make it more expensive to build data centers. And taxing consumer electronics, like laptops and phones, will make it harder for citizens to learn and use AI.

With regard to data-center buildouts, another silver lining is that, with the rise of generative AI,Â data gravity has decreasedÂ because compute processing costs are much greater than transmission costs, meaning itâ€™s more feasible to place data centers anywhere in the world rather than only in close proximity to end-users. Even though many places do not have enough trained technicians to build and operate data centers, I expect tariffs will encourage data centers to be built around the world, creating more job opportunities globally.

Finally, tariffs will create increased pressure for domestic manufacturing, which might create very mild tailwinds for robotics and industrial automation. As U.S. Vice President J.D. VanceÂ pointed outÂ in 2017, the U.S. should focus on automation (and education) rather than on tariffs. But the U.S. does not have the personnel â€” or know-how, or supply chain â€” to manufacture many of the goods that it currently counts on allies to make. Robotics can be helpful for addressing a small part of this large set of challenges. Generative AIâ€™s rate of progress in robotics is also significantly slower than in processing text, visual data, audio, and reasoning. So while the tariffs could create tailwinds for AI-enabled robotics, I expect this effect to be small.

My 4-year-old son had been complaining for a couple of weeks that his shoes were a tight fit â€” he was proud that heâ€™s growing! So last Sunday, we went shoe shopping. His new shoes cost $25, and while checking out, I paused and reflected on how lucky I am to be able to afford them. But I also thought about the many families living paycheck-to-paycheck, and for whom tariffs leading to shoes at $40 a pair would mean they let their kids wear ill-fitting shoes longer. I also thought about people Iâ€™ve met in clothing manufacturing plants in Asia and Latin America, for whom reduced demand would mean less work and less money to take home to their own kids.

I donâ€™t know what will happen next with the U.S. tariffs, and plenty of international trade will happen with or without U.S. involvement. I hope we can return to a world of vibrant global trade with strong, rules-based, U.S. participation. Until then, letâ€™s all of us in AI keep nurturing our international friendships, keep up the digital flow of ideas â€” including specifically open source software â€” and keep supporting each other. Letâ€™s all do what we can to keep the world as connected as we are able.

[I had written this letter before the 90 day pause on the tariffs, but am sharing this here since many of the points are still relevant depends on what happens next.] 

Original text: https://t.co/fNyTqzABWy

æˆ‘å¾ˆæŠ±æ­‰ï¼Œç¾å›½æ­£åœ¨è¾œè´Ÿæˆ‘ä»¬çš„æœ‹å‹å’Œç›Ÿå‹ã€‚å¹¿æ³›çš„å…³ç¨ï¼Œä¸ä»…é’ˆå¯¹å¯¹æ‰‹ï¼Œä¹Ÿé’ˆå¯¹åšå®šçš„ç›Ÿå‹å®æ–½ï¼Œå°†æŸå®³æ•°åäº¿äººçš„ç”Ÿè®¡ï¼Œé€ æˆé€šè´§è†¨èƒ€ï¼Œä½¿ä¸–ç•Œæ›´åŠ ç¢ç‰‡åŒ–ï¼Œå¹¶ä½¿ç¾å›½å’Œå…¨çƒå˜å¾—æ›´åŠ è´«ç©·ã€‚äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å¹¶éä¸‡èƒ½è¯ï¼Œä½†å³ä½¿åœ¨è¿™ç§å……æ»¡æŒ‘æˆ˜çš„ç¯å¢ƒä¸­ï¼Œæˆ‘å¸Œæœ›æˆ‘ä»¬çš„ç¤¾åŒºèƒ½å¤Ÿå›¢ç»“èµ·æ¥ï¼Œç»§ç»­å»ºç«‹è·¨è¶Šå›½ç•Œçš„å‹è°Šï¼Œç»§ç»­åˆ†äº«æ€æƒ³ï¼Œå¹¶ç»§ç»­äº’ç›¸æ”¯æŒã€‚

å…³äºä¸ºä»€ä¹ˆé«˜é¢ã€å¹¿æ³›çš„è¿›å£ç¨æœ‰å®³ï¼Œæ­¤å‰å·²æœ‰è¯¸å¤šè®ºè¿°ã€‚åœ¨è¿™å°ä¿¡ä¸­ï¼Œæˆ‘å¸Œæœ›èƒ½é‡ç‚¹æ¢è®¨å…¶å¯¹ AI å¯èƒ½äº§ç”Ÿçš„å½±å“ã€‚æ–°å…³ç¨çš„ä¸€ä¸ªäº®ç‚¹æ˜¯ï¼Œå®ƒä»¬ä¸»è¦é’ˆå¯¹å®ç‰©è¿›å£ï¼Œè€Œéæ•°å­—å•†å“å’ŒæœåŠ¡ï¼Œè¿™å…¶ä¸­åŒ…æ‹¬ AI ç ”ç©¶å‘æ˜å’Œè½¯ä»¶ç­‰çŸ¥è¯†äº§æƒï¼ˆIPï¼‰ã€‚çŸ¥è¯†äº§æƒéš¾ä»¥å¾ç¨ï¼Œå› ä¸ºæ¯ä¸€é¡¹çŸ¥è¯†äº§æƒéƒ½ç‹¬ä¸€æ— äºŒï¼Œå› æ­¤éš¾ä»¥ä¼°ä»·ï¼Œå¹¶ä¸”å®ƒå¯ä»¥é€šè¿‡äº’è”ç½‘å‡ ä¹æ²¡æœ‰é˜»åŠ›åœ°è·¨è¶Šå›½ç•Œã€‚è®¸å¤šå›½é™… AI å›¢é˜Ÿè·¨è¶Šå›½ç•Œå’Œæ—¶åŒºè¿›è¡Œåä½œï¼Œè€Œè½¯ä»¶ï¼Œç‰¹åˆ«æ˜¯å¼€æºè½¯ä»¶ï¼Œæ˜¯åˆ†äº«æ€æƒ³çš„é‡è¦æœºåˆ¶ã€‚æˆ‘å¸Œæœ›è¿™ç§æ€æƒ³çš„è‡ªç”±æµåŠ¨èƒ½å¤Ÿä¸å—é˜»ç¢ï¼Œå³ä½¿å®ç‰©å•†å“çš„æµåŠ¨å—åˆ°é™åˆ¶ã€‚

ç„¶è€Œï¼ŒAI ä¾èµ–ç¡¬ä»¶ï¼Œè€Œå…³ç¨å°†é€šè¿‡é™åˆ¶ç¡¬ä»¶çš„è·å–æ¥å‡ç¼“ AI çš„å‘å±•ã€‚å°½ç®¡åœ¨æœ€åä¸€åˆ»å¯¹åŠå¯¼ä½“åšå‡ºäº†ä¾‹å¤–å¤„ç†ï¼Œä½†å¯¹å¤ªé˜³èƒ½ç”µæ± æ¿ã€é£åŠ›æ¶¡è½®æœºä»¥åŠå…¶ä»–å‘ç”µå’Œé…ç”µè®¾å¤‡çš„è¿›å£å¾ç¨ï¼Œå°†å‰Šå¼±ç¾å›½æ•°æ®ä¸­å¿ƒçš„ä¾›ç”µèƒ½åŠ›ã€‚å¯¹æœåŠ¡å™¨ã€å†·å´ç¡¬ä»¶ã€ç½‘ç»œç¡¬ä»¶ç­‰è®¾å¤‡çš„è¿›å£å¾ç¨ï¼Œä¹Ÿå°†ä½¿æ•°æ®ä¸­å¿ƒçš„å»ºè®¾æˆæœ¬æ›´é«˜ã€‚æ­¤å¤–ï¼Œå¯¹ç¬”è®°æœ¬ç”µè„‘å’Œæ‰‹æœºç­‰æ¶ˆè´¹ç”µå­äº§å“å¾ç¨ï¼Œå°†ä½¿å…¬æ°‘å­¦ä¹ å’Œä½¿ç”¨ AI å˜å¾—æ›´åŠ å›°éš¾ã€‚

å…³äºæ•°æ®ä¸­å¿ƒå»ºè®¾ï¼Œå¦ä¸€ä¸ªå¥½æ¶ˆæ¯æ˜¯ï¼Œéšç€ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰çš„å…´èµ·ï¼Œæ•°æ®å¼•åŠ›ï¼ˆdata gravityï¼‰æœ‰æ‰€é™ä½ï¼Œå› ä¸ºè®¡ç®—å¤„ç†æˆæœ¬è¿œå¤§äºä¼ è¾“æˆæœ¬ã€‚è¿™æ„å‘³ç€åœ¨å…¨çƒä»»ä½•åœ°æ–¹æ”¾ç½®æ•°æ®ä¸­å¿ƒéƒ½æ¯”ä»…é è¿‘æœ€ç»ˆç”¨æˆ·æ›´å¯è¡Œã€‚å°½ç®¡è®¸å¤šåœ°æ–¹ç¼ºä¹è¶³å¤Ÿçš„åˆæ ¼æŠ€æœ¯äººå‘˜æ¥å»ºé€ å’Œè¿è¥æ•°æ®ä¸­å¿ƒï¼Œä½†æˆ‘é¢„è®¡å…³ç¨å°†é¼“åŠ±æ•°æ®ä¸­å¿ƒåœ¨å…¨çƒå„åœ°å»ºè®¾ï¼Œä»è€Œåœ¨å…¨çƒåˆ›é€ æ›´å¤šå°±ä¸šæœºä¼šã€‚

æœ€åï¼Œå…³ç¨å°†å¢åŠ å›½å†…åˆ¶é€ ä¸šçš„å‹åŠ›ï¼Œè¿™å¯èƒ½ä¼šä¸ºæœºå™¨äººæŠ€æœ¯å’Œå·¥ä¸šè‡ªåŠ¨åŒ–å¸¦æ¥ä¸€äº›å¾®å¼±çš„æ¨åŠ¨ä½œç”¨ã€‚æ­£å¦‚ç¾å›½å‰¯æ€»ç»Ÿ J.D. Vance åœ¨ 2017 å¹´æŒ‡å‡ºçš„é‚£æ ·ï¼Œç¾å›½åº”è¯¥ä¸“æ³¨äºè‡ªåŠ¨åŒ–ï¼ˆå’Œæ•™è‚²ï¼‰ï¼Œè€Œéå…³ç¨ã€‚ä½†ç¾å›½ç›®å‰ç¼ºä¹è¶³å¤Ÿçš„äººå‘˜ â€”â€” æˆ–è€…è¯´æŠ€æœ¯è¯€çªï¼Œæˆ–è€…è¯´å®Œå–„çš„ä¾›åº”é“¾ â€”â€” æ¥åˆ¶é€ å®ƒç›®å‰ä¾èµ–ç›Ÿå‹ç”Ÿäº§çš„è®¸å¤šå•†å“ã€‚æœºå™¨äººæŠ€æœ¯æœ‰åŠ©äºè§£å†³è¿™ä¸€ç³»åˆ—å·¨å¤§æŒ‘æˆ˜ä¸­çš„ä¸€å°éƒ¨åˆ†ã€‚ç”Ÿæˆå¼ AI åœ¨æœºå™¨äººæŠ€æœ¯æ–¹é¢çš„è¿›æ­¥é€Ÿåº¦ä¹Ÿæ˜¾è‘—æ…¢äºå…¶åœ¨å¤„ç†æ–‡æœ¬ã€è§†è§‰æ•°æ®ã€éŸ³é¢‘å’Œæ¨ç†æ–¹é¢çš„é€Ÿåº¦ã€‚å› æ­¤ï¼Œå°½ç®¡å…³ç¨å¯èƒ½ä¼šä¸º AI é©±åŠ¨çš„æœºå™¨äººæŠ€æœ¯å¸¦æ¥åˆ©å¥½ï¼Œä½†æˆ‘é¢„è®¡è¿™ç§å½±å“ä¼šå¾ˆå°ã€‚

æˆ‘ 4 å²çš„å„¿å­æŠ±æ€¨äº†å¥½å‡ ä¸ªæ˜ŸæœŸä»–çš„é‹å­å¤ªç´§ â€”â€” ä»–ä¸ºè‡ªå·±é•¿å¤§äº†æ„Ÿåˆ°è‡ªè±ªï¼æ‰€ä»¥ä¸Šå‘¨æ—¥ï¼Œæˆ‘ä»¬å»ä¹°é‹äº†ã€‚ä»–çš„æ–°é‹èŠ±äº† 25 ç¾å…ƒï¼Œç»“è´¦æ—¶ï¼Œæˆ‘åœä¸‹æ¥æ„Ÿæ…¨è‡ªå·±èƒ½è´Ÿæ‹…å¾—èµ·è¿™äº›é‹å­æ˜¯å¤šä¹ˆå¹¸è¿ã€‚ä½†æˆ‘ä¹Ÿæƒ³åˆ°äº†è®¸å¤šé å·¥èµ„å‹‰å¼ºåº¦æ—¥çš„å®¶åº­ï¼Œå¯¹ä»–ä»¬æ¥è¯´ï¼Œå¦‚æœå…³ç¨å¯¼è‡´é‹å­æ¯åŒé«˜è¾¾ 40 ç¾å…ƒï¼Œå°±æ„å‘³ç€ä»–ä»¬ä¼šè®©å­©å­ç©¿ç€ä¸åˆè„šçš„é‹å­æ›´é•¿æ—¶é—´ã€‚æˆ‘è¿˜æƒ³åˆ°äº†æˆ‘åœ¨äºšæ´²å’Œæ‹‰ä¸ç¾æ´²çš„æœè£…åˆ¶é€ å‚é‡åˆ°çš„äººä»¬ï¼Œå¯¹ä»–ä»¬æ¥è¯´ï¼Œéœ€æ±‚å‡å°‘å°†æ„å‘³ç€å·¥ä½œæ›´å°‘ï¼Œå¸¦å›å®¶çš„é’±æ›´å°‘ï¼Œç»™ä»–ä»¬çš„å­©å­ã€‚

æˆ‘ä¸çŸ¥é“ç¾å›½å…³ç¨æ¥ä¸‹æ¥ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œä½†æ— è®ºç¾å›½æ˜¯å¦å‚ä¸ï¼Œè®¸å¤šå›½é™…è´¸æ˜“ä»ä¼šè¿›è¡Œã€‚æˆ‘å¸Œæœ›æˆ‘ä»¬èƒ½å›åˆ°ä¸€ä¸ªå……æ»¡æ´»åŠ›çš„å…¨çƒè´¸æ˜“ä¸–ç•Œï¼Œä¼´éšç€å¼ºå¤§ä¸”åŸºäºè§„åˆ™çš„ç¾å›½å‚ä¸ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬æ‰€æœ‰ AI ç•Œçš„åŒä»ï¼Œè¯·ç»§ç»­åŸ¹å…»æˆ‘ä»¬çš„å›½é™…å‹è°Šï¼Œç»§ç»­ä¿æŒæ€æƒ³çš„æ•°å­—åŒ–æµåŠ¨ â€”â€” ç‰¹åˆ«æ˜¯å¼€æºè½¯ä»¶ â€”â€” å¹¶ç»§ç»­äº’ç›¸æ”¯æŒã€‚è®©æˆ‘ä»¬å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œè®©ä¸–ç•Œä¿æŒå°½å¯èƒ½ç´§å¯†çš„è”ç³»ã€‚

[æˆ‘æ˜¯åœ¨å…³ç¨æš‚åœ 90 å¤©ä¹‹å‰å†™çš„è¿™å°ä¿¡ï¼Œä½†åœ¨æ­¤åˆ†äº«ï¼Œå› ä¸ºè®¸å¤šè§‚ç‚¹ä¾ç„¶ç›¸å…³ï¼Œè¿™å–å†³äºæ¥ä¸‹æ¥ä¼šå‘ç”Ÿä»€ä¹ˆã€‚]

### 059

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-16
é“¾æ¥: https://x.com/AndrewYNg/status/1912560177745994098
äº’åŠ¨: Likes: 1,818; Retweets: 302; Replies: 50; Quotes: 21; Views: 183,935; Bookmarks: 1,881; isReply: 0

New Short Course: Building AI Browser Agents! 

Learn how to build AI agents that interact and take actions on websites in this course, created in partnership with @the_agi_company and taught by  @DivGarg_ and @namangarg0, Co-founders of AGI Inc.

AI browser agents can log into websites, fill out forms, click through web pages, or even place orders online for you. They use both visual information, like screenshots, and structural data, like the HTML or Document Object Model (DOM) of a web page, to reason and take action.

With the complexity of webpages and multiple possible actions at each step, it can be challenging for an AI browser agent to complete an assigned task. Because these agents run long action sequences, a single errorâ€”like clicking the wrong button or misreading a fieldâ€”can lead to unexpected outcomes or errors that compound over time.

In this course, you'll understand how autonomous web agents work, their current limitations, and how AgentQ enables them to improve through self-correction.

In detail, you'll:
- Learn what web agents are, how they automate tasks online, their architecture, key components, limitations, and an overview of their decision-making strategies.
- Build a web agent that can scrape https://t.co/zpIxRSuky4's website and return course recommendations in a structured output format.
- Build an autonomous web agent that can execute multiple tasks, such as finding and summarizing webpages, filling out a form, and signing up for a newsletter.
- Explore AgentQ, a framework that enables agents to self-correct by combining Monte Carlo Tree Search (MCTS), a self-critique mechanism for continuous improvement, and Direct Preference Optimization (DPO).
- Deep dive into MCTS, learn how it finds an effective path, illustrated by an example of Gridworld animation, and use AgentQ to complete web tasks.
- Understand AI agents' current state and future directionsâ€”including key factors shaping their evolution, such as hardware, algorithm innovation, and data availability.
By the end of this course, you will have hands-on experience building browser agents and a deeper understanding of how to make them more robust and reliable.

Please sign up here: https://t.co/kTzv4NkQ8H

æ–°è¯¾ç¨‹ï¼šæ„å»º AI æµè§ˆå™¨æ™ºèƒ½ä½“ï¼æœ¬è¯¾ç¨‹ä¸ @the_agi_company åˆä½œå¼€å‘ï¼Œç”± AGI Inc. çš„è”åˆåˆ›å§‹äºº @DivGarg_ å’Œ @namangarg0 æˆè¯¾ï¼Œæ—¨åœ¨æ•™æ‚¨å¦‚ä½•æ„å»ºèƒ½å¤Ÿä¸ç½‘ç«™äº’åŠ¨å¹¶é‡‡å–è¡ŒåŠ¨çš„ AI æ™ºèƒ½ä½“ï¼ˆAI agentsï¼‰ã€‚

AI æµè§ˆå™¨æ™ºèƒ½ä½“ï¼ˆAI Browser Agentsï¼‰å¯ä»¥æ‰§è¡Œå¤šç§ä»»åŠ¡ï¼Œä¾‹å¦‚ç™»å½•ç½‘ç«™ã€å¡«å†™è¡¨æ ¼ã€ç‚¹å‡»ç½‘é¡µï¼Œç”šè‡³ä¸ºæ‚¨åœ¨çº¿ä¸‹å•ã€‚å®ƒä»¬ä¼šç»“åˆè§†è§‰ä¿¡æ¯ï¼ˆvisual informationï¼‰(å¦‚ç½‘é¡µæˆªå›¾ï¼‰å’Œç»“æ„åŒ–æ•°æ®ï¼ˆstructural dataï¼‰(å¦‚ç½‘é¡µçš„ HTML æˆ–æ–‡æ¡£å¯¹è±¡æ¨¡å‹ï¼ˆDocument Object Modelï¼ŒDOM)ï¼‰æ¥è¿›è¡Œæ¨ç†å¹¶é‡‡å–è¡ŒåŠ¨ã€‚

ç„¶è€Œï¼Œç”±äºç½‘é¡µçš„å¤æ‚æ€§ä»¥åŠæ¯ä¸€æ­¥å¯èƒ½å­˜åœ¨çš„å¤šç§æ“ä½œï¼ŒAI æµè§ˆå™¨æ™ºèƒ½ä½“ï¼ˆAI Browser Agentsï¼‰åœ¨å®ŒæˆæŒ‡å®šä»»åŠ¡æ—¶ä¼šé¢ä¸´æŒ‘æˆ˜ã€‚è¿™äº›æ™ºèƒ½ä½“ï¼ˆagentsï¼‰é€šå¸¸éœ€è¦æ‰§è¡Œå†—é•¿çš„æ“ä½œåºåˆ—ï¼Œå•ä¸ªé”™è¯¯ï¼ˆä¾‹å¦‚ç‚¹é”™æŒ‰é’®æˆ–è¯¯è¯»æŸä¸ªå­—æ®µï¼‰éƒ½å¯èƒ½å¯¼è‡´æ„å¤–ç»“æœï¼Œç”šè‡³éšæ—¶é—´æ¨ç§»ç§¯ç´¯æˆæ›´å¤§çš„é—®é¢˜ã€‚

é€šè¿‡æœ¬è¯¾ç¨‹ï¼Œæ‚¨å°†æ·±å…¥äº†è§£è‡ªä¸»ç½‘ç»œæ™ºèƒ½ä½“ï¼ˆautonomous web agentsï¼‰çš„å·¥ä½œåŸç†ã€å®ƒä»¬ç›®å‰çš„å±€é™æ€§ï¼Œä»¥åŠ AgentQ å¦‚ä½•é€šè¿‡è‡ªæˆ‘ä¿®æ­£æœºåˆ¶æ¥æå‡å®ƒä»¬çš„è¡¨ç°ã€‚

å…·ä½“æ¥è¯´ï¼Œæ‚¨å°†ï¼š
- äº†è§£ä»€ä¹ˆæ˜¯ç½‘ç»œæ™ºèƒ½ä½“ï¼ˆweb agentsï¼‰ã€å®ƒä»¬å¦‚ä½•åœ¨çº¿å®ç°ä»»åŠ¡è‡ªåŠ¨åŒ–ã€å®ƒä»¬çš„æ¶æ„ã€å…³é”®ç»„ä»¶ã€å±€é™æ€§ä»¥åŠå®ƒä»¬å†³ç­–ç­–ç•¥çš„æ¦‚è§ˆã€‚
- æ„å»ºä¸€ä¸ªç½‘ç»œæ™ºèƒ½ä½“ï¼ˆweb agentï¼‰ï¼Œèƒ½å¤ŸæŠ“å– https://t.co/zpIxRSuky4 ç½‘ç«™çš„å†…å®¹ï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„è¾“å‡ºæ ¼å¼ï¼ˆstructured output formatï¼‰è¿”å›è¯¾ç¨‹æ¨èã€‚
- æ„å»ºä¸€ä¸ªè‡ªä¸»ç½‘ç»œæ™ºèƒ½ä½“ï¼ˆautonomous web agentï¼‰ï¼Œèƒ½å¤Ÿæ‰§è¡Œå¤šé¡¹ä»»åŠ¡ï¼Œä¾‹å¦‚æŸ¥æ‰¾å’Œæ€»ç»“ç½‘é¡µã€å¡«å†™è¡¨æ ¼ä»¥åŠæ³¨å†Œç”µå­æŠ¥ã€‚
- æ¢ç´¢ AgentQ æ¡†æ¶ï¼Œå®ƒé€šè¿‡ç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carlo Tree Searchï¼ŒMCTSï¼‰ã€ç”¨äºæŒç»­æ”¹è¿›çš„è‡ªæˆ‘æ‰¹è¯„æœºåˆ¶ï¼ˆself-critique mechanismï¼‰ä»¥åŠç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimizationï¼ŒDPOï¼‰ï¼Œä½¿æ™ºèƒ½ä½“ï¼ˆagentsï¼‰å…·å¤‡è‡ªæˆ‘ä¿®æ­£çš„èƒ½åŠ›ã€‚
- æ·±å…¥æ¢ç©¶ MCTSï¼Œå­¦ä¹ å®ƒå¦‚ä½•æ‰¾åˆ°æœ‰æ•ˆè·¯å¾„ï¼Œå¹¶é€šè¿‡ Gridworld åŠ¨ç”»ç¤ºä¾‹è¿›è¡Œè¯´æ˜ï¼Œç„¶åä½¿ç”¨ AgentQ æ¥å®Œæˆå®é™…çš„ç½‘ç»œä»»åŠ¡ã€‚
- ç†è§£ AI æ™ºèƒ½ä½“ï¼ˆAI agentsï¼‰çš„å½“å‰å‘å±•çŠ¶å†µå’Œæœªæ¥è¶‹åŠ¿ â€”â€” åŒ…æ‹¬å¡‘é€ å…¶æ¼”è¿›çš„å…³é”®å› ç´ ï¼Œä¾‹å¦‚ç¡¬ä»¶è¿›æ­¥ã€ç®—æ³•åˆ›æ–°ï¼ˆalgorithm innovationï¼‰å’Œæ•°æ®å¯ç”¨æ€§ï¼ˆdata availabilityï¼‰ã€‚
å®Œæˆæœ¬è¯¾ç¨‹åï¼Œæ‚¨å°†è·å¾—æ„å»ºæµè§ˆå™¨æ™ºèƒ½ä½“ï¼ˆbrowser agentsï¼‰çš„å®è·µç»éªŒï¼Œå¹¶å¯¹å¦‚ä½•ä½¿å®ƒä»¬æ›´åŠ å¥å£®å’Œå¯é æœ‰æ›´æ·±åˆ»çš„ç†è§£ã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/kTzv4NkQ8H

### 060

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-17
é“¾æ¥: https://x.com/AndrewYNg/status/1912908679344693711
äº’åŠ¨: Likes: 1,274; Retweets: 176; Replies: 56; Quotes: 35; Views: 206,735; Bookmarks: 1,245; isReply: 0

Iâ€™ve noticed that many GenAI application projects put in automated evaluations (evals) of the systemâ€™s output probably later â€” and rely on humans to judge outputs longer â€” than they should. This is because building evals is viewed as a massive investment (say, creating 100 or 1,000 examples, and designing and validating metrics) and thereâ€™s never a convenient moment to put in that up-front cost. Instead, I encourage teams to think of building evals as an iterative process. Itâ€™s okay to start with a quick-and-dirty implementation (say, 5 examples with unoptimized metrics) and then iterate and improve over time. This allows you to gradually shift the burden of evaluations away from humans and toward automated evals.

I wrote previously in The Batch about the importance and difficulty of creating evals. Say youâ€™re building a customer-service chatbot that responds to users in free text. Thereâ€™s no single right answer, so many teams end up having humans pore over dozens of example outputs with every update to judge if it improved the system. While techniques like LLM-as-judge are helpful, the details of getting this to work well (such as what prompt to use, what context to give the judge, and so on) are finicky to get right. All this contributes to the impression that building evals requires a large up-front investment, and thus on any given day, a team can make more progress by relying on human judges than figuring out how to build automated evals.

I encourage you to approach building evals differently. Itâ€™s okay to build quick evals that are only partial, incomplete, and noisy measures of the systemâ€™s performance, and to iteratively improve them. They can be a complement to, rather than replacement for, manual evaluations. Over time, you can gradually tune the evaluation methodology to close the gap between the evalsâ€™ output and human judgments. For example:
- Itâ€™s okay to start with very few examples in the eval set, say 5, and gradually add to them over time â€” or subtract them if you find that some examples are too easy or too hard, and not useful for distinguishing between the performance of different versions of your system.
- Itâ€™s okay to start with evals that measure only a subset of the dimensions of performance you care about, or measure narrow cues that you believe are correlated with, but donâ€™t fully capture, system performance. For example if, at a certain moment in the conversation, your customer-support agent is supposed to (i) call an API to issue a refund and (ii) generate an appropriate message to the user, you might start off measuring only whether or not it calls the API correctly and not worry about the message. Or if, at a certain moment, your chatbot should recommend a specific product, a basic eval could measure whether or not the chatbot mentions that product without worrying about what it says about it.

So long as the output of the evals correlates with overall performance, itâ€™s fine to measure only a subset of things you care about when starting.

The development process thus comprises two iterative loops, which you might execute in parallel:
- Iterating on the system to make it perform better, as measured by a combination of automated evals and human judgment;
- Iterating on the evals to make them correspond more closely to human judgment.

As with many things in AI, we often donâ€™t get it right the first time. So tâ€™s better to build an initial end-to-end system quickly and then iterate to improve it. Weâ€™re used to taking this approach to building AI systems. We can build evals the same way.

To me, a successful eval meets the following criteria. Say, we currently have system A, and we might tweak it to get a system B:
- If A works significantly better than B according to a skilled human judge, the eval should give A a significantly higher score than B.
- If A and B have similar performance, their eval scores should be similar.

Whenever a pair of systems A and B contradicts these criteria, that is a sign the eval is in â€œerrorâ€ and we should tweak it to make it rank A and B correctly. This is a similar philosophy to error analysis in building machine learning algorithms, only instead of focusing on errors of the machine learning algorithm's output â€” such as when it outputs an incorrect label â€” we focus on â€œerrorsâ€ of the evals â€” such as when they incorrectly rank two systems A and B, so the evals arenâ€™t helpful in choosing between them.

Relying purely on human judgment is a great way to get started on a project. But for many teams, building evals as a quick prototype and iterating to something more mature lets you put in evals earlier and accelerate your progress.

[Original text: https://t.co/V3BZe8sRWE ]

æˆ‘æ³¨æ„åˆ°ï¼Œè®¸å¤šç”Ÿæˆå¼ AIï¼ˆGenAIï¼‰åº”ç”¨é¡¹ç›®å¾€å¾€è¿‡æ™šæ‰å¼•å…¥ç³»ç»Ÿè¾“å‡ºçš„è‡ªåŠ¨åŒ–è¯„ä¼°ï¼ˆevalsï¼‰ï¼Œå¹¶ä¸”è¿‡åº¦ä¾èµ–äººå·¥åˆ¤æ–­è¾“å‡ºã€‚è¿™æ˜¯å› ä¸ºæ„å»ºè¯„ä¼°è¢«è§†ä¸ºä¸€é¡¹å·¨å¤§çš„æŠ•å…¥ï¼ˆæ¯”å¦‚ï¼Œéœ€è¦åˆ›å»º 100 ç”šè‡³ 1,000 ä¸ªç¤ºä¾‹ï¼Œå¹¶è®¾è®¡å’ŒéªŒè¯ç›¸å…³æŒ‡æ ‡ï¼‰ï¼Œè€Œé€šå¸¸äººä»¬å¾ˆéš¾æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„æ—¶é—´æ¥æ‰¿æ‹…è¿™ç¬”å‰æœŸæˆæœ¬ã€‚ä½†æˆ‘é¼“åŠ±å›¢é˜Ÿå°†è¯„ä¼°çš„æ„å»ºçœ‹ä½œä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ã€‚ä»ä¸€ä¸ªå¿«é€Ÿç²—ç³™çš„å®ç°ï¼ˆä¾‹å¦‚ï¼Œåªæœ‰ 5 ä¸ªç¤ºä¾‹ï¼Œä¸”æŒ‡æ ‡æœªç»ä¼˜åŒ–ï¼‰å¼€å§‹ï¼Œç„¶åéšç€æ—¶é—´çš„æ¨ç§»é€æ­¥è¿­ä»£å’Œæ”¹è¿›ï¼Œè¿™æ˜¯å®Œå…¨å¯è¡Œçš„ã€‚è¿™æ ·åšå¯ä»¥å¸®åŠ©æ‚¨å°†è¯„ä¼°çš„é‡æ‹…é€æ¸ä»äººå·¥åˆ¤æ–­è½¬ç§»åˆ°è‡ªåŠ¨åŒ–è¯„ä¼°ä¸Šã€‚

æˆ‘ä¹‹å‰åœ¨ The Batch ä¸­æ’°æ–‡è®¨è®ºè¿‡åˆ›å»ºè¯„ä¼°çš„é‡è¦æ€§å’Œéš¾åº¦ã€‚æ¯”æ–¹è¯´ï¼Œæ‚¨æ­£åœ¨å¼€å‘ä¸€ä¸ªèƒ½ä»¥è‡ªç”±æ–‡æœ¬å½¢å¼å›å¤ç”¨æˆ·çš„å®¢æˆ·æœåŠ¡èŠå¤©æœºå™¨äººã€‚ç”±äºæ²¡æœ‰å”¯ä¸€çš„æ­£ç¡®ç­”æ¡ˆï¼Œè®¸å¤šå›¢é˜Ÿæœ€ç»ˆåœ¨æ¯æ¬¡ç³»ç»Ÿæ›´æ–°åï¼Œéƒ½éœ€è¦è®©äººå·¥ä»”ç»†æ£€æŸ¥æ•°åä¸ªç¤ºä¾‹è¾“å‡ºï¼Œä»¥åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦æœ‰æ‰€æå‡ã€‚å°½ç®¡ã€Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºåˆ¤æ–­è€…ã€è¿™ç±»æŠ€æœ¯å¾ˆæœ‰ç”¨ï¼Œä½†è¦è®©å®ƒä»¬çœŸæ­£å‘æŒ¥ä½œç”¨ï¼Œå…¶å…·ä½“ç»†èŠ‚ï¼ˆæ¯”å¦‚ä½¿ç”¨ä»€ä¹ˆæç¤ºè¯ï¼Œç»™åˆ¤æ–­è€…æä¾›ä»€ä¹ˆä¸Šä¸‹æ–‡ç­‰ï¼‰å¾€å¾€éå¸¸ç¹çï¼Œéš¾ä»¥ç²¾ç¡®æ‹¿æã€‚æ‰€æœ‰è¿™äº›å› ç´ éƒ½è®©äººè§‰å¾—æ„å»ºè¯„ä¼°éœ€è¦å¤§é‡å‰æœŸæŠ•å…¥ï¼Œå› æ­¤åœ¨ä»»ä½•ç‰¹å®šçš„ä¸€å¤©ï¼Œå›¢é˜Ÿå¯èƒ½ä¼šè®¤ä¸ºä¾èµ–äººå·¥åˆ¤æ–­è€…æ¯”æ‘¸ç´¢å¦‚ä½•æ„å»ºè‡ªåŠ¨åŒ–è¯„ä¼°æ›´èƒ½æ¨è¿›é¡¹ç›®ã€‚

æˆ‘é¼“åŠ±æ‚¨ä»¥ä¸åŒçš„æ–¹å¼æ¥æ„å»ºè¯„ä¼°ã€‚æ‚¨å¯ä»¥ä»ä¸€äº›å¿«é€Ÿä½†å¯èƒ½åªæ˜¯éƒ¨åˆ†ã€ä¸å®Œæ•´ä¸”å¸¦æœ‰ä¸€å®šè¯¯å·®çš„ç³»ç»Ÿæ€§èƒ½è¡¡é‡æ ‡å‡†å¼€å§‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè¿­ä»£æ”¹è¿›ã€‚å®ƒä»¬å¯ä»¥ä½œä¸ºäººå·¥è¯„ä¼°çš„è¡¥å……ï¼Œè€Œéæ›¿ä»£ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæ‚¨å¯ä»¥é€æ­¥è°ƒæ•´è¯„ä¼°æ–¹æ³•ï¼Œç¼©å°è‡ªåŠ¨åŒ–è¯„ä¼°ç»“æœä¸äººå·¥åˆ¤æ–­ä¹‹é—´çš„å·®è·ã€‚ä¾‹å¦‚ï¼š
- è¯„ä¼°é›†å¯ä»¥å…ˆä»å¾ˆå°‘çš„ç¤ºä¾‹å¼€å§‹ï¼Œæ¯”å¦‚ 5 ä¸ªï¼Œç„¶åéšç€æ—¶é—´é€æ­¥å¢åŠ  â€”â€” å¦‚æœæ‚¨å‘ç°æŸäº›ç¤ºä¾‹è¿‡äºç®€å•æˆ–è¿‡äºå›°éš¾ï¼Œå¯¹åŒºåˆ†ç³»ç»Ÿä¸åŒç‰ˆæœ¬çš„æ€§èƒ½æ²¡æœ‰å¸®åŠ©ï¼Œä¹Ÿå¯ä»¥å°†å…¶ç§»é™¤ã€‚
- æ‚¨å¯ä»¥å…ˆä»åªè¡¡é‡æ‚¨æ‰€å…³æ³¨çš„æ€§èƒ½ç»´åº¦ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œæˆ–è€…åªè¡¡é‡é‚£äº›æ‚¨è®¤ä¸ºä¸ç³»ç»Ÿæ€§èƒ½ç›¸å…³ä½†æ— æ³•å®Œå…¨æ•æ‰çš„ç‹­çª„çº¿ç´¢çš„è¯„ä¼°å¼€å§‹ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœåœ¨å¯¹è¯çš„æŸä¸ªæ—¶åˆ»ï¼Œæ‚¨çš„å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“ï¼ˆagentï¼‰éœ€è¦ï¼ˆiï¼‰è°ƒç”¨ API æ¥å¤„ç†é€€æ¬¾ï¼Œå¹¶ï¼ˆiiï¼‰ç”Ÿæˆä¸€æ¡é€‚å½“çš„æ¶ˆæ¯ç»™ç”¨æˆ·ï¼Œé‚£ä¹ˆæ‚¨å¯èƒ½å¯ä»¥å…ˆåªè¡¡é‡å®ƒæ˜¯å¦æ­£ç¡®è°ƒç”¨äº† APIï¼Œæš‚æ—¶ä¸è€ƒè™‘æ¶ˆæ¯å†…å®¹ã€‚æˆ–è€…ï¼Œå¦‚æœåœ¨æŸä¸ªæ—¶åˆ»ï¼Œæ‚¨çš„èŠå¤©æœºå™¨äººåº”è¯¥æ¨èç‰¹å®šäº§å“ï¼Œä¸€ä¸ªåŸºæœ¬çš„è¯„ä¼°å¯ä»¥åªè¡¡é‡èŠå¤©æœºå™¨äººæ˜¯å¦æåˆ°äº†è¯¥äº§å“ï¼Œè€Œä¸ç”¨æ‹…å¿ƒå®ƒå¯¹è¯¥äº§å“å…·ä½“è¯´äº†ä»€ä¹ˆã€‚

åªè¦è¯„ä¼°çš„è¾“å‡ºä¸æ•´ä½“æ€§èƒ½ç›¸å…³ï¼Œé‚£ä¹ˆåœ¨é¡¹ç›®åˆæœŸåªè¡¡é‡æ‚¨å…³å¿ƒçš„éƒ¨åˆ†å†…å®¹æ˜¯å®Œå…¨å¯ä»¥çš„ã€‚

å› æ­¤ï¼Œå¼€å‘è¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªè¿­ä»£å¾ªç¯ï¼Œæ‚¨å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼š
- è¿­ä»£ä¼˜åŒ–ç³»ç»Ÿï¼Œä½¿å…¶è¡¨ç°æ›´å¥½ï¼Œè¿™é€šè¿‡ç»“åˆè‡ªåŠ¨åŒ–è¯„ä¼°å’Œäººå·¥åˆ¤æ–­æ¥è¡¡é‡ï¼›
- è¿­ä»£æ”¹è¿›è¯„ä¼°ï¼Œä½¿å…¶æ›´è´´è¿‘äººå·¥åˆ¤æ–­çš„ç»“æœã€‚

æ­£å¦‚ AI é¢†åŸŸçš„è®¸å¤šäº‹ç‰©ä¸€æ ·ï¼Œæˆ‘ä»¬é€šå¸¸æ— æ³•ä¸€æ­¥åˆ°ä½ã€‚å› æ­¤ï¼Œæœ€å¥½æ˜¯å¿«é€Ÿæ„å»ºä¸€ä¸ªåˆå§‹çš„ç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œç„¶åé€šè¿‡è¿­ä»£æ¥ä¸æ–­å®Œå–„å®ƒã€‚æˆ‘ä»¬å·²ç»ä¹ æƒ¯äº†ç”¨è¿™ç§æ–¹æ³•æ¥æ„å»º AI ç³»ç»Ÿï¼ŒåŒæ ·åœ°ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨è¿™ç§æ–¹å¼æ¥æ„å»ºè¯„ä¼°ã€‚

åœ¨æˆ‘çœ‹æ¥ï¼Œä¸€ä¸ªæˆåŠŸçš„è¯„ä¼°åº”æ»¡è¶³ä»¥ä¸‹æ ‡å‡†ã€‚å‡è®¾æˆ‘ä»¬å½“å‰æœ‰ä¸€ä¸ªç³»ç»Ÿ Aï¼Œå¹¶ä¸”æˆ‘ä»¬å¯èƒ½å¯¹å…¶è¿›è¡Œè°ƒæ•´ä»¥å¾—åˆ°ç³»ç»Ÿ Bï¼š
- å¦‚æœæ ¹æ®ç»éªŒä¸°å¯Œçš„äººå·¥åˆ¤æ–­ï¼ŒA çš„æ€§èƒ½æ˜æ˜¾ä¼˜äº Bï¼Œé‚£ä¹ˆè¯„ä¼°åº”è¯¥ç»™äºˆ A æ˜æ˜¾é«˜äº B çš„åˆ†æ•°ã€‚
- å¦‚æœ A å’Œ B çš„æ€§èƒ½ç›¸ä¼¼ï¼Œé‚£ä¹ˆå®ƒä»¬çš„è¯„ä¼°åˆ†æ•°ä¹Ÿåº”è¯¥ç›¸ä¼¼ã€‚

æ¯å½“ç³»ç»Ÿ A å’Œ B çš„æ¯”è¾ƒç»“æœä¸è¿™äº›æ ‡å‡†ç›¸æ‚–æ—¶ï¼Œå°±è¡¨æ˜è¯„ä¼°å­˜åœ¨ã€Œé”™è¯¯ã€ã€‚æ­¤æ—¶æˆ‘ä»¬åº”è¯¥è°ƒæ•´è¯„ä¼°ï¼Œä½¿å…¶èƒ½å¤Ÿæ­£ç¡®åœ°å¯¹ A å’Œ B è¿›è¡Œæ’åã€‚è¿™ä¸æ„å»ºæœºå™¨å­¦ä¹ ç®—æ³•æ—¶çš„é”™è¯¯åˆ†æç†å¿µç›¸ä¼¼ï¼Œåªä¸è¿‡æˆ‘ä»¬å…³æ³¨çš„ä¸æ˜¯æœºå™¨å­¦ä¹ ç®—æ³•è¾“å‡ºçš„é”™è¯¯ â€”â€” æ¯”å¦‚å®ƒè¾“å‡ºäº†ä¸æ­£ç¡®çš„æ ‡ç­¾ â€”â€” è€Œæ˜¯è¯„ä¼°æœ¬èº«çš„ã€Œé”™è¯¯ã€â€”â€” æ¯”å¦‚å½“å®ƒä»¬é”™è¯¯åœ°å¯¹ä¸¤ä¸ªç³»ç»Ÿ A å’Œ B è¿›è¡Œæ’åï¼Œå¯¼è‡´è¯„ä¼°æ— æ³•å¸®åŠ©æˆ‘ä»¬åœ¨è¿™ä¸¤è€…ä¹‹é—´åšå‡ºé€‰æ‹©ã€‚

çº¯ç²¹ä¾èµ–äººå·¥åˆ¤æ–­æ˜¯å¯åŠ¨é¡¹ç›®çš„ä¸€ä¸ªå¾ˆå¥½çš„æ–¹å¼ã€‚ä½†å¯¹äºè®¸å¤šå›¢é˜Ÿæ¥è¯´ï¼Œå°†è¯„ä¼°ä½œä¸ºå¿«é€ŸåŸå‹è¿›è¡Œæ„å»ºå¹¶é€æ­¥è¿­ä»£è‡³æ›´æˆç†Ÿçš„ç‰ˆæœ¬ï¼Œå¯ä»¥å¸®åŠ©æ‚¨æ›´æ—©åœ°å¼•å…¥è¯„ä¼°ï¼Œå¹¶åŠ é€Ÿæ‚¨çš„é¡¹ç›®è¿›å±•ã€‚

[Original textï¼šhttps://t.co/V3BZe8sRWE]

### 061

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-23
é“¾æ¥: https://x.com/AndrewYNg/status/1915101920500564406
äº’åŠ¨: Likes: 1,260; Retweets: 229; Replies: 37; Quotes: 12; Views: 126,757; Bookmarks: 866; isReply: 0

New short course: Building Code Agents with Hugging Face smolagents!

Learn how to build code agents in this course, created in collaboration with @huggingface, and taught by @Thom_Wolf, its co-founder and CSO, and @AymericRoucher, Hugging Faceâ€™s Project Lead on Agents.

Tool-calling agents use LLMs to generate multiple function calls sequentially to complete a complex sequence of tasks. They generate one function call, execute it, observe, reason, and decide what to do next. Code agents take a different approach. They consolidate all these calls into a single block of code, letting the LLM lay out an entire action plan at once, which can be executed efficiently to provide more reliable results.

Youâ€™ll learn how to code agents using smolagents, a lightweight agentic framework from Hugging Face. Along the way, youâ€™ll learn how to run LLM-generated code safely and develop an evaluation system to optimize your code agent for production.

In detail, youâ€™ll learn:
- How agentic systems have evolved, gaining greater levels of agency over timeâ€”and why code agents are a next step.
- How code agents write their actions in code.
- When code agents outperform function-calling agents.
- How to run code agents safely in your system using a constrained Python interpreter and sandboxing using E2B.
- To trace, debug, and assess the code agent to optimize its behaviours for complex requests.
- How to build a research multi-agent system that can find information online and organize it into an interactive report.

By the end of this course, youâ€™ll know how to build and run code agents using smolagents, and deploy them safely with a structured evaluation system in your projects.

Please sign up here! https://t.co/grcy0rH9Hg

æ–°è¯¾ç¨‹ï¼šç”¨ Hugging Face smolagents æ„å»ºä»£ç  AI æ™ºèƒ½ä½“ï¼ˆAI Agent)ï¼

åœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºä»£ç  AI æ™ºèƒ½ä½“ã€‚æœ¬è¯¾ç¨‹ç”± @huggingface åˆä½œåˆ›å»ºï¼Œå¹¶ç”±å…¶è”åˆåˆ›å§‹äººå…¼é¦–å¸­æˆ˜ç•¥å®˜ï¼ˆCSOï¼‰@Thom_Wolf ä»¥åŠ Hugging Face AI æ™ºèƒ½ä½“é¡¹ç›®è´Ÿè´£äºº @AymericRoucher æˆè¯¾ã€‚

å·¥å…·è°ƒç”¨ AI æ™ºèƒ½ä½“åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¡ºåºç”Ÿæˆå¤šä¸ªå‡½æ•°è°ƒç”¨ï¼Œä»¥å®Œæˆä¸€ç³»åˆ—å¤æ‚çš„ä»»åŠ¡ã€‚å®ƒä»¬ä¼šç”Ÿæˆä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼Œæ‰§è¡Œå®ƒï¼Œè§‚å¯Ÿç»“æœï¼Œè¿›è¡Œæ¨ç†ï¼Œç„¶åå†³å®šä¸‹ä¸€æ­¥è¯¥æ€ä¹ˆåšã€‚è€Œä»£ç  AI æ™ºèƒ½ä½“åˆ™é‡‡å–äº†ä¸€ç§ä¸åŒçš„æ–¹æ³•ã€‚å®ƒä»¬å°†æ‰€æœ‰è¿™äº›è°ƒç”¨æ•´åˆåˆ°ä¸€ä¸ªå•ä¸€çš„ä»£ç å—ä¸­ï¼Œè®© LLM èƒ½å¤Ÿä¸€æ¬¡æ€§åˆ¶å®šå‡ºå®Œæ•´çš„è¡ŒåŠ¨è®¡åˆ’ï¼Œè¿™æ ·å¯ä»¥é«˜æ•ˆæ‰§è¡Œå¹¶æä¾›æ›´å¯é çš„ç»“æœã€‚

ä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Hugging Face çš„è½»é‡çº§ AI æ™ºèƒ½ä½“æ¡†æ¶ smolagents æ¥ç¼–å†™ä»£ç  AI æ™ºèƒ½ä½“ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•å®‰å…¨åœ°è¿è¡Œç”± LLM ç”Ÿæˆçš„ä»£ç ï¼Œå¹¶å¼€å‘ä¸€ä¸ªè¯„ä¼°ç³»ç»Ÿæ¥ä¼˜åŒ–ä½ çš„ä»£ç  AI æ™ºèƒ½ä½“ï¼Œä½¿å…¶é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†å­¦ä¹ ï¼š
- AI æ™ºèƒ½ä½“ç³»ç»Ÿå¦‚ä½•æ¼”å˜ï¼Œéšç€æ—¶é—´çš„æ¨ç§»è·å¾—æ›´é«˜æ°´å¹³çš„è‡ªä¸»æ€§ â€”â€” ä»¥åŠä¸ºä»€ä¹ˆä»£ç  AI æ™ºèƒ½ä½“æ˜¯ä¸‹ä¸€æ­¥å‘å±•æ–¹å‘ã€‚
- ä»£ç  AI æ™ºèƒ½ä½“å¦‚ä½•åœ¨ä»£ç ä¸­ç¼–å†™å…¶è¡ŒåŠ¨ã€‚
- ä»£ç  AI æ™ºèƒ½ä½“ä½•æ—¶ä¼šä¼˜äºå‡½æ•°è°ƒç”¨ AI æ™ºèƒ½ä½“ã€‚
- å¦‚ä½•åœ¨ä½ çš„ç³»ç»Ÿä¸­ä½¿ç”¨å—é™çš„ Python è§£é‡Šå™¨å¹¶é€šè¿‡ E2B è¿›è¡Œæ²™ç›’éš”ç¦»ï¼Œä»è€Œå®‰å…¨åœ°è¿è¡Œä»£ç  AI æ™ºèƒ½ä½“ã€‚
- è¿½è¸ªã€è°ƒè¯•å’Œè¯„ä¼°ä»£ç  AI æ™ºèƒ½ä½“ï¼Œä»¥ä¼˜åŒ–å…¶å¤„ç†å¤æ‚è¯·æ±‚æ—¶çš„è¡¨ç°ã€‚
- å¦‚ä½•æ„å»ºä¸€ä¸ªç ”ç©¶å‹å¤š AI æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿåœ¨çº¿æŸ¥æ‰¾ä¿¡æ¯å¹¶å°†å…¶ç»„ç»‡æˆäº¤äº’å¼æŠ¥å‘Šã€‚

åœ¨æœ¬è¯¾ç¨‹ç»“æŸæ—¶ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•ä½¿ç”¨ smolagents æ„å»ºå’Œè¿è¡Œä»£ç  AI æ™ºèƒ½ä½“ï¼Œå¹¶åˆ©ç”¨ç»“æ„åŒ–çš„è¯„ä¼°ç³»ç»Ÿå°†å…¶å®‰å…¨éƒ¨ç½²åˆ°ä½ çš„é¡¹ç›®ä¸­ã€‚

è¯·åœ¨æ­¤å¤„æŠ¥åï¼https://t.co/grcy0rH9Hg

### 062

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-04-24
é“¾æ¥: https://x.com/AndrewYNg/status/1915421117998874899
äº’åŠ¨: Likes: 3,341; Retweets: 472; Replies: 129; Quotes: 65; Views: 263,141; Bookmarks: 1,140; isReply: 0

Even though Iâ€™m a much better Python than JavaScript developer, with AI assistance, Iâ€™ve been writing a lot of JavaScript code recently. AI-assisted coding, including vibe coding, is making specific programming languages less important, even though learning one is still helpful to make sure you understand the key concepts. This is helping many developers write code in languages weâ€™re not familiar with, which lets us get code working in many more contexts!

My background is in machine learning engineering and back-end development, but AI-assisted coding is making it easy for me to build front-end systems (the part of a website or app that users interact with) using JavaScript (JS) or TypeScript (TS), languages that I am weak in. Generative AI is making syntax less important, so we can all simultaneously be Python, JS, TS, C++, Java, and even Cobol developers. Perhaps one day, instead of being â€œPython developers" or â€œC++ developers,â€ many more of us will just be â€œdevelopersâ€!

But understanding the concepts behind different languages is still important. Thatâ€™s why learning at least one language like Python still offers a great foundation for prompting LLMs to generate code in Python and other languages. If you move from one programming language to another that carries out similar tasks but with different syntax â€” say, from JS to TS, or C++ to Java, or Rust to Go â€” once youâ€™ve learned the first set of concepts, youâ€™ll know a lot of the concepts needed to prompt an LLM to code in the second language. (Although TensorFlow and PyTorch are not programming languages, learning the concepts of deep learning behind TensorFlow will also make it much easier to get an LLM to write PyTorch code for you, and vice versa!)  In addition, youâ€™ll be able to understand much of the generated code (perhaps with a little LLM assistance).

Different programming languages reflect different views of how to organize computation, and understanding the concepts is still important. For example, someone who does not understand arrays, dictionaries, caches, and memory will be less effective at getting an LLM to write code in most languages.

Similarly, a Python developer who moves toward doing more front-end programming with JS would benefit from learning the concepts behind front-end systems. For example, if you want an LLM to build a front end using the React framework, it will benefit you to understand how React breaks front ends into reusable UI components, and how it updates the DOM data structure that determines what web pages look like. This lets you prompt the LLM much more precisely, and helps you understand how to fix issues if something goes wrong. Similarly, if you want an LLM to help you write code in CUDA or ROCm, it helps to understand how GPUs organize compute and memory.

Just as people who are fluent in multiple human languages can communicate more easily with other people, LLMs are making it easier for developers to build systems in multiple contexts. If you havenâ€™t already done so, I encourage you to try having an LLM write some code in a language youâ€™d like to learn but perhaps havenâ€™t yet gotten around to, and see if it helps you get some new applications to work.

[Original text: https://t.co/NdjaPgwwuk ]

å°½ç®¡æˆ‘æ˜¯ä¸€ä¸ªæ¯” JavaScript å¼€å‘è€…æ›´æ“…é•¿ Python çš„äººï¼Œä½†åœ¨ AI è¾…åŠ©ä¸‹ï¼Œæˆ‘æœ€è¿‘ç¼–å†™äº†å¤§é‡ JavaScript ä»£ç ã€‚AI è¾…åŠ©ç¼–ç¨‹ï¼ŒåŒ…æ‹¬éšå¿ƒæ‰€æ¬²çš„ç¼–ç ï¼ˆvibe codingï¼‰ï¼Œæ­£åœ¨é™ä½ç‰¹å®šç¼–ç¨‹è¯­è¨€çš„é‡è¦æ€§ã€‚å½“ç„¶ï¼Œå­¦ä¹ ä¸€é—¨è¯­è¨€ä»æœ‰åŠ©äºæˆ‘ä»¬ç†è§£æ ¸å¿ƒæ¦‚å¿µã€‚è¿™ç§æ–¹å¼æ­£åœ¨å¸®åŠ©è®¸å¤šå¼€å‘è€…ä½¿ç”¨æˆ‘ä»¬ä¸ç†Ÿæ‚‰çš„è¯­è¨€ç¼–å†™ä»£ç ï¼Œä»è€Œè®©æˆ‘ä»¬èƒ½å¤Ÿåœ¨æ›´å¤šåœºæ™¯ä¸­å®ç°ä»£ç åŠŸèƒ½ï¼

æˆ‘çš„ä¸“ä¸šèƒŒæ™¯æ˜¯æœºå™¨å­¦ä¹ å·¥ç¨‹å’Œåç«¯å¼€å‘ï¼Œä½† AI è¾…åŠ©ç¼–ç¨‹è®©æˆ‘èƒ½å¤Ÿè½»æ¾åœ°ä½¿ç”¨ JavaScriptï¼ˆJSï¼‰æˆ– TypeScriptï¼ˆTSï¼‰è¿™äº›æˆ‘å¹¶ä¸æ“…é•¿çš„è¯­è¨€æ¥æ„å»ºå‰ç«¯ç³»ç»Ÿï¼ˆç”¨æˆ·ä¸ç½‘ç«™æˆ–åº”ç”¨ç¨‹åºäº¤äº’çš„éƒ¨åˆ†ï¼‰ã€‚ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰æ­£åœ¨è®©è¯­æ³•å˜å¾—ä¸å†é‚£ä¹ˆé‡è¦ï¼Œæ‰€ä»¥æˆ‘ä»¬æ‰€æœ‰äººéƒ½å¯ä»¥åŒæ—¶æˆä¸º Pythonã€JSã€TSã€C++ã€Javaï¼Œç”šè‡³æ˜¯ Cobol å¼€å‘è€…ã€‚æˆ–è®¸æœ‰ä¸€å¤©ï¼Œæˆ‘ä»¬ä¸­çš„è®¸å¤šäººå°†ä¸å†è¢«å®šä¹‰ä¸ºã€ŒPython å¼€å‘è€…ã€æˆ–ã€ŒC++ å¼€å‘è€…ã€ï¼Œè€Œåªæ˜¯å•çº¯çš„ã€Œå¼€å‘è€…ã€ï¼

ç„¶è€Œï¼Œç†è§£ä¸åŒè¯­è¨€èƒŒåçš„æ ¸å¿ƒæ¦‚å¿µä¾ç„¶è‡³å…³é‡è¦ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå­¦ä¹ è‡³å°‘ä¸€é—¨åƒ Python è¿™æ ·çš„è¯­è¨€ï¼Œä»ç„¶èƒ½ä¸ºæˆ‘ä»¬æä¾›ä¸€ä¸ªåšå®çš„åŸºç¡€ï¼Œä»¥ä¾¿æç¤ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆ Python å’Œå…¶ä»–è¯­è¨€çš„ä»£ç ã€‚å¦‚æœä½ ä»ä¸€ç§ç¼–ç¨‹è¯­è¨€è½¬å‘å¦ä¸€ç§æ‰§è¡Œç±»ä¼¼ä»»åŠ¡ä½†è¯­æ³•ä¸åŒçš„è¯­è¨€ â€”â€” æ¯”å¦‚ä» JS åˆ° TSï¼Œæˆ–ä» C++ åˆ° Javaï¼Œå†æˆ–ä» Rust åˆ° Goâ€”â€” ä¸€æ—¦ä½ æŒæ¡äº†ç¬¬ä¸€ç§è¯­è¨€çš„æ¦‚å¿µï¼Œä½ å°±å·²ç»äº†è§£äº†è®¸å¤šæç¤ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”¨ç¬¬äºŒç§è¯­è¨€è¿›è¡Œç¼–ç æ‰€éœ€çš„å…³é”®æ¦‚å¿µã€‚ï¼ˆè™½ç„¶ TensorFlow å’Œ PyTorch å¹¶éç¼–ç¨‹è¯­è¨€ï¼Œä½†ç†è§£ TensorFlow èƒŒåçš„æ·±åº¦å­¦ä¹ æ¦‚å¿µï¼Œä¹Ÿä¼šè®©ä½ æ›´å®¹æ˜“è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºä½ ç¼–å†™ PyTorch ä»£ç ï¼Œåä¹‹äº¦ç„¶ï¼ï¼‰æ­¤å¤–ï¼Œä½ è¿˜èƒ½ç†è§£å¤§éƒ¨åˆ†ç”Ÿæˆçš„ä»£ç ï¼ˆæˆ–è®¸åªéœ€è¦ä¸€ç‚¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ååŠ©ï¼‰ã€‚

ä¸åŒçš„ç¼–ç¨‹è¯­è¨€åæ˜ äº†ç»„ç»‡è®¡ç®—çš„ä¸åŒæ€è·¯ï¼Œå› æ­¤ç†è§£è¿™äº›æ¦‚å¿µä»ç„¶å¾ˆé‡è¦ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªä¸ç†è§£æ•°ç»„ï¼ˆarraysï¼‰ã€å­—å…¸ï¼ˆdictionariesï¼‰ã€ç¼“å­˜ï¼ˆcachesï¼‰å’Œå†…å­˜ï¼ˆmemoryï¼‰çš„äººï¼Œåœ¨è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç¼–å†™å¤§å¤šæ•°è¯­è¨€ä»£ç æ—¶ï¼Œæ•ˆç‡ä¼šè¾ƒä½ã€‚

åŒæ ·ï¼Œä¸€ä¸ªè½¬å‘æ›´å¤šä½¿ç”¨ JS è¿›è¡Œå‰ç«¯ç¼–ç¨‹çš„ Python å¼€å‘è€…ï¼Œå°†å—ç›Šäºå­¦ä¹ å‰ç«¯ç³»ç»ŸèƒŒåçš„æ¦‚å¿µã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ å¸Œæœ›å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½¿ç”¨ React æ¡†æ¶æ„å»ºå‰ç«¯ï¼Œé‚£ä¹ˆç†è§£ React å¦‚ä½•å°†å‰ç«¯åˆ†è§£ä¸ºå¯é‡ç”¨çš„ UI ç»„ä»¶ï¼Œä»¥åŠå®ƒå¦‚ä½•æ›´æ–°å†³å®šç½‘é¡µå¤–è§‚çš„ DOMï¼ˆDocument Object Modelï¼‰æ•°æ®ç»“æ„ï¼Œå°†å¯¹ä½ å¤§æœ‰è£¨ç›Šã€‚è¿™èƒ½è®©ä½ æ›´ç²¾ç¡®åœ°æç¤ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶æœ‰åŠ©äºä½ åœ¨å‡ºç°é—®é¢˜æ—¶ç†è§£å¦‚ä½•ä¿®å¤ã€‚åŒç†ï¼Œå¦‚æœä½ æƒ³è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¸®åŠ©ä½ ç¼–å†™ CUDA æˆ– ROCm ä»£ç ï¼Œäº†è§£ GPU å¦‚ä½•ç»„ç»‡è®¡ç®—å’Œå†…å­˜ä¼šæœ‰å¾ˆå¤§å¸®åŠ©ã€‚

æ­£å¦‚ç²¾é€šå¤šç§äººç±»è¯­è¨€çš„äººèƒ½æ›´è½»æ¾åœ°ä¸ä»–äººäº¤æµä¸€æ ·ï¼Œ å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨è®©å¼€å‘è€…æ›´å®¹æ˜“åœ¨å¤šç§åº”ç”¨åœºæ™¯ä¸­æ„å»ºç³»ç»Ÿã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å°è¯•è¿‡ï¼Œæˆ‘é¼“åŠ±ä½ è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLLï¼‰ç”¨ä½ å¸Œæœ›å­¦ä¹ ä½†å¯èƒ½å°šæœªæ¶‰è¶³çš„è¯­è¨€ç¼–å†™ä¸€äº›ä»£ç ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦èƒ½å¸®åŠ©ä½ æˆåŠŸå¼€å‘å‡ºä¸€äº›æ–°çš„åº”ç”¨ç¨‹åºã€‚

[Original textï¼šhttps://t.co/NdjaPgwwuk]

### 063

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-01
é“¾æ¥: https://x.com/AndrewYNg/status/1917985792607363189
äº’åŠ¨: Likes: 786; Retweets: 122; Replies: 47; Quotes: 15; Views: 80,764; Bookmarks: 299; isReply: 0

I hope we can empower everyone to build with AI. Starting from K-12, we should teach every student AI enabled coding, since this will enable them to become more productive and more empowered adults. But there is a huge shortage of computer science (CS) teachers. I recently spoke with high school basketball coach Kyle Creasy, who graduated with a B.A. in Physical Education in 2023. Until two years ago, he had never written a line of Python. Now â€” with help from AI â€” he not only writes code, he also teaches CS. I found Kyleâ€™s story inspiring as a model for scaling up CS education in the primary- and secondary-school levels.

Kyleâ€™s success has been with the support of Kira Learning (an AI Fund portfolio company), whose founders Andrea Pasinetti and Jagriti Agrawal have created a compelling vision for CS education. In K-12 classrooms, teachers play a huge social-emotional support role, for example, encouraging students and helping them when they stumble. In addition, they are expected to be subject-matter experts who can deliver the content needed for their subject. Kira Learning uses digital content delivery â€” educational videos, autograded quizzes, and AI-enabled chatbots to answer students' questions but without giving away homework answers â€” so the teacher can focus on social-emotional support. While these are still early days, it appears to be working!

A key to making this possible is the hyperpersonalization that is now possible with AI (in contrast to the older idea of the flipped classroom, which had limited adoption). For example, when assigned a problem in an online coding environment, if a student writes this buggy line of Python code

best_$alty_snack = 'potato chips'

Kira Learningâ€™s AI system can spot the problem and directly tell the teacher that $ is an invalid character in a variable name. It can also suggest a specific question for the teacher to ask the student to help get them unstuck, like â€œCan you identify what characters are allowed in variable names?â€ Whereas AI can directly deliver personalized advice to students, the fact that it is now helping teachers also deliver personalized support will really help in K-12.

Additionally, agentic workflows can automate a lot of teachersâ€™ repetitive tasks. For example, when designing a curriculum, itâ€™s time-consuming to align the content to educational standards (such as the Common Core in the United States, or the AP CS standard for many CS classes). Having an AI system carry out tasks like these is already proving helpful for teachers.

Since learning to code, Kyle has built many pieces of software. He proudly showed me an analysis he generated in matplotlib of his basketball playersâ€™ attempts to shoot three-pointers (shown above), which in turn is affecting the teamâ€™s strategy on the court. One lesson is clear: When a basketball coach learns to code, they become a better basketball coach!

I talked about Kyle (and other topics) at the ASU+GSV Summit on education. You can see a video online.

In the future, people who know how to code and build with AI will be much more productive than people who donâ€™t. Iâ€™m excited about how AI will lead to new models for K-12 education. By delivering CS education to everyone, I hope that in the future, everyone will be able to build with AI.

[Original text: https://t.co/F4xAhwfHaU ]

æˆ‘å¸Œæœ›æˆ‘ä»¬èƒ½è®©æ¯ä¸ªäººéƒ½èƒ½åˆ©ç”¨ AI è¿›è¡Œå¼€å‘ã€‚ä» K-12 æ•™è‚²é˜¶æ®µå¼€å§‹ï¼Œæˆ‘ä»¬åº”è¯¥æ•™å¯¼æ¯ä¸€ä½å­¦ç”Ÿèå…¥ AI çš„ç¼–ç¨‹æŠ€èƒ½ï¼Œå› ä¸ºè¿™å°†ä½¿ä»–ä»¬æˆé•¿ä¸ºæ›´é«˜æ•ˆã€æ›´æœ‰èƒ½åŠ›çš„äººã€‚ç„¶è€Œï¼Œè®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰æ•™å¸ˆçš„ç¼ºå£å·¨å¤§ã€‚æˆ‘æœ€è¿‘ä¸é«˜ä¸­ç¯®çƒæ•™ç»ƒ Kyle Creasy äº¤æµï¼Œä»–äº 2023 å¹´æ¯•ä¸šï¼Œè·å¾—äº†ä½“è‚²æ•™è‚²å­¦å£«å­¦ä½ã€‚ç›´åˆ°ä¸¤å¹´å‰ï¼Œä»–ä»æœªå†™è¿‡ä¸€è¡Œ Python ä»£ç ã€‚ç°åœ¨ â€”â€” åœ¨ AI çš„å¸®åŠ©ä¸‹ â€”â€” ä»–ä¸ä»…ä¼šç¼–å†™ä»£ç ï¼Œè¿˜æ•™æˆè®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰ã€‚Kyle çš„æ•…äº‹ä»¤æˆ‘æ·±å—å¯å‘ï¼Œå®ƒä¸ºåœ¨å°å­¦å’Œä¸­å­¦é˜¶æ®µæ¨å¹¿ CS æ•™è‚²æä¾›äº†ä¸€ä¸ªå¯è¡Œçš„æ¨¡å¼ã€‚

Kyle çš„æˆåŠŸå¾—åˆ°äº† Kira Learningï¼ˆä¸€å®¶ç”± AI Fund æŠ•èµ„çš„å…¬å¸ï¼‰çš„æ”¯æŒï¼Œå…¶åˆ›å§‹äºº Andrea Pasinetti å’Œ Jagriti Agrawal ä¸º CS æ•™è‚²æç»˜äº†ä¸€ä¸ªä»¤äººæŒ¯å¥‹çš„æ„¿æ™¯ã€‚åœ¨ K-12 è¯¾å ‚ä¸Šï¼Œæ•™å¸ˆæ‰®æ¼”ç€é‡è¦çš„ç¤¾ä¼šæƒ…æ„Ÿæ”¯æŒè§’è‰²ï¼Œä¾‹å¦‚ï¼Œé¼“åŠ±å­¦ç”Ÿå¹¶åœ¨ä»–ä»¬é‡åˆ°å›°éš¾æ—¶ä¼¸å‡ºæ´æ‰‹ã€‚æ­¤å¤–ï¼Œä»–ä»¬è¿˜è¢«æœŸæœ›æˆä¸ºèƒ½å¤Ÿä¼ æˆå…¶å­¦ç§‘æ‰€éœ€å†…å®¹çš„å­¦ç§‘ä¸“å®¶ã€‚Kira Learning é‡‡ç”¨æ•°å­—åŒ–çš„æ•™å­¦å†…å®¹å‘ˆç°æ–¹å¼ â€”â€” åŒ…æ‹¬æ•™è‚²è§†é¢‘ã€è‡ªåŠ¨è¯„åˆ†çš„æµ‹éªŒå’Œé›†æˆ AI çš„èŠå¤©æœºå™¨äººæ¥å›ç­”å­¦ç”Ÿé—®é¢˜ï¼ˆä½†ä¸ä¼šç›´æ¥ç»™å‡ºå®¶åº­ä½œä¸šç­”æ¡ˆï¼‰â€”â€” è¿™æ ·æ•™å¸ˆå°±å¯ä»¥æŠŠæ›´å¤šç²¾åŠ›æ”¾åœ¨ç¤¾ä¼šæƒ…æ„Ÿæ”¯æŒä¸Šã€‚å°½ç®¡è¿™ä»å¤„äºèµ·æ­¥é˜¶æ®µï¼Œä½†ä¼¼ä¹å·²ç»å“æœ‰æˆæ•ˆï¼

å®ç°è¿™ä¸€ç›®æ ‡çš„å…³é”®åœ¨äº AI å¦‚ä»Šèƒ½å¤Ÿå®ç°çš„è¶…ä¸ªæ€§åŒ–ï¼ˆè¿™ä¸è¿‡å»é‡‡ç”¨æœ‰é™çš„ç¿»è½¬è¯¾å ‚ç†å¿µå½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼‰ã€‚ä¾‹å¦‚ï¼Œå½“å­¦ç”Ÿåœ¨åœ¨çº¿ç¼–ç¨‹ç¯å¢ƒä¸­é‡åˆ°é—®é¢˜æ—¶ï¼Œå¦‚æœä»–ä»¬å†™äº†è¿™æ ·ä¸€è¡Œæœ‰é”™è¯¯çš„ Python ä»£ç ï¼š

best_$alty_snack = 'potato chips'

Kira Learning çš„ AI ç³»ç»Ÿèƒ½ç«‹å³å‘ç°é—®é¢˜ï¼Œå¹¶ç›´æ¥å‘Šè¯‰æ•™å¸ˆï¼Œç¾å…ƒç¬¦å· $ åœ¨å˜é‡åä¸­æ˜¯æ— æ•ˆå­—ç¬¦ã€‚å®ƒè¿˜å¯ä»¥ä¸ºæ•™å¸ˆæä¾›ä¸€ä¸ªå…·ä½“çš„é—®é¢˜ï¼Œå¼•å¯¼å­¦ç”Ÿæ€è€ƒä»è€Œæ‘†è„±å›°å¢ƒï¼Œæ¯”å¦‚ã€Œä½ èƒ½è¯´å‡ºå˜é‡åä¸­å…è®¸ä½¿ç”¨å“ªäº›å­—ç¬¦å—ï¼Ÿã€é‰´äº AI èƒ½å¤Ÿç›´æ¥å‘å­¦ç”Ÿæä¾›ä¸ªæ€§åŒ–å»ºè®®ï¼Œå®ƒç°åœ¨ä¹Ÿèƒ½å¸®åŠ©æ•™å¸ˆæä¾›ä¸ªæ€§åŒ–æ”¯æŒï¼Œè¿™æ— ç–‘å°†æå¤§åœ°æ¨åŠ¨ K-12 æ•™è‚²çš„å‘å±•ã€‚

æ­¤å¤–ï¼Œæ™ºèƒ½ä½“å·¥ä½œæµï¼ˆagentic workflowsï¼‰èƒ½å¤Ÿè‡ªåŠ¨åŒ–æ•™å¸ˆçš„è®¸å¤šé‡å¤æ€§ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨è®¾è®¡è¯¾ç¨‹æ—¶ï¼Œå°†å†…å®¹ä¸æ•™è‚²æ ‡å‡†ï¼ˆä¾‹å¦‚ç¾å›½çš„ Common Core æˆ–è®¸å¤š CS è¯¾ç¨‹çš„ AP CS æ ‡å‡†ï¼‰å¯¹é½æ˜¯éå¸¸è€—æ—¶çš„ã€‚è®© AI ç³»ç»Ÿæ¥æ‰§è¡Œè¿™ç±»ä»»åŠ¡å·²ç»è¯æ˜å¯¹æ•™å¸ˆå¤§æœ‰è£¨ç›Šã€‚

è‡ªä»å­¦ä¼šç¼–ç¨‹ä»¥æ¥ï¼ŒKyle å·²ç»å¼€å‘äº†è®¸å¤šè½¯ä»¶ã€‚ä»–è‡ªè±ªåœ°ç»™æˆ‘çœ‹ä»–ç”¨ matplotlib å·¥å…·ç”Ÿæˆçš„ä¸€ä»½åˆ†ææŠ¥å‘Šï¼Œå†…å®¹æ˜¯å…³äºä»–çš„ç¯®çƒé˜Ÿå‘˜ä¸‰åˆ†çƒæŠ•ç¯®å°è¯•çš„ï¼ˆå¦‚ä¸Šå›¾æ‰€ç¤ºï¼‰ï¼Œè¿™ä»½åˆ†ææŠ¥å‘Šåè¿‡æ¥ä¹Ÿå½±å“äº†çƒé˜Ÿåœ¨åœºä¸Šçš„ç­–ç•¥ã€‚ä¸€ä¸ªæ¸…æ™°çš„å¯ç¤ºæ˜¯ï¼šå½“ä¸€ä½ç¯®çƒæ•™ç»ƒå­¦ä¼šç¼–ç¨‹æ—¶ï¼Œä»–ä»¬å°±æˆä¸ºäº†ä¸€åæ›´å‡ºè‰²çš„ç¯®çƒæ•™ç»ƒï¼

æˆ‘åœ¨ ASU+GSV æ•™è‚²å³°ä¼šä¸Šè°ˆåˆ°äº† Kyleï¼ˆä»¥åŠå…¶ä»–è¯é¢˜ï¼‰ã€‚æ‚¨å¯ä»¥åœ¨çº¿è§‚çœ‹ç›¸å…³è§†é¢‘ã€‚

åœ¨æœªæ¥ï¼Œæ‡‚å¾—å¦‚ä½•ç¼–å†™ä»£ç å¹¶åˆ©ç”¨ AI è¿›è¡Œå¼€å‘çš„äººï¼Œå°†æ¯”é‚£äº›ä¸å…·å¤‡è¿™äº›æŠ€èƒ½çš„äººç”Ÿäº§åŠ›é«˜å¾—å¤šã€‚æˆ‘å¯¹ AI å°†å¦‚ä½•å¼€åˆ› K-12 æ•™è‚²çš„æ–°æ¨¡å¼å……æ»¡æœŸå¾…ã€‚é€šè¿‡å‘æ‰€æœ‰äººæä¾›è®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰æ•™è‚²ï¼Œæˆ‘å¸Œæœ›æœªæ¥æ¯ä¸ªäººéƒ½èƒ½åˆ©ç”¨ AI è¿›è¡Œå¼€å‘ã€‚

[åŸå§‹æ–‡æœ¬ï¼šhttps://t.co/F4xAhwfHaU]

### 064

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-01
é“¾æ¥: https://x.com/AndrewYNg/status/1917986064851255658
äº’åŠ¨: Likes: 102; Retweets: 21; Replies: 3; Quotes: 1; Views: 55,903; Bookmarks: 49; isReply: 1

Video of the talk: https://t.co/C5OB2qm7OP

æœ¬æ¬¡è®²åº§çš„è§†é¢‘ï¼šhttps://t.co/C5OB2qm7OP

### 065

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-04
é“¾æ¥: https://x.com/AndrewYNg/status/1918839960880529641
äº’åŠ¨: Likes: 1,090; Retweets: 105; Replies: 38; Quotes: 10; Views: 116,363; Bookmarks: 132; isReply: 0

In addition to being a great investor, @WarrenBuffett has also been a great teacher, and I'm grateful to have learned a lot from him. For example, one concept I refer to frequently at @AI_Fund is the Circle of Competence, meaning we figure out what we're good at and what we're not, and act accordingly. His stepping down from Berkshire Hathaway will be the end of an era!

é™¤äº†æ˜¯ä¸€ä½æ°å‡ºçš„æŠ•èµ„è€…ï¼Œ@WarrenBuffett æ›´æ˜¯ä¸€ä½ä¼Ÿå¤§çš„è€å¸ˆï¼Œæˆ‘éå¸¸æ„Ÿæ¿€èƒ½ä»ä»–é‚£é‡Œå­¦åˆ°å¾ˆå¤šã€‚ä¾‹å¦‚ï¼Œæˆ‘åœ¨ @AI_Fund ç»å¸¸æåˆ°çš„ä¸€ä¸ªæ¦‚å¿µæ˜¯èƒ½åŠ›åœˆï¼ˆCircle of Competenceï¼‰ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬è¦å¼„æ¸…æ¥šè‡ªå·±æ“…é•¿ä»€ä¹ˆã€ä¸æ“…é•¿ä»€ä¹ˆï¼Œå¹¶æ®æ­¤é‡‡å–è¡ŒåŠ¨ã€‚ä»–ä» Berkshire Hathaway å¸ä»»ï¼Œå°†æ ‡å¿—ç€ä¸€ä¸ªæ—¶ä»£çš„ç»ˆç»“ï¼

### 066

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-07
é“¾æ¥: https://x.com/AndrewYNg/status/1920161212312268988
äº’åŠ¨: Likes: 926; Retweets: 163; Replies: 40; Quotes: 11; Views: 86,272; Bookmarks: 652; isReply: 0

Learn to build conversational AI voice agents in "Building AI Voice Agents for Production", created in collaboration with @livekit and @realavatarai, and taught by @dsa (Co-founder & CEO of LiveKit), @shayneparlo (Developer Advocate, LiveKit), and @nedteneva (Head of AI at RealAvatar, an AI Fund portfolio company).

Voice agents combine speech and reasoning capabilities to enable real-time conversations. They're already being used to support customer service, to improve accessibility in healthcare, for entertainment applications, and for talk therapy.

In this course, youâ€™ll learn to build voice agents that listen, reason, and respond naturally. Youâ€™ll follow the architecture used to create the "AI Andrew" Avatar, a collaborative project between https://t.co/zpIxRSuky4 and RealAvatar that responds to users in what sounds like my voice. Youâ€™ll build a voice agent from scratch and deploy it to the cloud, enabling support for many simultaneous users.

What youâ€™ll learn:
- Understand the fundamentals of voice agents, including key components like speech-to-text (STT), text-to-speech (TTS), and LLMs, and how latency is introduced at each layer.
- Explore voice agent architectures and the trade-offs between modular pipelines and speech-to-speech APIs.
- Explore how platforms like LiveKit mitigate latency issues with optimized networking infrastructure and low-latency communication protocols.
- Learn how to connect client devices to voice agents using WebRTCâ€”and why it outperforms HTTP and WebSocket for low-latency audio streaming.
- Incorporate voice activity detection (VAD), end-of-turn detection, and context management to detect turns, handle interruptions, and manage conversational flow.
- Understand the trade-offs between latency, quality, and cost in an example in which you build a voice agent and change its voice.
- Equip your agent with metrics to measure latency at each stage of the voice pipeline and learn the key levers you can pull to make your agent faster and more responsive.

The voice agents built in this course also incorporate voice technology from @elevenlabsio, a supporting contributor to the project.

By the end of this course, you'll have learned the components of an AI voice agent pipeline, combined them into a system with low-latency communication, and deployed them on cloud infrastructure so it scales to many users.

Iâ€™m looking forward to seeing what voice agents you build from this course!

Please sign up here: https://t.co/Offr7rPtDC

åœ¨ã€Œæ„å»ºç”¨äºç”Ÿäº§ç¯å¢ƒçš„ AI è¯­éŸ³æ™ºèƒ½ä½“ï¼ˆBuilding AI Voice Agents for Productionï¼‰ã€è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºå¯¹è¯å¼ AI è¯­éŸ³æ™ºèƒ½ä½“ã€‚æœ¬è¯¾ç¨‹ç”± @livekit å’Œ @realavatarai åˆä½œæ‰“é€ ï¼Œå¹¶ç”± LiveKit è”åˆåˆ›å§‹äººå…¼ CEO @dsaã€LiveKit å¼€å‘è€…å€¡å¯¼è€… @shayneparloï¼Œä»¥åŠ AI Fund æŠ•èµ„ç»„åˆå…¬å¸ RealAvatar çš„ AI è´Ÿè´£äºº @nedteneva å…±åŒæˆè¯¾ã€‚

è¯­éŸ³æ™ºèƒ½ä½“ï¼ˆVoice Agentï¼‰ç»“åˆäº†è¯­éŸ³å’Œæ¨ç†èƒ½åŠ›ï¼Œèƒ½å®ç°å®æ—¶å¯¹è¯ã€‚å®ƒä»¬å·²è¢«å¹¿æ³›åº”ç”¨äºå®¢æˆ·æœåŠ¡æ”¯æŒã€æå‡åŒ»ç–—ä¿å¥çš„å¯è®¿é—®æ€§ã€å„ç±»å¨±ä¹åº”ç”¨ä»¥åŠè°ˆè¯ç–—æ³•ç­‰é¢†åŸŸã€‚

é€šè¿‡æœ¬è¯¾ç¨‹ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºèƒ½å¤Ÿè‡ªç„¶åœ°å¬æ‡‚ã€æ€è€ƒå¹¶åšå‡ºå›åº”çš„è¯­éŸ³æ™ºèƒ½ä½“ã€‚ä½ å°†æ²¿ç”¨åˆ›å»ºã€ŒAI Andrewã€Avatar æ‰€é‡‡ç”¨çš„æ¶æ„ï¼Œè¿™æ˜¯ https://t.co/zpIxRSuky4 å’Œ RealAvatar ä¹‹é—´çš„ä¸€ä¸ªåˆä½œé¡¹ç›®ï¼Œå®ƒèƒ½ä»¥ä¸æˆ‘æœ¬äººç›¸ä¼¼çš„å£°éŸ³å›åº”ç”¨æˆ·ã€‚ä½ å°†ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªè¯­éŸ³æ™ºèƒ½ä½“ï¼Œå¹¶å°†å…¶éƒ¨ç½²åˆ°äº‘ç«¯ï¼Œä½¿å…¶èƒ½å¤Ÿæ”¯æŒå¤§é‡çš„å¹¶å‘ç”¨æˆ·ã€‚

ä½ å°†å­¦åˆ°ä»€ä¹ˆï¼š
- äº†è§£è¯­éŸ³æ™ºèƒ½ä½“çš„åŸºæœ¬åŸç†ï¼ŒåŒ…æ‹¬è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSTTï¼‰ã€æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç­‰æ ¸å¿ƒç»„ä»¶ï¼Œä»¥åŠæ¯ä¸ªç¯èŠ‚ä¸­å¯èƒ½å¼•å…¥çš„å»¶è¿Ÿã€‚
- æ¢ç´¢ä¸åŒçš„è¯­éŸ³æ™ºèƒ½ä½“æ¶æ„ï¼Œå¹¶æƒè¡¡æ¨¡å—åŒ–ç®¡é“ä¸è¯­éŸ³åˆ°è¯­éŸ³ API ä¹‹é—´çš„ä¼˜åŠ£ã€‚
- äº†è§£ LiveKit ç­‰å¹³å°å¦‚ä½•é€šè¿‡ä¼˜åŒ–çš„ç½‘ç»œåŸºç¡€è®¾æ–½å’Œä½å»¶è¿Ÿé€šä¿¡åè®®æ¥ç¼“è§£å»¶è¿Ÿé—®é¢˜ã€‚
- å­¦ä¹ å¦‚ä½•ä½¿ç”¨ WebRTC å°†å®¢æˆ·ç«¯è®¾å¤‡è¿æ¥åˆ°è¯­éŸ³æ™ºèƒ½ä½“ï¼Œä»¥åŠä¸ºä»€ä¹ˆå®ƒåœ¨ä½å»¶è¿ŸéŸ³é¢‘æµæ–¹é¢ä¼˜äº HTTP å’Œ WebSocketã€‚
- æŒæ¡å¦‚ä½•ç»“åˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰ã€å›åˆç»“æŸæ£€æµ‹å’Œä¸Šä¸‹æ–‡ç®¡ç†ï¼Œä»è€Œå‡†ç¡®è¯†åˆ«å¯¹è¯è½®æ¬¡ã€æœ‰æ•ˆå¤„ç†ä¸­æ–­å¹¶ç®¡ç†ä¼šè¯æµç¨‹ã€‚
- é€šè¿‡ä¸€ä¸ªç¤ºä¾‹ï¼Œäº†è§£åœ¨æ„å»ºå’Œæ”¹å˜è¯­éŸ³æ™ºèƒ½ä½“å£°éŸ³æ—¶ï¼Œå»¶è¿Ÿã€éŸ³è´¨å’Œæˆæœ¬ä¹‹é—´å­˜åœ¨çš„æƒè¡¡å…³ç³»ã€‚
- ä¸ºä½ çš„æ™ºèƒ½ä½“æ·»åŠ è¡¡é‡æŒ‡æ ‡ï¼Œä»¥ç›‘æµ‹è¯­éŸ³å¤„ç†ç®¡é“ï¼ˆvoice pipelineï¼‰å„é˜¶æ®µçš„å»¶è¿Ÿï¼Œå¹¶å­¦ä¹ å¯è°ƒæ•´çš„å…³é”®å› ç´ ï¼Œä»è€Œè®©ä½ çš„æ™ºèƒ½ä½“æ›´å¿«ã€å“åº”æ›´çµæ•ã€‚

æœ¬è¯¾ç¨‹ä¸­æ„å»ºçš„è¯­éŸ³æ™ºèƒ½ä½“è¿˜èå…¥äº†æ¥è‡ª @elevenlabsio çš„è¯­éŸ³æŠ€æœ¯ï¼Œè¯¥å…¬å¸æ˜¯æ­¤é¡¹ç›®çš„é‡è¦è´¡çŒ®è€…ã€‚

åˆ°æœ¬è¯¾ç¨‹ç»“æŸæ—¶ï¼Œä½ å°†æŒæ¡ AI è¯­éŸ³æ™ºèƒ½ä½“ç®¡é“çš„å„ä¸ªç»„ä»¶ï¼Œèƒ½å¤Ÿå°†å®ƒä»¬ç»„åˆæˆä¸€ä¸ªå…·æœ‰ä½å»¶è¿Ÿé€šä¿¡çš„ç³»ç»Ÿï¼Œå¹¶å°†å…¶éƒ¨ç½²åˆ°äº‘åŸºç¡€è®¾æ–½ä¸Šï¼Œä»¥æ”¯æŒå¤§è§„æ¨¡ç”¨æˆ·ã€‚

æˆ‘éå¸¸æœŸå¾…çœ‹åˆ°ä½ ä»¬é€šè¿‡æœ¬è¯¾ç¨‹æ„å»ºå‡ºçš„è¯­éŸ³æ™ºèƒ½ä½“ï¼

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/Offr7rPtDC

### 067

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-08
é“¾æ¥: https://x.com/AndrewYNg/status/1920480460318130460
äº’åŠ¨: Likes: 1,198; Retweets: 137; Replies: 58; Quotes: 27; Views: 120,142; Bookmarks: 481; isReply: 0

Iâ€™m delighted to announce that AI Fund has closed $190M for our new fund, in an oversubscribed round. I look forward to working with many more builders to create new companies that serve humanity.

AI Fund isnâ€™t a traditional venture capital firm that invests in existing businesses. Instead, we are a venture builder (also called a venture studio): We co-found AI companies, so our team is directly involved in writing code, talking to customers to get feedback, iterating on product designs, preparing market analyses, and so on. We have a lot of fun building multiple AI products at a time, and thus live daily the emerging AI startup best practices.

Many factors go into the success of a startup. But if I had to pick just one, it would be speed. Startups live or die based on their ability to make good decisions and execute fast, which has been a recurring theme of my posts here as well.

If you are building an AI startup, here are some ideas to consider:
- A startup with a small team that pursues one focused, concrete idea can move really fast. Rather than hedging, it is often better to pursue one hypothesis (for example, build one concrete product) but also be willing to switch quickly to a different hypothesis (say, change what features you decide to build) if the data that comes back indicates the original hypothesis is flawed. Concreteness gets you speed!
- A subject matter expertâ€™s gut is remarkably good at making quick decisions. Obviously, thereâ€™s a role for data and user studies as well. But if youâ€™re deciding whether to build feature A or B, or to sell first to user persona X or Y, sometimes a domain expertâ€™s gut will point to a quick decision that you can execute and validate or falsify. Trusting a domain expertâ€™s gut gets you speed!
- AI-assisted coding is making prototyping faster than ever before. Yes, AI assistance is speeding up building reliable, enterprise-grade applications and maintaining legacy codebases. But the acceleration it brings to building stand-alone prototypes is far greater. This is because stand-alone prototypes have low requirements for reliability, integration, or even security (if, say, you run them in a sandbox environment). This lets us prototype and test at a ferocious velocity. AI-assisted coding (including vibe coding, where you might barely look at the code) gets you speed!
- Finally, with faster prototyping, the bottleneck shifts to getting feedback from users. A single learning cycle might consist of (i) building a prototype and (ii) getting user feedback to inform the next iteration. Since (i) is now much faster than before, accelerating (ii) is growing in importance. This means teams that are skilled at finding prospective customers and getting their feedback in hours/days rather than weeks can go faster. For example, when building consumer products, I routinely approach strangers (in a respectful way) in public places to ask if theyâ€™re willing to give feedback on a prototype Iâ€™m working on. (Gathering feedback is more complex for enterprise products, because prospective customers are harder to track down.) Quick user feedback gets you speed!

In addition to speed, a second criterion that I find important for startup success is deep knowledge of the technology. Because AI technology is evolving rapidly, a team with a deep technical understanding of what AI can and cannot do, and when to use what tool, will make better decisions. This creates meaningful differentiation and saves wasting time in blind alleys. A good technical understanding, too, gets you speed!

Iâ€™m grateful to AI Fundâ€™s investors, team, and entrepreneur partners for working with us. There is much ahead to build!

[Original text: https://t.co/I1nkYeTkFA ]

æˆ‘éå¸¸é«˜å…´åœ°å®£å¸ƒï¼ŒAI Fund æ——ä¸‹æ–°åŸºé‡‘å·²æˆåŠŸå‹Ÿå¾— 1.9 äº¿ç¾å…ƒï¼Œæœ¬è½®èèµ„è·å¾—äº†è¶…é¢è®¤è´­ã€‚æˆ‘æœŸå¾…èƒ½ä¸æ›´å¤šæœ‰å¿—ä¹‹å£«æºæ‰‹åˆä½œï¼Œå…±åŒåˆ›å»ºé€ ç¦äººç±»çš„æ–°å…¬å¸ã€‚

AI Fund å¹¶éä¸€å®¶æŠ•èµ„ç°æœ‰ä¸šåŠ¡çš„ä¼ ç»Ÿé£é™©æŠ•èµ„æœºæ„ã€‚ç›¸åï¼Œæˆ‘ä»¬æ˜¯ã€Œé£é™©å»ºè®¾è€…ã€(Venture Builderï¼‰ï¼Œä¹Ÿå¯ä»¥ç§°ä¹‹ä¸ºã€Œåˆ›ä¸šå·¥ä½œå®¤ã€(Venture Studio)ï¼šæˆ‘ä»¬ä¸åˆ›ä¸šå›¢é˜Ÿå…±åŒå­µåŒ– AI å…¬å¸ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„å›¢é˜Ÿç›´æ¥å‚ä¸ç¼–å†™ä»£ç ã€ä¸å®¢æˆ·æ²Ÿé€šä»¥æ”¶é›†åé¦ˆã€è¿­ä»£äº§å“è®¾è®¡ã€è¿›è¡Œå¸‚åœºåˆ†æç­‰ç­‰ã€‚æˆ‘ä»¬å¾ˆäº«å—åŒæ—¶å¼€å‘å¤šä¸ª AI äº§å“çš„è¿‡ç¨‹ï¼Œå› æ­¤æ¯å¤©éƒ½åœ¨äº²èº«å®è·µç€æ–°å…´ AI åˆåˆ›å…¬å¸çš„æœ€ä½³æ–¹æ³•ã€‚

ä¸€å®¶åˆåˆ›å…¬å¸çš„æˆåŠŸç¦»ä¸å¼€è¯¸å¤šå› ç´ ã€‚ä½†å¦‚æœéè¦æˆ‘ä»ä¸­æŒ‘é€‰ä¸€ä¸ªï¼Œé‚£ä¸€å®šæ˜¯ã€Œé€Ÿåº¦ã€ã€‚åˆåˆ›å…¬å¸çš„ç”Ÿæ­»å­˜äº¡ï¼Œå–å†³äºå®ƒä»¬èƒ½å¦å¿«é€Ÿåšå‡ºæ­£ç¡®å†³ç­–å¹¶é«˜æ•ˆæ‰§è¡Œï¼Œè¿™ä¹Ÿæ˜¯æˆ‘åœ¨æ­¤å‰æ–‡ç« ä¸­åå¤å¼ºè°ƒçš„ä¸»é¢˜ã€‚

å¦‚æœä½ æ­£åœ¨åˆ›åŠä¸€å®¶ AI åˆåˆ›å…¬å¸ï¼Œè¿™é‡Œæœ‰ä¸€äº›å€¼å¾—æ€è€ƒçš„å»ºè®®ï¼š
- ä¸€æ”¯å°å›¢é˜Ÿçš„åˆåˆ›å…¬å¸ï¼Œå¦‚æœèƒ½ä¸“æ³¨äºä¸€ä¸ªæ˜ç¡®ã€å…·ä½“çš„æƒ³æ³•ï¼Œå°±èƒ½çœŸæ­£å®ç°å¿«é€Ÿå‘å±•ã€‚ä¸å…¶çŠ¹è±«ä¸å†³ï¼Œä¸å¦‚åšå®šåœ°è¿½æ±‚ä¸€ä¸ªæ ¸å¿ƒå‡è®¾ï¼ˆä¾‹å¦‚ï¼Œå¼€å‘ä¸€æ¬¾å…·ä½“çš„äº§å“ï¼‰ï¼Œä½†åŒæ—¶ä¹Ÿè¦ä¹äºæ ¹æ®æ•°æ®åé¦ˆï¼Œåœ¨å‘ç°åŸå§‹å‡è®¾æœ‰ç¼ºé™·æ—¶ï¼Œè¿…é€Ÿè½¬å‘æ–°çš„å‡è®¾ï¼ˆæ¯”å¦‚ï¼Œè°ƒæ•´ä½ å†³å®šå¼€å‘çš„åŠŸèƒ½ï¼‰ã€‚å…·ä½“æ€§å°±æ˜¯é€Ÿåº¦çš„ä¿è¯ï¼
- é¢†åŸŸä¸“å®¶ï¼ˆsubject matter expertï¼‰çš„ç›´è§‰åœ¨å¿«é€Ÿå†³ç­–æ–¹é¢æœ‰ç€æƒŠäººçš„å‡†ç¡®æ€§ã€‚å½“ç„¶ï¼Œæ•°æ®å’Œç”¨æˆ·ç ”ç©¶ä¹ŸåŒæ ·é‡è¦ã€‚ä½†å½“ä½ éœ€è¦åœ¨æ„å»ºåŠŸèƒ½ A æˆ–åŠŸèƒ½ B ä¹‹é—´åšé€‰æ‹©ï¼Œæˆ–æ˜¯å†³å®šæ˜¯ä¼˜å…ˆé¢å‘ç”¨æˆ·ç”»åƒ X è¿˜æ˜¯ Y é”€å”®æ—¶ï¼Œé¢†åŸŸä¸“å®¶çš„ç›´è§‰æœ‰æ—¶èƒ½è¿…é€Ÿå¸®ä½ åšå‡ºä¸€ä¸ªå¯ä»¥ç«‹å³æ‰§è¡Œã€éªŒè¯æˆ–è¯ä¼ªçš„å†³ç­–ã€‚ç›¸ä¿¡é¢†åŸŸä¸“å®¶çš„ç›´è§‰ï¼Œä½ å°±èƒ½æ›´å¿«ï¼
- AI è¾…åŠ©ç¼–ç ï¼ˆAI-assisted codingï¼‰è®©åŸå‹å¼€å‘ï¼ˆprototypingï¼‰çš„é€Ÿåº¦è¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„æ°´å¹³ã€‚æ²¡é”™ï¼ŒAI è¾…åŠ©æ­£åœ¨åŠ é€Ÿå¼€å‘å¯é çš„ä¼ä¸šçº§åº”ç”¨ç¨‹åºå’Œç»´æŠ¤é—ç•™ä»£ç åº“ã€‚ä½†å®ƒå¯¹æ„å»ºç‹¬ç«‹åŸå‹ï¼ˆstand-alone prototypesï¼‰æ‰€å¸¦æ¥çš„åŠ é€Ÿæ•ˆæœåˆ™è¦æ˜¾è‘—å¾—å¤šã€‚è¿™æ˜¯å› ä¸ºç‹¬ç«‹åŸå‹å¯¹å¯é æ€§ã€é›†æˆåº¦ä¹ƒè‡³å®‰å…¨æ€§ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨ä¸€ä¸ªæ²™ç›’ç¯å¢ƒï¼ˆsandbox environmentï¼‰ä¸­è¿è¡Œå®ƒä»¬ï¼‰çš„è¦æ±‚éƒ½è¾ƒä½ã€‚è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿä»¥æƒŠäººçš„é€Ÿåº¦è¿›è¡ŒåŸå‹è®¾è®¡å’Œæµ‹è¯•ã€‚AI è¾…åŠ©ç¼–ç ï¼ˆåŒ…æ‹¬ã€Œç›´è§‰ç¼–ç ã€(vibe codingï¼‰ï¼Œå³ä½ å¯èƒ½å‡ ä¹ä¸çœ‹ä»£ç ï¼Œä»…å‡­æ„Ÿè§‰ç¼–å†™ï¼‰èƒ½è®©ä½ è·å¾—é€Ÿåº¦ï¼
- æœ€åï¼Œéšç€åŸå‹å¼€å‘é€Ÿåº¦çš„åŠ å¿«ï¼Œç“¶é¢ˆè½¬ç§»åˆ°äº†ä»ç”¨æˆ·é‚£é‡Œè·å–åé¦ˆã€‚ä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ å‘¨æœŸå¯èƒ½åŒ…æ‹¬ï¼ˆiï¼‰æ„å»ºåŸå‹å’Œï¼ˆiiï¼‰è·å–ç”¨æˆ·åé¦ˆä»¥æŒ‡å¯¼ä¸‹ä¸€æ¬¡è¿­ä»£ã€‚ç”±äºï¼ˆiï¼‰ç°åœ¨æ¯”ä»¥å‰å¿«å¾—å¤šï¼Œå› æ­¤åŠ é€Ÿï¼ˆiiï¼‰çš„é‡è¦æ€§æ—¥ç›Šå‡¸æ˜¾ã€‚è¿™æ„å‘³ç€é‚£äº›å–„äºåœ¨æ•°å°æ—¶ / æ•°å¤©è€Œéæ•°å‘¨å†…æ‰¾åˆ°æ½œåœ¨å®¢æˆ·å¹¶è·å–åé¦ˆçš„å›¢é˜Ÿï¼Œèƒ½å¤Ÿæ›´å¿«åœ°è¿­ä»£å’Œå‘å±•ã€‚ä¾‹å¦‚ï¼Œåœ¨å¼€å‘æ¶ˆè´¹äº§å“æ—¶ï¼Œæˆ‘ç»å¸¸ä¼šä»¥å°Šé‡çš„æ€åº¦ï¼Œåœ¨å…¬å…±åœºæ‰€ä¸»åŠ¨æ¥è§¦é™Œç”Ÿäººï¼Œè¯¢é—®ä»–ä»¬æ˜¯å¦æ„¿æ„å¯¹æˆ‘æ­£åœ¨å¼€å‘çš„åŸå‹æä¾›åé¦ˆã€‚(å¯¹äºä¼ä¸šçº§äº§å“ï¼Œæ”¶é›†åé¦ˆæ›´ä¸ºå¤æ‚ï¼Œå› ä¸ºæ½œåœ¨å®¢æˆ·æ›´éš¾å¯»è§…ã€‚ï¼‰å¿«é€Ÿçš„ç”¨æˆ·åé¦ˆèƒ½è®©ä½ è·å¾—é€Ÿåº¦ï¼

é™¤äº†é€Ÿåº¦ï¼Œæˆ‘å‘ç°å¯¹äºåˆåˆ›å…¬å¸æˆåŠŸè‡³å…³é‡è¦çš„ç¬¬äºŒä¸ªæ ‡å‡†æ˜¯å¯¹æŠ€æœ¯æœ‰ç€æ·±åˆ»çš„ç†è§£ã€‚ç”±äº AI æŠ€æœ¯å‘å±•è¿…çŒ›ï¼Œä¸€ä¸ªå¯¹ AI çš„èƒ½åŠ›è¾¹ç•Œã€ä»¥åŠä½•æ—¶ä½¿ç”¨ä½•ç§å·¥å…·éƒ½æœ‰æ·±å…¥æŠ€æœ¯ç†è§£çš„å›¢é˜Ÿï¼Œå°†èƒ½åšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ã€‚è¿™ä¸ä»…èƒ½åˆ›é€ æœ‰æ„ä¹‰çš„å·®å¼‚åŒ–ä¼˜åŠ¿ï¼Œè¿˜èƒ½é¿å…åœ¨é”™è¯¯çš„é“è·¯ä¸Šæµªè´¹æ—¶é—´ã€‚è‰¯å¥½çš„æŠ€æœ¯ç†è§£ï¼ŒåŒæ ·èƒ½è®©ä½ è·å¾—é€Ÿåº¦ï¼

æˆ‘éå¸¸æ„Ÿè°¢ AI Fund çš„æŠ•èµ„è€…ã€å›¢é˜Ÿä»¥åŠåˆ›ä¸šä¼™ä¼´ä¸æˆ‘ä»¬å¹¶è‚©åä½œã€‚æœªæ¥è¿˜æœ‰è®¸å¤šå€¼å¾—æˆ‘ä»¬å»åˆ›é€ å’Œå»ºè®¾ï¼

[åŸå§‹æ–‡æœ¬ï¼šhttps://t.co/I1nkYeTkFA]

### 068

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-08
é“¾æ¥: https://x.com/AndrewYNg/status/1920480706439876889
äº’åŠ¨: Likes: 115; Retweets: 19; Replies: 7; Quotes: 1; Views: 31,969; Bookmarks: 90; isReply: 1

Additional tips on achieving speed:
- Concreteness: https://t.co/H21N1tzkHM
- Domain expertâ€™s gut: https://t.co/6zGF1Fv8Ym
- AI assisted coding: https://t.co/g41HynaFZ0
- Quick user feedback: https://t.co/7rA0dit4jx

åœ¨æå‡é€Ÿåº¦æ–¹é¢ï¼Œè¿˜æœ‰ä¸€äº›é¢å¤–çš„å»ºè®®ï¼š
- ä¿æŒå…·ä½“ï¼šhttps://t.co/H21N1tzkHM
- ä¾é é¢†åŸŸä¸“å®¶çš„ç›´è§‰ï¼šhttps://t.co/6zGF1Fv8Ym
- åˆ©ç”¨ AI è¾…åŠ©ç¼–ç¨‹ï¼šhttps://t.co/g41HynaFZ0
- å¿«é€Ÿè·å–ç”¨æˆ·åé¦ˆï¼šhttps://t.co/7rA0dit4jx

### 069

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-14
é“¾æ¥: https://x.com/AndrewYNg/status/1922671569429766178
äº’åŠ¨: Likes: 2,085; Retweets: 376; Replies: 44; Quotes: 33; Views: 139,740; Bookmarks: 1,834; isReply: 0

New course: MCP: Build Rich-Context AI Apps with Anthropic. Learn to build AI apps that access tools, data, and prompts using the Model Context Protocol in this short course, created in partnership with Anthropic @AnthropicAI and taught by Elie Schoppik @eschoppik, its Head of Technical Education.

Connecting AI applications to external systems that bring rich context to LLM-based applications has often meant writing custom integrations for each use case. MCP is an open protocol that standardizes how LLMs access tools, data, and prompts from external sources, and simplifies how you provide context to your LLM-based applications. For example, you can provide context via third-party tools that let your LLM make API calls to search the web, access data from local docs, retrieve code from a GitHub repo, and so on.

MCP, developed by Anthropic, is based on a client-server architecture that defines the communication details between an MCP client, hosted inside the AI application, and an MCP server that exposes tools, resources, and prompt templates. The server can be a subprocess launched by the client that runs locally or an independent process running remotely.

In this hands-on course, you'll learn the core architecture behind MCP. Youâ€™ll create an MCP-compatible chatbot, build and deploy an MCP server, and connect the chatbot to your MCP server and other open-source servers.

Hereâ€™s what youâ€™ll do:
- Understand why MCP makes AI development less fragmented and standardizes connections between AI applications and external data sources
- Learn the core components of the client-server architecture of MCP and the underlying communication mechanism
- Build a chatbot with custom tools for searching academic papers, and transform it into an MCP-compatible application
- Build a local MCP server that exposes tools, resources, and prompt templates using FastMCP, and test it using MCP Inspector
- Create an MCP client inside your chatbot to dynamically connect to your server
- Connect your chatbot to reference servers built by Anthropicâ€™s MCP team, such as filesystem, which implements filesystem operations, and fetch, which extracts contents from the web as markdown
- Configure Claude Desktop to connect to your server and others, and explore how it abstracts away the low-level logic of MCP clients
- Deploy your MCP server remotely and test it with the Inspector or other MCP-compatible applications
- Learn about the roadmap for future MCP development, such as multi-agent architecture, MCP registry API, server discovery, authorization, and authentication

MCP is an exciting and important technology that lets you build rich-context AI applications that connect to a growing ecosystem of MCP servers, with minimal integration work.

Please sign up here! https://t.co/UDyp8NRe8R

æ–°è¯¾ç¨‹ï¼šMCPï¼šAnthropic æºæ‰‹åŠ©æ‚¨æ„å»ºå¯Œä¸Šä¸‹æ–‡ AI åº”ç”¨ã€‚åœ¨è¿™ä¸ªçŸ­è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆModel Context Protocolï¼‰æ„å»ºå¯è®¿é—®å·¥å…·ã€æ•°æ®å’Œæç¤ºçš„ AI åº”ç”¨ã€‚è¯¥è¯¾ç¨‹ç”± Anthropicï¼ˆ@AnthropicAIï¼‰åˆä½œåˆ›å»ºï¼Œå¹¶ç”±å…¶æŠ€æœ¯æ•™è‚²ä¸»ç®¡ Elie Schoppikï¼ˆ@eschoppikï¼‰æˆè¯¾ã€‚

å°† AI åº”ç”¨ç¨‹åºè¿æ¥åˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œä¸ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼‰çš„åº”ç”¨å¸¦æ¥ä¸°å¯Œä¸Šä¸‹æ–‡ï¼Œè¿‡å»é€šå¸¸æ„å‘³ç€ä¸ºæ¯ä¸ªç”¨ä¾‹ç¼–å†™è‡ªå®šä¹‰é›†æˆã€‚MCP æ˜¯ä¸€ç§å¼€æ”¾åè®®ï¼Œå®ƒè§„èŒƒäº†å¤§è¯­è¨€æ¨¡å‹å¦‚ä½•ä»å¤–éƒ¨æºè®¿é—®å·¥å…·ã€æ•°æ®å’Œæç¤ºï¼Œå¹¶ç®€åŒ–äº†æ‚¨ä¸ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨æä¾›ä¸Šä¸‹æ–‡çš„æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€šè¿‡ç¬¬ä¸‰æ–¹å·¥å…·æä¾›ä¸Šä¸‹æ–‡ï¼Œè¿™äº›å·¥å…·èƒ½è®©æ‚¨çš„å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œ API è°ƒç”¨ï¼Œä»è€Œæœç´¢ç½‘é¡µã€è®¿é—®æœ¬åœ°æ–‡æ¡£ä¸­çš„æ•°æ®ã€ä» GitHub ä»“åº“æ£€ç´¢ä»£ç ç­‰ã€‚

MCP ç”± Anthropic å¼€å‘ï¼ŒåŸºäºå®¢æˆ·ç«¯ - æœåŠ¡å™¨ï¼ˆclient-serverï¼‰æ¶æ„ï¼Œå®ƒå®šä¹‰äº†æ‰˜ç®¡åœ¨ AI åº”ç”¨ç¨‹åºå†…éƒ¨çš„ MCP å®¢æˆ·ç«¯ä¸æš´éœ²å·¥å…·ã€èµ„æºå’Œæç¤ºæ¨¡æ¿çš„ MCP æœåŠ¡å™¨ä¹‹é—´çš„é€šä¿¡ç»†èŠ‚ã€‚æœåŠ¡å™¨å¯ä»¥æ˜¯ç”±å®¢æˆ·ç«¯åœ¨æœ¬åœ°å¯åŠ¨çš„å­è¿›ç¨‹ï¼Œä¹Ÿå¯ä»¥æ˜¯è¿œç¨‹è¿è¡Œçš„ç‹¬ç«‹è¿›ç¨‹ã€‚

åœ¨è¿™ä¸ªå®è·µè¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹  MCP èƒŒåçš„æ ¸å¿ƒæ¶æ„ã€‚æ‚¨å°†åˆ›å»ºä¸€ä¸ª MCP å…¼å®¹çš„èŠå¤©æœºå™¨äººï¼Œæ„å»ºå¹¶éƒ¨ç½²ä¸€ä¸ª MCP æœåŠ¡å™¨ï¼Œå¹¶å°†èŠå¤©æœºå™¨äººè¿æ¥åˆ°æ‚¨çš„ MCP æœåŠ¡å™¨å’Œå…¶ä»–å¼€æºæœåŠ¡å™¨ã€‚

æ‚¨å°†å­¦ä¹ åˆ°ï¼š
- äº†è§£ MCP å¦‚ä½•å‡å°‘ AI å¼€å‘çš„é›¶æ•£æ€§ï¼Œå¹¶æ ‡å‡†åŒ– AI åº”ç”¨ç¨‹åºä¸å¤–éƒ¨æ•°æ®æºä¹‹é—´çš„è¿æ¥
- å­¦ä¹  MCP å®¢æˆ·ç«¯ - æœåŠ¡å™¨æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ä»¥åŠåº•å±‚çš„é€šä¿¡æœºåˆ¶
- ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·æ„å»ºä¸€ä¸ªç”¨äºæœç´¢å­¦æœ¯è®ºæ–‡çš„èŠå¤©æœºå™¨äººï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ª MCP å…¼å®¹çš„åº”ç”¨ç¨‹åº
- ä½¿ç”¨ FastMCP æ„å»ºä¸€ä¸ªæš´éœ²å·¥å…·ã€èµ„æºå’Œæç¤ºæ¨¡æ¿çš„æœ¬åœ° MCP æœåŠ¡å™¨ï¼Œå¹¶ä½¿ç”¨ MCP Inspector å¯¹å…¶è¿›è¡Œæµ‹è¯•
- åœ¨æ‚¨çš„èŠå¤©æœºå™¨äººå†…éƒ¨åˆ›å»ºä¸€ä¸ª MCP å®¢æˆ·ç«¯ï¼Œä»¥åŠ¨æ€è¿æ¥åˆ°æ‚¨çš„æœåŠ¡å™¨
- å°†æ‚¨çš„èŠå¤©æœºå™¨äººè¿æ¥åˆ° Anthropic çš„ MCP å›¢é˜Ÿæ„å»ºçš„å‚è€ƒæœåŠ¡å™¨ï¼Œä¾‹å¦‚ `filesystem`ï¼ˆå®ç°æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼‰å’Œ `fetch`ï¼ˆå°†ç½‘é¡µå†…å®¹æå–ä¸º Markdown æ ¼å¼)
- é…ç½® Claude Desktop ä»¥è¿æ¥åˆ°æ‚¨çš„æœåŠ¡å™¨å’Œå…¶ä»–æœåŠ¡å™¨ï¼Œå¹¶æ¢ç´¢å®ƒå¦‚ä½•æŠ½è±¡æˆ–éšè— MCP å®¢æˆ·ç«¯çš„åº•å±‚é€»è¾‘
- è¿œç¨‹éƒ¨ç½²æ‚¨çš„ MCP æœåŠ¡å™¨ï¼Œå¹¶ä½¿ç”¨ Inspector æˆ–å…¶ä»– MCP å…¼å®¹çš„åº”ç”¨ç¨‹åºå¯¹å…¶è¿›è¡Œæµ‹è¯•
- äº†è§£æœªæ¥ MCP å¼€å‘çš„è·¯çº¿å›¾ï¼Œä¾‹å¦‚å¤š AI æ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰æ¶æ„ã€MCP æ³¨å†Œè¡¨ APIã€æœåŠ¡å™¨å‘ç°ã€æˆæƒå’Œèº«ä»½éªŒè¯

MCP æ˜¯ä¸€é¡¹ä»¤äººå…´å¥‹ä¸”é‡è¦çš„æŠ€æœ¯ï¼Œå®ƒèƒ½è®©æ‚¨ä»¥æœ€å°‘çš„é›†æˆå·¥ä½œï¼Œæ„å»ºè¿æ¥åˆ°ä¸æ–­å¢é•¿çš„ MCP æœåŠ¡å™¨ç”Ÿæ€ç³»ç»Ÿçš„å¯Œä¸Šä¸‹æ–‡ AI åº”ç”¨ç¨‹åºã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼https://t.co/UDyp8NRe8R

### 070

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-15
é“¾æ¥: https://x.com/AndrewYNg/status/1923045958511886549
äº’åŠ¨: Likes: 891; Retweets: 192; Replies: 79; Quotes: 34; Views: 124,357; Bookmarks: 406; isReply: 0

AIâ€™s ability to make tasks not just cheaper, but also faster, is underrated in its importance in creating business value.

For the task of writing code, AI is a game-changer. It takes so much less effort â€” and is so much cheaper â€” to write software with AI assistance than without. But beyond reducing the cost of writing software, AI is shortening the time from idea to working prototype, and the ability to test ideas faster is changing how teams explore and invent. When you can test 20 ideas per month, it dramatically changes what you can do compared to testing 1 idea per month. This is a benefit that comes from AI-enabled speed rather than AI-enabled cost reduction.

That AI-enabled automation can reduce costs is well understood. For example, providing automated customer service is cheaper than operating human-staffed call centers. Many businesses are more willing to invest in growth than just in cost savings; and, when a task becomes cheaper, some businesses will do a lot more of it, thus creating growth. But another recipe for growth is underrated: Making certain tasks much faster (whether or not they also become cheaper) can create significant new value.

I see this pattern across more and more businesses. Consider the following scenarios:
- If a lender can approve loans in minutes using AI, rather than days waiting for a human to review them, this creates more borrowing opportunities (and also lets the lender deploy its capital faster). Even if human-in-the-loop review is needed, using AI to get the most important information to the reviewer might speed things up. The ability to provide loans quickly opens up the market to new customers in need of rapid funds and helps customers who need a quick positive or negative decision to accept the loan or move on.
- If an academic institution gives homework feedback to students in minutes (via sophisticated autograding) rather than days (via human grading), not only is the automation cheaper, the rapid feedback facilitates better learning.
- If an online seller can approve purchases faster, this can lead to more sales. For example, many platforms that accept online ad purchases have an approval process that can take hours or days; if approvals can be done faster, they can earn revenue faster. Further, for customers buying ads, being able to post an ad in minutes lets them test ideas faster and also makes the ad product more valuable.
- If a companyâ€™s sales department can prioritize leads and respond to prospective customers in minutes or hours rather than days â€” closer to when the customersâ€™ buying intent first led them to contact the company â€” sales representatives might close more deals. Likewise, a business that can respond more quickly to requests for proposals may win more deals.

Iâ€™ve written previously about looking at the tasks a company does to explore where AI can help. Many teams already do this with an eye toward making tasks cheaper, either to save costs or to do those tasks many more times. If youâ€™re doing this exercise, consider also whether AI can significantly speed up certain tasks. One place to examine is the sequence of tasks on the path to earning revenue. If some of the steps can be sped up, perhaps this can help revenue growth.

Growth is more interesting to most businesses than cost savings, and if there are loops in your business that, when sped up, would drive growth, AI might be a tool to unlock this growth.

[Original text: https://t.co/qx2Ir6pkSp  ]

AI ä¸ä»…èƒ½è®©ä»»åŠ¡æ›´ä¾¿å®œï¼Œè¿˜èƒ½è®©ä»»åŠ¡å˜å¾—æ›´å¿«ï¼Œä½†å®ƒåœ¨åˆ›é€ å•†ä¸šä»·å€¼æ–¹é¢çš„é‡è¦æ€§å´è¢«ä½ä¼°äº†ã€‚

ä»¥ç¼–å†™ä»£ç è¿™é¡¹ä»»åŠ¡ä¸ºä¾‹ï¼ŒAI æ— ç–‘æ˜¯é¢ è¦†æ€§çš„æŠ€æœ¯ã€‚å€ŸåŠ© AI çš„å¸®åŠ©ï¼Œç¼–å†™è½¯ä»¶æ‰€éœ€çš„å·¥ä½œé‡å’Œæˆæœ¬éƒ½å¤§å¤§é™ä½äº†ã€‚ç„¶è€Œï¼Œé™¤äº†é™ä½è½¯ä»¶å¼€å‘æˆæœ¬ï¼ŒAI è¿˜åœ¨ç¼©çŸ­ä»åˆ›æ„åˆ°å·¥ä½œåŸå‹ï¼ˆworking prototypeï¼‰çš„æ—¶é—´ã€‚æ›´å¿«åœ°éªŒè¯æƒ³æ³•çš„èƒ½åŠ›æ­£åœ¨æ”¹å˜å›¢é˜Ÿæ¢ç´¢å’Œåˆ›æ–°çš„æ–¹å¼ã€‚å¦‚æœæ¯æœˆèƒ½æµ‹è¯• 20 ä¸ªæƒ³æ³•ï¼Œä¸æ¯æœˆåªèƒ½æµ‹è¯• 1 ä¸ªæƒ³æ³•ç›¸æ¯”ï¼Œæ‚¨çš„å·¥ä½œæ•ˆç‡å°†å‘ç”Ÿç¿»å¤©è¦†åœ°çš„å˜åŒ–ã€‚è¿™å°±æ˜¯ç”± AI èµ‹èƒ½çš„é€Ÿåº¦å¸¦æ¥çš„å¥½å¤„ï¼Œè€Œéä»…ä»…æ˜¯ AI å¸¦æ¥çš„æˆæœ¬é™ä½ã€‚

AI èµ‹èƒ½çš„è‡ªåŠ¨åŒ–èƒ½å¤Ÿé™ä½æˆæœ¬è¿™ä¸€ç‚¹å·²æ˜¯å…±è¯†ã€‚ä¾‹å¦‚ï¼Œæä¾›è‡ªåŠ¨åŒ–å®¢æˆ·æœåŠ¡æ¯”è¿è¥äººå·¥å®¢æœä¸­å¿ƒè¦ä¾¿å®œã€‚è®¸å¤šä¼ä¸šæ›´ä¹æ„æŠ•èµ„äºå¢é•¿ï¼Œè€Œéä»…ä»…æ˜¯å‰Šå‡æˆæœ¬ï¼›å½“ä¸€é¡¹ä»»åŠ¡å˜å¾—æ›´ä¾¿å®œæ—¶ï¼Œä¸€äº›ä¼ä¸šä¼šå¤§å¹…å¢åŠ è¿™é¡¹ä»»åŠ¡çš„æ‰§è¡Œæ¬¡æ•°ï¼Œä»è€Œå®ç°å¢é•¿ã€‚ä½†æ˜¯ï¼Œå¦ä¸€ç§å®ç°å¢é•¿çš„æ–¹å¼å´è¢«ä½ä¼°äº†ï¼šè®©æŸäº›ä»»åŠ¡å˜å¾—æ›´å¿«ï¼ˆæ— è®ºå®ƒä»¬æ˜¯å¦ä¹Ÿå˜å¾—æ›´ä¾¿å®œï¼‰èƒ½å¤Ÿåˆ›é€ å·¨å¤§çš„æ–°ä»·å€¼ã€‚

æˆ‘å‘ç°è¿™ç§æ¨¡å¼æ­£æ—¥ç›Šæ¸—é€åˆ°è¶Šæ¥è¶Šå¤šçš„ä¼ä¸šä¸­ã€‚è¯·çœ‹ä»¥ä¸‹å‡ ç§åœºæ™¯ï¼š
- å¦‚æœè´·æ¬¾æœºæ„èƒ½åˆ©ç”¨ AI åœ¨å‡ åˆ†é’Ÿå†…æ‰¹å‡†è´·æ¬¾ï¼Œè€Œæ— éœ€ç­‰å¾…äººå·¥å®¡æ ¸æ•°å¤©ï¼Œè¿™ä¸ä»…èƒ½åˆ›é€ æ›´å¤šå€Ÿè´·æœºä¼šï¼Œè¿˜èƒ½è®©è´·æ¬¾æœºæ„æ›´å¿«åœ°åˆ©ç”¨å…¶èµ„æœ¬ã€‚å³ä½¿ä»éœ€äººå·¥ä»‹å…¥å®¡æ ¸ï¼ŒAI ä¹Ÿèƒ½å¸®åŠ©å®¡æ ¸å‘˜è¿…é€Ÿè·å–æœ€å…³é”®çš„ä¿¡æ¯ï¼Œä»è€ŒåŠ å¿«æµç¨‹ã€‚å¿«é€Ÿæä¾›è´·æ¬¾çš„èƒ½åŠ›ä¸ä»…èƒ½ä¸ºéœ€è¦å³æ—¶èµ„é‡‘çš„æ–°å®¢æˆ·æ‰“å¼€å¸‚åœºï¼Œè¿˜èƒ½å¸®åŠ©å®¢æˆ·è¿…é€Ÿè·å¾—è´·æ¬¾æ‰¹å¤ï¼ˆæ— è®ºæ˜¯é€šè¿‡è¿˜æ˜¯æ‹’ç»ï¼‰ï¼Œä»¥ä¾¿åšå‡ºä¸‹ä¸€æ­¥å†³ç­–ã€‚
- å¦‚æœå­¦æœ¯æœºæ„èƒ½åœ¨å‡ åˆ†é’Ÿå†…ï¼ˆé€šè¿‡å¤æ‚çš„è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿï¼‰è€Œä¸æ˜¯å‡ å¤©å†…ï¼ˆé€šè¿‡äººå·¥è¯„åˆ†ï¼‰å‘å­¦ç”Ÿæä¾›ä½œä¸šåé¦ˆï¼Œé‚£ä¹ˆè‡ªåŠ¨åŒ–ä¸ä»…æ›´ç»æµï¼Œå¿«é€Ÿçš„åé¦ˆè¿˜èƒ½ä¿ƒè¿›æ›´å¥½çš„å­¦ä¹ æ•ˆæœã€‚
- å¦‚æœåœ¨çº¿å•†å®¶èƒ½æ›´å¿«åœ°æ‰¹å‡†è´­ä¹°è¯·æ±‚ï¼Œè¿™å¯èƒ½å¸¦æ¥æ›´å¤šé”€å”®ã€‚ä¾‹å¦‚ï¼Œè®¸å¤šæ¥å—åœ¨çº¿å¹¿å‘Šè´­ä¹°çš„å¹³å°éƒ½æœ‰ä¸€ä¸ªå¯èƒ½è€—æ—¶æ•°å°æ—¶ç”šè‡³æ•°å¤©çš„å®¡æ‰¹æµç¨‹ï¼›å¦‚æœå®¡æ‰¹èƒ½æ›´å¿«å®Œæˆï¼Œå®ƒä»¬å°±èƒ½æ›´å¿«åœ°è·å¾—æ”¶å…¥ã€‚æ­¤å¤–ï¼Œå¯¹äºè´­ä¹°å¹¿å‘Šçš„å®¢æˆ·æ¥è¯´ï¼Œèƒ½åœ¨å‡ åˆ†é’Ÿå†…å‘å¸ƒå¹¿å‘Šï¼Œå¯ä»¥è®©ä»–ä»¬æ›´å¿«åœ°æµ‹è¯•åˆ›æ„ï¼Œä¹Ÿä½¿å¾—å¹¿å‘Šäº§å“æœ¬èº«æ›´å…·ä»·å€¼ã€‚
- å¦‚æœä¸€å®¶å…¬å¸çš„é”€å”®éƒ¨é—¨èƒ½åœ¨å‡ åˆ†é’Ÿæˆ–å‡ å°æ—¶å†…ï¼Œè€Œéæ•°å¤©å†…ï¼Œä¼˜å…ˆå¤„ç†é”€å”®çº¿ç´¢å¹¶å›åº”æ½œåœ¨å®¢æˆ· â€”â€” è¿™æ›´æ¥è¿‘å®¢æˆ·æœ€åˆå› è´­ä¹°æ„æ„¿è€Œè”ç³»å…¬å¸çš„æ—¶é—´ â€”â€” é‚£ä¹ˆé”€å”®ä»£è¡¨å¯èƒ½ä¼šè¾¾æˆæ›´å¤šäº¤æ˜“ã€‚åŒæ ·ï¼Œä¸€å®¶èƒ½æ›´å¿«å›åº”é¡¹ç›®æŠ•æ ‡é‚€è¯·çš„ä¼ä¸šï¼Œä¹Ÿå¯èƒ½èµ¢å¾—æ›´å¤šä¸šåŠ¡ã€‚

æˆ‘ä¹‹å‰æ›¾æ’°æ–‡æ¢è®¨å¦‚ä½•å®¡è§†å…¬å¸å„é¡¹ä»»åŠ¡ï¼Œä»¥å‘ç° AI çš„æ½œåœ¨åº”ç”¨ã€‚è®¸å¤šå›¢é˜Ÿåœ¨è¿›è¡Œè¿™é¡¹å·¥ä½œæ—¶ï¼Œé€šå¸¸ä¾§é‡äºå¦‚ä½•é™ä½ä»»åŠ¡æˆæœ¬ï¼Œæ— è®ºæ˜¯ä¸ºäº†èŠ‚çœå¼€æ”¯è¿˜æ˜¯ä¸ºäº†èƒ½æ›´é¢‘ç¹åœ°æ‰§è¡Œè¿™äº›ä»»åŠ¡ã€‚åœ¨è¿›è¡Œè¿™é¡¹åˆ†ææ—¶ï¼Œè¯·åŠ¡å¿…è€ƒè™‘ AI æ˜¯å¦ä¹Ÿèƒ½æ˜¾è‘—åŠ å¿«æŸäº›ä»»åŠ¡çš„æ‰§è¡Œé€Ÿåº¦ã€‚ä¸€ä¸ªå€¼å¾—å…³æ³¨çš„é¢†åŸŸæ˜¯è¥æ”¶è·¯å¾„ä¸Šçš„ä»»åŠ¡åºåˆ—ã€‚å¦‚æœå…¶ä¸­æŸäº›ç¯èŠ‚èƒ½è¢«åŠ é€Ÿï¼Œæˆ–è®¸å°±èƒ½æœ‰æ•ˆæ¨åŠ¨è¥æ”¶å¢é•¿ã€‚

å¯¹å¤§å¤šæ•°ä¼ä¸šè€Œè¨€ï¼Œå¢é•¿æ¯”æˆæœ¬èŠ‚çº¦æ›´å…·å¸å¼•åŠ›ã€‚å¦‚æœæ‚¨çš„ä¸šåŠ¡ä¸­å­˜åœ¨ä¸€äº›é€šè¿‡åŠ é€Ÿå°±èƒ½é©±åŠ¨å¢é•¿çš„å¾ªç¯ï¼Œé‚£ä¹ˆ AI æˆ–è®¸å°±æ˜¯è§£é”è¿™ç§å¢é•¿çš„å…³é”®å·¥å…·ã€‚

[Original textï¼šhttps://t.co/qx2Ir6pkSp]

### 071

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-21
é“¾æ¥: https://x.com/AndrewYNg/status/1925213790892929149
äº’åŠ¨: Likes: 1,264; Retweets: 184; Replies: 29; Quotes: 17; Views: 84,598; Bookmarks: 873; isReply: 0

New Course: Reinforcement Fine-Tuning LLMs with GRPO! 

Learn to use reinforcement learning to improve your LLM performance in this short course, built in collaboration with @Predibase, and taught by @TravisAddair, its Co-Founder and CTO, and @grg_arnav, its Senior Engineer and Machine Learning Lead.

Reasoning models have been one of the most important developments in LLMs. Reinforcement Fine-Tuning (RFT) uses rewards to encourage LLMs to find solutions to multi-step reasoning tasks such as solving math problems and debugging code - without needing pre-existing training examples like in traditional supervised fine-tuning.

Group Relative Policy Optimization (GRPO) is a   reinforcement fine-tuning algorithm gaining rapid adoption. Developed by the DeepSeek team and used to train the R1 reasoning model, GRPO uses reward functions that you can write in Python to assign rewards to model responses. Itâ€™s beneficial for tasks with verifiable outcomes and can work well even with fewer than 100 training examples. It can also significantly improve the reasoning ability of smaller LLMs, making applications faster and more cost effective.

In this course, youâ€™ll take a technical deep dive into RFT with GRPO. Youâ€™ll learn to build reward functions that you can use in the GRPO training process to guide an LLM toward better performance on multi-step reasoning tasks.

In detail, youâ€™ll:
- Learn when reinforcement fine-tuning is a better fit than supervised fine-tuning, especially for tasks involving multi-step reasoning or limited labeled data.
- Understand how GRPO uses programmable reward functions as a more scalable alternative to the human feedback required for other reinforcement learning algorithms, such as RLHF and DPO.
- Frame the Wordle game as a reinforcement fine-tuning problem and see how an LLM can learn to plan, analyze feedback, and improve its strategy over time.
- Design reward functions that power the reinforcement fine-tuning process.
- Learn techniques for evaluating more subjective tasks, such as rating the quality of a text summary, using an LLM as a judge.
- Understand why reward hacking happens and how to avoid it by adding penalty functions to discourage undesirable behaviors.
- Learn the four key components of the loss calculation in the GRPO algorithm: token probability distribution ratios, advantages, clipping, and KL-divergence.
- Launch reinforcement fine-tuning jobs using Predibaseâ€™s hosted training services.

By the end of this course, youâ€™ll be able to build and fine-tune LLMs using reinforcement learning to improve reasoning without relying on large labeled datasets or subjective human feedback.

Please sign up here: https://t.co/2BSuKuzE6N

æ–°è¯¾ç¨‹ï¼šç”¨ GRPO å¼ºåŒ–å¾®è°ƒï¼ˆReinforcement Fine-Tuningï¼‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMs)ï¼

è¿™é—¨çŸ­æœŸè¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥æå‡ä½ çš„å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½ã€‚å®ƒç”± @Predibase åˆä½œå¼€å‘ï¼Œå¹¶ç”±å…¶è”åˆåˆ›å§‹äººå…¼é¦–å¸­æŠ€æœ¯å®˜ @TravisAddair å’Œé«˜çº§å·¥ç¨‹å¸ˆå…¼æœºå™¨å­¦ä¹ è´Ÿè´£äºº @grg_arnav äº²è‡ªæˆè¯¾ã€‚

æ¨ç†æ¨¡å‹ä¸€ç›´æ˜¯å¤§è¯­è¨€æ¨¡å‹å‘å±•ä¸­æœ€é‡è¦çš„çªç ´ä¹‹ä¸€ã€‚å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰é€šè¿‡å¥–åŠ±æœºåˆ¶ï¼Œé¼“åŠ±å¤§è¯­è¨€æ¨¡å‹è‡ªä¸»æ¢ç´¢å¤šæ­¥æ¨ç†ä»»åŠ¡çš„è§£å†³æ–¹æ¡ˆï¼Œä¾‹å¦‚è§£å†³æ•°å­¦é—®é¢˜å’Œè°ƒè¯•ä»£ç ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒä¸åŒï¼Œå®ƒä¸éœ€è¦é¢„å…ˆå­˜åœ¨çš„è®­ç»ƒç¤ºä¾‹ã€‚

ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ˜¯ä¸€ç§æ­£è¿…é€Ÿæ™®åŠçš„å¼ºåŒ–å¾®è°ƒç®—æ³•ã€‚å®ƒç”± DeepSeek å›¢é˜Ÿå¼€å‘ï¼Œå¹¶æˆåŠŸåº”ç”¨äºè®­ç»ƒ R1 æ¨ç†æ¨¡å‹ã€‚GRPO å…è®¸ä½ ç”¨ Python ç¼–å†™å¥–åŠ±å‡½æ•°ï¼Œä¸ºæ¨¡å‹çš„å“åº”åˆ†é…å¥–åŠ±ã€‚è¿™ç§æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºç»“æœå¯éªŒè¯çš„ä»»åŠ¡ï¼Œå¹¶ä¸”å³ä½¿è®­ç»ƒç¤ºä¾‹å°‘äº 100 ä¸ªä¹Ÿèƒ½è¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜èƒ½æ˜¾è‘—æå‡å°å‹å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä»è€Œè®©åº”ç”¨è¿è¡Œæ›´å¿«ã€æˆæœ¬æ•ˆç›Šæ›´é«˜ã€‚

åœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†å¯¹ GRPO å¼ºåŒ–å¾®è°ƒè¿›è¡Œä¸€æ¬¡æ·±å…¥çš„æŠ€æœ¯æ¢ç´¢ã€‚ä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºå¥–åŠ±å‡½æ•°ï¼Œå¹¶åœ¨ GRPO è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨å®ƒä»¬ï¼Œä»è€Œå¼•å¯¼å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸Šå–å¾—æ›´å¥½çš„è¡¨ç°ã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- äº†è§£ä½•æ—¶å¼ºåŒ–å¾®è°ƒæ¯”ç›‘ç£å¾®è°ƒæ›´é€‚ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šæ­¥æ¨ç†æˆ–æœ‰é™æ ‡æ³¨æ•°æ®çš„ä»»åŠ¡ä¸­ã€‚
- ç†è§£ GRPO å¦‚ä½•åˆ©ç”¨å¯ç¼–ç¨‹çš„å¥–åŠ±å‡½æ•°ï¼Œä½œä¸ºæ›¿ä»£å…¶ä»–å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆä¾‹å¦‚ RLHF å’Œ DPOï¼‰æ‰€éœ€çš„äººç±»åé¦ˆçš„ä¸€ç§æ›´å…·æ‰©å±•æ€§çš„æ–¹æ¡ˆã€‚
- å°† Wordle æ¸¸æˆè½¬åŒ–ä¸ºä¸€ä¸ªå¼ºåŒ–å¾®è°ƒé—®é¢˜ï¼Œå¹¶è§‚å¯Ÿå¤§è¯­è¨€æ¨¡å‹å¦‚ä½•å­¦ä¹ è§„åˆ’ã€åˆ†æåé¦ˆå¹¶é€æ­¥ä¼˜åŒ–å…¶ç­–ç•¥ã€‚
- è®¾è®¡èƒ½å¤Ÿé©±åŠ¨å¼ºåŒ–å¾®è°ƒè¿‡ç¨‹çš„å¥–åŠ±å‡½æ•°ã€‚
- å­¦ä¹ è¯„ä¼°æ›´ä¸»è§‚ä»»åŠ¡çš„æŠ€æœ¯ï¼Œä¾‹å¦‚ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºè£åˆ¤ï¼Œå¯¹æ–‡æœ¬æ‘˜è¦çš„è´¨é‡è¿›è¡Œè¯„åˆ†ã€‚
- ç†è§£ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿå¥–åŠ±æ¬ºéª—ï¼ˆreward hackingï¼‰ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡å¢åŠ æƒ©ç½šå‡½æ•°æ¥éåˆ¶ä¸è‰¯è¡Œä¸ºä»¥é¿å…å®ƒã€‚
- å­¦ä¹  GRPO ç®—æ³•ä¸­æŸå¤±è®¡ç®—çš„å››ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šToken æ¦‚ç‡åˆ†å¸ƒæ¯”ç‡ã€ä¼˜åŠ¿ã€è£å‰ªå’Œ KL æ•£åº¦ã€‚
- ä½¿ç”¨ Predibase çš„æ‰˜ç®¡è®­ç»ƒæœåŠ¡å¯åŠ¨å¼ºåŒ–å¾®è°ƒä»»åŠ¡ã€‚

å®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†èƒ½å¤Ÿä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥æ„å»ºå’Œå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ï¼Œä»è€Œåœ¨ä¸ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®é›†æˆ–ä¸»è§‚äººç±»åé¦ˆçš„æƒ…å†µä¸‹ï¼Œæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/2BSuKuzE6N

### 072

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-22
é“¾æ¥: https://x.com/AndrewYNg/status/1925575163325948123
äº’åŠ¨: Likes: 1,118; Retweets: 215; Replies: 68; Quotes: 18; Views: 136,115; Bookmarks: 749; isReply: 0

In the age of AI, large corporations â€” not just startups â€” can move fast. I often speak with large companiesâ€™ C-suite and Boards about AI strategy and implementation, and would like to share some ideas that are applicable to big companies. One key is to create an environment where small, scrappy teams donâ€™t need permission to innovate. Let me explain.

Large companies are slower than startups for many reasons. But why are even 3-person, scrappy teams within large companies slower than startups of a similar size? One major reason is that large companies have more to lose, and cannot afford for a small team to build and ship a feature that leaks sensitive information, damages the company brand, hurts revenue, invites regulatory scrutiny, or otherwise damages an important part of the business. To prevent these outcomes, I have seen companies require privacy review, marketing review, financial review, legal review, and so on before a team can ship anything. But if engineers need sign-off from 5 vice presidents before theyâ€™re even allowed to launch an MVP (minimum viable product) to run an experiment, how can they ever discover what customers want, iterate quickly, or invent any meaningful new product?

Thanks to AI-assisted coding, the world now has a capability to build software prototypes really fast. But many large companiesâ€™ processes â€“ designed to protect against legitimate downside risks â€“ make them unable to take advantage of this capability. In contrast, in small startups with no revenue, no customers, and no brand reputation the downside is limited. In fact, going out of business is a very real possibility anyway, so moving fast makes a superior tradeoff to moving slowly to protect against downside risk. In the worst case, it might invent a new way to go out of business, but in a good case, it might become very valuable.

Fortunately, large companies have a way out of this conundrum. They can create a sandbox environment for teams to experiment in a way that strictly limits the downside risk. Then those teams can go much faster and not have to slow down to get anyoneâ€™s permission.

The sandbox environment can be a set of written policies, not necessarily a software implementation of a sandbox. For example, it may permit a team to test the nascent product only on employees of the company and perhaps alpha testers who have signed an NDA, and give no access to sensitive information. It may be allowed to launch product experiments only under newly created brands not tied directly to the company. Perhaps it must operate within a pre-allocated budget for compute.

Within this sandbox, there can be broad scope for experimentation, and â€” importantly â€” a team is free to experiment without frequently needing to ask for permission, because the downside they can create is limited. Further, when a prototype shows sufficient promise to bring it to scale, the company can then invest in making sure the software is reliable, secure, treats sensitive information appropriately, is consistent with the companyâ€™s brand, and so on.

Under this framework, it is easier to build a company culture that encourages learning, building, and experimentation and celebrates even the inevitable failures that now come with modest cost. Dozens or hundreds of prototypes can be built and quickly discarded as part of the price of finding one or two ideas that turn out to be home runs. This also lets teams move quickly as they churn through those dozens of prototypes needed to get to the valuable ones.

I often speak with large companies about AI strategy and implementation. My quick checklist of things to consider is people, process, and platform. This letter has addressed only part of processes, with an emphasis on moving fast. Iâ€™m bullish about what both startups and large companies can do with AI, and I will write about the roles of people and platforms in future letters.

[Original text: https://t.co/Jn1QLnrRlI ]

åœ¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ—¶ä»£ï¼Œå¤§å…¬å¸ â€”â€” ä¸åªæ˜¯åˆåˆ›å…¬å¸ â€”â€” ä¹Ÿèƒ½å¿«é€Ÿè¡ŒåŠ¨ã€‚æˆ‘ç»å¸¸ä¸å¤§å…¬å¸çš„ C çº§é«˜ç®¡ï¼ˆC-suiteï¼‰å’Œè‘£äº‹ä¼šæ¢è®¨ AI æˆ˜ç•¥ä¸å®æ–½ï¼Œåœ¨æ­¤æƒ³åˆ†äº«ä¸€äº›é€‚ç”¨äºå¤§å‹ä¼ä¸šçš„æƒ³æ³•ã€‚å…¶ä¸­ä¸€ä¸ªå…³é”®ï¼Œå°±æ˜¯åˆ›é€ ä¸€ä¸ªç¯å¢ƒï¼Œè®©é‚£äº›å°è€Œç²¾å¹²çš„å›¢é˜Ÿæ— éœ€å±‚å±‚å®¡æ‰¹å°±èƒ½å¤§èƒ†åˆ›æ–°ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†è¯¦ç»†é˜è¿°è¿™ä¸€ç‚¹ã€‚

å¤§å…¬å¸ä¹‹æ‰€ä»¥æ¯”åˆåˆ›å…¬å¸æ…¢ï¼ŒåŸå› æœ‰å¾ˆå¤šã€‚ä½†ä¸ºä»€ä¹ˆå³ä½¿æ˜¯å¤§å…¬å¸å†…éƒ¨ä»…æœ‰ä¸‰äººçš„ç²¾å¹²å›¢é˜Ÿï¼Œå…¶é€Ÿåº¦ä¹Ÿæ¯”åŒç­‰è§„æ¨¡çš„åˆåˆ›å…¬å¸æ…¢å‘¢ï¼Ÿä¸€ä¸ªä¸»è¦åŸå› åœ¨äºï¼Œå¤§å…¬å¸æœ‰æ›´å¤šé¡¾è™‘ï¼Œå®ƒä»¬ä¸èƒ½æ‰¿å—ä¸€ä¸ªå°å‹å›¢é˜Ÿåœ¨å¼€å‘å’Œå‘å¸ƒæŸä¸ªåŠŸèƒ½æ—¶ï¼Œä¸æ…æ³„éœ²æ•æ„Ÿä¿¡æ¯ã€æŸå®³å…¬å¸å“ç‰Œã€å½±å“æ”¶å…¥ã€æ‹›è‡´ç›‘ç®¡å®¡æŸ¥ï¼Œæˆ–ä»¥å…¶ä»–æ–¹å¼å¯¹ä¸šåŠ¡é‡è¦éƒ¨åˆ†é€ æˆæŸå®³ã€‚ä¸ºäº†è§„é¿è¿™äº›é£é™©ï¼Œæˆ‘æ›¾è§è¿‡ä¸€äº›å…¬å¸è¦æ±‚å›¢é˜Ÿåœ¨å‘å¸ƒä»»ä½•å†…å®¹ä¹‹å‰ï¼Œå¿…é¡»ç»è¿‡éšç§å®¡æŸ¥ã€è¥é”€å®¡æŸ¥ã€è´¢åŠ¡å®¡æŸ¥ã€æ³•å¾‹å®¡æŸ¥ç­‰ç­‰ã€‚ç„¶è€Œï¼Œå¦‚æœå·¥ç¨‹å¸ˆä»¬éœ€è¦è·å¾—äº”ä½å‰¯æ€»è£çš„ç­¾å­—æ‰¹å‡†ï¼Œæ‰èƒ½å¯åŠ¨ä¸€ä¸ªæœ€å°å¯è¡Œäº§å“ï¼ˆMVPï¼‰æ¥è¿›è¡Œå®éªŒï¼Œä»–ä»¬åˆå¦‚ä½•èƒ½å¤Ÿå¿«é€Ÿå‘ç°å®¢æˆ·éœ€æ±‚ã€è¿…é€Ÿè¿­ä»£ï¼Œæˆ–å¼€å‘å‡ºä»»ä½•æœ‰æ„ä¹‰çš„æ–°äº§å“å‘¢ï¼Ÿ

å¾—ç›Šäº AI è¾…åŠ©ç¼–ç æŠ€æœ¯ï¼Œç°åœ¨çš„ä¸–ç•Œæ‹¥æœ‰äº†å¿«é€Ÿæ„å»ºè½¯ä»¶åŸå‹çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè®¸å¤šå¤§å…¬å¸ä¸ºé˜²èŒƒåˆæ³•ä¸‹è¡Œé£é™©ï¼ˆdownside riskï¼‰è€Œè®¾è®¡çš„æµç¨‹ï¼Œå´è®©å®ƒä»¬æ— æ³•å……åˆ†åˆ©ç”¨è¿™é¡¹èƒ½åŠ›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œé‚£äº›æ²¡æœ‰æ”¶å…¥ã€æ²¡æœ‰å®¢æˆ·ã€ä¹Ÿæ²¡æœ‰å“ç‰Œå£°èª‰çš„å°å‹åˆåˆ›å…¬å¸ï¼Œå…¶ä¸‹è¡Œé£é™©æ˜¯æœ‰é™çš„ã€‚äº‹å®ä¸Šï¼Œç ´äº§å€’é—­æœ¬èº«å°±æ˜¯ä¸€ç§éå¸¸ç°å®çš„å¯èƒ½æ€§ï¼Œå› æ­¤å¿«é€Ÿè¡ŒåŠ¨æ¯”ä¸ºäº†è§„é¿ä¸‹è¡Œé£é™©è€Œç¼“æ…¢è¡ŒåŠ¨ï¼Œå…·æœ‰æ›´é«˜çš„ä»·å€¼æƒè¡¡ã€‚åœ¨æœ€ç³Ÿç³•çš„æƒ…å†µä¸‹ï¼Œå®ƒæˆ–è®¸åªæ˜¯ä»¥ä¸€ç§æ–°çš„æ–¹å¼èµ°å‘å¤±è´¥ï¼Œä½†å¦‚æœæˆåŠŸï¼Œå®ƒå°†å¯èƒ½åˆ›é€ å·¨å¤§çš„ä»·å€¼ã€‚

å¹¸è¿çš„æ˜¯ï¼Œå¤§å…¬å¸æœ‰åŠæ³•æ‘†è„±è¿™ä¸ªå›°å¢ƒã€‚å®ƒä»¬å¯ä»¥ä¸ºå›¢é˜Ÿåˆ›å»ºä¸€ä¸ªæ²™ç›’ç¯å¢ƒï¼Œè®©å›¢é˜Ÿä»¥ä¸€ç§ä¸¥æ ¼é™åˆ¶ä¸‹è¡Œé£é™©çš„æ–¹å¼è¿›è¡Œå®éªŒã€‚è¿™æ ·ä¸€æ¥ï¼Œè¿™äº›å›¢é˜Ÿå°±å¯ä»¥å¤§å¤§åŠ å¿«é€Ÿåº¦ï¼Œè€Œæ— éœ€ä¸ºäº†è·å¾—ä»»ä½•äººçš„è®¸å¯è€Œæ‹–å»¶ã€‚

è¿™ä¸ªæ²™ç›’ç¯å¢ƒå¯ä»¥æ˜¯ä¸€å¥—ä¹¦é¢æ”¿ç­–ï¼Œä¸ä¸€å®šéè¦é€šè¿‡è½¯ä»¶æ¥å®ç°ã€‚ä¾‹å¦‚ï¼Œå®ƒå¯èƒ½åªå…è®¸å›¢é˜Ÿåœ¨å…¬å¸å‘˜å·¥ä»¥åŠå¯èƒ½å·²ç­¾ç½²ä¿å¯†åè®®ï¼ˆNDAï¼‰çš„æ—©æœŸæµ‹è¯•è€…ï¼ˆalpha testersï¼‰èº«ä¸Šæµ‹è¯•åˆç”Ÿäº§å“ï¼Œå¹¶ä¸”ä¸å…è®¸è®¿é—®æ•æ„Ÿä¿¡æ¯ã€‚å®ƒå¯èƒ½åªè¢«å…è®¸åœ¨ä¸å…¬å¸æ²¡æœ‰ç›´æ¥å…³è”çš„å…¨æ–°å“ç‰Œä¸‹å‘å¸ƒäº§å“å®éªŒã€‚æˆ–è®¸å®ƒå¿…é¡»åœ¨é¢„å…ˆåˆ†é…çš„è®¡ç®—èµ„æºé¢„ç®—å†…è¿è¡Œã€‚

åœ¨è¿™ä¸ªæ²™ç›’å†…éƒ¨ï¼Œå›¢é˜Ÿå¯ä»¥æ‹¥æœ‰å¹¿é˜”çš„å®éªŒç©ºé—´ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œä»–ä»¬å¯ä»¥è‡ªç”±åœ°è¿›è¡Œå®éªŒï¼Œè€Œæ— éœ€é¢‘ç¹åœ°è¯·æ±‚è®¸å¯ï¼Œå› ä¸ºä»–ä»¬å¯èƒ½é€ æˆçš„ä¸‹è¡Œé£é™©æ˜¯æœ‰é™çš„ã€‚æ­¤å¤–ï¼Œå½“ä¸€ä¸ªåŸå‹å±•ç°å‡ºè¶³å¤Ÿçš„æ½œåŠ›å€¼å¾—æ¨å¹¿æ—¶ï¼Œå…¬å¸å°±å¯ä»¥æŠ•å…¥èµ„æºï¼Œç¡®ä¿è½¯ä»¶çš„å¯é æ€§ã€å®‰å…¨æ€§ã€å¯¹æ•æ„Ÿä¿¡æ¯çš„æ°å½“å¤„ç†ã€ç¬¦åˆå…¬å¸å“ç‰Œå½¢è±¡ç­‰ã€‚

åœ¨è¿™ç§æ¡†æ¶ä¸‹ï¼Œæ›´å®¹æ˜“å»ºç«‹ä¸€ç§é¼“åŠ±å­¦ä¹ ã€æ„å»ºå’Œå®éªŒçš„ä¼ä¸šæ–‡åŒ–ï¼Œå¹¶å¯¹é‚£äº›ç°åœ¨ä»¥é€‚åº¦æˆæœ¬å‡ºç°çš„ä¸å¯é¿å…çš„å¤±è´¥åŠ ä»¥è‚¯å®šã€‚ä¸ºäº†æ‰¾åˆ°ä¸€ä¸¤ä¸ªã€Œå…¨å’æ‰“ã€ï¼ˆæŒ‡è·å¾—å·¨å¤§æˆåŠŸï¼‰èˆ¬çš„åˆ›æ„ï¼Œå¯ä»¥æ„å»ºæ•°åç”šè‡³æ•°ç™¾ä¸ªåŸå‹ï¼Œå¹¶è¿…é€Ÿæ·˜æ±°ï¼Œè¿™éƒ½æ˜¯æ¢ç´¢è¿‡ç¨‹ä¸­å¿…é¡»ä»˜å‡ºçš„ä»£ä»·ã€‚è¿™ä¹Ÿä½¿å¾—å›¢é˜Ÿåœ¨å¿«é€Ÿè¿­ä»£è¿™äº›ä¸ºäº†æ‰¾åˆ°æœ‰ä»·å€¼åˆ›æ„æ‰€éœ€çš„æ•°åä¸ªåŸå‹æ—¶ï¼Œèƒ½å¤Ÿè¿…é€Ÿè¡ŒåŠ¨ã€‚

æˆ‘ç»å¸¸ä¸å¤§å…¬å¸æ¢è®¨ AI æˆ˜ç•¥ä¸å®æ–½ã€‚æˆ‘çš„å¿«é€Ÿæ ¸å¯¹æ¸…å•é€šå¸¸ä¼šè€ƒè™‘ä¸‰ä¸ªæ–¹é¢ï¼šäººæ‰ï¼ˆpeopleï¼‰ã€æµç¨‹ï¼ˆprocessï¼‰å’Œå¹³å°ï¼ˆplatformï¼‰ã€‚æœ¬æ–‡åªæ¢è®¨äº†æµç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œé‡ç‚¹æ˜¯å¿«é€Ÿè¡ŒåŠ¨ã€‚æˆ‘å¯¹åˆåˆ›å…¬å¸å’Œå¤§å…¬å¸åˆ©ç”¨ AI æ‰€èƒ½åšçš„äº‹æƒ…å……æ»¡ä¿¡å¿ƒï¼Œæœªæ¥æˆ‘å°†åœ¨å…¶ä»–æ–‡ç« ä¸­è®¨è®ºäººæ‰å’Œå¹³å°çš„ä½œç”¨ã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/Jn1QLnrRlI]

### 073

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-27
é“¾æ¥: https://x.com/AndrewYNg/status/1927384264779170259
äº’åŠ¨: Likes: 3,820; Retweets: 605; Replies: 97; Quotes: 25; Views: 288,036; Bookmarks: 4,081; isReply: 0

Agentic Document Extraction just got much faster! From previous 135sec median processing time down to 8sec. Extracts not just text but diagrams, charts, and form fields from PDFs to give LLM-ready output. Please see the video for details and some application ideas. https://t.co/29lOKf6UGO

åŸºäº AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰çš„æ–‡æ¡£æå–æŠ€æœ¯é€Ÿåº¦å˜å¾—æ›´å¿«äº†ï¼å…¶å¤„ç†æ—¶é—´å·²ä»ä¹‹å‰çš„å¹³å‡ 135 ç§’å¤§å¹…ç¼©çŸ­è‡³ 8 ç§’ã€‚è¿™é¡¹æŠ€æœ¯ä¸ä»…èƒ½ä» PDF æ–‡æ¡£ä¸­æå–æ–‡æœ¬ï¼Œè¿˜èƒ½è¯†åˆ«å¹¶æå–å…¶ä¸­çš„ç¤ºæ„å›¾ã€å›¾è¡¨å’Œè¡¨å•å­—æ®µï¼Œä»è€Œæä¾›å¯ä»¥ç›´æ¥ç”¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°æ®è¾“å‡ºã€‚æœ‰å…³æ›´å¤šç»†èŠ‚å’Œåº”ç”¨åœºæ™¯çš„å¯å‘ï¼Œè¯·è§‚çœ‹æ­¤è§†é¢‘ï¼šhttps://t.co/29lOKf6UGO

### 074

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-05-29
é“¾æ¥: https://x.com/AndrewYNg/status/1928099650269237359
äº’åŠ¨: Likes: 2,655; Retweets: 473; Replies: 106; Quotes: 48; Views: 323,701; Bookmarks: 471; isReply: 0

I am alarmed by the proposed cuts to U.S. funding for basic research, and the impact this would have for U.S. competitiveness in AI and other areas. Funding research that is openly shared benefits the whole world, but the nation it benefits most is the one where the research is done.

If not for funding for my early work in deep learning from the National Science Foundation (NSF)  and Defense Advanced Research Projects Agency (DARPA), which disburse a good deal of U.S. research funding, I would not have discovered lessons about scaling that led me to pitch starting Google Brain to scale up deep learning. I am worried that cuts to funding for basic science will lead the U.S. â€” and also the world â€” to miss out on the next set of ideas.

In fact, such funding benefits the U.S. more than any other nation.  Scientific research brings the greatest benefit to the country where the work happens because (i) the new knowledge diffuses fastest within that country, and (ii) the process of doing research creates new talent for that nation.

Why does most innovation in generative AI still happen in Silicon Valley? Because two teams based in this area â€” Google Brain, which invented the transformer network, and OpenAI, which scaled it up â€” did a lot of the early work. Subsequently, team members moved to other nearby businesses, started competitors, or worked with local universities. Further, local social networks rapidly diffused the knowledge through casual coffee meetings, local conferences, and even childrenâ€™s play dates, where parents of like-aged kids meet and discuss technical ideas. In this way, the knowledge spread faster within Silicon Valley than to other geographies.

In a similar vein, research done in the U.S. diffuses to others in the U.S. much faster than to other geographic areas. This is particularly true when the research is openly shared through papers and/or open source: If researchers have permission to talk about an idea, they can share much more information, such as tips and tricks for how to really make an algorithm work, more quickly. It also lets others figure out faster who can answer their questions. Diffusion of knowledge created in academic environments is especially fast. Academia tends to be completely open, and students and professors, unlike employees of many companies, have full permission to talk about their work.

Thus funding basic research in the U.S. benefits the U.S. most, and also benefits our allies. It is true that openness benefits our adversaries, too. But as a subcommittee of the U.S. House of Representatives committee on science, space, and technology points out, â€œ... open sharing of fundamental research is [not] without risk. Rather, ... openness in research is so important to competitiveness and security that it warrants the risk that adversaries may benefit from scientific openness as well.â€

Further, generative AI is evolving so rapidly that staying on the cutting edge is whatâ€™s really critical. For example, the fact that many teams can now train a model with GPT-3.5- or even GPT-4-level capability does not seem to be hurting OpenAI much, which is busy growing its business by developing the cutting-edge o4, Codex, GPT-4.1, and so on. Those who invent a technology get to commercialize it first, and in a fast-moving world, the cutting-edge technology is whatâ€™s most valuable. Some studies (link in original post, below) also show how knowledge diffuses locally much faster than globally.

China was decisively behind the U.S. in generative AI when ChatGPT was first launched in 2022. However, Chinaâ€™s tech ecosystem is very open internally, and this has helped it to catch up over the past two years:
- There is ample funding for open academic research in China.
- Chinaâ€™s businesses such as DeepSeek and Alibaba have released cutting-edge, open-weights models. This openness at the corporate level accelerates diffusion of knowledge.
- Chinaâ€™s labor laws make non-compete agreements (which stop an employee from jumping ship to a competitor) relatively hard to enforce, and the work culture supports significant idea sharing among employees of different companies; this has made circulation of ideas relatively efficient.

While thereâ€™s also much about China that I would not want the U.S. to emulate, the openness of its tech ecosystem has helped it accelerate.

In 1945, Vannevar Bushâ€™s landmark report â€œScience, The Endless Frontierâ€ laid down key principles for public funding of U.S. research and talent development. Those principles enabled the U.S. to dominate scientific progress for decades. U.S. federal funding for science created numerous breakthroughs that have benefited the U.S. tremendously, and also the world, while training generations of domestic scientists, as well as immigrants who likewise benefit the U.S.

The good news is that this playbook is now well known. I hope many more nations will imitate it and invest heavily in science and talent. And I hope that, having pioneered this very successful model, the U.S. will not pull back from it by enacting drastic cuts to funding scientific research.

[Original post, with links: https://t.co/JR3x4O1iVr ]

ç¾å›½æ‹Ÿè®®å‰Šå‡åŸºç¡€ç ”ç©¶èµ„é‡‘çš„è®¡åˆ’ï¼Œä»¥åŠè¿™å¯èƒ½å¯¹ç¾å›½åœ¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åŠå…¶ä»–é¢†åŸŸçš„ç«äº‰åŠ›é€ æˆçš„å½±å“ï¼Œè®©æˆ‘æ·±æ„Ÿå¿§è™‘ã€‚å°½ç®¡å¯¹å¼€æ”¾å…±äº«ç ”ç©¶çš„èµ„åŠ©æƒ åŠå…¨çƒï¼Œä½†å—ç›Šæœ€å¤§çš„æ— ç–‘æ˜¯å¼€å±•è¿™é¡¹ç ”ç©¶çš„å›½å®¶ã€‚

å¦‚æœå½“åˆæ²¡æœ‰å›½å®¶ç§‘å­¦åŸºé‡‘ä¼šï¼ˆNSFï¼‰å’Œå›½é˜²é«˜çº§ç ”ç©¶è®¡åˆ’å±€ï¼ˆDARPAï¼‰å¯¹æˆ‘æ—©æœŸæ·±åº¦å­¦ä¹ å·¥ä½œçš„èµ„åŠ©ï¼ˆè¿™ä¸¤ä¸ªæœºæ„è´Ÿè´£åˆ†é…ç¾å›½å¤§éƒ¨åˆ†ç ”ç©¶ç»è´¹ï¼‰ï¼Œæˆ‘å°±ä¸ä¼šåœ¨æ‰©å±•æ–¹é¢æœ‰æ‰€å‘ç°ï¼Œè¿™äº›å‘ç°ä¿ƒä½¿æˆ‘æè®®æˆç«‹ Google Brain æ¥å¤§è§„æ¨¡å‘å±•æ·±åº¦å­¦ä¹ ã€‚æˆ‘æ‹…å¿ƒï¼Œä¸€æ—¦åŸºç¡€ç§‘å­¦çš„èµ„é‡‘é­åˆ°å‰Šå‡ï¼Œç¾å›½ä¹ƒè‡³å…¨ä¸–ç•Œéƒ½å°†é”™å¤±æœªæ¥çš„é‡è¦æ–°æ€æ½®ã€‚

äº‹å®ä¸Šï¼Œè¿™ç§èµ„åŠ©æ¨¡å¼è®©ç¾å›½æ¯”å…¶ä»–ä»»ä½•å›½å®¶éƒ½å—ç›ŠåŒªå¤šã€‚ç§‘å­¦ç ”ç©¶èƒ½ä¸ºæ‰€åœ¨å›½å¸¦æ¥æœ€å¤§ç›Šå¤„ï¼ŒåŸå› æœ‰äºŒï¼š(1ï¼‰æ–°çŸ¥è¯†åœ¨è¯¥å›½ä¼ æ’­å¾—æœ€å¿«ï¼›ï¼ˆ2ï¼‰ç ”ç©¶è¿‡ç¨‹æœ¬èº«å°±èƒ½ä¸ºè¯¥å›½åŸ¹å…»å‡ºæ–°çš„ä¸“ä¸šäººæ‰ã€‚

ä¸ºä»€ä¹ˆç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰çš„å¤§éƒ¨åˆ†åˆ›æ–°ä»ç„¶å‘ç”Ÿåœ¨ç¡…è°·å‘¢ï¼Ÿå› ä¸ºè¯¥åœ°åŒºæœ‰ä¸¤ä¸ªå›¢é˜Ÿ â€”â€” å‘æ˜äº† Transformer ç½‘ç»œçš„ Google Brain å’Œå°†å…¶è§„æ¨¡åŒ–çš„ OpenAIâ€”â€” å®Œæˆäº†å¤§é‡æ—©æœŸå·¥ä½œã€‚éšåï¼Œè¿™äº›å›¢é˜Ÿæˆå‘˜æœ‰çš„è·³æ§½åˆ°é™„è¿‘çš„å•†ä¸šå…¬å¸ï¼Œæœ‰çš„åˆ›åŠäº†ç«äº‰å¯¹æ‰‹ï¼Œè¿˜æœ‰çš„ä¸å½“åœ°å¤§å­¦åˆä½œã€‚æ­¤å¤–ï¼Œå½“åœ°çš„ç¤¾äº¤ç½‘ç»œä¹Ÿé€šè¿‡éšæ„çš„å’–å•¡èšä¼šã€æœ¬åœ°ä¼šè®®ï¼Œç”šè‡³å„¿ç«¥ç©ä¼´èšä¼šï¼ˆåŒé¾„å­©å­çš„çˆ¶æ¯åœ¨è¿™äº›åœºåˆè§é¢å¹¶äº¤æµæŠ€æœ¯æƒ³æ³•ï¼‰ï¼Œè¿…é€Ÿä¼ æ’­äº†çŸ¥è¯†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒçŸ¥è¯†åœ¨ç¡…è°·å†…éƒ¨çš„ä¼ æ’­é€Ÿåº¦è¿œè¶…å…¶ä»–åœ°åŒºã€‚

åŒç†ï¼Œåœ¨ç¾å›½å¼€å±•çš„ç ”ç©¶ï¼Œå…¶çŸ¥è¯†åœ¨ç¾å›½å›½å†…çš„æ‰©æ•£é€Ÿåº¦ä¹Ÿè¿œå¿«äºå‘å…¶ä»–åœ°ç†åŒºåŸŸçš„ä¼ æ’­ã€‚å½“ç ”ç©¶æˆæœé€šè¿‡è®ºæ–‡å’Œ / æˆ–å¼€æºå½¢å¼å…¬å¼€åˆ†äº«æ—¶ï¼Œè¿™ç§ç°è±¡å°¤ä¸ºæ˜¾è‘—ï¼šå¦‚æœç ”ç©¶äººå‘˜è·å‡†è®¨è®ºæŸä¸ªæƒ³æ³•ï¼Œä»–ä»¬å°±èƒ½æ›´å¿«åœ°åˆ†äº«æ›´å¤šä¿¡æ¯ï¼Œä¾‹å¦‚å¦‚ä½•çœŸæ­£è®©æŸä¸ªç®—æ³•å¥æ•ˆçš„è¯€çªå’ŒæŠ€å·§ã€‚è¿™ä¹Ÿèƒ½è®©å…¶ä»–äººæ›´å¿«åœ°æ‰¾åˆ°èƒ½è§£ç­”ä»–ä»¬ç–‘é—®çš„ä¸“å®¶ã€‚å­¦æœ¯ç¯å¢ƒä¸­äº§ç”Ÿçš„çŸ¥è¯†ä¼ æ’­å°¤å…¶è¿…é€Ÿã€‚å­¦æœ¯ç•Œé€šå¸¸æ˜¯å®Œå…¨å¼€æ”¾çš„ï¼Œå­¦ç”Ÿå’Œæ•™æˆä¸è®¸å¤šå…¬å¸çš„å‘˜å·¥ä¸åŒï¼Œä»–ä»¬æ‹¥æœ‰å……åˆ†çš„è‡ªç”±æ¥è°ˆè®ºè‡ªå·±çš„ç ”ç©¶å·¥ä½œã€‚

å› æ­¤ï¼Œèµ„åŠ©ç¾å›½çš„åŸºç¡€ç ”ç©¶ä¸ä»…å¯¹ç¾å›½æœ€æœ‰åˆ©ï¼Œä¹Ÿå¯¹æˆ‘ä»¬çš„ç›Ÿå‹å¤§æœ‰è£¨ç›Šã€‚å½“ç„¶ï¼Œå¼€æ”¾æ€§ä¹Ÿä¼šæƒ åŠæˆ‘ä»¬çš„å¯¹æ‰‹ã€‚ä½†æ­£å¦‚ç¾å›½ä¼—è®®é™¢ç§‘å­¦ã€ç©ºé—´å’ŒæŠ€æœ¯å§”å‘˜ä¼šçš„ä¸€ä¸ªå°ç»„å§”å‘˜ä¼šæ‰€æŒ‡å‡ºçš„é‚£æ ·ï¼šã€Œ... å…¬å¼€å…±äº«åŸºç¡€ç ”ç©¶å¹¶éæ²¡æœ‰é£é™©ã€‚ä½†â€¦â€¦ ç ”ç©¶çš„å¼€æ”¾æ€§å¯¹äºç«äº‰åŠ›å’Œå®‰å…¨è‡³å…³é‡è¦ï¼Œä»¥è‡³äºå®ƒæ‰€å¸¦æ¥çš„é£é™©ï¼Œå³å¯¹æ‰‹ä¹Ÿå¯èƒ½ä»ç§‘å­¦å¼€æ”¾ä¸­å—ç›Šï¼Œæ˜¯å€¼å¾—æ‰¿æ‹…çš„ã€‚ã€

æ­¤å¤–ï¼Œç”Ÿæˆå¼ AI çš„å‘å±•æ—¥æ–°æœˆå¼‚ï¼Œå› æ­¤ä¿æŒé¢†å…ˆåœ°ä½è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ï¼Œå°½ç®¡ç°åœ¨è®¸å¤šå›¢é˜Ÿéƒ½èƒ½è®­ç»ƒå‡ºè¾¾åˆ° GPT-3.5 ç”šè‡³ GPT-4 çº§åˆ«èƒ½åŠ›çš„æ¨¡å‹ï¼Œä½†è¿™ä¼¼ä¹å¹¶æœªå¯¹ OpenAI é€ æˆå¤ªå¤§å†²å‡»ã€‚OpenAI æ­£åœ¨å¿™äºé€šè¿‡å¼€å‘å°–ç«¯çš„ o4ã€Codexã€GPT-4.1 ç­‰æ¥æ‹“å±•å…¶ä¸šåŠ¡ã€‚æŠ€æœ¯å‘æ˜è€…èƒ½å¤Ÿç‡å…ˆå°†å…¶å•†ä¸šåŒ–ï¼Œè€Œåœ¨ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„ä¸–ç•Œä¸­ï¼Œå°–ç«¯æŠ€æœ¯æ— ç–‘æ˜¯æœ€å…·ä»·å€¼çš„ã€‚ä¸€äº›ç ”ç©¶ ï¼ˆè¯¦è§ä¸‹æ–‡åŸå§‹å¸–å­é“¾æ¥ï¼‰ä¹Ÿè¡¨æ˜ï¼ŒçŸ¥è¯†åœ¨æœ¬åœ°ä¼ æ’­çš„é€Ÿåº¦è¿œå¿«äºå…¨çƒä¼ æ’­ã€‚

2022 å¹´ ChatGPT é¦–æ¬¡æ¨å‡ºæ—¶ï¼Œä¸­å›½åœ¨ç”Ÿæˆå¼ AI é¢†åŸŸæ˜æ˜¾è½åäºç¾å›½ã€‚ç„¶è€Œï¼Œä¸­å›½çš„æŠ€æœ¯ç”Ÿæ€ç³»ç»Ÿå†…éƒ¨éå¸¸å¼€æ”¾ï¼Œè¿™å¸®åŠ©å®ƒåœ¨è¿‡å»ä¸¤å¹´ä¸­è¿å¤´èµ¶ä¸Šï¼š
- ä¸­å›½ä¸ºå¼€æ”¾çš„å­¦æœ¯ç ”ç©¶æä¾›äº†å……è¶³çš„èµ„é‡‘æ”¯æŒã€‚
- åƒ DeepSeek å’Œ Alibaba è¿™æ ·çš„ä¸­å›½ä¼ä¸šå·²ç»å‘å¸ƒäº†å°–ç«¯çš„å¼€æºæ¨¡å‹ï¼ˆopen-weights modelsï¼‰ã€‚è¿™ç§ä¼ä¸šå±‚é¢çš„å¼€æ”¾æ€§æå¤§åœ°åŠ é€Ÿäº†çŸ¥è¯†çš„ä¼ æ’­ã€‚
- ä¸­å›½çš„åŠ³åŠ¨æ³•ä½¿å¾—ç«ä¸šç¦æ­¢åè®® ï¼ˆé˜»æ­¢å‘˜å·¥è·³æ§½åˆ°ç«äº‰å¯¹æ‰‹å…¬å¸ï¼‰ç›¸å¯¹éš¾ä»¥æ‰§è¡Œï¼Œå¹¶ä¸”å·¥ä½œæ–‡åŒ–æ”¯æŒä¸åŒå…¬å¸å‘˜å·¥ä¹‹é—´è¿›è¡Œå¤§é‡æ€æƒ³äº¤æµï¼›è¿™ä½¿å¾—æ€æƒ³çš„æµé€šæ•ˆç‡ç›¸å¯¹è¾ƒé«˜ã€‚

è™½ç„¶ä¸­å›½åœ¨è®¸å¤šæ–¹é¢æˆ‘å¹¶ä¸å¸Œæœ›ç¾å›½æ•ˆä»¿ï¼Œä½†å…¶æŠ€æœ¯ç”Ÿæ€ç³»ç»Ÿçš„å¼€æ”¾æ€§ç¡®å®å¸®åŠ©å®ƒå®ç°äº†åŠ é€Ÿå‘å±•ã€‚

1945 å¹´ï¼ŒVannevar Bush é‚£ä»½é‡Œç¨‹ç¢‘å¼çš„æŠ¥å‘Šã€Šç§‘å­¦ï¼Œæ— å°½çš„å‰æ²¿ã€‹ä¸ºç¾å›½ç ”ç©¶å’Œäººæ‰åŸ¹å…»çš„å…¬å…±èµ„åŠ©å¥ å®šäº†å…³é”®åŸåˆ™ã€‚è¿™äº›åŸåˆ™ä½¿å¾—ç¾å›½å¾—ä»¥åœ¨ç§‘å­¦è¿›æ­¥æ–¹é¢ä¸»å¯¼æ•°åå¹´ã€‚ç¾å›½è”é‚¦å¯¹ç§‘å­¦çš„èµ„åŠ©åˆ›é€ äº†æ— æ•°çªç ´ï¼Œä¸ä»…æå¤§åœ°é€ ç¦äº†ç¾å›½ï¼Œä¹Ÿæƒ åŠäº†å…¨ä¸–ç•Œï¼ŒåŒæ—¶åŸ¹å…»äº†å‡ ä»£æœ¬åœŸç§‘å­¦å®¶ä»¥åŠåŒæ ·è´¡çŒ®å“è‘—çš„ç§»æ°‘äººæ‰ã€‚

ä»¤äººæ¬£æ…°çš„æ˜¯ï¼Œè¿™å¥—æˆåŠŸç­–ç•¥å¦‚ä»Šå·²æ˜¯ä¼—æ‰€å‘¨çŸ¥ã€‚æˆ‘å¸Œæœ›æœ‰æ›´å¤šå›½å®¶èƒ½å¤Ÿæ•ˆä»¿ï¼Œå¤§åŠ›æŠ•èµ„ç§‘å­¦å’Œäººæ‰ã€‚æˆ‘ä¹Ÿå¸Œæœ›ï¼Œä½œä¸ºè¿™ä¸€æˆåŠŸæ¨¡å¼çš„å¼€åˆ›è€…ï¼Œç¾å›½ä¸ä¼šé€šè¿‡å¤§å¹…å‰Šå‡ç§‘å­¦ç ”ç©¶èµ„é‡‘è€ŒèƒŒç¦»å®ƒã€‚

[åŸæ–‡é“¾æ¥ï¼š https://t.co/JR3x4O1iVr]

### 075

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-03
é“¾æ¥: https://x.com/AndrewYNg/status/1929906213208113409
äº’åŠ¨: Likes: 2,278; Retweets: 427; Replies: 79; Quotes: 24; Views: 159,465; Bookmarks: 1,339; isReply: 0

Everyone should learn to code with AI! At AI Fund, everyone - not just engineers - can vibe code or use AI assistance to code. This has been great for our creativity and productivity. I hope more teams will  empower everyone to build with AI. Please watch the  video for details. https://t.co/rsGC1QSKHL

æ¯ä¸ªäººéƒ½åº”è¯¥å­¦ä¹ å¦‚ä½•ç”¨ AIï¼ˆäººå·¥æ™ºèƒ½ï¼‰ç¼–ç¨‹ï¼åœ¨ AI Fundï¼Œæ¯ä¸ªäºº â€”â€” ä¸ä»…ä»…æ˜¯å·¥ç¨‹å¸ˆ â€”â€” éƒ½èƒ½äº²èº«ä½“éªŒç¼–ç¨‹æˆ–ä½¿ç”¨ AI è¾…åŠ©ç¼–ç¨‹ã€‚è¿™å¯¹æˆ‘ä»¬çš„åˆ›é€ åŠ›å’Œç”Ÿäº§åŠ›éå¸¸æœ‰ç›Šã€‚æˆ‘å¸Œæœ›æ›´å¤šå›¢é˜Ÿèƒ½å¤Ÿè®©æ¯ä¸ªäººéƒ½åˆ©ç”¨ AI è¿›è¡Œåˆ›é€ ã€‚è¯·è§‚çœ‹è§†é¢‘äº†è§£è¯¦æƒ…ã€‚https://t.co/rsGC1QSKHL

### 076

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-04
é“¾æ¥: https://x.com/AndrewYNg/status/1930277912030392356
äº’åŠ¨: Likes: 1,523; Retweets: 313; Replies: 40; Quotes: 27; Views: 177,674; Bookmarks: 1,319; isReply: 0

New short course: DSPy: Build and Optimize Agentic Apps

DSPy is a powerful open-source framework for automatically tuning prompts for GenAI applications. In this course, you'll learn to use DSPy, together with MLflow. This is built in partnership with @databricks and taught by @ChenMoneyQ, co-lead of the DSPy framework.

Many AI builders spend hours hand-tuning prompts. When given a set of evals, DSPy automates this process. Itâ€™s especially useful for optimizing prompts, including few-shot prompts,  in complex agentic AI workflows. Further, if you switch an application to a newer LLM, performance can degrade if your prompts were optimized to the previous model. DSPy automatically optimizes the entire system for the new LLM as well, using just a few evaluation examples.

This course teaches DSPy works, and best practices for using it. Youâ€™ll write programs using DSPyâ€™s signature-based programming model, debug them with MLflow tracing -- to gain visibility into how different parts of a pipeline, as well as how the overall system, are performing -- and automatically improve their accuracy with DSPy Optimizer.

Please sign up here: https://t.co/bb8uILyepf

æ–°çŸ­æœŸè¯¾ç¨‹ï¼šDSPyï¼šæ„å»ºå’Œä¼˜åŒ–æ™ºèƒ½ä½“åº”ç”¨ï¼ˆAgentic Apps)

DSPy æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å¼€æºæ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨è°ƒæ•´ç”Ÿæˆå¼ AIï¼ˆGenAIï¼‰åº”ç”¨çš„æç¤ºè¯ï¼ˆpromptsï¼‰ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ç»“åˆ MLflow ä½¿ç”¨ DSPyã€‚è¯¥è¯¾ç¨‹ç”± @databricks åˆä½œå¼€å‘ï¼Œå¹¶ç”± DSPy æ¡†æ¶çš„å…±åŒè´Ÿè´£äºº @ChenMoneyQ æˆè¯¾ã€‚

è®¸å¤š AI å¼€å‘è€…èŠ±è´¹å¤§é‡æ—¶é—´æ‰‹åŠ¨è°ƒæ•´æç¤ºè¯ã€‚æœ‰äº† DSPyï¼Œåœ¨æä¾›ä¸€ç»„è¯„ä¼°ï¼ˆevalsï¼‰æ•°æ®åï¼Œå®ƒèƒ½è‡ªåŠ¨å®Œæˆè¿™ä¸€è¿‡ç¨‹ã€‚è¿™å¯¹äºä¼˜åŒ–å¤æ‚æ™ºèƒ½ä½“ AI å·¥ä½œæµä¸­çš„æç¤ºè¯ï¼ˆåŒ…æ‹¬å°‘æ ·æœ¬ï¼ˆfew-shotï¼‰æç¤ºè¯ï¼‰å°¤å…¶æœ‰ç”¨ã€‚æ­¤å¤–ï¼Œå¦‚æœä½ çš„åº”ç”¨ç¨‹åºåˆ‡æ¢åˆ°æ›´æ–°çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè€Œæç¤ºè¯æ˜¯ä¸ºæ—§æ¨¡å‹ä¼˜åŒ–çš„ï¼Œæ€§èƒ½å¯èƒ½ä¼šéšä¹‹ä¸‹é™ã€‚DSPy èƒ½å¤Ÿåˆ©ç”¨å°‘é‡è¯„ä¼°ç¤ºä¾‹ï¼Œè‡ªåŠ¨ä¸ºæ–°çš„å¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ•´ä¸ªç³»ç»Ÿã€‚

æœ¬è¯¾ç¨‹å°†è®²è§£ DSPy çš„å·¥ä½œåŸç†åŠå…¶æœ€ä½³å®è·µã€‚ä½ å°†ä½¿ç”¨ DSPy åŸºäºç­¾åçš„ç¼–ç¨‹æ¨¡å‹æ¥ç¼–å†™ç¨‹åºï¼Œå¹¶å€ŸåŠ© MLflow è¿½è¸ªï¼ˆtracingï¼‰è¿›è¡Œè°ƒè¯• â€”â€” è¿™å°†å¸®åŠ©ä½ æ¸…æ™°äº†è§£ç®¡é“ï¼ˆpipelineï¼‰çš„å„ä¸ªéƒ¨åˆ†ä»¥åŠæ•´ä¸ªç³»ç»Ÿçš„è¿è¡Œè¡¨ç° â€”â€” æœ€åé€šè¿‡ DSPy Optimizer è‡ªåŠ¨æé«˜ç¨‹åºçš„å‡†ç¡®æ€§ã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/bb8uILyepf

### 077

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-04
é“¾æ¥: https://x.com/AndrewYNg/status/1930320263780151402
äº’åŠ¨: Likes: 299; Retweets: 77; Replies: 13; Quotes: 1; Views: 61,537; Bookmarks: 50; isReply: 0

Thank you for your pioneering research work @lateinteraction on DSPy (together with @matei_zaharia, @ChrisGPotts and many others). I'm glad we could do a short course on this!

æ„Ÿè°¢ @lateinteraction åœ¨ DSPy æ–¹é¢çš„å¼€åˆ›æ€§ç ”ç©¶å·¥ä½œï¼ˆè¿™é¡¹å·¥ä½œä¹Ÿç¦»ä¸å¼€ @matei_zahariaã€@ChrisGPotts ä»¥åŠå…¶ä»–è®¸å¤šäººçš„è´¡çŒ®ï¼‰ã€‚æˆ‘å¾ˆé«˜å…´æˆ‘ä»¬èƒ½å°±æ­¤å¼€è®¾ä¸€é—¨çŸ­æœŸè¯¾ç¨‹ï¼

### 078

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-06
é“¾æ¥: https://x.com/AndrewYNg/status/1931072122853691639
äº’åŠ¨: Likes: 722; Retweets: 148; Replies: 62; Quotes: 9; Views: 77,924; Bookmarks: 94; isReply: 0

Hanging out with @juberti , OpenAIâ€™s head of realtime AI, responsible for the companyâ€™s voice AI products. One thing both of us agree on: while some things in AI are overhyped, voice applications seem underhyped right now. The application opportunities seem larger than the amount of developer or business attention on this right now.

ä¸ OpenAI å®æ—¶ AIï¼ˆrealtime AIï¼‰è´Ÿè´£äºº @juberti äº¤æµæ—¶ï¼Œä»–è´Ÿè´£å…¬å¸æ——ä¸‹çš„è¯­éŸ³ AIï¼ˆvoice AIï¼‰äº§å“ã€‚æˆ‘ä»¬éƒ½ä¸€è‡´è®¤ä¸ºï¼šå°½ç®¡äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰é¢†åŸŸæœ‰äº›æŠ€æœ¯è¢«è¿‡åº¦å®£ä¼ ï¼Œä½†è¯­éŸ³åº”ç”¨ç›®å‰ä¼¼ä¹è¢«ä½ä¼°äº†ã€‚å®ƒæ‰€è•´å«çš„åº”ç”¨æœºä¼šï¼Œè¿œè¶…å½“å‰å¼€å‘è€…æˆ–å•†ä¸šé¢†åŸŸçš„å…³æ³¨åº¦ã€‚

### 079

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-11
é“¾æ¥: https://x.com/AndrewYNg/status/1932822251273093247
äº’åŠ¨: Likes: 843; Retweets: 174; Replies: 41; Quotes: 6; Views: 72,585; Bookmarks: 393; isReply: 0

Learn to build and deploy GenAI pipelines in "Orchestrating Workflows for GenAI Applications", built in partnership with @astronomerio and taught by Kenten Danas, the company's DevRel Senior Manager, and Tamara Fingerlin, developer advocate. 

Many GenAI applications require executing a pipeline comprising many steps. For example, a RAG app for recommending books might ingest and embed book descriptions, store the embeddings in a vector database, and later use the database to retrieve and recommend specific books based on a user query. After having prototyped this -- maybe in a Jupyter notebook -- how do you turn this into a reliable, repeatable workflow to run in production? 

In this short course, youâ€™ll learn to build reliable GenAI pipelines and orchestrate them using the popular open-source tool Airflow 3.0. Youâ€™ll learn to break down a workflow into discrete tasks so that an orchestration framework can schedule tasks to run in the right order at the right time (using time-based or data-aware triggers), and execute tasks in parallel when possible. It can also use retries to recover gracefully from failure (such as transient API rate limits) and provide observability (using Airflow UI) to help you track the status of the pipeline. You'll do this by using Airflow dags, which helps sequence tasks that need to run in a specific order, with clear task dependencies. 

By the end of this course, youâ€™ll know how to turn your prototype Jupyter notebook or Python script into production-ready workflow. 

Please sign up here:  https://t.co/Ei8JZeS0ey

åœ¨ã€Œç¼–æ’ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰åº”ç”¨çš„å·¥ä½œæµã€è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºå’Œéƒ¨ç½² GenAI ç®¡é“ã€‚è¿™é—¨è¯¾ç¨‹æ˜¯ä¸ @astronomerio åˆä½œå¼€å‘çš„ï¼Œç”±è¯¥å…¬å¸ DevRel é«˜çº§ç»ç† Kenten Danas å’Œå¼€å‘è€…å€¡å¯¼è€… Tamara Fingerlin å…±åŒæˆè¯¾ã€‚

è®¸å¤š GenAI åº”ç”¨éƒ½éœ€è¦æ‰§è¡Œä¸€ä¸ªåŒ…å«å¤šä¸ªæ­¥éª¤çš„ç®¡é“ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œä¸€ä¸ªç”¨äºå›¾ä¹¦æ¨èçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval Augmented Generationï¼ŒRAGï¼‰åº”ç”¨ï¼Œå¯èƒ½éœ€è¦è·å–å¹¶åµŒå…¥ï¼ˆembedï¼‰å›¾ä¹¦æè¿°ï¼Œå°†è¿™äº›åµŒå…¥å‘é‡å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œç„¶åæ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œåˆ©ç”¨è¯¥æ•°æ®åº“æ£€ç´¢å¹¶æ¨èç‰¹å®šçš„å›¾ä¹¦ã€‚åœ¨ä½ å®ŒæˆåŸå‹è®¾è®¡ â€”â€” ä¹Ÿè®¸æ˜¯åœ¨ Jupyter notebook ä¸­ â€”â€” ä¹‹åï¼Œå¦‚ä½•å°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªå¯é ã€å¯é‡å¤ã€èƒ½åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šè¿è¡Œçš„å·¥ä½œæµå‘¢ï¼Ÿ

åœ¨è¿™ä¸ªçŸ­æœŸè¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºå¯é çš„ GenAI ç®¡é“ï¼Œå¹¶ä½¿ç”¨æµè¡Œçš„å¼€æºå·¥å…· Airflow 3.0 æ¥ç¼–æ’å®ƒä»¬ã€‚ä½ å°†å­¦ä¹ å¦‚ä½•å°†ä¸€ä¸ªå·¥ä½œæµåˆ†è§£æˆç‹¬ç«‹çš„ä»»åŠ¡ï¼Œä»¥ä¾¿ç¼–æ’æ¡†æ¶èƒ½è®©ä»»åŠ¡åœ¨æ­£ç¡®çš„æ—¶é—´ä»¥æ­£ç¡®çš„é¡ºåºè¿è¡Œï¼ˆé€šè¿‡åŸºäºæ—¶é—´æˆ–æ•°æ®æ„ŸçŸ¥çš„è§¦å‘å™¨ï¼‰ï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹å¹¶è¡Œæ‰§è¡Œä»»åŠ¡ã€‚å®ƒè¿˜èƒ½é€šè¿‡é‡è¯•æœºåˆ¶æ¥å¦¥å–„å¤„ç†æ•…éšœï¼ˆä¾‹å¦‚ä¸´æ—¶çš„ API é€Ÿç‡é™åˆ¶ï¼‰ï¼Œå¹¶æä¾›å¯è§‚æµ‹æ€§ï¼ˆé€šè¿‡ Airflow UIï¼‰æ¥å¸®åŠ©ä½ è¿½è¸ªç®¡é“çš„è¿è¡ŒçŠ¶æ€ã€‚ä½ å°†é€šè¿‡ä½¿ç”¨ Airflow dagsï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰æ¥å®ç°è¿™äº›ï¼Œå®ƒæœ‰åŠ©äºæŒ‰ç‰¹å®šé¡ºåºã€ä»¥æ˜ç¡®çš„ä»»åŠ¡ä¾èµ–å…³ç³»æ¥ç»„ç»‡éœ€è¦è¿è¡Œçš„ä»»åŠ¡ã€‚

å­¦å®Œæœ¬è¯¾ç¨‹åï¼Œä½ å°†çŸ¥é“å¦‚ä½•æŠŠä½ çš„ Jupyter notebook åŸå‹æˆ– Python è„šæœ¬è½¬åŒ–ä¸ºç”Ÿäº§çº§åˆ«çš„å°±ç»ªå·¥ä½œæµã€‚

è¯·åœ¨æ­¤å¤„æŠ¥åï¼š https://t.co/Ei8JZeS0ey

### 080

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-12
é“¾æ¥: https://x.com/AndrewYNg/status/1933185193059516442
äº’åŠ¨: Likes: 4,431; Retweets: 813; Replies: 138; Quotes: 84; Views: 530,992; Bookmarks: 5,754; isReply: 0

Thereâ€™s a new breed of GenAI Application Engineers who can build more-powerful applications faster than was possible before, thanks to generative AI. Individuals who can play this role are highly sought-after by businesses, but the job description is still coming into focus. Let me describe their key skills, as well as the sorts of interview questions I use to identify them.

Skilled GenAI Application Engineers meet two primary criteria: (i) They are able to use the new AI building blocks to quickly build powerful applications. (ii) They are able to use AI assistance to carry out rapid engineering, building software systems in dramatically less time than was possible before. In addition, good product/design instincts are a significant bonus.

AI building blocks. If you own a lot of copies of only a single type of Lego brick, you might be able to build some basic structures. But if you own many types of bricks, you can combine them rapidly to form complex, functional structures. Software frameworks, SDKs, and other such tools are like that. If all you know is how to call a large language model (LLM) API, that's a great start. But if you have a broad range of building block types â€” such as prompting techniques, agentic frameworks, evals, guardrails, RAG, voice stack, async programming, data extraction, embeddings/vectorDBs, model fine tuning, graphDB usage with LLMs, agentic browser/computer use, MCP, reasoning models, and so on â€” then you can create much richer combinations of building blocks.

The number of powerful AI building blocks continues to grow rapidly. But as open-source contributors and businesses make more building blocks available, staying on top of what is available helps you keep on expanding what you can build. Even though new building blocks are created, many building blocks from 1 to 2 years ago (such as eval techniques or frameworks for using vectorDBs) are still very relevant today.

AI-assisted coding. AI-assisted coding tools enable developers to be far more productive, and such tools are advancing rapidly. Github Copilot, first announced in 2021 (and made widely available in 2022), pioneered modern code autocompletion. But shortly after, a new breed of AI-enabled IDEs such as Cursor and Windsurf offered much better code-QA and code generation. As LLMs improved, these AI-assisted coding tools that were built on them improved as well.

Now we have highly agentic coding assistants such as OpenAIâ€™s Codex and Anthropicâ€™s Claude Code (which I really enjoy using and find impressive in its ability to write code, test, and debug autonomously for many iterations). In the hands of skilled engineers â€” who donâ€™t just â€œvibe codeâ€ but deeply understand AI and software architecture fundamentals and can steer a system toward a thoughtfully selected product goal â€” these tools make it possible to build software with unmatched speed and efficiency.

I find that AI-assisted coding techniques become obsolete much faster than AI building blocks, and techniques from 1 or 2 years ago are far from today's best practices. Part of the reason for this might be that, while AI builders might use dozens (hundreds?) of different building blocks, they arenâ€™t likely to use dozens of different coding assistance tools at once, and so the forces of Darwinian competition are stronger among tools. Given the massive investments in this space by  Anthropic, Google, OpenAI, and other players, I expect the frenetic pace of development to continue, but keeping up with the latest developments in AI-assisted coding tools will pay off, since each generation is much better than the last.

Bonus: Product skills. In some companies, engineers are expected to take pixel-perfect drawings of a product, specified in great detail, and write code to implement it. But if a product manager has to specify even the smallest detail, this slows down the team. The shortage of AI product managers exacerbates this problem. I see teams move much faster if GenAI Engineers also have some user empathy as well at basic skill at designing products, so that, given only high-level guidance on what to build (â€œa user interface that lets users see their profiles and change their passwordsâ€), they can make a lot of decisions themselves and build at least a prototype to iterate from.

When interviewing GenAI Application Engineers, I will usually ask about their mastery of AI building blocks and ability to use AI-assisted coding, and sometimes also their product/design instincts. One additional question I've found highly predictive of their skill is, â€œHow do you keep up with the latest developments in AI?â€ Because AI is evolving so rapidly, someone with good strategies for keeping up â€” such as reading The Batch and taking short courses ğŸ˜ƒ, regular hands-on practice building projects, and having a community to talk to â€” really does stay ahead of the game.

[Original post: https://t.co/I3alxNs0vn ]

å¾—ç›Šäºç”Ÿæˆå¼ AIï¼ˆgenerative AIï¼‰ï¼Œä¸€ç±»æ–°å‹çš„ç”Ÿæˆå¼ AI åº”ç”¨ç¨‹åºå·¥ç¨‹å¸ˆï¼ˆGenAI Application Engineersï¼‰æ­£åœ¨å´›èµ·ï¼Œä»–ä»¬èƒ½å¤Ÿä»¥æ¯”ä»¥å¾€æ›´å¿«çš„é€Ÿåº¦æ„å»ºå‡ºæ›´å¼ºå¤§çš„åº”ç”¨ç¨‹åºã€‚å…·å¤‡è¿™ç§èƒ½åŠ›çš„äººæ‰å¤‡å—ä¼ä¸šé’çï¼Œå°½ç®¡ç›®å‰å¯¹è¯¥èŒä½çš„æè¿°ä»åœ¨ä¸æ–­å®Œå–„ä¸­ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†ä»‹ç»ä»–ä»¬çš„å…³é”®æŠ€èƒ½ï¼Œä»¥åŠæˆ‘ç”¨æ¥è¯†åˆ«è¿™ç±»äººæ‰çš„é¢è¯•é—®é¢˜ç±»å‹ã€‚

ä¸€åå‡ºè‰²çš„ç”Ÿæˆå¼ AI åº”ç”¨ç¨‹åºå·¥ç¨‹å¸ˆéœ€æ»¡è¶³ä¸¤å¤§æ ¸å¿ƒæ ‡å‡†ï¼šï¼ˆiï¼‰ä»–ä»¬èƒ½å¤Ÿè¿ç”¨æ–°å‹ AI æ„å»ºæ¨¡å—ï¼ˆAI building blocksï¼‰è¿…é€Ÿå¼€å‘å‡ºå¼ºå¤§çš„åº”ç”¨ç¨‹åºã€‚(iiï¼‰ä»–ä»¬èƒ½å¤Ÿå€ŸåŠ© AI è¾…åŠ©ï¼ˆAI assistanceï¼‰è¿›è¡Œå¿«é€Ÿå·¥ç¨‹ï¼ˆrapid engineeringï¼‰ï¼Œä»¥è¿œè¶…ä»¥å¾€çš„é€Ÿåº¦æ„å»ºè½¯ä»¶ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè‰¯å¥½çš„äº§å“ / è®¾è®¡ç›´è§‰ï¼ˆproduct/design instinctsï¼‰ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åŠ åˆ†é¡¹ã€‚

AI æ„å»ºæ¨¡å—ã€‚å¦‚æœä½ åªæœ‰ä¸€ç§ç±»å‹çš„ä¹é«˜ç§¯æœ¨ï¼ˆLego brickï¼‰ï¼Œä½ æˆ–è®¸èƒ½æ­å‡ºä¸€äº›åŸºæœ¬ç»“æ„ã€‚ä½†å¦‚æœä½ æ‹¥æœ‰å¤šç§ç±»å‹çš„ç§¯æœ¨ï¼Œå°±èƒ½è¿…é€Ÿå°†å®ƒä»¬ç»„åˆèµ·æ¥ï¼Œå½¢æˆå¤æ‚ä¸”åŠŸèƒ½é½å…¨çš„ç»“æ„ã€‚è½¯ä»¶æ¡†æ¶ã€SDK åŠå…¶ä»–ç±»ä¼¼å·¥å…·äº¦æ˜¯å¦‚æ­¤ã€‚å¦‚æœä½ åªçŸ¥é“å¦‚ä½•è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰APIï¼Œè¿™å·²ç»æ˜¯ä¸ªä¸é”™çš„å¼€ç«¯ã€‚ä½†å¦‚æœä½ æŒæ¡äº†å¹¿æ³›çš„æ„å»ºæ¨¡å—ç±»å‹ â€”â€” ä¾‹å¦‚æç¤ºæŠ€æœ¯ï¼ˆprompting techniquesï¼‰ã€æ™ºèƒ½ä½“æ¡†æ¶ï¼ˆagentic frameworksï¼‰ã€è¯„ä¼°ï¼ˆevalsï¼‰ã€æŠ¤æ ï¼ˆguardrailsï¼‰ã€RAGã€è¯­éŸ³å †æ ˆï¼ˆvoice stackï¼‰ã€å¼‚æ­¥ç¼–ç¨‹ï¼ˆasync programmingï¼‰ã€æ•°æ®æå–ï¼ˆdata extractionï¼‰ã€åµŒå…¥ / å‘é‡æ•°æ®åº“ï¼ˆembeddings/vectorDBsï¼‰ã€æ¨¡å‹å¾®è°ƒï¼ˆmodel fine tuningï¼‰ã€å¤§è¯­è¨€æ¨¡å‹ä¸å›¾æ•°æ®åº“ï¼ˆgraphDBï¼‰çš„ç»“åˆä½¿ç”¨ã€æ™ºèƒ½ä½“é©±åŠ¨çš„æµè§ˆå™¨ / è®¡ç®—æœºæ“ä½œï¼ˆagentic browser/computer useï¼‰ã€MCPã€æ¨ç†æ¨¡å‹ï¼ˆreasoning modelsï¼‰ç­‰ç­‰ â€”â€” é‚£ä¹ˆä½ å°±èƒ½åˆ›é€ å‡ºæ›´ä¸°å¯Œå¤šæ ·çš„ç»„åˆã€‚

å¼ºå¤§çš„ AI æ„å»ºæ¨¡å—æ•°é‡æ­£æŒç»­å¿«é€Ÿå¢é•¿ã€‚éšç€å¼€æºè´¡çŒ®è€…å’Œä¼ä¸šä¸æ–­æ¨å‡ºæ›´å¤šæ„å»ºæ¨¡å—ï¼ŒåŠæ—¶äº†è§£è¿™äº›æ–°å·¥å…·å°†å¸®åŠ©ä½ ä¸æ–­æ‹“å±•å¯æ„å»ºçš„èŒƒå›´ã€‚å°½ç®¡æ–°æ¨¡å—å±‚å‡ºä¸ç©·ï¼Œä½†è®¸å¤šä¸€ä¸¤å¹´å‰çš„æ„å»ºæ¨¡å—ï¼ˆä¾‹å¦‚è¯„ä¼°æŠ€æœ¯æˆ–ä½¿ç”¨å‘é‡æ•°æ®åº“çš„æ¡†æ¶ï¼‰åœ¨ä»Šå¤©ä¾ç„¶éå¸¸é‡è¦ã€‚

AI è¾…åŠ©ç¼–ç¨‹ï¼ˆAI-assisted codingï¼‰ã€‚AI è¾…åŠ©ç¼–ç¨‹å·¥å…·æå¤§åœ°æå‡äº†å¼€å‘äººå‘˜çš„ç”Ÿäº§åŠ›ï¼Œå¹¶ä¸”è¿™äº›å·¥å…·æœ¬èº«ä¹Ÿåœ¨é£é€Ÿå‘å±•ã€‚Github Copilot äº 2021 å¹´é¦–æ¬¡å…¬å¸ƒï¼ˆå¹¶äº 2022 å¹´å¹¿æ³›å‘å¸ƒï¼‰ï¼Œç‡å…ˆå¼€å¯äº†ç°ä»£ä»£ç è‡ªåŠ¨è¡¥å…¨çš„æ–°çºªå…ƒã€‚ä½†ä¸ä¹…ä¹‹åï¼ŒCursor å’Œ Windsurf ç­‰æ–°å‹ AI èµ‹èƒ½çš„é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEsï¼‰ä¾¿æä¾›äº†æ›´å‡ºè‰²çš„ä»£ç è´¨é‡ä¿è¯ï¼ˆcode-QAï¼‰å’Œä»£ç ç”ŸæˆåŠŸèƒ½ã€‚éšç€å¤§è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ï¼Œè¿™äº›åŸºäºå¤§è¯­è¨€æ¨¡å‹æ„å»ºçš„ AI è¾…åŠ©ç¼–ç¨‹å·¥å…·ä¹Ÿéšä¹‹å‡çº§ã€‚

å¦‚ä»Šï¼Œæˆ‘ä»¬å·²æ‹¥æœ‰å…·å¤‡é«˜åº¦æ™ºèƒ½ä½“èƒ½åŠ›çš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œä¾‹å¦‚ OpenAI çš„ Codex å’Œ Anthropic çš„ Claude Codeï¼ˆæˆ‘éå¸¸å–œæ¬¢ä½¿ç”¨ï¼Œå¹¶å¯¹å…¶åœ¨å¤šæ¬¡è¿­ä»£ä¸­è‡ªä¸»ç¼–å†™ã€æµ‹è¯•å’Œè°ƒè¯•ä»£ç çš„èƒ½åŠ›å°è±¡æ·±åˆ»ï¼‰ã€‚åœ¨æŠ€è‰ºç²¾æ¹›çš„å·¥ç¨‹å¸ˆæ‰‹ä¸­ â€”â€” é‚£äº›ä¸åªã€Œå‡­æ„Ÿè§‰å†™ä»£ç ã€ï¼Œè€Œæ˜¯æ·±å…¥ç†è§£ AI å’Œè½¯ä»¶æ¶æ„åŸºç¡€ï¼Œå¹¶èƒ½å°†ç³»ç»Ÿå¯¼å‘æ·±æ€ç†Ÿè™‘çš„äº§å“ç›®æ ‡çš„å·¥ç¨‹å¸ˆ â€”â€” è¿™äº›å·¥å…·èƒ½ä»¥æ— ä¸ä¼¦æ¯”çš„é€Ÿåº¦å’Œæ•ˆç‡æ„å»ºè½¯ä»¶ã€‚

æˆ‘å‘ç° AI è¾…åŠ©ç¼–ç¨‹æŠ€æœ¯çš„è¿‡æ—¶é€Ÿåº¦è¿œè¶… AI æ„å»ºæ¨¡å—ï¼Œä¸€ä¸¤å¹´å‰çš„æŠ€æœ¯ä¸å½“ä»Šçš„æœ€ä½³å®è·µå·²ç›¸å»ç”šè¿œã€‚éƒ¨åˆ†åŸå› å¯èƒ½åœ¨äºï¼ŒAI å¼€å‘è€…å¯èƒ½ä¼šä½¿ç”¨å‡ åç§ï¼ˆç”šè‡³å‡ ç™¾ç§ï¼Ÿï¼‰ä¸åŒçš„æ„å»ºæ¨¡å—ï¼Œä½†ä»–ä»¬ä¸å¤ªå¯èƒ½åŒæ—¶ä½¿ç”¨å‡ åç§ä¸åŒçš„ç¼–ç¨‹è¾…åŠ©å·¥å…·ï¼Œå› æ­¤è¿™äº›å·¥å…·ä¹‹é—´çš„ä¼˜èƒœåŠ£æ±°ç«äº‰æ›´ä¸ºæ¿€çƒˆã€‚é‰´äº Anthropicã€Googleã€OpenAI åŠå…¶ä»–å‚ä¸è€…åœ¨è¯¥é¢†åŸŸçš„å·¨å¤§æŠ•å…¥ï¼Œæˆ‘é¢„è®¡å¼€å‘æ­¥ä¼å°†ç»§ç»­ä¿æŒç‹‚çƒ­ï¼Œä½†æŒç»­å…³æ³¨ AI è¾…åŠ©ç¼–ç¨‹å·¥å…·çš„æœ€æ–°è¿›å±•å°†å¸¦æ¥ä¸°åšå›æŠ¥ï¼Œå› ä¸ºæ¯ä¸€ä»£äº§å“éƒ½æ¯”ä¸Šä¸€ä»£æ›´ä¸ºå‡ºè‰²ã€‚

é¢å¤–åŠ åˆ†ï¼šäº§å“æŠ€èƒ½ã€‚åœ¨æŸäº›å…¬å¸ï¼Œå·¥ç¨‹å¸ˆè¢«æœŸæœ›æ ¹æ®é«˜åº¦è¯¦ç»†ã€åƒç´ çº§ç²¾ç¡®çš„äº§å“è®¾è®¡å›¾æ¥ç¼–å†™ä»£ç å®ç°ã€‚ä½†å¦‚æœäº§å“ç»ç†è¿æœ€å°çš„ç»†èŠ‚éƒ½å¿…é¡»æŒ‡å®šï¼Œè¿™ä¼šå¤§å¤§å‡æ…¢å›¢é˜Ÿçš„é€Ÿåº¦ã€‚AI äº§å“ç»ç†çš„çŸ­ç¼ºä½¿å¾—è¿™ä¸ªé—®é¢˜é›ªä¸ŠåŠ éœœã€‚æˆ‘å‘ç°ï¼Œå¦‚æœç”Ÿæˆå¼ AI å·¥ç¨‹å¸ˆåŒæ—¶å…·å¤‡ä¸€å®šçš„ç”¨æˆ·åŒç†å¿ƒå’ŒåŸºæœ¬çš„äº§å“è®¾è®¡æŠ€èƒ½ï¼Œé‚£ä¹ˆåœ¨ä»…è·å¾—é«˜å±‚æ¬¡æŒ‡å¯¼ï¼ˆä¾‹å¦‚ï¼šã€Œä¸€ä¸ªè®©ç”¨æˆ·æŸ¥çœ‹ä¸ªäººèµ„æ–™å’Œæ›´æ”¹å¯†ç çš„ç”¨æˆ·ç•Œé¢ã€ï¼‰çš„æƒ…å†µä¸‹ï¼Œä»–ä»¬å°±èƒ½è‡ªè¡Œåšå‡ºè®¸å¤šå†³ç­–ï¼Œå¹¶è‡³å°‘æ„å»ºä¸€ä¸ªå¯ä¾›è¿­ä»£çš„åŸå‹ï¼Œè¿™æ ·å›¢é˜Ÿçš„è¿›å±•ä¼šå¿«å¾—å¤šã€‚

åœ¨é¢è¯•ç”Ÿæˆå¼ AI åº”ç”¨ç¨‹åºå·¥ç¨‹å¸ˆæ—¶ï¼Œæˆ‘é€šå¸¸ä¼šè¯¢é—®ä»–ä»¬å¯¹ AI æ„å»ºæ¨¡å—çš„æŒæ¡ç¨‹åº¦ä»¥åŠä½¿ç”¨ AI è¾…åŠ©ç¼–ç¨‹çš„èƒ½åŠ›ï¼Œæœ‰æ—¶ä¹Ÿä¼šè€ƒå¯Ÿä»–ä»¬çš„äº§å“ / è®¾è®¡ç›´è§‰ã€‚æˆ‘å‘ç°ï¼Œä¸€ä¸ªé¢å¤–çš„é—®é¢˜å¯¹é¢„æµ‹ä»–ä»¬çš„æŠ€èƒ½éå¸¸æœ‰å¸®åŠ©ï¼Œé‚£å°±æ˜¯ï¼šã€Œæ‚¨å¦‚ä½•è·Ÿä¸Š AI çš„æœ€æ–°å‘å±•ï¼Ÿã€å› ä¸º AI å‘å±•å¦‚æ­¤è¿…é€Ÿï¼Œé‚£äº›æœ‰è‰¯å¥½ç­–ç•¥æ¥è·Ÿè¿›çš„äººæ‰ â€”â€” ä¾‹å¦‚é˜…è¯» The Batch å’Œå‚åŠ çŸ­æœŸè¯¾ç¨‹ ğŸ˜ƒã€å®šæœŸåŠ¨æ‰‹å®è·µé¡¹ç›®ï¼Œå¹¶æ‹¥æœ‰ä¸€ä¸ªå¯ä»¥äº¤æµçš„ç¤¾åŒº â€”â€” ç¡®å®èƒ½ä¿æŒé¢†å…ˆã€‚

[åŸæ–‡é“¾æ¥ï¼š https://t.co/I3alxNs0vn]

### 081

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-18
é“¾æ¥: https://x.com/AndrewYNg/status/1935350552692658202
äº’åŠ¨: Likes: 886; Retweets: 250; Replies: 34; Quotes: 3; Views: 66,483; Bookmarks: 464; isReply: 0

Introducing "Building with Llama 4." This short course is created with @Meta @AIatMeta, and taught by  @asangani7, Director of Partner Engineering for Metaâ€™s AI team.

Metaâ€™s new Llama 4 has added three new models and introduced the Mixture-of-Experts (MoE) architecture to its family of open-weight models, making them more efficient to serve. 

In this course, youâ€™ll work with two of the three new models introduced in Llama 4. First is Maverick, a 400B  parameter model, with 128 experts and 17B active parameters. Second is Scout, a 109B parameter model with 16 experts and 17B active parameters. Maverick and Scout support long context windows of up to a million tokens and 10M tokens, respectively. The latter is enough to support directly inputting even fairly large GitHub repos for analysis!

In hands-on lessons, youâ€™ll build apps using Llama 4â€™s new multimodal capabilities including reasoning across multiple images and image grounding, in which you can identify elements in images. Youâ€™ll also use the official Llama API, work with Llama 4â€™s long-context abilities, and learn about Llamaâ€™s newest open-source tools: its prompt optimization tool that automatically improves system prompts and synthetic data kit that generates high-quality datasets for fine-tuning.

If you need an open model, Llama is a great option, and the Llama 4 family is an important part of any GenAI developer's toolkit. Through this course, youâ€™ll learn to call Llama 4 via API, use its optimization tools, and build features that span text, images, and large context.

Please sign up here: https://t.co/oRFRi9vQNg

éš†é‡æ¨å‡ºã€Œä½¿ç”¨ Llama 4 è¿›è¡Œå¼€å‘ã€è¯¾ç¨‹ã€‚è¿™é—¨çŸ­æœŸè¯¾ç¨‹ç”± @Meta @AIatMeta åˆä½œæ‰“é€ ï¼Œå¹¶ç”± Meta AI å›¢é˜Ÿçš„åˆä½œä¼™ä¼´å·¥ç¨‹æ€»ç›‘ @asangani7 äº²è‡ªæˆè¯¾ã€‚

Meta å…¨æ–°çš„ Llama 4 æ–°å¢äº†ä¸‰æ¬¾æ¨¡å‹ï¼Œå¹¶ä¸ºå…¶å¼€æºæƒé‡æ¨¡å‹å®¶æ—å¼•å…¥äº†ä¸“å®¶æ··åˆï¼ˆMixture-of-Expertsï¼ŒMoEï¼‰æ¶æ„ï¼Œè¿™å¤§å¤§æå‡äº†æ¨¡å‹çš„æœåŠ¡æ•ˆç‡ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†äº²èº«ä½“éªŒ Llama 4 ä¸­å¼•å…¥çš„ä¸‰æ¬¾æ–°æ¨¡å‹ä¸­çš„ä¸¤æ¬¾ã€‚é¦–å…ˆæ˜¯ Maverickï¼Œè¿™æ˜¯ä¸€ä¸ªæ‹¥æœ‰ 4000 äº¿ï¼ˆ400Bï¼‰å‚æ•°çš„æ¨¡å‹ï¼ŒåŒ…å« 128 ä¸ªä¸“å®¶å’Œ 170 äº¿ï¼ˆ17Bï¼‰æ´»è·ƒå‚æ•°ã€‚å…¶æ¬¡æ˜¯ Scoutï¼Œä¸€ä¸ª 1090 äº¿ï¼ˆ109Bï¼‰å‚æ•°æ¨¡å‹ï¼ŒåŒ…å« 16 ä¸ªä¸“å®¶å’Œ 170 äº¿ï¼ˆ17Bï¼‰æ´»è·ƒå‚æ•°ã€‚Maverick å’Œ Scout åˆ†åˆ«æ”¯æŒé«˜è¾¾ä¸€ç™¾ä¸‡ä¸ª Token å’Œä¸€åƒä¸‡ä¸ª Token çš„é•¿ä¸Šä¸‹æ–‡çª—å£ã€‚åè€…ç”šè‡³è¶³ä»¥ç›´æ¥è¾“å…¥ç›¸å½“å¤§çš„ GitHub ä»£ç åº“è¿›è¡Œåˆ†æï¼

åœ¨å®è·µè¯¾ç¨‹ä¸­ï¼Œä½ å°†åˆ©ç”¨ Llama 4 çš„å…¨æ–°å¤šæ¨¡æ€åŠŸèƒ½æ„å»ºåº”ç”¨ç¨‹åºï¼Œè¿™äº›åŠŸèƒ½åŒ…æ‹¬è·¨å¤šä¸ªå›¾åƒè¿›è¡Œæ¨ç†ï¼Œä»¥åŠå›¾åƒå†…å®¹ç†è§£ï¼ˆimage groundingï¼‰ï¼Œé€šè¿‡å®ƒä½ å¯ä»¥è¯†åˆ«å›¾åƒä¸­çš„å…·ä½“å…ƒç´ ã€‚ä½ è¿˜å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å®˜æ–¹ Llama APIï¼Œåˆ©ç”¨ Llama 4 çš„é•¿ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›ï¼Œå¹¶äº†è§£ Llama æœ€æ–°çš„å¼€æºå·¥å…·ï¼šèƒ½å¤Ÿè‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯çš„æç¤ºä¼˜åŒ–å·¥å…·ï¼ˆprompt optimization toolï¼‰ï¼Œä»¥åŠå¯ä»¥ç”Ÿæˆé«˜è´¨é‡å¾®è°ƒæ•°æ®é›†çš„åˆæˆæ•°æ®å·¥å…·åŒ…ï¼ˆsynthetic data kitï¼‰ã€‚

å¦‚æœä½ æ­£åœ¨å¯»æ‰¾ä¸€æ¬¾å¼€æ”¾æ¨¡å‹ï¼ŒLlama æ— ç–‘æ˜¯ç»ä½³é€‰æ‹©ï¼Œè€Œ Llama 4 ç³»åˆ—æ›´æ˜¯ä»»ä½•ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰å¼€å‘äººå‘˜å·¥å…·åŒ…ä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚é€šè¿‡æœ¬è¯¾ç¨‹ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•é€šè¿‡ API è°ƒç”¨ Llama 4ï¼Œä½¿ç”¨å…¶ä¼˜åŒ–å·¥å…·ï¼Œå¹¶æ„å»ºèƒ½å¤Ÿè·¨è¶Šæ–‡æœ¬ã€å›¾åƒå’Œé•¿ä¸Šä¸‹æ–‡çš„åŠŸèƒ½ã€‚

è¯·ç‚¹å‡»æ­¤é“¾æ¥æ³¨å†Œï¼šhttps://t.co/oRFRi9vQNg

### 082

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-19
é“¾æ¥: https://x.com/AndrewYNg/status/1935741989204770837
äº’åŠ¨: Likes: 2,167; Retweets: 396; Replies: 307; Quotes: 69; Views: 520,932; Bookmarks: 316; isReply: 0

One of the most effective things the U.S. or any other nation can do to ensure its competitiveness in AI is to welcome high-skilled immigration and international students who have the potential to become high-skilled. For centuries, the U.S. has welcomed immigrants, and this helped make it a worldwide leader in technology. Letting immigrants and native-born Americans collaborate makes everyone better off. Reversing this stance would have a huge negative impact on U.S. technology development.

I was born in the UK and came to the U.S. on an F-1 student visa as a relatively unskilled and clueless teenager to attend college. Fortunately I gained skills and became less clueless over time. After completing my graduate studies, I started working at Stanford under the OPT (Optional Practical Training) program, and later an H-1B visa, and ended up staying here. Many other immigrants have followed similar paths to contribute to the U.S.

I am very concerned that making visas harder to obtain for students and high-skilled workers, such as the pause in new visa interviews that started last month and a newly chaotic process of visa cancellations, will hurt our ability to attract great students and workers. In addition, many international students without substantial means count on being able to work under OPT to pay off the high cost of a U.S. college degree. Gutting the OPT program, as has been proposed, would both hurt many international studentsâ€™ ability to study here and deprive U.S. businesses of great talent. (This wonâ€™t stop students from wealthy families. But the U.S. should try to attract the best talent without regard to wealth.)

Failure to attract promising students and high-skilled workers would have a huge negative impact on American competitiveness in AI. Indeed, a recent report by the National Security Commission on Artificial Intelligence exhorts the government to â€œstrengthen AI talent through immigration.â€

If talented people do not come to the U.S., will they have an equal impact on global AI development just working somewhere else? Unfortunately, the net impact will be negative. The U.S. has a number of tech hubs including Silicon Valley, Seattle, New York, Boston/Cambridge, Los Angeles, Pittsburgh and Austin, and these hubs concentrate talent and foster innovation. (This is why cities, where people can more easily find each other and collaborate, promote innovation.) Making it harder for AI talent to find each other and collaborate will slow down innovation, and it will take time for new hubs to become as advanced.

Nonetheless, other nations are working hard to attract immigrants who can drive innovation â€” a good move for them! Many have thoughtful programs to attract AI and other talent. There are the UKâ€™s Global Talent Visa, Franceâ€™s French Tech Visa, Australiaâ€™s Global Talent Visa, the UAEâ€™s Golden Visa, Taiwanâ€™s Employment Gold Card, Chinaâ€™s Thousand Talents Plan, and many more. The U.S. is fortunate that many people already want to come here to study and work. Squandering that advantage would be a huge unforced error.

Beyond the matter of national competitiveness, there is the even more important ethical matter of making sure people are treated decently. I have spoken with international students who are terrified that their visas may be canceled arbitrarily. One recently agonized about whether to attend an international conference to present a research paper, because they were worried about being unable to return. In the end, with great sadness, they cancelled their trip. I also spoke with a highly skilled technologist who is in the U.S. on an H-1B visa. Their company shut down, leading them â€” after over a decade in this country, and with few ties to their nation of origin â€” scrambling to find alternative employment that would enable them to stay. 

These stories, and many far worse, are heartbreaking. While I do what I can to help individuals I know personally, it is tragic that we are creating such an uncertain environment for immigrants, that many people who have extraordinary skills and talents will no longer want to come here.

To every immigrant or migrant in the U.S. who is concerned about the current national environment: I see you and empathize with your worries. As an immigrant myself, I will be fighting to protect everyoneâ€™s dignity and right to due process, and to encourage legal immigration, which makes both the U.S. and individuals much better off.

[Full text, with links: https://t.co/6JNJz88Qyq ]

ç¾å›½æˆ–ä»»ä½•å…¶ä»–å›½å®¶ä¸ºç¡®ä¿å…¶åœ¨ AI é¢†åŸŸï¼ˆAI fieldï¼‰çš„ç«äº‰åŠ›ï¼Œæœ€æœ‰æ•ˆçš„ä¸¾æªä¹‹ä¸€å°±æ˜¯æ¬¢è¿é«˜æŠ€èƒ½ç§»æ°‘å’Œæœ‰æ½œåŠ›æˆä¸ºé«˜æŠ€èƒ½äººæ‰çš„å›½é™…å­¦ç”Ÿã€‚å‡ ä¸ªä¸–çºªä»¥æ¥ï¼Œç¾å›½ä¸€ç›´å¼ å¼€åŒè‡‚æ¬¢è¿ç§»æ°‘ï¼Œè¿™æ­£æ˜¯å…¶æˆä¸ºå…¨çƒæŠ€æœ¯é¢†å¯¼è€…çš„åŸå› ä¹‹ä¸€ã€‚è®©ç§»æ°‘å’Œæœ¬åœŸå‡ºç”Ÿçš„ç¾å›½äººæºæ‰‹åˆä½œï¼Œèƒ½è®©æ‰€æœ‰äººéƒ½å—ç›Šã€‚åè½¬è¿™ä¸€ç«‹åœºï¼Œå°†å¯¹ç¾å›½çš„æŠ€æœ¯å‘å±•é€ æˆå·¨å¤§çš„è´Ÿé¢å½±å“ã€‚

æˆ‘å‡ºç”Ÿåœ¨è‹±å›½ï¼Œåå‡ å²æ—¶ä»¥ä¸€ä¸ªç›¸å¯¹ç¼ºä¹ç»éªŒã€æ‡µæ‡‚æ— çŸ¥çš„å°‘å¹´èº«ä»½ï¼ŒæŒ F-1 å­¦ç”Ÿç­¾è¯æ¥åˆ°ç¾å›½ä¸Šå¤§å­¦ã€‚å¹¸è¿çš„æ˜¯ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œæˆ‘é€æ¸ä¹ å¾—æŠ€èƒ½ï¼Œå˜å¾—ä¸å†é‚£ä¹ˆæ‡µæ‡‚ã€‚å®Œæˆç ”ç©¶ç”Ÿå­¦ä¸šåï¼Œæˆ‘é€šè¿‡ OPTï¼ˆOptional Practical Trainingï¼‰é¡¹ç›®å¼€å§‹åœ¨æ–¯å¦ç¦å¤§å­¦å·¥ä½œï¼Œåæ¥åˆè·å¾—äº† H-1B ç­¾è¯ï¼Œå¹¶æœ€ç»ˆç•™åœ¨äº†è¿™é‡Œã€‚è®¸å¤šå…¶ä»–ç§»æ°‘ä¹Ÿå¾ªç€ç±»ä¼¼çš„è·¯å¾„ï¼Œä¸ºç¾å›½åšå‡ºäº†è´¡çŒ®ã€‚

æˆ‘éå¸¸æ‹…å¿§ï¼Œè®©å­¦ç”Ÿå’Œé«˜æŠ€èƒ½äººæ‰æ›´éš¾è·å¾—ç­¾è¯ï¼Œä¾‹å¦‚ä¸Šä¸ªæœˆå¼€å§‹æš‚åœæ–°çš„ç­¾è¯é¢è¯•ï¼Œä»¥åŠæ–°è¿‘å‡ºç°çš„æ··ä¹±çš„ç­¾è¯å–æ¶ˆæµç¨‹ï¼Œéƒ½å°†æŸå®³æˆ‘ä»¬å¸å¼•ä¼˜ç§€å­¦ç”Ÿå’Œäººæ‰çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®¸å¤šç»æµæ¡ä»¶å¹¶ä¸å®½è£•çš„å›½é™…å­¦ç”Ÿï¼Œéƒ½æŒ‡æœ›èƒ½é€šè¿‡ OPT å·¥ä½œæ¥æ”¯ä»˜åœ¨ç¾å›½æ”»è¯»å¤§å­¦å­¦ä½çš„é«˜æ˜‚è´¹ç”¨ã€‚æ­£å¦‚æœ‰äººæè®®çš„é‚£æ ·ï¼Œå¦‚æœå–æ¶ˆ OPT é¡¹ç›®ï¼Œä¸ä»…ä¼šæŸå®³è®¸å¤šå›½é™…å­¦ç”Ÿåœ¨è¿™é‡Œå­¦ä¹ çš„å¯èƒ½ï¼Œä¹Ÿä¼šè®©ç¾å›½ä¼ä¸šå¤±å»å¤§æ‰¹ä¼˜ç§€äººæ‰ã€‚ï¼ˆå½“ç„¶ï¼Œè¿™ä¸ä¼šé˜»æ­¢æ¥è‡ªå¯Œè£•å®¶åº­çš„å­¦ç”Ÿã€‚ä½†ç¾å›½åº”è¯¥åŠªåŠ›å¸å¼•æœ€ä¼˜ç§€çš„äººæ‰ï¼Œè€Œä¸è®ºå…¶è´¢å¯ŒçŠ¶å†µã€‚ï¼‰

æœªèƒ½å¸å¼•æœ‰å‰é€”çš„å­¦ç”Ÿå’Œé«˜æŠ€èƒ½äººæ‰ï¼Œå°†å¯¹ç¾å›½åœ¨ AI é¢†åŸŸï¼ˆAI fieldï¼‰çš„ç«äº‰åŠ›äº§ç”Ÿå·¨å¤§çš„è´Ÿé¢å½±å“ã€‚äº‹å®ä¸Šï¼Œå›½å®¶äººå·¥æ™ºèƒ½å®‰å…¨å§”å‘˜ä¼šï¼ˆNational Security Commission on Artificial Intelligenceï¼‰æœ€è¿‘çš„ä¸€ä»½æŠ¥å‘Šæ˜ç¡®å‘¼åæ”¿åºœã€Œé€šè¿‡ç§»æ°‘åŠ å¼º AI äººæ‰ã€ã€‚

å¦‚æœäººæ‰ä¸æ¥ç¾å›½ï¼Œä»–ä»¬åªæ˜¯åœ¨å…¶ä»–åœ°æ–¹å·¥ä½œï¼Œè¿™å¯¹å…¨çƒ AI å‘å±•ä¼šäº§ç”ŸåŒæ ·çš„å½±å“å—ï¼Ÿä¸å¹¸çš„æ˜¯ï¼Œå‡€æ•ˆåº”å°†æ˜¯è´Ÿé¢çš„ã€‚ç¾å›½æ‹¥æœ‰ä¼—å¤šç§‘æŠ€ä¸­å¿ƒï¼ŒåŒ…æ‹¬ç¡…è°·ã€è¥¿é›…å›¾ã€çº½çº¦ã€æ³¢å£«é¡¿ / å‰‘æ¡¥ã€æ´›æ‰çŸ¶ã€åŒ¹å…¹å ¡å’Œå¥¥æ–¯æ±€ï¼Œè¿™äº›ä¸­å¿ƒæ±‡èšäººæ‰ï¼Œä¿ƒè¿›åˆ›æ–°ã€‚ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆåŸå¸‚èƒ½å¤Ÿä¿ƒè¿›åˆ›æ–°ï¼Œå› ä¸ºäººä»¬åœ¨è¿™é‡Œæ›´å®¹æ˜“ç›¸äº’è”ç³»å’Œåä½œã€‚ï¼‰å¦‚æœè®© AI äººæ‰æ›´éš¾ç›¸äº’æ‰¾åˆ°å¹¶åä½œï¼Œå°†å‡ç¼“åˆ›æ–°æ­¥ä¼ï¼Œè€Œæ–°çš„ä¸­å¿ƒè¦è¾¾åˆ°åŒæ ·çš„å…ˆè¿›æ°´å¹³ï¼Œåˆ™éœ€è¦æ—¶é—´ã€‚

å°½ç®¡å¦‚æ­¤ï¼Œå…¶ä»–å›½å®¶æ­£åœ¨åŠªåŠ›å¸å¼•èƒ½å¤Ÿæ¨åŠ¨åˆ›æ–°çš„ç§»æ°‘ â€”â€” è¿™å¯¹å®ƒä»¬æ¥è¯´æ˜¯æ˜æ™ºä¹‹ä¸¾ï¼è®¸å¤šå›½å®¶éƒ½åˆ¶å®šäº†æ·±æ€ç†Ÿè™‘çš„è®¡åˆ’ï¼Œä»¥å¸å¼• AI åŠå…¶ä»–é¢†åŸŸçš„äººæ‰ã€‚ä¾‹å¦‚ï¼Œè‹±å›½çš„å…¨çƒäººæ‰ç­¾è¯ã€æ³•å›½çš„æ³•å›½ç§‘æŠ€ç­¾è¯ã€æ¾³å¤§åˆ©äºšçš„å…¨çƒäººæ‰ç­¾è¯ã€é˜¿è”é…‹çš„é»„é‡‘ç­¾è¯ã€å°æ¹¾çš„å°±ä¸šé‡‘å¡ã€ä¸­å›½çš„åƒäººè®¡åˆ’ç­‰ç­‰ã€‚ç¾å›½æ˜¯å¹¸è¿çš„ï¼Œå› ä¸ºè®¸å¤šäººå·²ç»æ¸´æœ›æ¥è¿™é‡Œå­¦ä¹ å’Œå·¥ä½œã€‚æµªè´¹è¿™ä¸€ä¼˜åŠ¿å°†æ˜¯ä¸€ä¸ªå·¨å¤§çš„è‡ªæˆ‘ä¼¤å®³ã€‚

é™¤äº†å›½å®¶ç«äº‰åŠ›é—®é¢˜ï¼Œè¿˜æœ‰ä¸€ä¸ªæ›´é‡è¦çš„é“å¾·é—®é¢˜ï¼Œé‚£å°±æ˜¯ç¡®ä¿äººä»¬å—åˆ°å…¬æ­£å¯¹å¾…ã€‚æˆ‘æ›¾ä¸ä¸€äº›å›½é™…å­¦ç”Ÿäº¤è°ˆï¼Œä»–ä»¬éå¸¸æ‹…å¿ƒè‡ªå·±çš„ç­¾è¯å¯èƒ½è¢«ä»»æ„å–æ¶ˆã€‚æœ‰ä¸€ä½å­¦ç”Ÿæœ€è¿‘å°±çº ç»“æ˜¯å¦è¦å‚åŠ ä¸€ä¸ªå›½é™…ä¼šè®®å¹¶å‘è¡¨ç ”ç©¶è®ºæ–‡ï¼Œå› ä¸ºä»–ä»¬æ‹…å¿ƒå¯èƒ½æ— æ³•è¿”å›ã€‚æœ€ç»ˆï¼Œä»–ä»¬å¸¦ç€å·¨å¤§çš„é—æ†¾å–æ¶ˆäº†è¡Œç¨‹ã€‚æˆ‘è¿˜ä¸ä¸€ä½æŒ H-1B ç­¾è¯åœ¨ç¾å›½çš„é«˜æŠ€èƒ½æŠ€æœ¯ä¸“å®¶äº¤è°ˆã€‚ä»–ä»¬çš„å…¬å¸å€’é—­äº†ï¼Œè¿™å¯¼è‡´ä»–ä»¬ â€”â€” åœ¨è¿™ä¸ªå›½å®¶ç”Ÿæ´»äº†åå¤šå¹´ï¼Œä¸åŸç±å›½å‡ ä¹æ²¡æœ‰è”ç³» â€”â€” ä¸å¾—ä¸æ‰‹å¿™è„šä¹±åœ°å¯»æ‰¾æ›¿ä»£å·¥ä½œï¼Œä»¥ä¾¿èƒ½å¤Ÿç•™ä¸‹æ¥ã€‚

è¿™äº›æ•…äº‹ï¼Œä»¥åŠè®¸å¤šè¿œæ¯”è¿™ç³Ÿç³•çš„ç»å†ï¼Œéƒ½ä»¤äººå¿ƒç¢ã€‚è™½ç„¶æˆ‘å°½åŠ›å¸®åŠ©æˆ‘è®¤è¯†çš„ä¸ªäººï¼Œä½†æˆ‘ä»¬ä¸ºç§»æ°‘åˆ›é€ äº†è¿™æ ·ä¸€ä¸ªå……æ»¡ä¸ç¡®å®šæ€§çš„ç¯å¢ƒï¼Œå¯¼è‡´è®¸å¤šæ‹¥æœ‰éå‡¡æŠ€èƒ½å’Œæ‰åçš„äººä¸å†æ„¿æ„æ¥è¿™é‡Œï¼Œè¿™å®åœ¨ä»¤äººæ‚²å“€ã€‚

è‡´æ‰€æœ‰èº«åœ¨ç¾å›½ã€æ‹…å¿§å½“å‰å›½å®¶ç¯å¢ƒçš„ç§»æ°‘ä»¬ï¼šæˆ‘ç†è§£å¹¶åŒæƒ…ä½ ä»¬çš„å¿§è™‘ã€‚ä½œä¸ºä¸€åç§»æ°‘ï¼Œæˆ‘å°†ä¸ºä¿æŠ¤æ¯ä¸ªäººçš„å°Šä¸¥å’Œæ­£å½“ç¨‹åºï¼ˆdue processï¼‰æƒåˆ©è€Œå¥‹æ–—ï¼Œå¹¶é¼“åŠ±åˆæ³•ç§»æ°‘ï¼Œå› ä¸ºè¿™èƒ½è®©ç¾å›½å’Œä¸ªäººéƒ½å—ç›Šè‰¯å¤šã€‚

[å…¨æ–‡ï¼Œå¸¦é“¾æ¥ï¼š https://t.co/6JNJz88Qyq]

### 083

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-25
é“¾æ¥: https://x.com/AndrewYNg/status/1937907934094360582
äº’åŠ¨: Likes: 1,547; Retweets: 362; Replies: 52; Quotes: 17; Views: 102,818; Bookmarks: 949; isReply: 0

New Course: ACP: Agent Communication Protocol

Learn to build agents that communicate and collaborate across different frameworks using ACP in this short course built with @IBMResearch's BeeAI, and taught by @sandi_besen, AI Research Engineer & Ecosystem Lead at IBM, and @nicholasrenotte, Head of AI Developer Advocacy at IBM.

Building a multi-agent system with agents built or used by different teams and organizations can become challenging. You may need to write custom integrations each time a team updates their agent design or changes their choice of agentic orchestration framework.

The Agent Communication Protocol (ACP) is an open protocol that addresses this challenge by standardizing how agents communicate, using a unified RESTful interface that works across frameworks. In this protocol, you host an agent inside an ACP server, which handles requests from an ACP client and passes them to the appropriate agent. Using a standardized client-server interface allows multiple teams to reuse agents across projects. It also makes it easier to switch between frameworks, replace an agent with a new version, or update a multi-agent system without refactoring the entire system.

In this course, youâ€™ll learn to connect agents through ACP. Youâ€™ll understand the lifecycle of an ACP Agent and how it compares to other protocols, such as MCP (Model Context Protocol) and A2A (Agent-to-Agent). Youâ€™ll build ACP-compliant agents and implement both sequential and hierarchical workflows of multiple agents collaborating using ACP.

Through hands-on exercises, youâ€™ll build:
- A RAG agent with CrewAI and wrap it inside an ACP server.
- An ACP Client to make calls to the ACP server you created.
- A sequential workflow that chains an ACP server, created with Smolagents, to the RAG agent.
- A hierarchical workflow using a router agent that transforms user queries into tasks, delegated to agents available through ACP servers.
- An agent that uses MCP to access tools and ACP to communicate with other agents.

Youâ€™ll finish up by importing your ACP agents into the BeeAI platform, an open-source registry for discovering and sharing agents.

ACP enables collaboration between agents across teams and organizations. By the end of this course, youâ€™ll be able to build ACP agents and workflows that communicate and collaborate regardless of framework.

Please sign up here: https://t.co/csyHrswJuB

<æ–°è¯¾ç¨‹ï¼šACPï¼šAI æ™ºèƒ½ä½“é€šä¿¡åè®®>

è¿™é—¨çŸ­æœŸè¯¾ç¨‹å°†æ•™æ‚¨å¦‚ä½•ä½¿ç”¨ AI æ™ºèƒ½ä½“é€šä¿¡åè®®ï¼ˆAgent Communication Protocolï¼ŒACPï¼‰æ¥æ„å»º AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ï¼Œè®©å®ƒä»¬èƒ½å¤Ÿåœ¨ä¸åŒçš„æ¡†æ¶ä¹‹é—´é¡ºç•…é€šä¿¡ä¸åä½œã€‚è¯¾ç¨‹ç”± @IBMResearch çš„ BeeAI å¹³å°æ”¯æŒï¼Œå¹¶ç”± IBM çš„ AI ç ”ç©¶å·¥ç¨‹å¸ˆå…¼ç”Ÿæ€ç³»ç»Ÿè´Ÿè´£äºº @sandi_besen ä»¥åŠ IBM çš„ AI å¼€å‘è€…å®£ä¼ è´Ÿè´£äºº @nicholasrenotte å…±åŒè®²æˆã€‚

å½“æˆ‘ä»¬å°è¯•æ„å»ºä¸€ä¸ªå¤š AI æ™ºèƒ½ä½“ç³»ç»Ÿæ—¶ï¼Œå¦‚æœå…¶ä¸­çš„ AI æ™ºèƒ½ä½“æ˜¯ç”±ä¸åŒå›¢é˜Ÿå’Œç»„ç»‡å¼€å‘æˆ–ä½¿ç”¨çš„ï¼Œé‚£ä¹ˆè¿™ä¸ªè¿‡ç¨‹å¯èƒ½ä¼šå˜å¾—éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æ¯å½“ä¸€ä¸ªå›¢é˜Ÿæ›´æ–°ä»–ä»¬çš„ AI æ™ºèƒ½ä½“è®¾è®¡ï¼Œæˆ–è€…æ›´æ”¹ä»–ä»¬é€‰æ‹©çš„ AI æ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶æ—¶ï¼Œæ‚¨å¯èƒ½éƒ½éœ€è¦é‡æ–°ç¼–å†™å®šåˆ¶åŒ–çš„é›†æˆæ–¹æ¡ˆã€‚

AI æ™ºèƒ½ä½“é€šä¿¡åè®®ï¼ˆACPï¼‰å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜è€Œè®¾è®¡çš„å¼€æ”¾åè®®ã€‚å®ƒé€šè¿‡æ ‡å‡†åŒ– AI æ™ºèƒ½ä½“ä¹‹é—´çš„é€šä¿¡æ–¹å¼ï¼Œæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„ RESTful æ¥å£ï¼Œèƒ½å¤Ÿè·¨è¶Šå„ç§æ¡†æ¶ã€‚åœ¨è¿™ä¸ªåè®®ä¸­ï¼Œæ‚¨éœ€è¦å°† AI æ™ºèƒ½ä½“æ‰˜ç®¡åœ¨ä¸€ä¸ª ACP æœåŠ¡å™¨å†…éƒ¨ï¼Œç”±è¯¥æœåŠ¡å™¨è´Ÿè´£å¤„ç†æ¥è‡ª ACP å®¢æˆ·ç«¯çš„è¯·æ±‚ï¼Œå¹¶å°†å…¶è½¬å‘ç»™å¯¹åº”çš„ AI æ™ºèƒ½ä½“ã€‚é‡‡ç”¨æ ‡å‡†åŒ–çš„å®¢æˆ·ç«¯ - æœåŠ¡å™¨æ¥å£ï¼Œä¸ä»…èƒ½è®©å¤šä¸ªå›¢é˜Ÿåœ¨ä¸åŒçš„é¡¹ç›®ä¸­é‡ç”¨ AI æ™ºèƒ½ä½“ï¼Œè¿˜èƒ½æ›´è½»æ¾åœ°å®ç°æ¡†æ¶åˆ‡æ¢ã€AI æ™ºèƒ½ä½“ç‰ˆæœ¬æ›´æ–°ï¼Œæˆ–è€…åœ¨ä¸é‡æ„æ•´ä¸ªç³»ç»Ÿçš„å‰æä¸‹å‡çº§å¤š AI æ™ºèƒ½ä½“ç³»ç»Ÿã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•é€šè¿‡ ACP è¿æ¥å„ç§ AI æ™ºèƒ½ä½“ã€‚æ‚¨å°†æ·±å…¥äº†è§£ ACP AI æ™ºèƒ½ä½“çš„ç”Ÿå‘½å‘¨æœŸï¼Œå¹¶å°†å…¶ä¸å…¶ä»–åè®®ï¼ˆå¦‚æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆModel Context Protocolï¼ŒMCPï¼‰å’Œ AI æ™ºèƒ½ä½“é—´é€šä¿¡åè®®ï¼ˆAgent-to-Agentï¼ŒA2A)ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚æ‚¨å°†äº²æ‰‹æ„å»ºç¬¦åˆ ACP è§„èŒƒçš„ AI æ™ºèƒ½ä½“ï¼Œå¹¶å®ç°ä½¿ç”¨ ACP åä½œçš„å¤šä¸ª AI æ™ºèƒ½ä½“çš„é¡ºåºå·¥ä½œæµå’Œåˆ†å±‚å·¥ä½œæµã€‚

é€šè¿‡ä¸€ç³»åˆ—åŠ¨æ‰‹ç»ƒä¹ ï¼Œæ‚¨å°†æ„å»º:
- ä¸€ä¸ªåŸºäº CrewAI çš„ RAG AI æ™ºèƒ½ä½“ï¼Œå¹¶å°†å…¶å°è£…åœ¨ ACP æœåŠ¡å™¨ä¸­ã€‚
- ä¸€ä¸ª ACP å®¢æˆ·ç«¯ï¼Œç”¨äºè°ƒç”¨æ‚¨åˆ›å»ºçš„ ACP æœåŠ¡å™¨ã€‚
- ä¸€ä¸ªé¡ºåºå·¥ä½œæµï¼Œå°†ä½¿ç”¨ Smolagents åˆ›å»ºçš„ ACP æœåŠ¡å™¨ä¸ RAG AI æ™ºèƒ½ä½“è¿æ¥èµ·æ¥ã€‚
- ä¸€ä¸ªåˆ†å±‚å·¥ä½œæµï¼Œå…¶ä¸­è·¯ç”± AI æ™ºèƒ½ä½“è´Ÿè´£å°†ç”¨æˆ·æŸ¥è¯¢è½¬æ¢ä¸ºå…·ä½“ä»»åŠ¡ï¼Œå¹¶å°†è¿™äº›ä»»åŠ¡å§”æ´¾ç»™é€šè¿‡ ACP æœåŠ¡å™¨å¯ç”¨çš„ AI æ™ºèƒ½ä½“ã€‚
- ä¸€ä¸ªæ—¢ä½¿ç”¨ MCP è®¿é—®å·¥å…·ï¼Œåˆä½¿ç”¨ ACP ä¸å…¶ä»– AI æ™ºèƒ½ä½“é€šä¿¡çš„ AI æ™ºèƒ½ä½“ã€‚

å®Œæˆè¯¾ç¨‹åï¼Œæ‚¨ä¼šå°†æ‚¨çš„ ACP AI æ™ºèƒ½ä½“å¯¼å…¥ BeeAI å¹³å° â€”â€” è¿™æ˜¯ä¸€ä¸ªç”¨äºå‘ç°å’Œå…±äº« AI æ™ºèƒ½ä½“çš„å¼€æºæ³¨å†Œè¡¨ã€‚

ACP æœ‰æ•ˆåœ°ä¿ƒè¿›äº† AI æ™ºèƒ½ä½“åœ¨ä¸åŒå›¢é˜Ÿå’Œç»„ç»‡é—´çš„åä½œã€‚å®Œæˆæœ¬è¯¾ç¨‹çš„å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿæ„å»ºå‡º ACP AI æ™ºèƒ½ä½“å’Œå·¥ä½œæµï¼Œæ— è®ºåº•å±‚æ¡†æ¶å¦‚ä½•ï¼Œå®ƒä»¬éƒ½èƒ½å®ç°æ— ç¼é€šä¿¡ä¸åä½œã€‚

è¯·ç‚¹å‡»æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/csyHrswJuB

### 084

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-06-26
é“¾æ¥: https://x.com/AndrewYNg/status/1938265468986659075
äº’åŠ¨: Likes: 1,221; Retweets: 374; Replies: 121; Quotes: 54; Views: 158,103; Bookmarks: 341; isReply: 0

On Monday, a United States District Court ruled that training LLMs on copyrighted books constitutes fair use. A number of authors had filed suit against Anthropic for training its models on their books without permission. Just as we allow people to read books and learn from them to become better writers, but not to regurgitate copyrighted text verbatim, the judge concluded that it is fair use for AI models to do so as well.

Indeed, Judge Alsup wrote that the authorsâ€™ lawsuit is â€œno different than it would be if they complained that training schoolchildren to write well would result in an explosion of competing works.â€ While it remains to be seen whether the decision will be appealed, this ruling is reasonable and will be good for AI progress. (Usual caveat: I am not a lawyer and am not giving legal advice.)

AI has massive momentum, but a few things could put progress at risk:
- Regulatory capture that stifles innovation, including especially open source
- Loss of access to cutting-edge semiconductor chips (the most likely cause would be war breaking out in Taiwan)
- Regulations that severely impede access to data for training AI systems

Access to high-quality data is important. Even though the mass media tends to talk about the importance of building large data centers and scaling up models, when I speak with friends at companies that train foundation models, many describe a very large amount of their daily challenges as data preparation. Specifically, a significant fraction of their day-to-day work follows the usual Data Centric AI practices of identifying high-quality data (books are one important source), cleaning data (the ruling describes Anthropic taking steps like removing book pages' headers, footers, and page numbers), carrying out error analyses to figure out what types of data to acquire more of, and inventing new ways to generate synthetic data.

I am glad that a major risk to data access just decreased. Appropriately, the ruling further said that Anthropicâ€™s conversion of books from paper format to digital â€” a step thatâ€™s needed to enable training â€” also was fair use. However, in a loss for Anthropic, the judge indicated that, while training on data that was acquired legitimately is fine, using pirated materials (such as  texts downloaded from pirate websites) is not fair use. Thus, Anthropic still may be liable on this point. Other LLM providers, too, will now likely have to revisit their practices if they use datasets that may contain pirated works.

Overall, the ruling is positive for AI progress. Perhaps the biggest benefit is that it reduces ambiguity with respect to AI training and copyright and (if it stands up to appeals) makes the roadmap for compliance clearer. This decision indicates it is okay to train on legitimately acquired data to build models that generate transformational outputs, and to convert printed books to digital format for this purpose. However, downloading from pirate sites (as well as permanently building a â€œgeneral purposeâ€ library of texts, stored indefinitely for purposes to be determined, without permission from the relevant copyright holders) are not considered fair use.

I am very sympathetic with the many writers who are worried about their livelihoods being affected by AI. I donâ€˜t know the right solution for that. Society is better off with free access to more data; but if a subset of people is significantly negatively affected, I hope we can figure out an arrangement that compensates them fairly.

[Original text: https://t.co/kxcCgL4tpH ]

æœ¬å‘¨ä¸€ï¼Œç¾å›½åœ°æ–¹æ³•é™¢è£å®šï¼Œä½¿ç”¨å—ç‰ˆæƒä¿æŠ¤çš„ä¹¦ç±æ¥è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±äºåˆç†ä½¿ç”¨ã€‚æ­¤å‰ï¼Œä¸€äº›ä½œè€…æ›¾èµ·è¯‰ Anthropic å…¬å¸ï¼Œç†ç”±æ˜¯å…¶æœªç»å…è®¸å°±ç”¨ä»–ä»¬çš„ä½œå“è®­ç»ƒ AI æ¨¡å‹ã€‚æ³•å®˜çš„ç»“è®ºæ˜¯ï¼Œæ­£å¦‚æˆ‘ä»¬å…è®¸äººä»¬é€šè¿‡é˜…è¯»ä¹¦ç±æ¥å­¦ä¹ å¹¶æˆä¸ºæ›´å¥½çš„ä½œè€…ï¼Œä½†ä¸å…è®¸ä»–ä»¬é€å­—é€å¥åœ°æŠ„è¢­å—ç‰ˆæƒä¿æŠ¤çš„æ–‡æœ¬ä¸€æ ·ï¼ŒAI æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿™æ ·åšä¹Ÿåº”è¢«è§†ä¸ºåˆç†ä½¿ç”¨ã€‚

äº‹å®ä¸Šï¼ŒAlsup æ³•å®˜å†™é“ï¼Œè¿™äº›ä½œè€…çš„è¯‰è®¼ã€Œä¸ä»–ä»¬æŠ±æ€¨è®­ç»ƒå­¦ç«¥å†™å¥½æ–‡ç« ä¼šå¯¼è‡´å¤§é‡ç«äº‰ä½œå“å‡ºç°çš„æƒ…å†µå¹¶æ— äºŒè‡´ã€‚ã€å°½ç®¡è¿™é¡¹è£å†³æ˜¯å¦ä¼šä¸Šè¯‰å°šå¾…è§‚å¯Ÿï¼Œä½†è¿™ä¸€åˆ¤å†³æ˜¯åˆç†ä¸”æœ‰åˆ©äº AI å‘å±•çš„ã€‚ï¼ˆå¸¸è§„å…è´£å£°æ˜ï¼šæˆ‘å¹¶éå¾‹å¸ˆï¼Œä¸æä¾›æ³•å¾‹å»ºè®®ã€‚ï¼‰

å½“å‰ AI å‘å±•åŠ¿å¤´è¿…çŒ›ï¼Œä½†æœ‰å‡ é¡¹å› ç´ å¯èƒ½ä¼šé˜»ç¢å…¶è¿›æ­¥ï¼š
- ç›‘ç®¡ä¿˜è·ï¼ˆRegulatory captureï¼‰æŠ‘åˆ¶åˆ›æ–°ï¼Œå°¤å…¶å¯¹å¼€æºé¡¹ç›®å½±å“æ˜¾è‘—
- å¤±å»è·å–å°–ç«¯åŠå¯¼ä½“èŠ¯ç‰‡çš„é€”å¾„ï¼ˆæœ€å¯èƒ½çš„åŸå› æ˜¯å°æ¹¾åœ°åŒºçˆ†å‘å†²çªï¼‰
- ä¸¥è‹›çš„æ³•è§„ï¼Œä¸¥é‡é™åˆ¶ AI ç³»ç»Ÿè®­ç»ƒæ•°æ®çš„è·å–è·å–é«˜è´¨é‡æ•°æ®è‡³å…³é‡è¦ã€‚å°½ç®¡å¤§ä¼—åª’ä½“æ›´å€¾å‘äºå…³æ³¨æ„å»ºå¤§å‹æ•°æ®ä¸­å¿ƒå’Œæ‰©å±•æ¨¡å‹è§„æ¨¡ï¼Œä½†å½“æˆ‘ä¸é‚£äº›è®­ç»ƒåŸºç¡€æ¨¡å‹å…¬å¸çš„æœ‹å‹äº¤æµæ—¶ï¼Œè®¸å¤šäººæåˆ°ä»–ä»¬æ—¥å¸¸å·¥ä½œä¸­çš„ä¸€å¤§æŒ‘æˆ˜å°±æ˜¯æ•°æ®å‡†å¤‡ã€‚å…·ä½“æ¥è¯´ï¼Œä»–ä»¬å¤§éƒ¨åˆ†çš„æ—¥å¸¸å·¥ä½œéƒ½éµå¾ªç€å¸¸è§çš„æ•°æ®ä¸­å¿ƒ AIï¼ˆData Centric AIï¼‰å®è·µï¼šè¯†åˆ«é«˜è´¨é‡æ•°æ®ï¼ˆä¹¦ç±æ˜¯é‡è¦çš„æ¥æºä¹‹ä¸€ï¼‰ï¼Œæ¸…ç†æ•°æ®ï¼ˆåˆ¤å†³ä¹¦ä¸­æåˆ° Anthropic é‡‡å–äº†åˆ é™¤ä¹¦é¡µçš„é¡µçœ‰ã€é¡µè„šå’Œé¡µç ç­‰æªæ–½ï¼‰ï¼Œè¿›è¡Œé”™è¯¯åˆ†æä»¥æ˜ç¡®éœ€è¦è·å–æ›´å¤šå“ªç§ç±»å‹çš„æ•°æ®ï¼Œä»¥åŠæ¢ç´¢ç”Ÿæˆåˆæˆæ•°æ®çš„æ–°æ–¹æ³•ã€‚

ä»¤æˆ‘æ¬£æ…°çš„æ˜¯ï¼Œä¸€é¡¹å…³äºæ•°æ®è·å–çš„ä¸»è¦é£é™©åˆšåˆšæœ‰æ‰€ç¼“è§£ã€‚æ­¤å¤–ï¼Œåˆ¤å†³ä¹¦æ°å½“åœ°æŒ‡å‡ºï¼ŒAnthropic å°†ä¹¦ç±ä»çº¸è´¨ç‰ˆè½¬æ¢ä¸ºæ•°å­—ç‰ˆ â€”â€” è¿™æ˜¯è®­ç»ƒ AI æ‰€éœ€çš„ä¸€ä¸ªæ­¥éª¤ â€”â€” ä¹Ÿå±äºåˆç†ä½¿ç”¨ã€‚ç„¶è€Œï¼Œå¯¹ Anthropic è€Œè¨€ï¼Œä¸åˆ©çš„ä¸€ç‚¹æ˜¯ï¼Œæ³•å®˜æŒ‡å‡ºï¼Œè™½ç„¶ä½¿ç”¨åˆæ³•è·å–çš„æ•°æ®è¿›è¡Œè®­ç»ƒæ²¡æœ‰é—®é¢˜ï¼Œä½†ä½¿ç”¨ç›—ç‰ˆææ–™ï¼ˆæ¯”å¦‚ä»ç›—ç‰ˆç½‘ç«™ä¸‹è½½çš„æ–‡æœ¬ï¼‰ä¸æ„æˆåˆç†ä½¿ç”¨ã€‚å› æ­¤ï¼ŒAnthropic åœ¨è¿™ä¸€ç‚¹ä¸Šä»å¯èƒ½é¢ä¸´æ³•å¾‹è´£ä»»ã€‚å…¶ä»–å¤§è¯­è¨€æ¨¡å‹æä¾›å•†ï¼Œå¦‚æœä»–ä»¬ä½¿ç”¨çš„æ•°æ®é›†å¯èƒ½åŒ…å«ç›—ç‰ˆä½œå“ï¼Œç°åœ¨ä¹Ÿéœ€è¦é‡æ–°å®¡è§†è‡ªå·±çš„åšæ³•ã€‚

æ€»è€Œè¨€ä¹‹ï¼Œè¿™é¡¹è£å†³å¯¹ AI çš„è¿›æ­¥æ˜¯ç§¯æçš„ã€‚ä¹Ÿè®¸å®ƒæœ€å¤§çš„å¥½å¤„åœ¨äºå‡å°‘äº† AI è®­ç»ƒå’Œç‰ˆæƒä¹‹é—´çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶ä¸”ï¼ˆå¦‚æœä¸Šè¯‰åç»´æŒåŸåˆ¤ï¼‰èƒ½è®©åˆè§„çš„è·¯å¾„å˜å¾—æ›´åŠ æ¸…æ™°ã€‚è¿™é¡¹è£å†³è¡¨æ˜ï¼Œä½¿ç”¨åˆæ³•è·å–çš„æ•°æ®æ¥æ„å»ºèƒ½äº§ç”Ÿå˜é©æ€§è¾“å‡ºçš„æ¨¡å‹æ˜¯å…è®¸çš„ï¼Œå¹¶ä¸”ä¸ºæ­¤ç›®çš„å°†å°åˆ·ä¹¦ç±è½¬æ¢ä¸ºæ•°å­—æ ¼å¼ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚ç„¶è€Œï¼Œä»ç›—ç‰ˆç½‘ç«™ä¸‹è½½ï¼ˆä»¥åŠæœªç»ç›¸å…³ç‰ˆæƒæ‰€æœ‰è€…è®¸å¯ï¼Œæ°¸ä¹…å»ºç«‹ä¸€ä¸ªã€Œé€šç”¨ã€æ–‡æœ¬åº“ï¼Œæ— é™æœŸå­˜å‚¨ä»¥å¾…æ—¥åä½¿ç”¨ï¼‰åˆ™ä¸è¢«è§†ä¸ºåˆç†ä½¿ç”¨ã€‚

æˆ‘éå¸¸ç†è§£è®¸å¤šä½œå®¶å¯¹äºç”Ÿè®¡å¯èƒ½å— AI å½±å“çš„æ‹…å¿§ã€‚æˆ‘ä¸çŸ¥é“è¯¥å¦‚ä½•å®Œç¾è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç¤¾ä¼šç¡®å®éœ€è¦æ›´è‡ªç”±åœ°è·å–æ›´å¤šæ•°æ®ï¼Œè¿™æ ·ä¼šæ›´å¥½ï¼›ä½†å¦‚æœæœ‰ä¸€éƒ¨åˆ†äººçš„åˆ©ç›Šå—åˆ°äº†æ˜¾è‘—æŸå®³ï¼Œæˆ‘å¸Œæœ›æˆ‘ä»¬èƒ½æ‰¾åˆ°ä¸€ç§å…¬å¹³è¡¥å¿ä»–ä»¬çš„æ–¹æ¡ˆã€‚

[åŸæ–‡é“¾æ¥ï¼š https://t.co/kxcCgL4tpH]

### 085

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-03
é“¾æ¥: https://x.com/AndrewYNg/status/1940864335083196819
äº’åŠ¨: Likes: 1,650; Retweets: 484; Replies: 76; Quotes: 32; Views: 321,412; Bookmarks: 1,316; isReply: 0

Iâ€™d like to share a tip for getting more practice building with AI â€” that is, either using AI building blocks to build applications or using AI coding assistance to create powerful applications quickly: If you find yourself with only limited time to build, reduce the scope of your project until you can build something in whatever time you do have.

If you have only an hour, find a small component of an idea that you're excited about that you can build in an hour. With modern coding assistants like Anthropicâ€™s Claude Code (my favorite dev tool right now), you might be surprised at how much you can do even in short periods of time! This gets you going, and you can always continue the project later.

To become good at building with AI, most people must (i) learn relevant techniques, for example by taking online AI courses, and (ii) practice building. I know developers who noodle on ideas for months without actually building anything â€” Iâ€™ve done this too! â€” because we feel we donâ€™t have time to get started. If you find yourself in this position, I encourage you to keep cutting the initial project scope until you identify a small component you can build right away.

Let me illustrate with an example â€” one of my many small, fun weekend projects that might never go anywhere, but that Iâ€™m glad I did.

Hereâ€™s the idea: Many people fear public speaking. And public speaking is challenging to practice, because it's hard to organize an audience. So I thought it would be interesting to build an audience simulator to provide a digital audience of dozens to hundreds of virtual people on a computer monitor and let a user practice by speaking to them.

One Saturday afternoon, I found myself in a coffee shop with a couple of hours to spare and decided to give the audience simulator a shot. My familiarity with graphics coding is limited, so instead of building a complex simulator of a large audience and writing AI software to simulate appropriate audience responses, I decided to cut scope significantly to (a) simulating an audience of one person (which I could replicate later to simulate N persons), (b) omitting AI and letting a human operator manually select the reaction of the simulated audience (similar to Wizard of Oz prototyping), and (c) implementing the graphics using a simple 2D avatar.

Using a mix of several coding assistants, I built a basic version in the time I had. The avatar could move subtly and blink, but otherwise it used basic graphics. Even though it fell far short of a sophisticated audience simulator, I am glad I built this. In addition to moving the project forward and letting me explore different designs, it advanced my knowledge of basic graphics. Further, having this crude prototype to show friends helped me get user feedback that shaped my views on the product idea.

I have on my laptop a list of ideas of things that I think would be interesting to build. Most of them would take much longer than the handful of hours I might have to try something on a given day, but by cutting their scope, I can get going, and the initial progress on a project helps me decide if itâ€™s worth further investment. As a bonus, hacking on a wide variety of applications helps me practice a wide range of skills. But most importantly, this gets an idea out of my head and potentially in front of prospective users for feedback that lets the project move faster.

[Original text: https://t.co/UP6arTWAdV ]

æˆ‘å¸Œæœ›åˆ†äº«ä¸€ä¸ªå…³äºå¦‚ä½•é€šè¿‡ AI ï¼ˆäººå·¥æ™ºèƒ½ï¼‰è·å¾—æ›´å¤šå®è·µæ„å»ºçš„æŠ€å·§ â€”â€” ä¹Ÿå°±æ˜¯è¯´ï¼Œæ— è®ºæ˜¯åˆ©ç”¨ AI æ„å»ºæ¨¡å—æ¥å¼€å‘åº”ç”¨ç¨‹åºï¼Œè¿˜æ˜¯å€ŸåŠ© AI ç¼–ç è¾…åŠ©æ¥å¿«é€Ÿåˆ›å»ºå¼ºå¤§çš„åº”ç”¨ï¼šå¦‚æœä½ å‘ç°è‡ªå·±ç”¨äºå¼€å‘çš„æ—¶é—´æœ‰é™ï¼Œé‚£å°±è¯·ç¼©å°é¡¹ç›®èŒƒå›´ï¼Œç›´åˆ°ä½ èƒ½åœ¨æ‰€æ‹¥æœ‰çš„ä»»ä½•æ—¶é—´å†…å®Œæˆä¸€äº›æ„å»ºã€‚

å¦‚æœä½ åªæœ‰ä¸€ä¸ªå°æ—¶ï¼Œé‚£ä¹ˆå°±æ‰¾ä¸€ä¸ªä½ æ„Ÿå…´è¶£çš„æƒ³æ³•ä¸­ï¼Œèƒ½åœ¨è¿™ä¸€å°æ—¶å†…å®Œæˆçš„å°ç»„ä»¶ã€‚æœ‰äº† Anthropic çš„ Claude Code ï¼ˆæˆ‘ç›®å‰æœ€å–œæ¬¢çš„å¼€å‘å·¥å…·ï¼‰è¿™ç±»ç°ä»£ç¼–ç åŠ©æ‰‹ï¼Œä½ å¯èƒ½ä¼šæƒŠè®¶äºå³ä½¿åœ¨çŸ­æ—¶é—´å†…ï¼Œä½ ä¹Ÿèƒ½å®Œæˆå¤šå°‘å·¥ä½œï¼è¿™èƒ½è®©ä½ å°½å¿«ä¸Šæ‰‹ï¼Œè€Œä¸”ä½ éšæ—¶éƒ½å¯ä»¥é€‰æ‹©ç¨åç»§ç»­è¿™ä¸ªé¡¹ç›®ã€‚

è¦æ“…é•¿åˆ©ç”¨ AI è¿›è¡Œå¼€å‘ï¼Œå¤§å¤šæ•°äººå¿…é¡»ï¼ˆiï¼‰å­¦ä¹ ç›¸å…³æŠ€æœ¯ï¼Œä¾‹å¦‚é€šè¿‡å‚åŠ åœ¨çº¿ AI è¯¾ç¨‹ï¼Œä»¥åŠï¼ˆiiï¼‰å®è·µæ„å»ºã€‚æˆ‘è®¤è¯†ä¸€äº›å¼€å‘è€…ï¼Œä»–ä»¬ä¼šæ²‰æµ¸åœ¨æƒ³æ³•ä¸­å¥½å‡ ä¸ªæœˆï¼Œä½†å´æ²¡æœ‰ä»»ä½•å®é™…çš„äº§å‡º â€”â€” æˆ‘ä¹Ÿæ›¾è¿™æ ·åšè¿‡ï¼â€”â€” å› ä¸ºæˆ‘ä»¬æ€»è§‰å¾—æ²¡æœ‰æ—¶é—´å¼€å§‹ã€‚å¦‚æœä½ å‘ç°è‡ªå·±å¤„äºè¿™ç§å¢ƒåœ°ï¼Œæˆ‘é¼“åŠ±ä½ æŒç»­ç¼©å‡åˆå§‹é¡¹ç›®èŒƒå›´ï¼Œç›´åˆ°æ‰¾åˆ°å¯ä»¥ç«‹å³ç€æ‰‹æ„å»ºçš„å°æ¨¡å—ã€‚

è®©æˆ‘ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜ â€”â€” è¿™æ˜¯æˆ‘ä¼—å¤šå°å‹ã€æœ‰è¶£çš„å‘¨æœ«é¡¹ç›®ä¹‹ä¸€ï¼Œå®ƒä»¬å¯èƒ½æœ€ç»ˆä¸äº†äº†ä¹‹ï¼Œä½†æˆ‘ä»ç„¶å¾ˆé«˜å…´æˆ‘å°è¯•äº†ã€‚

è¿™ä¸ªæƒ³æ³•æ˜¯è¿™æ ·çš„ï¼šè®¸å¤šäººå®³æ€•å…¬å¼€æ¼”è®²ã€‚ç„¶è€Œï¼Œå…¬å¼€æ¼”è®²åˆå¾ˆéš¾ç»ƒä¹ ï¼Œå› ä¸ºç»„ç»‡å¬ä¼—æ˜¯ä¸€ä»¶éº»çƒ¦äº‹ã€‚æ‰€ä»¥æˆ‘æƒ³ï¼Œå¦‚æœèƒ½æ„å»ºä¸€ä¸ªè§‚ä¼—æ¨¡æ‹Ÿå™¨ï¼Œåœ¨ç”µè„‘æ˜¾ç¤ºå™¨ä¸Šæä¾›æ•°ååˆ°æ•°ç™¾ä¸ªè™šæ‹Ÿäººçš„æ•°å­—å¬ä¼—ï¼Œå¹¶è®©ç”¨æˆ·é€šè¿‡å‘ä»–ä»¬è®²è¯æ¥ç»ƒä¹ ï¼Œé‚£ä¼šå¾ˆæœ‰è¶£ã€‚

ä¸€ä¸ªå‘¨å…­ä¸‹åˆï¼Œæˆ‘å‘ç°è‡ªå·±åœ¨ä¸€ä¸ªå’–å•¡é¦†é‡Œï¼Œæœ‰å‡ ä¸ªå°æ—¶çš„ç©ºé—²æ—¶é—´ï¼Œäºæ˜¯å†³å®šå°è¯•ä¸€ä¸‹è¿™ä¸ªè§‚ä¼—æ¨¡æ‹Ÿå™¨ã€‚æˆ‘å¯¹å›¾å½¢ç¼–ç¨‹çš„äº†è§£ä¸å¤šï¼Œæ‰€ä»¥ä¸å…¶æ„å»ºä¸€ä¸ªå¤æ‚çš„å¤§å‹è§‚ä¼—æ¨¡æ‹Ÿå™¨å¹¶ç¼–å†™ AI è½¯ä»¶æ¥æ¨¡æ‹Ÿé€‚å½“çš„è§‚ä¼—ååº”ï¼Œæˆ‘å†³å®šå¤§å¹…ç¼©å‡é¡¹ç›®èŒƒå›´ï¼Œå…·ä½“åšæ³•æ˜¯ï¼šï¼ˆaï¼‰åªæ¨¡æ‹Ÿä¸€ä¸ªäººçš„è§‚ä¼—ï¼ˆæˆ‘ä»¥åå¯ä»¥å¤åˆ¶å®ƒæ¥æ¨¡æ‹Ÿ N ä¸ªäººï¼‰ï¼Œï¼ˆbï¼‰æš‚æ—¶ä¸å¼•å…¥ AI ï¼Œè€Œæ˜¯è®©äººå·¥æ“ä½œå‘˜æ‰‹åŠ¨é€‰æ‹©æ¨¡æ‹Ÿè§‚ä¼—çš„ååº”ï¼ˆç±»ä¼¼äºç»¿é‡ä»™è¸ªåŸå‹æ³•ï¼ˆWizard of Oz prototyping)ï¼‰ï¼Œä»¥åŠï¼ˆcï¼‰ä½¿ç”¨ç®€å•çš„ 2D è™šæ‹Ÿå½¢è±¡ï¼ˆ2D avatarï¼‰æ¥å®ç°å›¾å½¢ã€‚

é€šè¿‡ç»“åˆä½¿ç”¨å‡ ä¸ªç¼–ç åŠ©æ‰‹ï¼Œæˆ‘åœ¨æœ‰é™çš„æ—¶é—´å†…æ„å»ºäº†ä¸€ä¸ªåŸºæœ¬ç‰ˆæœ¬ã€‚è¿™ä¸ªè™šæ‹Ÿå½¢è±¡å¯ä»¥è¿›è¡Œç»†å¾®çš„åŠ¨ä½œå¹¶çœ¨çœ¼ï¼Œä½†é™¤æ­¤ä¹‹å¤–ï¼Œå®ƒåªä½¿ç”¨äº†åŸºæœ¬çš„å›¾å½¢æ•ˆæœã€‚å°½ç®¡å®ƒè¿œä¸æ˜¯ä¸€ä¸ªå¤æ‚çš„è§‚ä¼—æ¨¡æ‹Ÿå™¨ï¼Œä½†æˆ‘å¾ˆé«˜å…´æˆ‘æ„å»ºäº†å®ƒã€‚é™¤äº†æ¨åŠ¨é¡¹ç›®å‘å‰å‘å±•å¹¶è®©æˆ‘æ¢ç´¢ä¸åŒçš„è®¾è®¡ï¼Œå®ƒè¿˜åŠ æ·±äº†æˆ‘å¯¹åŸºç¡€å›¾å½¢çš„ç†è§£ã€‚æ­¤å¤–ï¼Œèƒ½å¤Ÿå‘æœ‹å‹å±•ç¤ºè¿™ä¸ªç²—ç³™çš„åŸå‹ï¼Œè¿™å¸®åŠ©æˆ‘è·å¾—äº†ç”¨æˆ·åé¦ˆï¼Œä»è€Œå¡‘é€ äº†æˆ‘å¯¹äº§å“æƒ³æ³•çš„çœ‹æ³•ã€‚

æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šæœ‰ä¸€ä¸ªæˆ‘è®¤ä¸ºæœ‰è¶£çš„å¼€å‘æƒ³æ³•æ¸…å•ã€‚å®ƒä»¬ä¸­çš„å¤§å¤šæ•°éƒ½éœ€è¦æ¯”æˆ‘æŸå¤©å¯èƒ½æ‹¥æœ‰çš„å‡ ä¸ªå°æ—¶å¤šå¾—å¤šçš„æ—¶é—´ï¼Œä½†é€šè¿‡ç¼©å‡å…¶èŒƒå›´ï¼Œæˆ‘å¯ä»¥å¼€å§‹è¡ŒåŠ¨ï¼Œå¹¶ä¸”é¡¹ç›®çš„åˆæ­¥è¿›å±•æœ‰åŠ©äºæˆ‘å†³å®šå®ƒæ˜¯å¦å€¼å¾—è¿›ä¸€æ­¥æŠ•èµ„ã€‚ä½œä¸ºé¢å¤–çš„å¥½å¤„ï¼Œå°è¯•å¼€å‘å„ç§å„æ ·çš„åº”ç”¨ç¨‹åºæœ‰åŠ©äºæˆ‘ç»ƒä¹ å¹¿æ³›çš„æŠ€èƒ½ã€‚ä½†æœ€é‡è¦çš„æ˜¯ï¼Œè¿™èƒ½è®©ä¸€ä¸ªæƒ³æ³•ä»æˆ‘çš„è„‘æµ·ä¸­é‡Šæ”¾å‡ºæ¥ï¼Œå¹¶å¯èƒ½å‘ˆç°åœ¨æ½œåœ¨ç”¨æˆ·é¢å‰ä»¥è·å–åé¦ˆï¼Œä»è€Œè®©é¡¹ç›®æ›´å¿«åœ°æ¨è¿›ã€‚

[Original textï¼šhttps://t.co/UP6arTWAdV]

### 086

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-09
é“¾æ¥: https://x.com/AndrewYNg/status/1942952817049915596
äº’åŠ¨: Likes: 1,488; Retweets: 329; Replies: 38; Quotes: 10; Views: 122,792; Bookmarks: 1,185; isReply: 0

New Course: Post-training of LLMs

Learn to post-train and customize an LLM in this short course, taught by @BanghuaZ, Assistant Professor at  the University of Washington @UW, and co-founder of @NexusflowX.

Training an LLM to follow instructions or answer questions has two key stages: pre-training and post-training. In pre-training, it learns to predict the next word or token from large amounts of unlabeled text. In post-training, it learns useful behaviors such as following instructions, tool use, and reasoning.

Post-training transforms a general-purpose token predictorâ€”trained on trillions of unlabeled text tokensâ€”into an assistant that follows instructions and performs specific tasks. Because it is much cheaper than pre-training, it is practical for many more teams to incorporate post-training methods into their workflows than pre-training.

In this course, youâ€™ll learn three common post-training methodsâ€”Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Online Reinforcement Learning (RL)â€”and how to use each one effectively. With SFT, you train the model on pairs of input and ideal output responses. With DPO, you provide both a preferred (chosen) and a less preferred (rejected) response and train the model to favor the preferred output. With RL, the model generates an output, receives a reward score based on human or automated feedback, and updates the model to improve performance.

Youâ€™ll learn the basic concepts, common use cases, and principles for curating high-quality data for effective training. Through hands-on labs, youâ€™ll download a pre-trained model from Hugging Face and post-train it using SFT, DPO, and RL to see how each technique shapes model behavior.

In detail, youâ€™ll:
- Understand what post-training is, when to use it, and how it differs from pre-training.
- Build an SFT pipeline to turn a base model into an instruct model.
- Explore how DPO reshapes behavior by minimizing contrastive lossâ€”penalizing poor responses and reinforcing preferred ones.
- Implement a DPO pipeline to change the identity of a chat assistant.
- Learn online RL methods such as Proximal Policy Optimization (PPO) and Group Relative Policy Optimization (GRPO), and how to design reward functions.
- Train a model with GRPO to improve its math capabilities using a verifiable reward.

Post-training is one of the most rapidly developing areas of LLM training. Whether youâ€™re building a high-accuracy context-specific assistant, fine-tuning a model's tone, or improving task-specific accuracy, this course will give you experience with the most important techniques shaping how LLMs are post-trained today.

Please sign up here: https://t.co/efSt2FnVNS

æ–°è¯¾ç¨‹ï¼šå¤§è¯­è¨€æ¨¡å‹çš„åè®­ç»ƒåœ¨è¿™é—¨çŸ­è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œåè®­ç»ƒå’Œå®šåˆ¶ã€‚è¯¾ç¨‹ç”±åç››é¡¿å¤§å­¦ @UW åŠ©ç†æ•™æˆã€@NexusflowX è”åˆåˆ›å§‹äºº @BanghuaZ æˆè¯¾ã€‚

è®­ç»ƒä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ä»¥ä½¿å…¶èƒ½å¤Ÿéµå¾ªæŒ‡ä»¤æˆ–å›ç­”é—®é¢˜ï¼Œé€šå¸¸éœ€è¦ç»å†ä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šé¢„è®­ç»ƒå’Œåè®­ç»ƒã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹ä»æµ·é‡çš„æœªæ ‡è®°æ–‡æœ¬æ•°æ®ä¸­å­¦ä¹ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯æˆ– Tokenã€‚è€Œåœ¨åè®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹åˆ™è¢«è®­ç»ƒå‡ºå„ç§å®ç”¨è¡Œä¸ºï¼Œæ¯”å¦‚ç†è§£å¹¶éµå¾ªæŒ‡ä»¤ã€ä½¿ç”¨å·¥å…·ä»¥åŠè¿›è¡Œæ¨ç†ã€‚

åè®­ç»ƒæ˜¯ä¸€ä¸ªå…³é”®çš„è½¬åŒ–è¿‡ç¨‹ï¼Œå®ƒèƒ½å°†ä¸€ä¸ªåœ¨æ•°ä¸‡äº¿ä¸ªæœªæ ‡è®°æ–‡æœ¬ Token ä¸Šè®­ç»ƒå‡ºçš„ã€åªèƒ½é¢„æµ‹ä¸‹ä¸€ä¸ª Token çš„é€šç”¨æ¨¡å‹ï¼Œè½¬å˜ä¸ºä¸€ä¸ªèƒ½å¤Ÿéµå¾ªæŒ‡ä»¤å¹¶æ‰§è¡Œç‰¹å®šä»»åŠ¡çš„æ™ºèƒ½åŠ©æ‰‹ã€‚ç”±äºåè®­ç»ƒçš„æˆæœ¬è¿œä½äºé¢„è®­ç»ƒï¼Œå› æ­¤å¯¹äºæ›´å¤šå›¢é˜Ÿæ¥è¯´ï¼Œå°†åè®­ç»ƒæ–¹æ³•æ•´åˆåˆ°å…¶å·¥ä½œæµç¨‹ä¸­ï¼Œæ¯”è¿›è¡Œé¢„è®­ç»ƒæ›´ä¸ºå®é™…å¯è¡Œã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸‰ç§å¸¸è§çš„åè®­ç»ƒæ–¹æ³• â€”â€” ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼ŒSFTï¼‰ã€ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimizationï¼ŒDPOï¼‰å’Œåœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOnline Reinforcement Learningï¼ŒRL)â€”â€” ä»¥åŠå¦‚ä½•æœ‰æ•ˆåœ°è¿ç”¨å®ƒä»¬ã€‚
- ä½¿ç”¨ SFTï¼Œä½ å¯ä»¥åœ¨ä¸€ç³»åˆ—è¾“å…¥å’Œç†æƒ³è¾“å‡ºçš„å“åº”å¯¹ä¸Šè®­ç»ƒæ¨¡å‹ã€‚
- ä½¿ç”¨ DPOï¼Œä½ åŒæ—¶æä¾›ä¸€ä¸ªåå¥½çš„ï¼ˆé€‰å®šçš„ï¼‰å“åº”å’Œä¸€ä¸ªä¸é‚£ä¹ˆåå¥½çš„ï¼ˆè¢«æ‹’ç»çš„ï¼‰å“åº”ï¼Œç„¶åè®­ç»ƒæ¨¡å‹ä½¿å…¶æ›´å€¾å‘äºç”Ÿæˆåå¥½çš„è¾“å‡ºã€‚
- è€Œ RL æ–¹æ³•åˆ™æ˜¯æ¨¡å‹ç”Ÿæˆä¸€ä¸ªè¾“å‡ºåï¼Œæ ¹æ®äººç±»æˆ–è‡ªåŠ¨åé¦ˆè·å¾—ä¸€ä¸ªå¥–åŠ±åˆ†æ•°ï¼Œç„¶åæ¨¡å‹ä¼šæ ¹æ®è¿™ä¸ªåˆ†æ•°è¿›è¡Œæ›´æ–°ï¼Œä»è€Œæå‡æ€§èƒ½ã€‚

ä½ å°†å­¦ä¹ åŸºæœ¬æ¦‚å¿µã€å¸¸è§åº”ç”¨åœºæ™¯ï¼Œä»¥åŠå¦‚ä½•ç­›é€‰å’Œæ•´ç†é«˜è´¨é‡æ•°æ®ä»¥è¿›è¡Œé«˜æ•ˆè®­ç»ƒã€‚é€šè¿‡å®è·µæ“ä½œï¼Œä½ å°†ä» Hugging Face ä¸‹è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶åˆ†åˆ«ä½¿ç”¨ SFTã€DPO å’Œ RL å¯¹å…¶è¿›è¡Œåè®­ç»ƒï¼Œäº²èº«æ„Ÿå—æ¯ç§æŠ€æœ¯å¦‚ä½•å¡‘é€ æ¨¡å‹çš„è¡Œä¸ºã€‚

å…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š
- ç†è§£ä»€ä¹ˆæ˜¯åè®­ç»ƒï¼Œä½•æ—¶åº”è¯¥ä½¿ç”¨å®ƒï¼Œä»¥åŠå®ƒä¸é¢„è®­ç»ƒæœ‰ä½•ä¸åŒã€‚
- æ„å»ºä¸€ä¸ª SFT æµç¨‹ï¼Œå°†ä¸€ä¸ªåŸºç¡€æ¨¡å‹è½¬åŒ–ä¸ºä¸€ä¸ªèƒ½å¤Ÿç†è§£æŒ‡ä»¤çš„æ¨¡å‹ã€‚
- æ¢ç´¢ DPO å¦‚ä½•é€šè¿‡æœ€å°åŒ–å¯¹æ¯”æŸå¤±æ¥æ”¹å˜æ¨¡å‹è¡Œä¸º â€”â€” å³é€šè¿‡æƒ©ç½šä¸ä½³å“åº”å¹¶å¼ºåŒ–åå¥½å“åº”æ¥å®ç°ã€‚
- å®ç°ä¸€ä¸ª DPO æµç¨‹ï¼Œä»¥æ”¹å˜ä¸€ä¸ªèŠå¤©åŠ©æ‰‹çš„ä¸ªæ€§æˆ–é£æ ¼ã€‚
- å­¦ä¹ åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä¾‹å¦‚è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimizationï¼ŒPPOï¼‰å’Œç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGroup Relative Policy Optimizationï¼ŒGRPOï¼‰ï¼Œå¹¶äº†è§£å¦‚ä½•è®¾è®¡å¥–åŠ±å‡½æ•°ã€‚
- ä½¿ç”¨ GRPO è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶é€šè¿‡å¯éªŒè¯çš„å¥–åŠ±æœºåˆ¶æå‡å…¶æ•°å­¦èƒ½åŠ›ã€‚

åè®­ç»ƒæ˜¯å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒé¢†åŸŸå‘å±•æœ€å¿«çš„æ–¹å‘ä¹‹ä¸€ã€‚æ— è®ºä½ æ˜¯æƒ³æ„å»ºä¸€ä¸ªé«˜ç²¾åº¦çš„ç‰¹å®šåœºæ™¯åŠ©æ‰‹ã€å¾®è°ƒæ¨¡å‹çš„è¯­æ°”é£æ ¼ï¼Œè¿˜æ˜¯æé«˜ç‰¹å®šä»»åŠ¡çš„å‡†ç¡®æ€§ï¼Œæœ¬è¯¾ç¨‹éƒ½å°†ä¸ºä½ æä¾›å½“ä¸‹å¤§è¯­è¨€æ¨¡å‹åè®­ç»ƒä¸­æœ€é‡è¦çš„æŠ€æœ¯å®è·µç»éªŒã€‚

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/efSt2FnVNS

### 087

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-10
é“¾æ¥: https://x.com/AndrewYNg/status/1943319708859834499
äº’åŠ¨: Likes: 2,277; Retweets: 361; Replies: 67; Quotes: 18; Views: 190,568; Bookmarks: 2,055; isReply: 0

Agentic Document Extraction now supports field extraction! Many doc extraction use cases extract specific fields from forms and other structured documents. You can now input a picture or PDF of an invoice, request the vendor name, item list, and prices, and get back the extracted fields. Or input a medical form and specify a schema to extract patient name, patient ID, insurance number, etc. 

One cool feature: If you don't feel like writing a schema (json specification of what fields to extract) yourself, upload one sample document and write a natural language prompt saying what you want, and we automatically generate a schema for you.

See the video for details!

Agentic Document Extraction ç°åœ¨æ”¯æŒ ** å­—æ®µæå– **ï¼ˆfield extractionï¼‰åŠŸèƒ½ï¼è®¸å¤šæ–‡æ¡£æå–çš„åœºæ™¯éƒ½éœ€è¦ä»è¡¨æ ¼æˆ–å…¶ä»–ç»“æ„åŒ–æ–‡æ¡£ä¸­æå–ç‰¹å®šå­—æ®µã€‚ç°åœ¨ï¼Œä½ å¯ä»¥ä¸Šä¼ ä¸€å¼ å‘ç¥¨çš„å›¾ç‰‡æˆ– PDFï¼Œè¯·æ±‚æå–ä¾›åº”å•†åç§°ã€é¡¹ç›®åˆ—è¡¨å’Œä»·æ ¼ï¼Œç„¶åå°±èƒ½å¾—åˆ°è¿™äº›å·²æå–çš„å­—æ®µä¿¡æ¯ã€‚æˆ–è€…ï¼Œä½ ä¹Ÿå¯ä»¥ä¸Šä¼ ä¸€ä»½åŒ»ç–—è¡¨æ ¼ï¼Œå¹¶æŒ‡å®šä¸€ä¸ª ** æ¨¡å¼ **ï¼ˆschemaï¼‰æ¥æå–æ‚£è€…å§“åã€æ‚£è€… IDã€ä¿é™©å·ç ç­‰ã€‚

å…¶ä¸­ä¸€é¡¹å¾ˆæ£’çš„åŠŸèƒ½æ˜¯ï¼šå¦‚æœä½ ä¸æƒ³è‡ªå·±åŠ¨æ‰‹ç¼–å†™ ** æ¨¡å¼ **ï¼ˆschemaï¼‰(ä¹Ÿå°±æ˜¯å®šä¹‰è¦æå–å“ªäº›å­—æ®µçš„ JSON ** è§„èŒƒ **ï¼ˆJSON specificationï¼‰ï¼‰ï¼Œåªéœ€ä¸Šä¼ ä¸€ä»½æ ·æœ¬æ–‡æ¡£ï¼Œå¹¶ç”¨ ** è‡ªç„¶è¯­è¨€æç¤º **ï¼ˆnatural language promptï¼‰è¯´æ˜ä½ çš„éœ€æ±‚ï¼Œæˆ‘ä»¬å°±ä¼šè‡ªåŠ¨ä¸ºä½ ç”Ÿæˆä¸€ä¸ªæ¨¡å¼ã€‚

è§‚çœ‹è§†é¢‘äº†è§£æ›´å¤šè¯¦æƒ…ï¼

### 088

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-10
é“¾æ¥: https://x.com/AndrewYNg/status/1943385392469962846
äº’åŠ¨: Likes: 1,471; Retweets: 323; Replies: 53; Quotes: 11; Views: 178,548; Bookmarks: 1,153; isReply: 0

My talk at YC Startup School on how to build AI startups. I share tips from @AI_Fund on how to use AI to build fast. Let me know what you think!

æˆ‘åœ¨ YC Startup School åšäº†å…³äºå¦‚ä½•å»ºç«‹ AI åˆåˆ›å…¬å¸çš„æ¼”è®²ã€‚æˆ‘åˆ†äº«äº†æ¥è‡ª @AI_Fund çš„ç»éªŒå’ŒæŠ€å·§ï¼Œè®²è§£å¦‚ä½•åˆ©ç”¨ AI å¿«é€Ÿæ„å»ºå’Œå‘å±•ã€‚æ¬¢è¿å¤§å®¶æå‡ºå®è´µæ„è§ï¼

### 089

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-11
é“¾æ¥: https://x.com/AndrewYNg/status/1943710282381180934
äº’åŠ¨: Likes: 332; Retweets: 72; Replies: 39; Quotes: 10; Views: 67,932; Bookmarks: 72; isReply: 0

Last week, the United States Congress passed President Trumpâ€™s â€œBig Beautiful Bill.â€ Iâ€™m disappointed it didnâ€™t include a proposed moratorium on U.S. state-level AI regulation. While there is a role for AI regulation, it is when the technology is new and poorly understood that lobbyists are most likely to succeed at pushing through anti-competitive regulations that hamper open-source and other beneficial AI efforts. A moratorium would have bought more time for regulators to figure out the realistic risks and rewards of AI and thereby avoid bad regulatory proposals.

Many jurisdictions loosely follow this trajectory:
- When new AI technology is still poorly understood, companies can make grandiose statements about its benefits or dangers, and both traditional and social media are ineffective at fact-checking them and tend to parrot what they say. During this initial period, businesses can get away with saying almost anything.
- This opens opportunities for hype as well as fear mongering based on exaggerated claims about AI dangers. Some businesses exploit this opportunity to try to get regulators to pass anti-competitive laws that impede open-source and other competitors.
- But eventually, smart regulators learn enough about AI to understand its realistic benefits and risks. For example, the U.S. Senateâ€™s bipartisan Insight Forum on AI, which I participated in, heard from many stakeholders and came to support innovation and dismiss ill-founded fears of â€œAI takeoverâ€ and the like.

Indeed, the European Union went through this trajectory as well. After the EU AI Act was passed, many regulators realized many of its â€œprotectionsâ€ are not actually helpful. They relaxed some of the lawâ€™s provisions to make it less stifling of innovation than many observers initially had feared.

There are AI regulations that would limit harmful applications appropriately, for example, banning non-consensual deepfake porn and preventing misleading marketing. However, many states, which have less resources than the federal government to deeply understand AI, have proposed harmful regulations, especially those that aim to regulate the technology rather than the applications.

For example:
- Californiaâ€™s SB 1047 purported to impose safety requirements on frontier AI systems, but it placed ambiguous and/or technically infeasible requirements on model creators to prevent harmful downstream uses. This is akin to holding the maker of a hammer liable if someone uses it for harmful purposes. Fortunately, Governor Gavin Newsom quashed SB 1047 with a veto.
- New Yorkâ€™s Responsible AI Safety and Education Act, which passed the state legislature in June and awaits Governor Kathy Hochulâ€™s signature or veto, also places ambiguous and unreasonable requirements on model builders, purportedly to guard against theoretical â€œcritical harms.â€ It would hamper open source without making anyone meaningfully safer.
- The Texas Responsible AI Governance Act initially included many of the problematic elements of SB 1047. It would have created unreasonable requirements that model providers would have had a hard time complying with, and compliance would have amounted to safety theater that was unlikely to actually make people safer. Fortunately, as Texas regulators came to understand AI better, they significantly scaled back the law, and Governor Greg Abbott signed it into law in late June. The final law focuses on specific application areas, establishes an advisory council and regulatory sandbox, and places more burden on government agencies than private companies.

Sadly, I see the net impact of the regulations proposed so far as negative. Many would severely hamper innovation despite some lesser positive benefits. This is why a moratorium on state-level regulation would have been a net benefit to AI and to society. Shutting down bad regulations for a limited period would have given regulators time to figure out AI technology and ignore irresponsible fear mongering. In addition, it would have helped them avoid creating a patchwork of state-level regulations that businesses large and small have a hard time complying with.

Perhaps a 10-year blanket moratorium was a step too far. A more modest, say, 2-year moratorium, and one that covered only the most problematic regulatory proposals, might have had a better chance of passing.

Even though a moratorium did not make it into Trumpâ€™s bill, I hope that efforts continue in the U.S. and other nations to give regulators time to understand the real risks and benefits of AI, and not pass stifling regulations during that initial period when the technology is new and the power of fear mongering is strongest.

[Original text: https://t.co/56ZkPD9ta5 ]

<p> ä¸Šå‘¨ï¼Œç¾å›½å›½ä¼šé€šè¿‡äº†ç‰¹æœ—æ™®æ€»ç»Ÿçš„ã€Œå®å¤§ç¾ä¸½æ³•æ¡ˆã€ï¼ˆBig Beautiful Billï¼‰ã€‚æˆ‘æ„Ÿåˆ°å¤±æœ›çš„æ˜¯ï¼Œè¿™é¡¹æ³•æ¡ˆå¹¶æœªåŒ…å«ä¸€é¡¹æ—¨åœ¨æš‚åœç¾å›½å·çº§äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç›‘ç®¡çš„ææ¡ˆã€‚å°½ç®¡å¯¹ AI è¿›è¡Œç›‘ç®¡æ˜¯å¿…è¦çš„ï¼Œä½†å½“è¿™é¡¹æŠ€æœ¯å°šå¤„äºæ–°ç”Ÿé˜¶æ®µã€äººä»¬å¯¹å…¶äº†è§£ä¸è¶³æ—¶ï¼Œæ¸¸è¯´è€…æœ€å®¹æ˜“æˆåŠŸæ¨åŠ¨é‚£äº›å…·æœ‰åç«äº‰æ€§è´¨çš„æ³•è§„ï¼Œä»è€Œé˜»ç¢ <a href="https://baike.baidu.com/item/% E5% BC%80% E6% BA%90% E8% BD% AF% E4% BB% B6"> å¼€æº </a>ï¼ˆopen-sourceï¼‰å’Œå…¶ä»–æœ‰ç›Šçš„ AI å‘å±•ã€‚ä¸€é¡¹æš‚åœä»¤æœ¬å¯ä»¥ä¸ºç›‘ç®¡æœºæ„äº‰å–æ›´å¤šæ—¶é—´ï¼Œä»¥ä¾¿ä»–ä»¬å……åˆ†ç†è§£ AI çš„å®é™…é£é™©å’Œæ½œåœ¨å›æŠ¥ï¼Œä»è€Œé¿å…å‡ºå°ä¸æ°å½“çš„ç›‘ç®¡æ–¹æ¡ˆã€‚</p>
<p> è®¸å¤šå¸æ³•ç®¡è¾–åŒºå¤§éƒ½éµå¾ªä»¥ä¸‹å‘å±•è½¨è¿¹ï¼š</p>
<ul>
<li> å½“æ–°å…´çš„ AI æŠ€æœ¯ä»æœªè¢«å……åˆ†ç†è§£æ—¶ï¼Œå…¬å¸å¯èƒ½ä¼šå¯¹å…¶ç›Šå¤„æˆ–æ½œåœ¨å±é™©åšå‡ºå¤¸å¤§å…¶è¯çš„å£°æ˜ï¼Œè€Œä¼ ç»Ÿåª’ä½“å’Œç¤¾äº¤åª’ä½“åœ¨äº‹å®æ ¸æŸ¥æ–¹é¢å¾€å¾€æ•ˆç‡ä¸é«˜ï¼Œå®¹æ˜“ä¸åŠ æ‰¹åˆ¤åœ°é‡å¤è¿™äº›è¯´æ³•ã€‚åœ¨è¿™ä¸ªåˆå§‹é˜¶æ®µï¼Œä¼ä¸šå‡ ä¹å¯ä»¥éšæ„å‘è¡¨è¨€è®ºè€Œæ— éœ€æ‰¿æ‹…å¤ªå¤šåæœã€‚</li>
<li> è¿™ä¸ºåŸºäºå¯¹ AI å±é™©çš„å¤¸å¤§æè¿°è€Œäº§ç”Ÿçš„ç‚’ä½œå’Œææ…Œæƒ…ç»ªæä¾›äº†æ»‹ç”ŸåœŸå£¤ã€‚ä¸€äº›ä¼ä¸šä¼šåˆ©ç”¨è¿™ç§æœºä¼šï¼Œè¯•å›¾ä¿ƒä½¿ç›‘ç®¡æœºæ„é€šè¿‡åç«äº‰æ€§æ³•å¾‹ï¼Œä»è€Œé˜»ç¢å¼€æºé¡¹ç›®å’Œå…¶ä»–ç«äº‰å¯¹æ‰‹çš„å‘å±•ã€‚</li>
<li> ç„¶è€Œï¼Œæœ€ç»ˆï¼Œæ˜æ™ºçš„ç›‘ç®¡æœºæ„ä¼šç§¯ç´¯è¶³å¤Ÿå¤šçš„ AI çŸ¥è¯†ï¼Œä»è€Œèƒ½å¤Ÿç†è§£å…¶çœŸå®çš„ç›Šå¤„å’Œé£é™©ã€‚ä¾‹å¦‚ï¼Œæˆ‘æ›¾å‚ä¸çš„ç¾å›½å‚è®®é™¢ä¸¤å…š AI æ´å¯Ÿè®ºå›ï¼Œå°±å¬å–äº†ä¼—å¤šåˆ©ç›Šç›¸å…³è€…çš„æ„è§ï¼Œå¹¶å¼€å§‹æ”¯æŒåˆ›æ–°ï¼ŒåŒæ—¶é©³æ–¥äº†ã€ŒAI æ¥ç®¡ã€ç­‰æ¯«æ— æ ¹æ®çš„æ‹…å¿§ã€‚</li>
</ul>
<p> äº‹å®ä¸Šï¼Œæ¬§ç›Ÿä¹Ÿç»å†äº†ç±»ä¼¼çš„å‘å±•è½¨è¿¹ã€‚åœ¨ã€Šæ¬§ç›Ÿ AI æ³•æ¡ˆã€‹ï¼ˆEU AI Actï¼‰é€šè¿‡åï¼Œè®¸å¤šç›‘ç®¡æœºæ„æ„è¯†åˆ°å…¶ä¸å°‘ã€Œä¿æŠ¤æªæ–½ã€å®é™…ä¸Šå¹¶æ— åŠ©ç›Šã€‚äºæ˜¯ï¼Œä»–ä»¬æ”¾å®½äº†è¯¥æ³•æ¡ˆçš„éƒ¨åˆ†æ¡æ¬¾ï¼Œä½¿å…¶å¯¹åˆ›æ–°çš„æŠ‘åˆ¶ä½œç”¨ä½äºè®¸å¤šè§‚å¯Ÿå®¶æœ€åˆçš„æ‹…å¿§ã€‚</p>
<p> æœ‰äº› AI ç›‘ç®¡æªæ–½ç¡®å®èƒ½å¤Ÿæ°å½“åœ°é™åˆ¶æœ‰å®³åº”ç”¨ï¼Œä¾‹å¦‚ï¼Œç¦æ­¢æœªç»åŒæ„çš„ <a href="https://baike.baidu.com/item/% E6% B7% B1% E5% BA% A6% E4% BC% AA% E9%80% A0"> æ·±åº¦ä¼ªé€  </a>ï¼ˆdeepfakeï¼‰è‰²æƒ…åˆ¶å“ï¼Œä»¥åŠé˜²æ­¢è¯¯å¯¼æ€§è¥é”€ã€‚ç„¶è€Œï¼Œè®¸å¤šå·åœ¨æ·±å…¥ç†è§£ AI æ–¹é¢ï¼Œå…¶èµ„æºä¸å¦‚è”é‚¦æ”¿åºœå……è¶³ï¼Œå´å·²ç»æå‡ºäº†ä¸€äº›æœ‰å®³çš„ç›‘ç®¡æªæ–½ï¼Œç‰¹åˆ«æ˜¯é‚£äº›æ—¨åœ¨ç›‘ç®¡æŠ€æœ¯æœ¬èº«è€Œéå…¶å…·ä½“åº”ç”¨çš„æè®®ã€‚</p>
<p> ä¾‹å¦‚ï¼š</p>
<ul>
<li> åŠ å·çš„ SB 1047 æ³•æ¡ˆå£°ç§°è¦å¯¹ <a href="https://baike.baidu.com/item/% E5%89%8D% E6% B2% BF% E4% BA% BA% E5% B7% A5% E6%99% BA% E8%83% BD"> å‰æ²¿ AI ç³»ç»Ÿ </a>ï¼ˆfrontier AI systemsï¼‰æ–½åŠ å®‰å…¨è¦æ±‚ï¼Œä½†å®ƒå¯¹æ¨¡å‹åˆ›å»ºè€…æå‡ºäº†æ¨¡ç³Šä¸æ¸…ï¼Œç”šè‡³æŠ€æœ¯ä¸Šä¸å¯è¡Œçš„è¦æ±‚ï¼Œä»¥æœŸé˜²æ­¢æœ‰å®³çš„ä¸‹æ¸¸ä½¿ç”¨ã€‚è¿™æ— å¼‚äºå¦‚æœæœ‰äººç”¨é”¤å­åšæœ‰å®³ç”¨é€”ï¼Œå°±è¿½ç©¶é”¤å­åˆ¶é€ å•†çš„è´£ä»»ã€‚å¹¸è¿çš„æ˜¯ï¼Œå·é•¿ Gavin Newsom è¡Œä½¿å¦å†³æƒï¼Œé˜»æ­¢äº† SB 1047 æ³•æ¡ˆçš„é€šè¿‡ã€‚</li>
<li> çº½çº¦çš„ã€Šè´Ÿè´£ä»» AI å®‰å…¨ä¸æ•™è‚²æ³•æ¡ˆã€‹å·²äºå…­æœˆé€šè¿‡å·è®®ä¼šï¼Œç›®å‰æ­£ç­‰å¾…å·é•¿ Kathy Hochul ç­¾ç½²æˆ–å¦å†³ã€‚è¯¥æ³•æ¡ˆåŒæ ·å¯¹æ¨¡å‹å¼€å‘è€…æ–½åŠ äº†æ¨¡ç³Šä¸”ä¸åˆç†çš„è¦æ±‚ï¼Œå£°ç§°æ˜¯ä¸ºäº†é˜²èŒƒç†è®ºä¸Šçš„ã€Œå…³é”®å±å®³ã€ã€‚åœ¨æœªèƒ½æ˜¾è‘—æå‡ä»»ä½•äººçš„å®‰å…¨æ€§çš„å‰æä¸‹ï¼Œå®ƒåè€Œä¼šé˜»ç¢å¼€æºå‘å±•ã€‚</li>
<li> å¾·å…‹è¨æ–¯å·çš„ã€Šè´Ÿè´£ä»» AI æ²»ç†æ³•æ¡ˆã€‹æœ€åˆä¹ŸåŒ…å«äº† SB 1047 æ³•æ¡ˆä¸­çš„è®¸å¤šé—®é¢˜è¦ç´ ã€‚å®ƒæ›¾æå‡ºä¸€äº›ä¸åˆç†çš„è¦æ±‚ï¼Œä½¿å¾—æ¨¡å‹æä¾›å•†å°†éš¾ä»¥éµå®ˆï¼›è€Œè¿™ç§éµå®ˆè¡Œä¸ºä¸è¿‡æ˜¯ <a href="https://baike.baidu.com/item/% E5% AE%89% E5%85% A8% E5%89% A7% E5%9C% BA"> å®‰å…¨å‰§åœº </a>ï¼ˆsafety theaterï¼‰ï¼Œä¸å¤ªå¯èƒ½çœŸæ­£æé«˜äººä»¬çš„å®‰å…¨æ€§ã€‚å¹¸è¿çš„æ˜¯ï¼Œéšç€å¾·å…‹è¨æ–¯å·ç›‘ç®¡æœºæ„å¯¹ AI çš„ç†è§£åŠ æ·±ï¼Œä»–ä»¬å¤§å¹…ç¼©å‡äº†è¯¥æ³•æ¡ˆçš„èŒƒå›´ï¼Œå·é•¿ Greg Abbott å·²äºå…­æœˆä¸‹æ—¬å°†å…¶ç­¾ç½²æˆä¸ºæ³•å¾‹ã€‚æœ€ç»ˆçš„æ³•å¾‹ä¾§é‡äºç‰¹å®šçš„åº”ç”¨é¢†åŸŸï¼Œå»ºç«‹äº†å’¨è¯¢å§”å‘˜ä¼šå’Œ <a href="https://baike.baidu.com/item/% E7%9B%91% E7% AE% A1% E6% B2%99% E7%9B%92"> ç›‘ç®¡æ²™ç›’ </a>ï¼ˆregulatory sandboxï¼‰ï¼Œå¹¶å°†æ›´å¤šè´£ä»»å’Œè´Ÿæ‹…åˆ†é…ç»™æ”¿åºœæœºæ„ï¼Œè€Œéç§äººä¼ä¸šã€‚</li>
</ul>
<p> é—æ†¾çš„æ˜¯ï¼Œæˆ‘è®¤ä¸ºè¿„ä»Šä¸ºæ­¢æå‡ºçš„è¿™äº›æ³•è§„çš„æ€»ä½“å½±å“æ˜¯è´Ÿé¢çš„ã€‚è®¸å¤šæ³•è§„å°½ç®¡æœ‰ä¸€äº›å¾®å°çš„ç§¯æç›Šå¤„ï¼Œå´ä¼šä¸¥é‡é˜»ç¢åˆ›æ–°ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæš‚åœå·çº§ç›‘ç®¡æœ¬å¯ä»¥ä¸º AI å’Œæ•´ä¸ªç¤¾ä¼šå¸¦æ¥æ˜¾è‘—çš„æ€»ä½“ç›Šå¤„ã€‚åœ¨æœ‰é™çš„æ—¶é—´å†…é˜»æ­¢ä¸å½“æ³•è§„ï¼Œèƒ½è®©ç›‘ç®¡æœºæ„æœ‰æ—¶é—´å¼„æ¸…æ¥š AI æŠ€æœ¯ï¼Œå¹¶å¿½ç•¥ä¸è´Ÿè´£ä»»çš„ææ…Œæ•£å¸ƒã€‚æ­¤å¤–ï¼Œè¿™è¿˜æœ‰åŠ©äºä»–ä»¬é¿å…å½¢æˆä¸€å¥—è®©å¤§å°ä¼ä¸šéƒ½éš¾ä»¥éµå®ˆçš„é›¶æ•£å·çº§æ³•è§„ã€‚</p>
<p> æˆ–è®¸å…¨é¢çš„ 10 å¹´æš‚åœä»¤å¯èƒ½è¿‡äºæ¿€è¿›ã€‚ä¸€ä¸ªæ›´æ¸©å’Œçš„æ–¹æ¡ˆï¼Œä¾‹å¦‚ï¼Œä¸ºæœŸ 2 å¹´çš„æš‚åœä»¤ï¼Œå¹¶ä¸”ä»…é™äºå¤„ç†é‚£äº›é—®é¢˜æœ€ä¸ºçªå‡ºçš„ç›‘ç®¡æè®®ï¼Œæˆ–è®¸ä¼šæœ‰æ›´å¤§çš„é€šè¿‡æœºä¼šã€‚</p>
<p> å°½ç®¡æš‚åœä»¤æœ€ç»ˆæœªèƒ½çº³å…¥ç‰¹æœ—æ™®çš„æ³•æ¡ˆï¼Œä½†æˆ‘å¸Œæœ›ç¾å›½åŠå…¶ä»–å›½å®¶èƒ½ç»§ç»­åŠªåŠ›ï¼Œç»™äºˆç›‘ç®¡æœºæ„è¶³å¤Ÿçš„æ—¶é—´æ¥ç†è§£ AI çš„çœŸå®é£é™©å’Œç›Šå¤„ï¼Œé¿å…åœ¨è¯¥æŠ€æœ¯å°šæ–°é¢–ã€ææ…Œæ•£å¸ƒå½±å“åŠ›æœ€å¼ºçš„åˆå§‹é˜¶æ®µï¼Œå°±é€šè¿‡æ‰¼æ€åˆ›æ–°çš„æ³•è§„ã€‚</p>
<p>[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/56ZkPD9ta5]</p>

### 090

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-15
é“¾æ¥: https://x.com/AndrewYNg/status/1945148766962729370
äº’åŠ¨: Likes: 878; Retweets: 161; Replies: 66; Quotes: 9; Views: 122,038; Bookmarks: 462; isReply: 0

Announcing AI Aspire, our new advisory firm to help enterprises with their AI strategy and transformation journey! We are partnering with Bain & Company and looking forward to helping businesses unlock scalable, transformative value.

C-suite is now realizing that top-down leadership is needed for AI transformation. But figuring out the implications of AI on a particular business is extremely complex. The Bain team is world class at helping businesses craft strategy and navigate complex landscapes. Kirsty Tan (at AI Aspire) and I are thrilled to be working with Bain's Chuck Whitten, Sarah Elk, Erika Serow and team to help businesses.

Questions that C-suite and boards are now asking include:
- What new products are now possible? What can we (or our competitors) now do for customers that were not possible before?
- How do we use AI to boost productivity? What workflows can be streamlined or processes reinvented?
- What technology investments, for example in data infrastructure, should now be prioritized? And what are the risks, for example to security and compliance?
- What are the HR implications: What roles do we hire more or fewer of?
- How do we bring the team with us for the journey, and enable transformation from within?
- Does AI enable new competitors; or alternatively, are there now new markets that are possible for us to move into?

Technology is no longer merely a support system for business â€” it isÂ  engine of growth for the companies nimble enough to adapt and daring enough to lead.

Press release: https://t.co/cjYX3yoWEn

éš†é‡æ¨å‡º AI Aspireï¼Œæˆ‘ä»¬å…¨æ–°çš„å’¨è¯¢å…¬å¸ï¼Œæ—¨åœ¨åŠ©åŠ›ä¼ä¸šåˆ¶å®šäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æˆ˜ç•¥å¹¶é¡ºåˆ©å®Œæˆè½¬å‹ä¹‹æ—…ï¼æˆ‘ä»¬æ­£ä¸ Bain & Company æºæ‰‹åˆä½œï¼ŒæœŸå¾…èƒ½å¸®åŠ©å„è¡Œå„ä¸šçš„å®¢æˆ·é‡Šæ”¾å¯æ‰©å±•ã€é¢ è¦†æ€§çš„ä»·å€¼ã€‚

å¦‚ä»Šï¼Œä¼ä¸šé«˜ç®¡ï¼ˆC-suiteï¼‰ä»¬æ­£é€æ¸æ„è¯†åˆ°ï¼ŒAI è½¬å‹éœ€è¦è‡ªä¸Šè€Œä¸‹çš„é¢†å¯¼åŠ›ã€‚ç„¶è€Œï¼Œè¦å¼„æ¸…æ¥š AI å¯¹ç‰¹å®šä¸šåŠ¡çš„æ·±è¿œå½±å“ï¼Œå´æ˜¯ä¸€é¡¹æå…¶å¤æ‚çš„æŒ‘æˆ˜ã€‚Bain å›¢é˜Ÿåœ¨ååŠ©ä¼ä¸šåˆ¶å®šæˆ˜ç•¥å’Œåº”å¯¹å¤æ‚å±€é¢æ–¹é¢å ªç§°ä¸–ç•Œä¸€æµã€‚AI Aspire çš„ Kirsty Tan å’Œæˆ‘æœ¬äººï¼Œéƒ½éå¸¸é«˜å…´èƒ½ä¸ Bain çš„ Chuck Whittenã€Sarah Elkã€Erika Serow åŠå…¶å›¢é˜Ÿåˆä½œï¼Œå…±åŒä¸ºä¼ä¸šæä¾›å¸®åŠ©ã€‚

ä¼ä¸šé«˜ç®¡å’Œè‘£äº‹ä¼šç›®å‰å…³æ³¨çš„é—®é¢˜åŒ…æ‹¬ï¼š
- ç°åœ¨æœ‰å“ªäº›å…¨æ–°çš„äº§å“æˆ–æœåŠ¡æˆä¸ºå¯èƒ½ï¼Ÿæˆ‘ä»¬ï¼ˆæˆ–æˆ‘ä»¬çš„ç«äº‰å¯¹æ‰‹ï¼‰ç°åœ¨èƒ½å¤Ÿä¸ºå®¢æˆ·æä¾›å“ªäº›ä»¥å¾€æ— æ³•å®ç°çš„åŠŸèƒ½ï¼Ÿ
- æˆ‘ä»¬åº”å¦‚ä½•è¿ç”¨ AI æ¥å¤§å¹…æå‡ç”Ÿäº§åŠ›ï¼Ÿå“ªäº›å·¥ä½œæµç¨‹å¯ä»¥è¢«ç²¾ç®€ä¼˜åŒ–ï¼Œæˆ–è€…å“ªäº›ä¸šåŠ¡æµç¨‹å¯ä»¥è¢«å½»åº•é‡å¡‘ï¼Ÿ
- ä¾‹å¦‚åœ¨æ•°æ®åŸºç¡€è®¾æ–½æ–¹é¢ï¼Œç°åœ¨åº”è¯¥ä¼˜å…ˆè€ƒè™‘å“ªäº›æŠ€æœ¯æŠ•èµ„ï¼ŸåŒæ—¶ï¼Œå¯èƒ½é¢ä¸´å“ªäº›é£é™©ï¼Œæ¯”å¦‚åœ¨å®‰å…¨å’Œåˆè§„æ€§æ–¹é¢ï¼Ÿ
- å¯¹äºäººåŠ›èµ„æºï¼ˆHRï¼‰åˆæœ‰å“ªäº›å½±å“ï¼šæˆ‘ä»¬åº”è¯¥å¢è˜å“ªäº›èŒä½ï¼Œåˆè¯¥ç¼©å‡å“ªäº›èŒä½ï¼Ÿ
- æˆ‘ä»¬å¦‚ä½•ç¡®ä¿å›¢é˜Ÿåœ¨è½¬å‹è¿‡ç¨‹ä¸­ä¿æŒåŒæ­¥ï¼Œå¹¶ä»å†…éƒ¨æ¿€å‘è½¬å‹çš„åŠ¨åŠ›ï¼Ÿ
- AI æ˜¯å¦ä¼šå‚¬ç”Ÿæ–°çš„ç«äº‰å¯¹æ‰‹ï¼Ÿæˆ–è€…ï¼Œæ˜¯å¦å­˜åœ¨æˆ‘ä»¬èƒ½å¤Ÿè¿›å†›çš„æ–°å…´å¸‚åœºï¼Ÿ

æŠ€æœ¯ä¸å†ä»…ä»…æ˜¯ä¸šåŠ¡çš„è¾…åŠ©ç³»ç»Ÿï¼Œå®ƒå·²æˆä¸ºé‚£äº›è¶³å¤Ÿæ•æ·ä»¥é€‚åº”å˜åŒ–ã€è¶³å¤Ÿå¤§èƒ†ä»¥å¼•é¢†æ½®æµçš„å…¬å¸çš„å¢é•¿å¼•æ“ã€‚

æ–°é—»ç¨¿ï¼šhttps://t.co/cjYX3yoWEn

### 091

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-16
é“¾æ¥: https://x.com/AndrewYNg/status/1945502636012445937
äº’åŠ¨: Likes: 1,676; Retweets: 329; Replies: 63; Quotes: 14; Views: 121,427; Bookmarks: 1,428; isReply: 0

Announcing a new Coursera course: Retrieval Augmented Generation (RAG)

You'll learn to build high performance, production-ready RAG systems in this hands-on, in-depth course created by https://t.co/zpIxRSuky4 and taught by @ZainHasan6, experienced AI and ML engineer, researcher, and educator. 

RAG is a critical component today of many LLM-based applications in customer support, internal company Q&A systems, even many of the leading chatbots that use web search to answer your questions. This course teaches you in-depth how to make RAG work well.

LLMs can produce generic or outdated responses, especially when asked specialized questions not covered in its training data. RAG is the most widely used technique for addressing this. It brings in data from new data sources, such as internal documents or recent news, to give the LLM the relevant context to private, recent, or specialized information. This lets it generate more grounded and accurate responses.

In this course, youâ€™ll learn to design and implement every part of a RAG system, from retrievers to vector databases to generation to evals. Youâ€™ll learn about the fundamental principles behind RAG and how to optimize it at both the component and whole-system levels.

As AI evolves, RAG is evolving too. New models can handle longer context windows, reason more effectively, and can be parts of complex agentic workflows. One exciting growth area is Agentic RAG, in which an AI agent at runtime (rather than it being hardcoded at development time) autonomously decides what data to retrieve, and when/how to go deeper. Even with this evolution, access to high-quality data at runtime is essential, which is why RAG is a key part of so many applications.

You'll learn via hands-on experiences to:
- Build a RAG system with retrieval and prompt augmentation
- Compare retrieval methods like BM25, semantic search, and Reciprocal Rank Fusion
- Chunk, index, and retrieve documents using a Weaviate vector database and a news dataset
- Develop a chatbot, using open-source LLMs hosted by Together AI, for a fictional store that answers product and FAQ questions
- Use evals to drive improving reliability, and incorporate multi-modal data

RAG is an important foundational technique. Become good at it through this course!

Please sign up here: https://t.co/81DSVlDEOW

Coursera æ¨å‡ºå…¨æ–°è¯¾ç¨‹ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval Augmented Generationï¼ŒRAG)

åœ¨è¿™é—¨ç”± https://t.co/zpIxRSuky4 ç²¾å¿ƒæ‰“é€ ï¼Œå¹¶ç”±ç»éªŒä¸°å¯Œçš„ AI å’Œæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å·¥ç¨‹å¸ˆã€ç ”ç©¶å‘˜åŠæ•™è‚²å®¶ @ZainHasan6 äº²è‡ªæˆè¯¾çš„æ·±åº¦å®è·µè¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºé«˜æ€§èƒ½ã€ç”Ÿäº§çº§çš„ RAG ç³»ç»Ÿã€‚

å¦‚ä»Šï¼ŒRAG å·²æˆä¸ºè®¸å¤šåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨ä¸­çš„æ ¸å¿ƒç»„ä»¶ï¼ŒåŒ…æ‹¬å®¢æˆ·æ”¯æŒã€ä¼ä¸šå†…éƒ¨é—®ç­”ç³»ç»Ÿï¼Œç”šè‡³è®¸å¤šåˆ©ç”¨ç½‘ç»œæœç´¢æ¥å›ç­”é—®é¢˜çš„é¡¶å°–èŠå¤©æœºå™¨äººã€‚æœ¬è¯¾ç¨‹å°†æ·±å…¥æ•™ä½ å¦‚ä½•è®© RAG å‘æŒ¥æœ€ä½³æ•ˆèƒ½ã€‚

å¤§è¯­è¨€æ¨¡å‹æœ‰æ—¶ä¼šç»™å‡ºæ³›æ³›è€Œè°ˆæˆ–ä¿¡æ¯è¿‡æ—¶çš„å›ç­”ï¼Œç‰¹åˆ«æ˜¯å½“å®ƒä»¬è¢«é—®åŠè®­ç»ƒæ•°æ®ä¸­æœªæ¶µç›–çš„ä¸“ä¸šé—®é¢˜æ—¶ã€‚RAG æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„æœ€æ™®éé‡‡ç”¨çš„æŠ€æœ¯æ–¹æ¡ˆã€‚å®ƒèƒ½å¤Ÿä»æ–°çš„æ•°æ®æºï¼ˆå¦‚å†…éƒ¨æ–‡æ¡£æˆ–æœ€æ–°æ–°é—»ï¼‰ä¸­å¼•å…¥ç›¸å…³ä¿¡æ¯ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›ä¸ç§æœ‰ã€ä¸“ä¸šæˆ–æœ€æ–°ä¿¡æ¯ç›¸å…³çš„ä¸Šä¸‹æ–‡ã€‚è¿™ä½¿å¾—å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´å¯é ã€æ›´ç²¾å‡†çš„å›ç­”ã€‚

åœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ è®¾è®¡å’Œå®ç° RAG ç³»ç»Ÿçš„æ¯ä¸€ä¸ªç¯èŠ‚ï¼Œä»æ£€ç´¢å™¨ã€å‘é‡æ•°æ®åº“ï¼Œåˆ°å†…å®¹ç”Ÿæˆå’Œç³»ç»Ÿè¯„ä¼°ç­‰å„ä¸ªæ–¹é¢ã€‚ä½ å°†æ·±å…¥ç†è§£ RAG èƒŒåçš„åŸºæœ¬åŸç†ï¼Œå¹¶å­¦ä¹ å¦‚ä½•åœ¨ç»„ä»¶å±‚é¢å’Œæ•´ä¸ªç³»ç»Ÿå±‚é¢è¿›è¡Œä¼˜åŒ–ã€‚

éšç€ AI çš„ä¸æ–­å‘å±•ï¼ŒRAG æŠ€æœ¯ä¹Ÿåœ¨æŒç»­æ¼”è¿›ã€‚æ–°æ¨¡å‹èƒ½å¤Ÿå¤„ç†æ›´é•¿çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œè¿›è¡Œæ›´æœ‰æ•ˆçš„æ¨ç†ï¼Œå¹¶èƒ½å¤Ÿèå…¥å¤æ‚çš„ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰å·¥ä½œæµã€‚å…¶ä¸­ä¸€ä¸ªæ¿€åŠ¨äººå¿ƒçš„å¢é•¿é¢†åŸŸæ˜¯ Agentic RAGï¼Œåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼ŒAI æ™ºèƒ½ä½“åœ¨è¿è¡Œæ—¶ï¼ˆè€Œéåœ¨å¼€å‘é˜¶æ®µè¿›è¡Œç¡¬ç¼–ç ï¼‰è‡ªä¸»å†³ç­–éœ€è¦æ£€ç´¢å“ªäº›æ•°æ®ï¼Œä»¥åŠä½•æ—¶ã€å¦‚ä½•è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„æ¢ç´¢ã€‚å³ä¾¿æœ‰äº†è¿™äº›æ–°å‘å±•ï¼Œåœ¨è¿è¡Œæ—¶è®¿é—®é«˜è´¨é‡æ•°æ®ä¾ç„¶è‡³å…³é‡è¦ï¼Œè¿™ä¹Ÿæ˜¯ RAG æˆä¸ºä¼—å¤šåº”ç”¨æ ¸å¿ƒæŠ€æœ¯çš„åŸå› æ‰€åœ¨ã€‚

ä½ å°†é€šè¿‡äº²æ‰‹å®è·µå­¦ä¹ åˆ°ï¼š
- æ„å»ºä¸€ä¸ªå…·å¤‡æ£€ç´¢å’Œæç¤ºå¢å¼ºåŠŸèƒ½çš„ RAG ç³»ç»Ÿ
- æ¯”è¾ƒå„ç§æ£€ç´¢æ–¹æ³•ï¼Œå¦‚ BM25ã€è¯­ä¹‰æœç´¢å’Œ Reciprocal Rank Fusion
- å­¦ä¹ å¦‚ä½•åˆ©ç”¨ Weaviate å‘é‡æ•°æ®åº“å’Œæ–°é—»æ•°æ®é›†ï¼Œå¯¹æ–‡æ¡£è¿›è¡Œåˆ†å—ã€å»ºç«‹ç´¢å¼•å¹¶é«˜æ•ˆæ£€ç´¢
- å¼€å‘ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œä½¿ç”¨ Together AI æ‰˜ç®¡çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œä¸ºä¸€ä¸ªè™šæ„å•†åº—å›ç­”äº§å“å’Œå¸¸è§é—®é¢˜
- é€šè¿‡è¯„ä¼°æ¥æå‡ç³»ç»Ÿå¯é æ€§ï¼Œå¹¶æ•´åˆå¤šæ¨¡æ€æ•°æ®

RAG æ˜¯ä¸€é¡¹é‡è¦çš„åŸºç¡€æŠ€æœ¯ï¼Œæœ¬è¯¾ç¨‹å°†åŠ©ä½ æŒæ¡å…¶ç²¾é«“ï¼

è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/81DSVlDEOW

### 092

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-21
é“¾æ¥: https://x.com/AndrewYNg/status/1947308544916889979
äº’åŠ¨: Likes: 1,233; Retweets: 287; Replies: 74; Quotes: 28; Views: 341,746; Bookmarks: 698; isReply: 0

The invention of modern writing instruments like the typewriter made writing easier, but they also led to the rise of writerâ€™s block, where deciding what to write became the bottleneck. Similarly, the invention of agentic coding assistants has led to a new builderâ€™s block, where the holdup is deciding what to build. I call this the Product Management Bottleneck.

Product management is the art and science of deciding what to build. Because highly agentic coding accelerates the writing of software to a given product specification, deciding what to build is the new bottleneck, especially in early-stage projects. As the teams I work with take advantage of agentic coders, I increasingly value product managers (PMs) who have very high user empathy and can make product decisions quickly, so the speed of product decision-making matches the speed of coding.

PMs with high user empathy can make decisions by gut and get them right a lot of the time. As new information comes in, they can keep refining their mental models of what users like or do not like â€” and thereby refine their gut â€” and keep making fast decisions of increasing quality.

Many tactics are available to get user feedback and other forms of data that shape our beliefs about users. They include  conversations with a handful of users, focus groups, surveys, and A/B tests on scaled products. But to drive progress at GenAI speed, I find that synthesizing all these sources of data in a PM's gut helps us move faster.

Let me illustrate with an example. Recently, my team debated which of 4 features users would prefer. I had my instincts, but none of us were sure, so we surveyed about 1,000 users. The results contradicted my initial beliefs â€” I was wrong! So what was the right thing to do at this point?
- Option 1: Go by the survey and build what users told us clearly they prefer.
- Option 2: Examine the survey data in detail to see how it changes my beliefs about what users want. That is, refine my mental model of users. Then use my revised mental model to decide what to do.

Even though some would consider Option 1 the â€œdata-drivenâ€ way to make decisions, I consider this an inferior approach for most projects. Surveys may be flawed. Further, taking time to run a survey before making a decision results in slow decision-making.

In contrast, using Option 2, the survey results give much more generalizable information that can help me shape not just this decision, but many others as well. And it lets me process this one piece of data alongside all the user conversations, surveys, market reports, and observations of user behavior when theyâ€™re engaging with our product to form a much fuller view on how to serve users. Ultimately, that mental model drives my product decisions.

Of course, this technique does not always scale. For example, with programmatic online advertising in which AI might try to optimize the number of clicks on ads shown, an automated system conducts far more experiments in parallel and gathers data on what users do and do not click on, to filter through a PM's mental model of users. When a system needs to make a huge number of decisions, such as what ads to show (or products to recommend) on a huge number of pages, PM review and human intuition do not scale.

But in products where a team is making a small number of critical decisions such as what key features to prioritize, I find that data â€” used to help build a good mental model of the user, which is then applied to make decisions very quickly â€” is still the best way to drive rapid progress and relieve the Product Management Bottleneck.

[Original text: https://t.co/1tulDs3k7U ]

ç°ä»£å†™ä½œå·¥å…·ï¼Œæ¯”å¦‚æ‰“å­—æœºçš„å‘æ˜ï¼Œè®©å†™ä½œå˜å¾—æ›´è½»æ¾ï¼Œä½†ä¹Ÿå› æ­¤å‚¬ç”Ÿäº†ã€Œä½œå®¶ä¹‹å›°ï¼ˆwriter's blockï¼‰ã€â€”â€” å†™ä»€ä¹ˆåè€Œæˆäº†æœ€å¤§çš„éš¾é¢˜ã€‚ç±»ä¼¼åœ°ï¼Œèƒ½åŠ¨æ€§ç¼–ç åŠ©æ‰‹ï¼ˆagentic coding assistantsï¼‰çš„å‡ºç°ï¼Œä¹Ÿå¸¦æ¥äº†ä¸€ç§æ–°çš„ã€Œæ„å»ºè€…ä¹‹å›°ï¼ˆbuilder's blockï¼‰ã€â€”â€” æ­¤æ—¶ï¼Œå†³å®šè¦æ„å»ºä»€ä¹ˆæˆäº†é˜»ç¢ã€‚æˆ‘å°†è¿™ç§ç°è±¡ç§°ä¸ºã€Œäº§å“ç®¡ç†ç“¶é¢ˆï¼ˆProduct Management Bottleneckï¼‰ã€ã€‚

äº§å“ç®¡ç†çš„æ ¸å¿ƒï¼Œæ­£æ˜¯å…³äºå¦‚ä½•å†³å®šæ„å»ºä»€ä¹ˆçš„è‰ºæœ¯å’Œç§‘å­¦ã€‚ç”±äºé«˜èƒ½åŠ¨æ€§çš„ç¼–ç æŠ€æœ¯èƒ½å¤Ÿæå¤§åŠ é€Ÿæ ¹æ®æ—¢å®šäº§å“è§„èŒƒç¼–å†™è½¯ä»¶çš„è¿‡ç¨‹ï¼Œåœ¨é¡¹ç›®æ—©æœŸé˜¶æ®µï¼Œå†³å®šã€Œåšä»€ä¹ˆã€å°±æˆäº†æ–°çš„ç“¶é¢ˆã€‚åœ¨æˆ‘æ‰€åˆä½œçš„å›¢é˜Ÿä¸­ï¼Œéšç€ä»–ä»¬è¶Šæ¥è¶Šå¤šåœ°å€ŸåŠ©èƒ½åŠ¨æ€§ç¼–ç å™¨ï¼ˆagentic codersï¼‰ï¼Œæˆ‘å‘ç°é‚£äº›æ‹¥æœ‰æé«˜ç”¨æˆ·åŒç†å¿ƒï¼ˆuser empathyï¼‰ä¸”èƒ½è¿…é€Ÿåšå‡ºäº§å“å†³ç­–çš„äº§å“ç»ç†ï¼ˆPMsï¼‰å˜å¾—å°¤ä¸ºå®è´µï¼Œå› ä¸ºè¿™æ ·æ‰èƒ½è®©äº§å“å†³ç­–çš„é€Ÿåº¦ä¸ç¼–ç æ•ˆç‡åŒæ­¥ã€‚

å…·å¤‡é«˜ç”¨æˆ·åŒç†å¿ƒçš„äº§å“ç»ç†ï¼Œå¾€å¾€èƒ½å‡­ç›´è§‰åšå‡ºå†³ç­–ï¼Œå¹¶ä¸”åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½æ˜¯æ­£ç¡®çš„ã€‚å½“æ–°çš„ä¿¡æ¯ä¸æ–­æ¶Œå…¥æ—¶ï¼Œä»–ä»¬èƒ½æŒç»­å®Œå–„è‡ªå·±å¯¹ç”¨æˆ·å–œå¥½å’Œè¡Œä¸ºçš„ ** å¿ƒç†æ¨¡å‹ï¼ˆmental models)**ï¼ˆå³å¯¹ç”¨æˆ·éœ€æ±‚å’Œåå¥½çš„å†…åœ¨ç†è§£ï¼‰â€”â€” ä»è€Œä¸æ–­æå‡ç›´è§‰çš„å‡†ç¡®æ€§ â€”â€” å¹¶æŒç»­åšå‡ºè´¨é‡æ›´é«˜ã€é€Ÿåº¦æ›´å¿«çš„å†³ç­–ã€‚

æœ‰è®¸å¤šç­–ç•¥å¯ä»¥å¸®åŠ©æˆ‘ä»¬è·å–ç”¨æˆ·åé¦ˆåŠå…¶ä»–å½¢å¼çš„æ•°æ®ï¼Œä»è€Œå½¢æˆæˆ‘ä»¬å¯¹ç”¨æˆ·çš„è®¤çŸ¥ã€‚è¿™äº›æ–¹æ³•åŒ…æ‹¬ä¸å°‘é‡ç”¨æˆ·è¿›è¡Œè®¿è°ˆã€ç»„ç»‡ç„¦ç‚¹å°ç»„ã€å¼€å±•é—®å·è°ƒæŸ¥ï¼Œä»¥åŠå¯¹æˆç†Ÿäº§å“è¿›è¡Œ A/B æµ‹è¯•ã€‚ç„¶è€Œï¼Œä¸ºäº†ä»¥ GenAI çš„é€Ÿåº¦æ¨åŠ¨é¡¹ç›®è¿›å±•ï¼Œæˆ‘å‘ç°å°†æ‰€æœ‰è¿™äº›æ•°æ®æ¥æºèæ±‡åˆ°äº§å“ç»ç†çš„ç›´è§‰ä¸­ï¼Œèƒ½å¸®åŠ©æˆ‘ä»¬è¡ŒåŠ¨å¾—æ›´å¿«ã€‚

è®©æˆ‘ç”¨ä¸€ä¸ªä¾‹å­æ¥å…·ä½“è¯´æ˜ã€‚æœ€è¿‘ï¼Œæˆ‘çš„å›¢é˜Ÿæ­£åœ¨è®¨è®ºç”¨æˆ·ä¼šæ›´åçˆ±æˆ‘ä»¬æä¾›çš„å››ä¸ªåŠŸèƒ½ä¸­çš„å“ªä¸€ä¸ªã€‚æˆ‘æœ‰ä¸€äº›ç›´è§‰ï¼Œä½†æˆ‘ä»¬è°éƒ½æ— æ³•ç¡®å®šï¼Œäºæ˜¯æˆ‘ä»¬å¯¹å¤§çº¦ 1,000 åç”¨æˆ·è¿›è¡Œäº†è°ƒæŸ¥ã€‚ç»“æœå‡ºä¹æˆ‘çš„æ„æ–™ â€”â€” æˆ‘é”™äº†ï¼é‚£ä¹ˆï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
- é€‰é¡¹ 1ï¼šå®Œå…¨ä¾æ®è°ƒæŸ¥ç»“æœï¼Œå»æ„å»ºç”¨æˆ·æ˜ç¡®è¡¨ç¤ºå–œæ¬¢çš„åŠŸèƒ½ã€‚
- é€‰é¡¹ 2ï¼šè¯¦ç»†å®¡è§†è°ƒæŸ¥æ•°æ®ï¼Œçœ‹çœ‹å®ƒå¦‚ä½•æ”¹å˜æˆ‘å¯¹ç”¨æˆ·éœ€æ±‚çš„ç†è§£ã€‚æ¢å¥è¯è¯´ï¼Œæ˜¯å®Œå–„æˆ‘å¯¹ç”¨æˆ·çš„å¿ƒç†æ¨¡å‹ã€‚ç„¶åæ ¹æ®æˆ‘ä¿®æ­£åçš„å¿ƒç†æ¨¡å‹æ¥å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚

å°½ç®¡æœ‰äº›äººå¯èƒ½ä¼šè®¤ä¸ºé€‰é¡¹ 1 æ˜¯ã€Œæ•°æ®é©±åŠ¨ã€çš„å†³ç­–æ–¹å¼ï¼Œä½†æˆ‘è®¤ä¸ºå¯¹äºå¤§å¤šæ•°é¡¹ç›®æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ç§æ¬¡ä¼˜çš„æ–¹æ³•ã€‚è°ƒæŸ¥æœ¬èº«å¯èƒ½å­˜åœ¨ç¼ºé™·ã€‚æ­¤å¤–ï¼Œåœ¨åšå‡ºå†³ç­–å‰èŠ±è´¹æ—¶é—´è¿›è¡Œè°ƒæŸ¥ï¼Œä¹Ÿä¼šå¯¼è‡´å†³ç­–è¿‡ç¨‹ç¼“æ…¢ã€‚

ç›¸æ¯”ä¹‹ä¸‹ï¼Œé‡‡ç”¨é€‰é¡¹ 2ï¼Œè°ƒæŸ¥ç»“æœèƒ½æä¾›æ›´å…·æ™®é€‚æ€§çš„ä¿¡æ¯ï¼Œä¸ä»…æœ‰åŠ©äºæˆ‘åšå‡ºå½“å‰è¿™ä¸ªå†³ç­–ï¼Œè¿˜èƒ½å¸®åŠ©æˆ‘å¤„ç†è®¸å¤šå…¶ä»–å†³ç­–ã€‚å®ƒè®©æˆ‘å¯ä»¥å°†è¿™ä»½æ•°æ®ï¼Œä¸æ‰€æœ‰çš„ç”¨æˆ·è®¿è°ˆã€è°ƒæŸ¥æŠ¥å‘Šã€å¸‚åœºåˆ†æä»¥åŠç”¨æˆ·åœ¨ä½¿ç”¨æˆ‘ä»¬äº§å“æ—¶çš„è¡Œä¸ºè§‚å¯Ÿç›¸ç»“åˆï¼Œä»è€Œå¯¹å¦‚ä½•æ›´å¥½åœ°æœåŠ¡ç”¨æˆ·å½¢æˆä¸€ä¸ªæ›´å…¨é¢çš„è§†è§’ã€‚æœ€ç»ˆï¼Œæ­£æ˜¯è¿™ç§æ·±åŒ–çš„å¿ƒç†æ¨¡å‹é©±åŠ¨ç€æˆ‘çš„äº§å“å†³ç­–ã€‚

å½“ç„¶ï¼Œè¿™ç§æ–¹æ³•å¹¶éæ€»æ˜¯èƒ½å¤§è§„æ¨¡åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¨‹åºåŒ–åœ¨çº¿å¹¿å‘Šé¢†åŸŸï¼ŒAI å¯èƒ½ä¼šå°è¯•ä¼˜åŒ–å¹¿å‘Šçš„ç‚¹å‡»æ¬¡æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨åŒ–ç³»ç»Ÿä¼šå¹¶è¡Œæ‰§è¡Œå¤§é‡å®éªŒï¼Œå¹¶æ”¶é›†ç”¨æˆ·ç‚¹å‡»æˆ–ä¸ç‚¹å‡»å¹¿å‘Šçš„æ•°æ®ï¼Œè€Œä¸ä¼šä»…ä»…ä¾èµ–äº§å“ç»ç†å¯¹ç”¨æˆ·çš„å¿ƒç†æ¨¡å‹è¿›è¡Œè¿‡æ»¤ã€‚å½“ä¸€ä¸ªç³»ç»Ÿéœ€è¦åšå‡ºæµ·é‡å†³ç­–æ—¶ï¼Œæ¯”å¦‚åœ¨æ— æ•°é¡µé¢ä¸Šæ˜¾ç¤ºå“ªäº›å¹¿å‘Šï¼ˆæˆ–æ¨èå“ªäº›äº§å“ï¼‰ï¼Œäº§å“ç»ç†çš„å®¡æŸ¥å’Œäººç±»ç›´è§‰å°±éš¾ä»¥è·Ÿä¸Šã€‚

ä½†åœ¨é‚£äº›å›¢é˜Ÿéœ€è¦åšå‡ºå°‘æ•°å…³é”®å†³ç­–çš„äº§å“ä¸­ï¼Œä¾‹å¦‚ä¼˜å…ˆå¼€å‘å“ªäº›æ ¸å¿ƒåŠŸèƒ½ï¼Œæˆ‘å‘ç°æ•°æ® â€”â€” ç”¨æ¥å¸®åŠ©å»ºç«‹ä¸€ä¸ªè‰¯å¥½çš„ç”¨æˆ·å¿ƒç†æ¨¡å‹ï¼Œå¹¶åŸºäºæ­¤å¿«é€Ÿåšå‡ºå†³ç­– â€”â€” ä»ç„¶æ˜¯æ¨åŠ¨å¿«é€Ÿè¿›å±•å’Œç¼“è§£äº§å“ç®¡ç†ç“¶é¢ˆçš„æœ€ä½³é€”å¾„ã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/1tulDs3k7U]

### 093

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-23
é“¾æ¥: https://x.com/AndrewYNg/status/1948032883664519244
äº’åŠ¨: Likes: 1,403; Retweets: 524; Replies: 61; Quotes: 14; Views: 96,578; Bookmarks: 427; isReply: 0

Announcing our new event - Buildathon: The Rapid Engineering Competition. See the video for details, and please apply to participate!

éš†é‡æ¨å‡ºæˆ‘ä»¬çš„æ–°æ´»åŠ¨ â€”â€”Buildathonï¼šå¿«é€Ÿå·¥ç¨‹ç«èµ›ï¼è§‚çœ‹è§†é¢‘äº†è§£è¯¦æƒ…ï¼Œå¹¶æ¬¢è¿å¤§å®¶è¸Šè·ƒæŠ¥åå‚ä¸ï¼

### 094

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-07-31
é“¾æ¥: https://x.com/AndrewYNg/status/1950941108000964654
äº’åŠ¨: Likes: 4,284; Retweets: 1,082; Replies: 253; Quotes: 156; Views: 629,438; Bookmarks: 1,648; isReply: 0

There is now a path for China to surpass the U.S. in AI. Even though the U.S. is still ahead, China has tremendous momentum with its vibrant open-weights model ecosystem and aggressive moves in semiconductor design and manufacturing. In the startup world, we know momentum matters: Even if a company is small today, a high rate of growth compounded for a few years quickly becomes an unstoppable force. This is why a small, scrappy team with high growth can threaten even behemoths. While both the U.S. and China are behemoths, Chinaâ€™s hypercompetitive business landscape and rapid diffusion of knowledge give it tremendous momentum. The White Houseâ€™s AI Action Plan released last week, which explicitly champions open source (among other things), is a very positive step for the U.S., but by itself it wonâ€™t be sufficient to sustain the U.S. lead.

Now, AI isnâ€™t a single, monolithic technology, and different countries are ahead in different areas. For example, even before Generative AI, the U.S. had long been ahead in scaled cloud AI implementations, while China has long been ahead in surveillance technology. These translate to different advantages in economic growth as well as both soft and hard power. Even though nontechnical pundits talk about â€œthe race to AGIâ€ as if AGI were a discrete technology to be invented, the reality is that AI technology will progress continuously, and there is no single finish line. If a company or nation declares that it has achieved AGI, I expect that declaration to be less a technology milestone than a marketing milestone. A slight speed advantage in the Olympic 100m dash translates to a dramatic difference between winning a gold medal versus a silver medal. An advantage in AI prowess translates into a proportionate advantage in economic growth and national power; while the impact wonâ€™t be a binary one of either winning or losing everything, these advantages nonetheless matter.

Looking at Artificial Analysis and LMArena leaderboards, the top proprietary models were developed in the U.S., but the top open models come from China. Googleâ€™s Gemini 2.5 Pro, OpenAIâ€™s o4, Anthropicâ€™s Claude 4 Opus, and Grok 4 are all strong models. But open alternatives from China such as DeepSeek R1-0528, Kimi K2 (designed for agentic reasoning), Qwen3 variations (including Qwen3-Coder, which is strong at coding) and Zhipuâ€™s GLM 4.5 (whose post-training software was released as open source) are close behind, and many are ahead of Metaâ€™s Llama 4 and Googleâ€™s Gemma 3 â€” the U.S.â€™ best open-weights offerings.

Because many U.S. companies have taken a secretive approach to developing foundation models â€” a reasonable business strategy â€” the leading companies spend huge numbers of dollars to recruit key team members from each other who might know the â€œsecret sauceâ€œ that enabled a competitor to develop certain capabilities. So knowledge does circulate, but at high cost and slowly. In contrast, in Chinaâ€™s open AI ecosystem, many advanced foundation model companies undercut each other on pricing, make bold PR announcements, and poach each othersâ€™ employees and customers. This Darwinian life-or-death struggle will lead to the demise of many of the existing players, but the intense competition breeds strong companies.

In semiconductors, too, China is making progress. Huaweiâ€™s CloudMatrix 384 aims to compete with Nvidiaâ€™s GB200 high-performance computing system. While China has struggled to develop GPUs with a similar capability as Nvidiaâ€™s top-of-the-line B200, Huawei is trying to build a competitive system by combining a larger number (384 instead of 72) of lower-capability chips. Chinaâ€™s automotive sector once struggled to compete with U.S. and European internal combustion engine vehicles, but leapfrogged ahead by betting on electric vehicles. It remains to be seen how effective Huaweiâ€™s alternative architectures prove to be, but the U.S. export restrictions have given Huawei and other Chinese businesses a strong incentive to invest heavily in developing their own technology. Further, if China were to develop its domestic semiconductor manufacturing capabilities while the U.S. remained reliant on TSMC in Taiwan, then the U.S.â€™ AI roadmap would be much more vulnerable to a disruption of the Taiwan supply chain (perhaps due to a blockade or, worse, a hot war).

With the rise of electricity, the internet, and other general-purpose technologies, there was room for many nations to benefit, and the benefit to one nation hasnâ€™t come at the expense of another. I know of businesses that, many months back, planned for a future in which China dominates open models (indeed, we are there at this moment, although the future depends on our actions). Given the transformative impact of AI, I hope all nations â€” especially democracies with a strong respect for human rights and the rule of law â€” will clear roadblocks from AI progress and invest in open science and technology to increase the odds that this technology will support democracy and benefit the greatest possible number of people.

[Full text: https://t.co/jn0KNi3gmA ]

ä¸­å›½ç°åœ¨æœ‰å¸Œæœ›åœ¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰é¢†åŸŸè¶…è¶Šç¾å›½ã€‚å°½ç®¡ç¾å›½ç›®å‰ä»ä¿æŒé¢†å…ˆï¼Œä½†ä¸­å›½å‡­å€Ÿå…¶è“¬å‹ƒå‘å±•çš„å¼€æºæƒé‡æ¨¡å‹ç”Ÿæ€ç³»ç»Ÿï¼Œä»¥åŠåœ¨åŠå¯¼ä½“è®¾è®¡å’Œåˆ¶é€ é¢†åŸŸçš„ç§¯æå¸ƒå±€ï¼Œæ­£ç§¯è“„ç€å·¨å¤§çš„å‘å±•åŠ¿å¤´ã€‚åœ¨åˆ›ä¸šåœˆï¼Œæˆ‘ä»¬éƒ½æ˜ç™½ã€ŒåŠ¿å¤´ã€çš„é‡è¦æ€§ï¼šä¸€å®¶å…¬å¸å³ä¾¿ä»Šå¤©è§„æ¨¡ä¸å¤§ï¼Œä½†å¦‚æœèƒ½ä¿æŒé«˜é€Ÿå¢é•¿ï¼Œå‡ å¹´æ—¶é—´çš„å¤åˆæ•ˆåº”å¾ˆå¿«å°±ä¼šä½¿å…¶å‘å±•æˆä¸ºä¸€è‚¡ä¸å¯é˜»æŒ¡çš„åŠ›é‡ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä¸€ä¸ªè™½ç„¶è§„æ¨¡å°ã€ä½†å……æ»¡æ´»åŠ›çš„å›¢é˜Ÿï¼Œå‡­å€Ÿé«˜å¢é•¿ç‡ï¼Œä¹Ÿèƒ½å¯¹è¡Œä¸šå·¨å¤´æ„æˆå¨èƒã€‚è™½ç„¶ç¾å›½å’Œä¸­å›½éƒ½å¯ç§°å¾—ä¸Šæ˜¯å·¨æ— éœ¸ï¼Œä½†ä¸­å›½ç«äº‰å¼‚å¸¸æ¿€çƒˆçš„å•†ä¸šç¯å¢ƒå’ŒçŸ¥è¯†çš„å¿«é€Ÿä¼ æ’­èµ‹äºˆäº†å®ƒå·¨å¤§çš„å‘å±•åŠ¨åŠ›ã€‚ç™½å®«ä¸Šå‘¨å‘å¸ƒçš„ AI è¡ŒåŠ¨è®¡åˆ’ï¼Œæ˜ç¡®æ”¯æŒå¼€æºï¼ˆOpen Sourceï¼‰ç­‰ç­–ç•¥ï¼Œå¯¹ç¾å›½è€Œè¨€æ˜¯ä¸€ä¸ªéå¸¸ç§¯æçš„ä¿¡å·ï¼Œä½†ä»…å‡­å®ƒæœ¬èº«ä¸è¶³ä»¥ç»´æŒç¾å›½åœ¨ AI é¢†åŸŸçš„é¢†å…ˆåœ°ä½ã€‚

éœ€è¦æ˜ç¡®çš„æ˜¯ï¼ŒAI å¹¶éä¸€é¡¹å•ä¸€ã€æ•´ä½“ï¼ˆMonolithicï¼‰çš„æŠ€æœ¯ï¼Œä¸åŒå›½å®¶åœ¨ä¸åŒé¢†åŸŸå„æœ‰ä¼˜åŠ¿ã€‚ä¾‹å¦‚ï¼Œå³ä½¿åœ¨ç”Ÿæˆå¼ AIï¼ˆGenerative AIï¼‰å…´èµ·ä¹‹å‰ï¼Œç¾å›½åœ¨è§„æ¨¡åŒ–äº‘ AI å®æ–½æ–¹é¢å°±é•¿æœŸé¢†å…ˆï¼Œè€Œä¸­å›½åˆ™åœ¨ç›‘æ§æŠ€æœ¯æ–¹é¢å æ®ä¸Šé£ã€‚è¿™äº›ä¼˜åŠ¿ç»§è€Œè½¬åŒ–ä¸ºç»æµå¢é•¿ä»¥åŠè½¯å®åŠ›å’Œç¡¬å®åŠ›æ–¹é¢çš„ä¸åŒä¼˜åŠ¿ã€‚å°½ç®¡ä¸€äº›éæŠ€æœ¯è¯„è®ºå‘˜å°†ã€Œé€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰ç«èµ›ã€æç»˜æˆä¸€åœºæ—¨åœ¨å‘æ˜æŸç§ç‹¬ç«‹æŠ€æœ¯çš„è§’é€ï¼Œä½†ç°å®æ˜¯ AI æŠ€æœ¯å°†æŒç»­æ¼”è¿›ï¼Œæ²¡æœ‰ä¸€ä¸ªæ˜ç¡®çš„ç»ˆç‚¹çº¿ã€‚å¦‚æœä¸€å®¶å…¬å¸æˆ–å›½å®¶å®£å¸ƒå·²å®ç° AGIï¼Œæˆ‘é¢„è®¡é‚£ä¸å…¶è¯´æ˜¯ä¸€ä¸ªæŠ€æœ¯é‡Œç¨‹ç¢‘ï¼Œä¸å¦‚è¯´æ˜¯ä¸€ä¸ªè¥é”€é‡Œç¨‹ç¢‘ã€‚åœ¨å¥¥è¿ä¼š 100 ç±³çŸ­è·‘ä¸­ï¼Œå“ªæ€•æ˜¯å¾®å°çš„é€Ÿåº¦ä¼˜åŠ¿ï¼Œä¹Ÿæ„å‘³ç€é‡‘ç‰Œå’Œé“¶ç‰Œä¹‹é—´çš„å·¨å¤§å·®å¼‚ã€‚åŒç†ï¼Œåœ¨ AI å®åŠ›ä¸Šçš„ä¼˜åŠ¿ï¼Œå°†è½¬åŒ–ä¸ºç»æµå¢é•¿å’Œå›½å®¶å®åŠ›çš„ç›¸åº”ä¼˜åŠ¿ï¼›è™½ç„¶è¿™ç§å½±å“ä¸ä¼šæ˜¯å…¨ç›˜çš†èµ¢æˆ–å…¨ç›˜çš†è¾“çš„äºŒå…ƒç»“æœï¼Œä½†è¿™äº›ä¼˜åŠ¿æ— ç–‘è‡³å…³é‡è¦ã€‚

å®¡è§† Artificial Analysis å’Œ LMArena çš„æ’è¡Œæ¦œï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°é¡¶çº§çš„ä¸“æœ‰æ¨¡å‹æ¥è‡ªç¾å›½ï¼Œè€Œé¡¶çº§çš„å¼€æ”¾æ¨¡å‹åˆ™æºè‡ªä¸­å›½ã€‚Google çš„ Gemini 2.5 Proã€OpenAI çš„ o4ã€Anthropic çš„ Claude 4 Opus å’Œ Grok 4 éƒ½æ˜¯æ€§èƒ½å¼ºåŠ²çš„æ¨¡å‹ã€‚ä½†æ¥è‡ªä¸­å›½çš„å¼€æ”¾æ›¿ä»£å“ï¼Œå¦‚ DeepSeek R1-0528ã€Kimi K2ï¼ˆä¸“ä¸º AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰æ¨ç†è®¾è®¡ï¼‰ã€Qwen3 ç³»åˆ—æ¨¡å‹ï¼ˆåŒ…æ‹¬åœ¨ç¼–ç æ–¹é¢è¡¨ç°å‡ºè‰²çš„ Qwen3-Coderï¼‰ä»¥åŠæ™ºè°±çš„ GLM 4.5ï¼ˆå…¶åæœŸè®­ç»ƒè½¯ä»¶å·²ä½œä¸ºå¼€æºå‘å¸ƒï¼‰ï¼Œæ­£ç´§éšå…¶åï¼Œå…¶ä¸­è®¸å¤šç”šè‡³è¶…è¶Šäº† Meta çš„ Llama 4 å’Œ Google çš„ Gemma 3 â€” è¿™ä¸¤æ¬¾æ˜¯ç¾å›½ç›®å‰æœ€ä¼˜ç§€çš„å¼€æºæƒé‡äº§å“ã€‚

ç”±äºè®¸å¤šç¾å›½å…¬å¸åœ¨å¼€å‘åŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰æ—¶é‡‡å–äº†ä¿å¯†ç­–ç•¥ â€” è¿™æ— ç–‘æ˜¯ä¸€ç§åˆç†çš„å•†ä¸šç­–ç•¥ â€” å› æ­¤ï¼Œé¢†å…ˆå…¬å¸ä¸æƒœæŠ•å…¥å·¨èµ„ï¼Œç›¸äº’æŒ–è§’æ ¸å¿ƒå›¢é˜Ÿæˆå‘˜ï¼Œä»¥æœŸè·å¾—ç«äº‰å¯¹æ‰‹å¼€å‘æŸäº›èƒ½åŠ›çš„ã€Œç‹¬å®¶ç§˜è¯€ã€ã€‚å› æ­¤ï¼ŒçŸ¥è¯†ç¡®å®åœ¨æµé€šï¼Œä½†å…¶ä»£ä»·é«˜æ˜‚ä¸”é€Ÿåº¦ç¼“æ…¢ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨ä¸­å›½å¼€æ”¾çš„ AI ç”Ÿæ€ç³»ç»Ÿä¸­ï¼Œè®¸å¤šå…ˆè¿›çš„åŸºç¡€æ¨¡å‹å…¬å¸ä¸ºäº†äº‰å¤ºå¸‚åœºï¼Œä¸ä»…åœ¨å®šä»·ä¸Šç›¸äº’ç«äº‰ï¼Œè¿˜ä¼šå‘å¸ƒå¤§èƒ†çš„å…¬å…³å£°æ˜ï¼Œç”šè‡³ç›¸äº’æŒ–èµ°å‘˜å·¥å’Œå®¢æˆ·ã€‚è¿™ç§è¾¾å°”æ–‡å¼çš„ã€Œä¼˜èƒœåŠ£æ±°ã€ç«äº‰ï¼Œè™½ç„¶ä¼šå¯¼è‡´è®¸å¤šç°æœ‰å‚ä¸è€…è¢«æ·˜æ±°ï¼Œä½†æ¿€çƒˆçš„ç«äº‰æ— ç–‘ä¼šå­•è‚²å‡ºæ›´å¼ºå¤§çš„å…¬å¸ã€‚

åœ¨åŠå¯¼ä½“é¢†åŸŸï¼Œä¸­å›½åŒæ ·åœ¨å–å¾—è¿›å±•ã€‚åä¸ºçš„ CloudMatrix 384 ç³»ç»Ÿæ—¨åœ¨ä¸è‹±ä¼Ÿè¾¾çš„ GB200 é«˜æ€§èƒ½è®¡ç®—ç³»ç»Ÿä¸€è¾ƒé«˜ä¸‹ã€‚å°½ç®¡ä¸­å›½åœ¨å¼€å‘ä¸è‹±ä¼Ÿè¾¾é¡¶çº§ B200 æ€§èƒ½ç›¸å½“çš„å›¾å½¢å¤„ç†å™¨ï¼ˆGPUï¼‰æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œä½†åä¸ºæ­£å°è¯•é€šè¿‡ç»„åˆæ›´å¤šæ•°é‡ï¼ˆ384 ä¸ªè€Œé 72 ä¸ªï¼‰çš„æ€§èƒ½ç¨ä½çš„èŠ¯ç‰‡æ¥æ„å»ºä¸€ä¸ªå…·æœ‰ç«äº‰åŠ›çš„ç³»ç»Ÿã€‚ä¸­å›½æ±½è½¦è¡Œä¸šæ›¾ä¸€åº¦éš¾ä»¥ä¸ç¾å›½å’Œæ¬§æ´²çš„å†…ç‡ƒæœºæ±½è½¦ç«äº‰ï¼Œä½†é€šè¿‡å¤§åŠ›å‘å±•ç”µåŠ¨æ±½è½¦å®ç°äº†å¼¯é“è¶…è½¦ã€‚åä¸ºçš„æ›¿ä»£æ¶æ„æœ€ç»ˆæ•ˆæœå¦‚ä½•å°šå¾…è§‚å¯Ÿï¼Œä½†ç¾å›½çš„å‡ºå£é™åˆ¶å·²ç»ä¸ºåä¸ºåŠå…¶ä»–ä¸­å›½ä¼ä¸šæä¾›äº†å¼ºå¤§çš„åŠ¨åŠ›ï¼Œä¿ƒä½¿å®ƒä»¬å¤§åŠ›æŠ•èµ„å¼€å‘è‡ªèº«æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œå¦‚æœä¸­å›½èƒ½å¤Ÿå‘å±•èµ·å›½å†…çš„åŠå¯¼ä½“åˆ¶é€ èƒ½åŠ›ï¼Œè€Œç¾å›½ä»ä¾èµ–å°æ¹¾çš„å°ç§¯ç”µï¼ˆTSMCï¼‰ï¼Œé‚£ä¹ˆç¾å›½çš„ AI å‘å±•è·¯çº¿å›¾å°†æ›´å®¹æ˜“å—åˆ°å°æ¹¾ä¾›åº”é“¾ä¸­æ–­ï¼ˆå¯èƒ½ç”±äºå°é”ï¼Œç”šè‡³æ›´ç³Ÿçš„ï¼Œä¸€åœºçƒ­æˆ˜ï¼‰çš„å½±å“ï¼Œå˜å¾—æ›´ä¸ºè„†å¼±ã€‚

éšç€ç”µåŠ›ã€äº’è”ç½‘ä»¥åŠå…¶ä»–é€šç”¨æŠ€æœ¯ï¼ˆGeneral-Purpose Technologiesï¼‰çš„å…´èµ·ï¼Œè®¸å¤šå›½å®¶éƒ½ä»ä¸­å—ç›Šï¼Œä¸€ä¸ªå›½å®¶è·å¾—çš„ç›Šå¤„å¹¶æœªä»¥ç‰ºç‰²å¦ä¸€ä¸ªå›½å®¶ä¸ºä»£ä»·ã€‚æˆ‘äº†è§£åˆ°ä¸€äº›ä¼ä¸šæ—©åœ¨æ•°æœˆå‰å°±å·²é¢„è§åˆ°ä¸­å›½ä¸»å¯¼å¼€æ”¾æ¨¡å‹çš„æœªæ¥ï¼ˆäº‹å®ä¸Šï¼Œæˆ‘ä»¬ç›®å‰æ­£å¤„äºè¿™ä¸€æ—¶åˆ»ï¼Œå°½ç®¡æœªæ¥ä»å–å†³äºæˆ‘ä»¬çš„è¡ŒåŠ¨ï¼‰ã€‚é‰´äº AI å…·æœ‰å˜é©æ€§å½±å“ï¼Œæˆ‘è¡·å¿ƒå¸Œæœ›æ‰€æœ‰å›½å®¶ â€” å°¤å…¶æ˜¯é‚£äº›é«˜åº¦å°Šé‡äººæƒå’Œæ³•æ²»çš„æ°‘ä¸»å›½å®¶ â€” èƒ½å¤Ÿä¸º AI è¿›æ­¥æ¸…é™¤éšœç¢ï¼Œå¹¶ç§¯ææŠ•èµ„äºå¼€æ”¾ç§‘å­¦å’ŒæŠ€æœ¯ï¼Œä»è€Œå¢åŠ è¿™é¡¹æŠ€æœ¯æ”¯æŒæ°‘ä¸»å¹¶æƒ åŠå°½å¯èƒ½å¤šæ°‘ä¼—çš„å¯èƒ½æ€§ã€‚

 [åŸæ–‡é“¾æ¥ï¼šhttps://t.co/jn0KNi3gmA]

### 095

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-05
é“¾æ¥: https://x.com/AndrewYNg/status/1952838045235126510
äº’åŠ¨: Likes: 2,696; Retweets: 369; Replies: 74; Quotes: 11; Views: 179,472; Bookmarks: 173; isReply: 0

I'm thrilled @OpenAI has released two open weight models. Thank you to all my friends at OpenAI for this gift! I'm also encouraged that from my quick tests gpt-oss-120b looks strong (though we should still wait for rigorous 3rd party evals).

æˆ‘éå¸¸é«˜å…´ @OpenAI å‘å¸ƒäº†ä¸¤ä¸ªå¼€æ”¾æƒé‡æ¨¡å‹ã€‚æ„Ÿè°¢æˆ‘åœ¨ OpenAI çš„æ‰€æœ‰æœ‹å‹å¸¦æ¥è¿™ä»½æƒŠå–œï¼æˆ‘ä¹Ÿå¾ˆå—é¼“èˆï¼Œä»æˆ‘è¿›è¡Œçš„å¿«é€Ÿæµ‹è¯•æ¥çœ‹ï¼Œgpt-oss-120b è¡¨ç°éå¸¸å¼ºåŠ²ï¼ˆå°½ç®¡æˆ‘ä»¬ä»éœ€ç­‰å¾…ä¸¥è°¨çš„ç¬¬ä¸‰æ–¹è¯„ä¼°ç»“æœï¼‰ã€‚

### 096

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-06
é“¾æ¥: https://x.com/AndrewYNg/status/1953097967361245251
äº’åŠ¨: Likes: 6,791; Retweets: 1,022; Replies: 137; Quotes: 105; Views: 747,408; Bookmarks: 8,523; isReply: 0

I'm thrilled to announce the definitive course on Claude Code, created with @AnthropicAI and taught by Elie Schoppik @eschoppik. If you want to use highly agentic coding - where AI works autonomously for many minutes or longer, not just completing code snippets - this is it.

Claude Code has been a game-changer for many developers (including me!), but there's real depth to using it well. This comprehensive course covers everything from fundamentals to advanced patterns.

After this short course, you'll be able to:
- Orchestrate multiple Claude subagents to work on different parts of your codebase simultaneously
- Tag Claude in GitHub issues and have it autonomously create, review, and merge pull requests
- Transform messy Jupyter notebooks into clean, production-ready dashboards
- Use MCP tools like Playwright so Claude can see what's wrong with your UI and fix it autonomously

Whether you're new to Claude Code or already using it, you'll discover powerful capabilities that can fundamentally change how you build software.

I'm very excited about what agentic coding lets everyone now do. Please take this course!

https://t.co/HGM8ArDalK

æˆ‘éå¸¸é«˜å…´åœ°å®£å¸ƒï¼Œç”± @AnthropicAI åˆä½œåˆ›å»ºã€Elie Schoppik @eschoppik äº²æˆçš„ Claude Code æƒå¨è¯¾ç¨‹æ­£å¼ä¸Šçº¿äº†ã€‚å¦‚æœä½ æƒ³å®ç°é«˜åº¦æ™ºèƒ½ä½“ç¼–ç¨‹ï¼ˆagentic codingï¼‰â€”â€” è®© AI èƒ½å¤Ÿè‡ªä¸»è¿è¡Œæ•°åˆ†é’Ÿç”šè‡³æ›´é•¿æ—¶é—´ï¼Œè€Œä¸ä»…ä»…æ˜¯å®Œæˆä»£ç ç‰‡æ®µ â€”â€” é‚£ä¹ˆè¿™é—¨è¯¾ç¨‹æ­£æ˜¯ä½ æ‰€éœ€è¦çš„ã€‚

Claude Code å¯¹è®¸å¤šå¼€å‘è€…ï¼ˆåŒ…æ‹¬æˆ‘æœ¬äººï¼ï¼‰æ¥è¯´ï¼Œéƒ½æ˜¯ä¸€ä¸ªé¢ è¦†æ€§çš„å·¥å…·ï¼Œä½†è¦ç”¨å¥½å®ƒç¡®å®éœ€è¦æ·±å…¥çš„ç†è§£å’ŒæŠ€å·§ã€‚è¿™é—¨å…¨é¢çš„è¯¾ç¨‹å°†æ¶µç›–ä»åŸºç¡€çŸ¥è¯†åˆ°é«˜çº§æ¨¡å¼çš„æ‰€æœ‰å†…å®¹ã€‚

å®Œæˆè¿™é—¨çŸ­æœŸçš„è¯¾ç¨‹åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- ç¼–æ’å¤šä¸ª Claude å­æ™ºèƒ½ä½“ï¼ˆsubagentsï¼‰åŒæ—¶å¤„ç†ä½ çš„ä»£ç åº“çš„ä¸åŒéƒ¨åˆ†
- åœ¨ GitHub issues ä¸­æåŠ Claudeï¼Œè®©å®ƒè‡ªä¸»åˆ›å»ºã€å®¡æŸ¥å’Œåˆå¹¶æ‹‰å–è¯·æ±‚ï¼ˆpull requests)
- å°†æ‚ä¹±çš„ Jupyter notebooks è½¬æ¢æˆæ•´æ´ã€å¯ç”¨äºç”Ÿäº§ç¯å¢ƒçš„ä»ªè¡¨ç›˜
- ä½¿ç”¨åƒ Playwright è¿™æ ·çš„ MCP å·¥å…·ï¼Œè®© Claude èƒ½å¤Ÿå‘ç°ä½ çš„ UIï¼ˆç”¨æˆ·ç•Œé¢ï¼‰ä¸­å­˜åœ¨çš„é—®é¢˜å¹¶è‡ªä¸»ä¿®å¤æ— è®ºä½ æ˜¯ Claude Code çš„æ–°æ‰‹ï¼Œè¿˜æ˜¯å·²ç»åœ¨ä½¿ç”¨å®ƒï¼Œä½ éƒ½å°†å‘ç°å…¶å¼ºå¤§çš„åŠŸèƒ½ï¼Œè¿™äº›åŠŸèƒ½å°†ä»æ ¹æœ¬ä¸Šæ”¹å˜ä½ æ„å»ºè½¯ä»¶çš„æ–¹å¼ã€‚

æˆ‘å¯¹æ™ºèƒ½ä½“ç¼–ç¨‹ç°åœ¨èƒ½è®©æ¯ä¸ªäººåšçš„äº‹æƒ…æ„Ÿåˆ°éå¸¸å…´å¥‹ã€‚è¯·åŠ¡å¿…å‚åŠ è¿™é—¨è¯¾ç¨‹ï¼

https://t.co/HGM8ArDalK

### 097

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-07
é“¾æ¥: https://x.com/AndrewYNg/status/1953509055584252013
äº’åŠ¨: Likes: 3,743; Retweets: 490; Replies: 109; Quotes: 46; Views: 478,698; Bookmarks: 1,760; isReply: 0

Recently Meta made headlines with unprecedented, massive compensation packages for AI model builders exceeding $100M (sometimes spread over multiple years). With the company planning to spend $66B-72B this year on capital expenses such as data centers, a meaningful fraction of which will be devoted to AI, from a purely financial point of view, itâ€™s not irrational to spend a few extra billion dollars on salaries to make sure this hardware is used well.

A typical software-application startup thatâ€™s not involved in training foundation models might spend 70-80% of its dollars on salaries, 5-10% on rent, and 10-25% on other operating expenses (cloud hosting, software licenses, marketing, legal/accounting, etc.). But scaling up models is so capital-intensive, salaries are a small fraction of the overall expense. This makes it feasible for businesses in this area to pay their relatively few employees exceptionally well. If youâ€™re spending tens of billions of dollars on GPU hardware, why not spend just a tenth of that on salaries? Even before Metaâ€™s recent offers, salaries of AI model trainers have been high, with many being paid $5-10M/year, although Meta has raised these numbers to new heights.

Meta carries out many activities, including run Facebook, Instagram, WhatsApp, and Oculus. But the Llama/AI-training part of its operations is particularly capital-intensive. Many of Metaâ€™s properties rely on user-generated content (UGC) to attract attention, which is then monetized through advertising. AI is a huge threat and opportunity to such businesses: If AI-generated content (AIGC) substitutes for UGC to capture people's attention to sell ads against, this will transform the social-media landscape.

This is why Meta â€” like TikTok, YouTube, and other social-media properties â€” is paying close attention to AIGC, and why making significant investments in AI is rational. Further, when Meta hires a key employee, not only does it gain the future work output of that person, but it also potentially gets insight into a competitorâ€™s technology, which also makes its willingness to pay high salaries a rational business move (so long as it does not adversely affect the companyâ€™s culture).

The pattern of capital-intensive businesses compensating employees extraordinarily well is not new. For example, Netflix expects to spend a huge $18B this year on content. This makes the salary expense of paying its 14,000 employees a small fraction of the total expense, which allows the company to routinely pay above-market salaries. Its ability to spend this way also shapes a distinctive culture that includes elements of â€œweâ€™re a sports team, not a familyâ€ (which seems to work for Netflix but isnâ€™t right for everyone). In contrast, a labor-intensive manufacturing business like Foxconn, which employs over 1 million people globally, has to be much more price-sensitive in what it pays people.

Even a decade ago, when I led a team that worked to scale up AI, I built spreadsheets that modeled how much of my budget to allocate toward salaries and how much to allocate toward GPUs (using a custom model for how much productive output N employees and M GPUs would lead to, so I could optimize N and M subject to my budget constraint). Since then, the business of scaling up AI has skewed the spending significantly toward GPUs.

Iâ€™m happy for the individuals who are getting large pay packages. And regardless of any individual's pay, Iâ€™m grateful for the contributions of everyone working in AI. Everyone in AI deserves a good salary, and while the gaps in compensation are growing, I believe this reflects the broader phenomenon that developers who work in AI, at this moment in history, have an opportunity to make a huge impact and do world-changing work.

[Original text: https://t.co/5wQe7foww8 ]

æœ€è¿‘ï¼ŒMeta å…¬å¸å› å‘å…¶ AI æ¨¡å‹æ„å»ºè€…æä¾›äº†å‰æ‰€æœªæœ‰çš„ã€é«˜è¾¾ä¸Šäº¿ç¾å…ƒï¼ˆæœ‰æ—¶åˆ†å¤šå¹´æ”¯ä»˜ï¼‰çš„å·¨é¢è–ªé…¬æ–¹æ¡ˆè€Œç™»ä¸Šäº†æ–°é—»å¤´æ¡ã€‚è¯¥å…¬å¸è®¡åˆ’ä»Šå¹´åœ¨æ•°æ®ä¸­å¿ƒç­‰èµ„æœ¬æ”¯å‡ºä¸ŠèŠ±è´¹ 660 äº¿è‡³ 720 äº¿ç¾å…ƒï¼Œå…¶ä¸­æœ‰ç›¸å½“å¤§ä¸€éƒ¨åˆ†å°†æŠ•å…¥åˆ° AI é¢†åŸŸã€‚ä»çº¯ç²¹çš„è´¢åŠ¡è§’åº¦æ¥çœ‹ï¼Œä¸ºäº†ç¡®ä¿è¿™äº›ç¡¬ä»¶å¾—åˆ°å……åˆ†åˆ©ç”¨è€Œé¢å¤–æŠ•å…¥å‡ åäº¿ç¾å…ƒç”¨äºæ”¯ä»˜è–ªæ°´ï¼Œè¿™ç¬”å¼€é”€æ˜¯å®Œå…¨åˆç†çš„ã€‚

### 098

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-13
é“¾æ¥: https://x.com/AndrewYNg/status/1955656413075919051
äº’åŠ¨: Likes: 777; Retweets: 206; Replies: 57; Quotes: 12; Views: 117,430; Bookmarks: 225; isReply: 0

Buildathon: The Rapid Engineering Competition livestreams this Saturday, August 16. Top developers will compete to build 5+ products in a single day using AI coding assistants â€“ projects that traditionally took weeks. Watch live as they advance through semifinals and finals, and see how fast software can now be built!  Register at https://t.co/3vAkmZDU4V

æœ¬å‘¨å…­ï¼Œ8 æœˆ 16 æ—¥ï¼Œã€ŒBuildathonï¼šå¿«é€Ÿå·¥ç¨‹ç«èµ›ã€å°†è¿›è¡Œç›´æ’­ã€‚é¡¶å°–å¼€å‘è€…ä»¬å°†åˆ©ç”¨ AI ç¼–ç åŠ©æ‰‹ï¼ˆAI coding assistantsï¼‰ï¼Œåœ¨çŸ­çŸ­ä¸€å¤©å†…æ„å»ºå‡º 5 ä¸ªä»¥ä¸Šçš„é¡¹ç›® â€”â€” è¦çŸ¥é“ï¼Œè¿™äº›é¡¹ç›®åœ¨è¿‡å»å¾€å¾€éœ€è¦æ•°å‘¨æ‰èƒ½å®Œæˆã€‚å¿«æ¥è§‚çœ‹ç›´æ’­ï¼Œè§è¯ä»–ä»¬å¦‚ä½•ä¸€è·¯æ™‹çº§åŠå†³èµ›å’Œå†³èµ›ï¼Œäº²çœ¼çœ‹çœ‹å¦‚ä»Šè½¯ä»¶å¼€å‘çš„é€Ÿåº¦èƒ½æœ‰å¤šå¿«ï¼ç«‹å³æ³¨å†Œï¼Œè¯·è®¿é—® https://t.co/3vAkmZDU4V

### 099

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-18
é“¾æ¥: https://x.com/AndrewYNg/status/1957475040523644936
äº’åŠ¨: Likes: 509; Retweets: 99; Replies: 36; Quotes: 4; Views: 53,666; Bookmarks: 32; isReply: 0

Just as many businesses are transforming to become more capable by using AI, universities are too. I recently visited the UK to receive an honorary doctorate from the University of Exeterâ€™s Faculty of Environment, Science and Economy. @UniofExeter The name of this faculty stood out to me as a particularly forward-looking way to organize an academic division. Having Computer Science sit alongside Environmental Science and the Business School creates natural opportunities for collaboration across these fields.

Leveraging AI leads a university to do things differently. Speaking with Vice Chancellor Lisa Roberts, Deputy Vice Chancellor Timothy Quine, and CS Department Head Andrew Howes, I was struck by the university leadershipâ€™s pragmatic and enthusiastic embrace of AI. This is not a group whose primary worry is whether students will cheat using AI. This is a group that is thinking about how to create a student body that is empowered through AI, whether by teaching more students to code, helping them use AI tools effectively, or showing them whatâ€™s newly possible in their disciplines.

Exeter is a wonderful place to create synergies between AI, environmental science, and business. It hosts 5 of the worldâ€™s top 21 most influential climate scientists according to Reuters, and its scholars are major contributors to reports by the UNâ€™s IPCC (Intergovernmental Panel on Climate Change) as well as pioneers in numerous areas of climate research including geoengineering, which I wrote about previously. Its Centre for Environmental Intelligence, a partnership with the Met Office (the UKâ€™s national weather service), applies AI to massive climate datasets. More work like this is needed to understand climate change and strategies for mitigation and adaptation. Add to this its Business School â€” named Business School of the Year by the consultancy Times Higher Education â€” and you have the ingredients for building applications and pursuing interdisciplinary studies that span technological, environmental, and economic realities.

Having been born in the UK and spent most of my career in Silicon Valley, I find it exciting to see Exeterâ€™s leadership embrace AI with an enthusiasm I more often associate with California. The UK has always punched above its weight in research, and seeing that tradition continue in the AI era is encouraging.

Just as every company is becoming an AI company, every university must become an AI university â€” not just teaching AI, but using it to advance every field of study. This doesnâ€™t mean abandoning disciplinary expertise. It means maintaining technical excellence while ensuring AI enhances every field.

Like almost all other universities and businesses worldwide, Exeterâ€™s AI transformation is just beginning. But the enthusiastic embrace of AI by its leadership will give it momentum. As someone who is proud to be an honorary graduate of the university, I look forward to seeing what comes next!

[Original text: https://t.co/Y1PyN17Qzs ]

æ­£å¦‚è®¸å¤šä¼ä¸šéƒ½åœ¨ç§¯æè¿ç”¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ¥æå‡è‡ªèº«èƒ½åŠ›ä¸€æ ·ï¼Œå¤§å­¦ä¹Ÿåœ¨ç»å†ä¸€åœºç±»ä¼¼çš„è½¬å‹ã€‚æˆ‘æœ€è¿‘è®¿é—®äº†è‹±å›½ï¼Œå¹¶åœ¨åŸƒå…‹å¡ç‰¹å¤§å­¦ï¼ˆUniversity of Exeterï¼‰çš„ç¯å¢ƒã€ç§‘å­¦ä¸ç»æµå­¦é™¢è£å¹¸åœ°è·å¾—äº†è£èª‰åšå£«å­¦ä½ã€‚@UniofExeter è¿™ä¸ªå­¦é™¢çš„åç§°ç»™æˆ‘ç•™ä¸‹äº†æ·±åˆ»å°è±¡ï¼Œå› ä¸ºå®ƒä½“ç°äº†ä¸€ç§ç‰¹åˆ«å…·æœ‰å‰ç»æ€§çš„å­¦æœ¯éƒ¨é—¨ç»„ç»‡æ–¹å¼ã€‚å°†è®¡ç®—æœºç§‘å­¦ï¼ˆComputer Scienceï¼‰ä¸ç¯å¢ƒç§‘å­¦ï¼ˆEnvironmental Scienceï¼‰å’Œå•†å­¦é™¢ï¼ˆBusiness Schoolï¼‰æ”¾åœ¨ä¸€èµ·ï¼Œä¸ºè¿™äº›é¢†åŸŸä¹‹é—´çš„äº¤å‰åˆä½œåˆ›é€ äº†å¤©ç„¶çš„æœºé‡ã€‚

å–„ç”¨ AI ä¼šä¿ƒä½¿å¤§å­¦ä»¥å…¨æ–°çš„æ–¹å¼å¼€å±•å·¥ä½œã€‚åœ¨ä¸å‰¯æ ¡é•¿ Lisa Robertsã€å‰¯æ•™åŠ¡é•¿ Timothy Quine ä»¥åŠè®¡ç®—æœºç§‘å­¦ç³»ä¸»ä»» Andrew Howes äº¤æµæ—¶ï¼Œå¤§å­¦é¢†å¯¼å±‚å¯¹ AI åŠ¡å®è€Œçƒ­æƒ…çš„æ€åº¦ä»¤æˆ‘å°è±¡æ·±åˆ»ã€‚ä»–ä»¬å…³å¿ƒçš„é‡ç‚¹å¹¶éå­¦ç”Ÿæ˜¯å¦ä¼šåˆ©ç”¨ AI ä½œå¼Šï¼Œè€Œæ˜¯åœ¨æ€è€ƒå¦‚ä½•é€šè¿‡ AI èµ‹èƒ½å­¦ç”Ÿç¾¤ä½“ï¼Œæ— è®ºæ˜¯é€šè¿‡æ•™æˆæ›´å¤šå­¦ç”Ÿç¼–ç¨‹æŠ€èƒ½ï¼Œå¸®åŠ©ä»–ä»¬æœ‰æ•ˆåˆ©ç”¨ AI å·¥å…·ï¼Œè¿˜æ˜¯å‘ä»–ä»¬å±•ç¤ºåœ¨å„è‡ªå­¦ç§‘é¢†åŸŸä¸­å¯èƒ½å®ç°çš„æ–°çªç ´ã€‚

åŸƒå…‹å¡ç‰¹å¤§å­¦æ˜¯ä¿ƒæˆ AIã€ç¯å¢ƒç§‘å­¦å’Œå•†ä¸šä¹‹é—´ååŒæ•ˆåº”çš„ç†æƒ³ä¹‹åœ°ã€‚æ ¹æ®è·¯é€ç¤¾ï¼ˆReutersï¼‰çš„æŠ¥é“ï¼Œè¯¥æ ¡æ‹¥æœ‰å…¨çƒæœ€å…·å½±å“åŠ›çš„ 21 ä½æ°”å€™ç§‘å­¦å®¶ä¸­çš„ 5 ä½ï¼Œå…¶å­¦è€…ä¹Ÿæ˜¯è”åˆå›½æ”¿åºœé—´æ°”å€™å˜åŒ–ä¸“é—¨å§”å‘˜ä¼šï¼ˆUN's IPCC - Intergovernmental Panel on Climate Changeï¼‰æŠ¥å‘Šçš„ä¸»è¦æ’°ç¨¿äººï¼Œå¹¶ä¸”åœ¨åŒ…æ‹¬åœ°çƒå·¥ç¨‹ï¼ˆgeoengineeringï¼‰åœ¨å†…çš„ä¼—å¤šæ°”å€™ç ”ç©¶é¢†åŸŸéƒ½æ˜¯å…ˆé©±è€…ï¼Œæˆ‘æ­¤å‰ä¹Ÿæ›¾æ’°æ–‡æ¢è®¨è¿‡åœ°çƒå·¥ç¨‹ã€‚è¯¥æ ¡çš„ç¯å¢ƒæ™ºèƒ½ä¸­å¿ƒï¼ˆCentre for Environmental Intelligenceï¼‰ä¸è‹±å›½å›½å®¶æ°”è±¡å±€ï¼ˆMet Officeï¼‰åˆä½œï¼Œå°† AI åº”ç”¨äºæµ·é‡çš„æ°”å€™æ•°æ®é›†ã€‚æˆ‘ä»¬éœ€è¦æ›´å¤šç±»ä¼¼çš„å·¥ä½œæ¥æ·±å…¥ç†è§£æ°”å€™å˜åŒ–åŠå…¶å‡ç¼“å’Œé€‚åº”æˆ˜ç•¥ã€‚å†åŠ ä¸Šè¯¥æ ¡çš„å•†å­¦é™¢ â€”â€” è¢«å’¨è¯¢å…¬å¸ Times Higher Education è¯„ä¸ºã€Œå¹´åº¦å•†å­¦é™¢ã€â€”â€” è¿™äº›æ¡ä»¶å…±åŒä¸ºå¼€å‘è·¨è¶ŠæŠ€æœ¯ã€ç¯å¢ƒå’Œç»æµç°å®çš„åº”ç”¨ï¼Œä»¥åŠå¼€å±•è·¨å­¦ç§‘ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚

æˆ‘å‡ºç”Ÿåœ¨è‹±å›½ï¼ŒèŒä¸šç”Ÿæ¶¯çš„å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨ç¡…è°·ï¼ˆSilicon Valleyï¼‰åº¦è¿‡ï¼Œå› æ­¤æˆ‘å¾ˆé«˜å…´çœ‹åˆ°åŸƒå…‹å¡ç‰¹å¤§å­¦çš„é¢†å¯¼å±‚ä»¥æˆ‘é€šå¸¸åœ¨åŠ åˆ©ç¦å°¼äºšï¼ˆCaliforniaï¼‰æ‰èƒ½çœ‹åˆ°çš„çƒ­æƒ…æ‹¥æŠ± AIã€‚è‹±å›½åœ¨ç ”ç©¶é¢†åŸŸä¸€ç›´éƒ½è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿçœ‹åˆ°è¿™ä¸€ä¼ ç»Ÿåœ¨ AI æ—¶ä»£å¾—ä»¥å»¶ç»­ï¼Œè¿™ä»¤äººéå¸¸é¼“èˆã€‚

æ­£å¦‚æ¯å®¶å…¬å¸éƒ½åœ¨è½¬å‹æˆä¸ºä¸€å®¶ AI å…¬å¸ä¸€æ ·ï¼Œæ¯æ‰€å¤§å­¦ä¹Ÿå¿…é¡»æˆä¸ºä¸€æ‰€ AI å¤§å­¦ â€”â€” è¿™ä¸ä»…ä»…æ„å‘³ç€æ•™æˆ AI è¯¾ç¨‹ï¼Œæ›´é‡è¦çš„æ˜¯è¦åˆ©ç”¨ AI æ¥æ¨åŠ¨æ¯ä¸ªç ”ç©¶é¢†åŸŸçš„å‘å±•ã€‚è¿™å¹¶éè¦æ”¾å¼ƒå­¦ç§‘ä¸“ä¸šçŸ¥è¯†ï¼Œè€Œæ˜¯è¦åœ¨ä¿æŒæŠ€æœ¯å“è¶Šçš„åŒæ—¶ï¼Œç¡®ä¿ AI èƒ½å¤Ÿèµ‹èƒ½å’Œæå‡æ¯ä¸€ä¸ªé¢†åŸŸã€‚

åƒå…¨çƒå‡ ä¹æ‰€æœ‰å…¶ä»–å¤§å­¦å’Œä¼ä¸šä¸€æ ·ï¼ŒåŸƒå…‹å¡ç‰¹å¤§å­¦çš„ AI è½¬å‹æ‰åˆšåˆšèµ·æ­¥ã€‚ä½†å…¶é¢†å¯¼å±‚å¯¹ AI çš„çƒ­æƒ…æ¥çº³å°†ä¸ºå…¶æ³¨å…¥å¼ºå¤§çš„åŠ¨åŠ›ã€‚ä½œä¸ºè¯¥å¤§å­¦çš„è£èª‰æ ¡å‹ï¼Œæˆ‘å¯¹æ­¤æ·±æ„Ÿè‡ªè±ªï¼Œå¹¶æœŸå¾…ç€çœ‹åˆ°æœªæ¥å°†å¸¦æ¥å“ªäº›ç²¾å½©ï¼

[Original textï¼šhttps://t.co/Y1PyN17Qzs]

### 100

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-20
é“¾æ¥: https://x.com/AndrewYNg/status/1958165941369634825
äº’åŠ¨: Likes: 477; Retweets: 75; Replies: 56; Quotes: 6; Views: 65,646; Bookmarks: 111; isReply: 0

AI Dev 25 is coming to NYC on November 14!

1,200+ developers will dive into technical topics such as:
- Agentic AI: Multi-agent orchestration, tool use, complex reasoning chains
- Coding with AI: Agentic coding assistants, automated testing, debugging strategies
- Context engineering: Advanced RAG, structured context, memory systems
- Multimodal AI: Vision-language models, audio processing, cross-modal architectures
- Fintech applications: Fraud detection, credit modeling, regulatory compliance

Our Pi Day AI Dev event sold out quickly, so we booked a bigger venue this time. Tickets available here: https://t.co/baLDrB1EPd

AI Dev 25 å¤§ä¼šå°†äº 11 æœˆ 14 æ—¥åœ¨çº½çº¦å¸‚ä¸¾è¡Œï¼

å±Šæ—¶ï¼Œå°†æœ‰è¶…è¿‡ 1,200 åå¼€å‘è€…å…±åŒæ¢ç´¢ä»¥ä¸‹å‰æ²¿æŠ€æœ¯ä¸»é¢˜ï¼š
- **AI æ™ºèƒ½ä½“ï¼ˆAI Agent)**ï¼šæ¶µç›–å¤šæ™ºèƒ½ä½“ç¼–æ’ã€å·¥å…·ä½¿ç”¨ä»¥åŠå¤æ‚çš„æ¨ç†é“¾æ„å»ºã€‚
- **AI è¾…åŠ©ç¼–ç¨‹ **ï¼šåŒ…æ‹¬ AI æ™ºèƒ½ä½“ç¼–ç åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–æµ‹è¯•ä»¥åŠé«˜æ•ˆçš„è°ƒè¯•ç­–ç•¥ã€‚
- ** ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆContext Engineering)**ï¼šæ·±å…¥ç ”ç©¶é«˜çº§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€ç»“æ„åŒ–ä¸Šä¸‹æ–‡å¤„ç†å’Œè®°å¿†ç³»ç»Ÿã€‚
- ** å¤šæ¨¡æ€ AIï¼ˆMultimodal AI)**ï¼šèšç„¦è§†è§‰ - è¯­è¨€æ¨¡å‹ã€éŸ³é¢‘å¤„ç†æŠ€æœ¯å’Œè·¨æ¨¡æ€æ¶æ„è®¾è®¡ã€‚
- ** é‡‘èç§‘æŠ€åº”ç”¨ **ï¼šè®¨è®ºæ¬ºè¯ˆæ£€æµ‹ã€ä¿¡ç”¨é£é™©å»ºæ¨¡å’Œç›‘ç®¡åˆè§„ç­‰å®é™…åº”ç”¨ã€‚

æˆ‘ä»¬ä¸Šæ¬¡çš„ Pi Day AI Dev æ´»åŠ¨é—¨ç¥¨å¾ˆå¿«å°±æŠ¢è´­ä¸€ç©ºï¼Œæ‰€ä»¥è¿™æ¬¡æˆ‘ä»¬ç‰¹æ„é¢„è®¢äº†æ›´å¤§çš„åœºåœ°ã€‚ç«‹å³ç‚¹å‡»è¿™é‡Œè´­ä¹°é—¨ç¥¨ï¼šhttps://t.co/baLDrB1EPd

### 101

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-21
é“¾æ¥: https://x.com/AndrewYNg/status/1958595107457999073
äº’åŠ¨: Likes: 427; Retweets: 52; Replies: 41; Quotes: 7; Views: 56,243; Bookmarks: 129; isReply: 0

On Saturday at the Buildathon hosted by AI Fund and https://t.co/zpIxRSuky4, over 100 developers competed to build software products quickly using AI assisted coding. I was inspired to see developers build functional products in just 1-2 hours. The best practices for rapid engineering are changing quickly along with the tools, and I loved the hallway conversations sharing tips with other developers on using AI to code!

The competitors raced to fulfill product specs like this one (you can see the full list in our github repo; link in reply): 
Project: Codebase Time Machine
Description: Navigate any codebase through time, understanding evolution of features and architectural decisions.
Requirements:
- Clone repo and analyze full git history
- Build semantic understanding of code changes over time
- Answer questions like â€œWhy was this pattern introduced?â€ or â€œShow me how auth evolvedâ€
- Visualize code ownership and complexity trends
- Link commits to business features/decisions

Teams had 6Â½ hours to build 5 products. And many of them managed to do exactly that! They created fully functional applications with good UIs and sometimes embellishments.

What excites me most isnâ€™t just what can now be built in a few hours. Rather, it is that, if AI assistance lets us build basic but fully functional products this quickly, then imagine what can now be done in a week, or a month, or six months. If the teams that participated in the Buildathon had this velocity of execution and iterated over multiple cycles of getting customer feedback and using that to improve the product, imagine how quickly it is now possible to build great products.

Owning proprietary software has long been a moat for businesses, because it has been hard to write complex software. Now, as AI assistance enables rapid engineering, this moat is weakening. 

While many members of the winning teams had computer science backgrounds â€” which does provide an edge â€” not all did. Team members who took home prizes included a high school senior, a product manager, and a healthcare entrepreneur who initially posted on Discord that he was â€œover his skisâ€ as someone who â€œisn't a coder.â€ I was thrilled that multiple participants told me they exceeded their own expectations and discovered they can now build faster than they realized. If you havenâ€™t yet pushed yourself to build quickly using agentic coding tools, you, too, might be surprised at what you can do!

At AI Fund and https://t.co/zpIxRSuky4, we pride ourselves on building and iterating quickly. At the Buildathon, I saw many teams execute quickly using a wide range of tools including Claude Code, GPT-5, Replit, Cursor, Windsurf, Trae, and many others.

I offer my hearty congratulations to all the winners!
- 1st Place: Milind Pathak, Mukul Pathak, and  Sapna Sangmitra (Team Vibe-as-a-Service), a team of three family members. They also received an award for Best Design.
- 2nd Place: David Schuster, Massimiliano Viola, and Manvik Pasula. (Team Two Coders and a Finance Guy).
- Solo Participant Award: Ivelina Dimova, who had just flown to San Francisco from Portugal, and who worked on the 5 projects not sequentially, but in parallel!
- Graph Thinking Award: Divya Mahajan, Terresa Pan, and Achin Gupta (Team A-sync).
- Honorable mentions went to finalists Alec Hewitt, Juan Martinez, Mark Watson and Sophia Tang (Team Secret Agents) and Yuanyuan Pan, Jack Lin, and Xi Huang (Team Can Kids).

To everyone who participated, thank you! Through events like these, I hope we can all learn from each other, encourage each other, invent new best practices, and spread the word about where agentic coding is taking software engineering.

[Original text: https://t.co/wJbQMrnZdL ]

ä¸Šå‘¨å…­ï¼Œç”± AI Fund å’Œ https://t.co/zpIxRSuky4 å…±åŒä¸»åŠäº†ä¸€åœºã€Œç¼–ç¨‹é©¬æ‹‰æ¾ã€(Buildathonï¼‰ï¼Œå¸å¼•äº† 100 å¤šåå¼€å‘è€…å‚ä¸ï¼Œä»–ä»¬åˆ©ç”¨ AI è¾…åŠ©ç¼–ç ï¼ˆAI assisted codingï¼‰äº‰ç›¸å¿«é€Ÿå¼€å‘è½¯ä»¶äº§å“ã€‚æˆ‘æ·±å—å¯å‘ï¼Œçœ‹åˆ°å¼€å‘è€…ä»¬åœ¨çŸ­çŸ­ 1-2 å°æ—¶å†…å°±æ„å»ºå‡ºäº†åŠŸèƒ½å®Œå–„çš„äº§å“ã€‚éšç€å·¥å…·çš„ä¸æ–­æ›´æ–°ï¼Œå¿«é€Ÿå¼€å‘çš„æœ€ä½³å®è·µä¹Ÿåœ¨è¿…é€Ÿæ¼”å˜ã€‚æˆ‘éå¸¸å–œæ¬¢åœ¨æ´»åŠ¨ç°åœºä¸å¼€å‘è€…ä»¬äº¤æµï¼Œåˆ†äº«ä»–ä»¬ä½¿ç”¨ AI è¿›è¡Œç¼–ç¨‹çš„æŠ€å·§ï¼

å‚èµ›è€…ä»¬ç«ç›¸å®Œæˆä»¥ä¸‹è¿™ç±»äº§å“è¦æ±‚ï¼ˆæ‚¨å¯ä»¥åœ¨æˆ‘ä»¬çš„ GitHub ä»“åº“ä¸­æŸ¥çœ‹å®Œæ•´åˆ—è¡¨ï¼Œé“¾æ¥é™„åœ¨æ–‡ç« åï¼‰ï¼š
é¡¹ç›®ï¼šä»£ç åº“æ—¶é—´æœºå™¨æè¿°ï¼šåœ¨æ—¶é—´ç»´åº¦ä¸Šæµè§ˆä»»ä½•ä»£ç åº“ï¼Œæ·±å…¥äº†è§£åŠŸèƒ½å¦‚ä½•æ¼”å˜ä»¥åŠæ¶æ„å†³ç­–å¦‚ä½•å½¢æˆã€‚
è¦æ±‚ï¼š
- å…‹éš†ä»“åº“å¹¶åˆ†æå®Œæ•´çš„ Git å†å²è®°å½•
- æ·±å…¥ç†è§£ä»£ç éšæ—¶é—´å˜åŒ–çš„è¯­ä¹‰
- å›ç­”è¯¸å¦‚ã€Œä¸ºä»€ä¹ˆä¼šå¼•å…¥è¿™ç§æ¨¡å¼ï¼Ÿã€æˆ–ã€Œå±•ç¤ºè®¤è¯æ¨¡å—çš„æ¼”å˜è¿‡ç¨‹ã€ç­‰é—®é¢˜
- ä»¥å¯è§†åŒ–æ–¹å¼å±•ç°ä»£ç æ‰€æœ‰æƒå’Œå¤æ‚æ€§çš„å˜åŒ–è¶‹åŠ¿
- å°†ä»£ç æäº¤ä¸ä¸šåŠ¡åŠŸèƒ½ / å†³ç­–å…³è”èµ·æ¥å„å›¢é˜Ÿæœ‰ 6.5 å°æ—¶æ¥æ„å»º 5 ä¸ªäº§å“ã€‚è®¸å¤šå›¢é˜Ÿéƒ½æˆåŠŸå®Œæˆäº†ä»»åŠ¡ï¼ä»–ä»¬ä¸ä»…åˆ›å»ºäº†åŠŸèƒ½é½å…¨ã€ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰å‹å¥½çš„åº”ç”¨ç¨‹åºï¼Œæœ‰äº›ç”šè‡³è¿˜åŠ å…¥äº†é¢å¤–çš„ç²¾å·§è®¾è®¡ã€‚

æœ€ä»¤æˆ‘å…´å¥‹çš„ï¼Œä¸ä»…ä»…æ˜¯ç°åœ¨çŸ­çŸ­å‡ å°æ—¶å†…èƒ½å¤Ÿæ„å»ºå‡ºçš„äº§å“ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå¦‚æœ AI è¾…åŠ©èƒ½å¤Ÿè®©æˆ‘ä»¬å¦‚æ­¤è¿…é€Ÿåœ°å¼€å‘å‡ºåŸºç¡€ä½†åŠŸèƒ½å®Œæ•´çš„åº”ç”¨ï¼Œé‚£ä¹ˆè¯•æƒ³ï¼Œåœ¨ä¸€å‘¨ã€ä¸€ä¸ªæœˆä¹ƒè‡³å…­ä¸ªæœˆçš„æ—¶é—´é‡Œï¼Œåˆèƒ½å®Œæˆæ€æ ·çš„å£®ä¸¾ã€‚å¦‚æœå‚åŠ è¿™åœºç¼–ç¨‹é©¬æ‹‰æ¾çš„å›¢é˜Ÿèƒ½å¤Ÿä¿æŒè¿™æ ·çš„æ‰§è¡Œé€Ÿåº¦ï¼Œå¹¶ä¸”ç»å†å¤šä¸ªè¿­ä»£å‘¨æœŸï¼Œä¸æ–­æ”¶é›†å®¢æˆ·åé¦ˆå¹¶æ®æ­¤æ”¹è¿›äº§å“ï¼Œé‚£ä¹ˆï¼Œç°åœ¨å¼€å‘å‡ºå“è¶Šäº§å“çš„é€Ÿåº¦å°†ä¼šå¿«å¾—æƒŠäººã€‚

é•¿æœŸä»¥æ¥ï¼Œæ‹¥æœ‰ä¸“æœ‰è½¯ä»¶ä¸€ç›´æ˜¯ä¼ä¸šçš„ä¸€é“ã€ŒæŠ¤åŸæ²³ã€ï¼Œå› ä¸ºç¼–å†™å¤æ‚çš„è½¯ä»¶å¹¶éæ˜“äº‹ã€‚ç„¶è€Œï¼Œéšç€ AI è¾…åŠ©èµ‹èƒ½å¿«é€Ÿå¼€å‘ï¼Œè¿™é“ã€ŒæŠ¤åŸæ²³ã€æ­£åœ¨é€æ¸å˜å¼±ã€‚

å°½ç®¡è®¸å¤šè·å¥–å›¢é˜Ÿæˆå‘˜æ‹¥æœ‰è®¡ç®—æœºç§‘å­¦èƒŒæ™¯ â€”â€” è¿™ç¡®å®èƒ½å¸¦æ¥ä¼˜åŠ¿ â€”â€” ä½†å¹¶éæ‰€æœ‰äººéƒ½å¦‚æ­¤ã€‚è·å¥–å›¢é˜Ÿæˆå‘˜ä¸­ï¼ŒåŒ…æ‹¬ä¸€åé«˜ä¸­ç”Ÿã€ä¸€åäº§å“ç»ç†å’Œä¸€ååŒ»ç–—ä¿å¥é¢†åŸŸçš„åˆ›ä¸šè€…ã€‚è¿™ä½åˆ›ä¸šè€…æœ€åˆåœ¨ Discord ä¸Šå‘å¸–ï¼Œç§°è‡ªå·±ã€Œè¶…å‡ºäº†èƒ½åŠ›èŒƒå›´ã€(over his skisï¼‰ï¼Œå› ä¸ºä»–ã€Œä¸æ˜¯ä¸€ä¸ªç¼–ç å‘˜ã€ã€‚æˆ‘éå¸¸é«˜å…´ï¼Œå¤šä½å‚ä¸è€…å‘Šè¯‰æˆ‘ï¼Œä»–ä»¬è¶…å‡ºäº†è‡ªå·±çš„é¢„æœŸï¼Œå‘ç°è‡ªå·±ç°åœ¨æ„å»ºäº§å“çš„é€Ÿåº¦æ¯”ä»–ä»¬æƒ³è±¡çš„è¦å¿«ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å°è¯•ä½¿ç”¨ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ç¼–ç å·¥å…·æ¥å¿«é€Ÿæ„å»ºï¼Œä½ æˆ–è®¸ä¹Ÿä¼šå¯¹è‡ªå·±èƒ½å®Œæˆçš„äº‹æƒ…æ„Ÿåˆ°æƒŠè®¶ï¼

åœ¨ AI Fund å’Œ https://t.co/zpIxRSuky4ï¼Œæˆ‘ä»¬ä»¥å¿«é€Ÿæ„å»ºå’Œè¿­ä»£ä¸ºè£ã€‚åœ¨è¿™æ¬¡ç¼–ç¨‹é©¬æ‹‰æ¾ä¸­ï¼Œæˆ‘çœ‹åˆ°è®¸å¤šå›¢é˜Ÿåˆ©ç”¨å„ç§å·¥å…·è¿…é€ŸæŠ•å…¥å¼€å‘ï¼Œè¿™äº›å·¥å…·åŒ…æ‹¬ Claude Codeã€GPT-5ã€Replitã€Cursorã€Windsurfã€Trae ç­‰ç­‰ã€‚

æˆ‘å‘æ‰€æœ‰è·å¥–è€…è‡´ä»¥è¡·å¿ƒçš„ç¥è´ºï¼
- ç¬¬ä¸€åï¼šMilind Pathakã€Mukul Pathak å’Œ Sapna Sangmitraï¼ˆTeam Vibe-as-a-Serviceï¼‰ï¼Œä¸€ä¸ªç”±ä¸‰åå®¶åº­æˆå‘˜ç»„æˆçš„å›¢é˜Ÿã€‚ä»–ä»¬è¿˜è·å¾—äº†æœ€ä½³è®¾è®¡å¥–ã€‚
- ç¬¬äºŒåï¼šDavid Schusterã€Massimiliano Viola å’Œ Manvik Pasulaï¼ˆTeam Two Coders and a Finance Guyï¼‰ã€‚
- ä¸ªäººå‚ä¸å¥–ï¼šIvelina Dimovaï¼Œå¥¹åˆšä»è‘¡è„ç‰™é£åˆ°æ—§é‡‘å±±ï¼Œå¹¶ä¸”ä¸æ˜¯æŒ‰é¡ºåºï¼Œè€Œæ˜¯å¹¶è¡Œåœ°å®Œæˆäº† 5 ä¸ªé¡¹ç›®ï¼
- å›¾å½¢æ€ç»´å¥–ï¼šDivya Mahajanã€Terresa Pan å’Œ Achin Guptaï¼ˆTeam A-syncï¼‰ã€‚
- è£èª‰å¥–æˆäºˆå†³èµ›é€‰æ‰‹ Alec Hewittã€Juan Martinezã€Mark Watson å’Œ Sophia Tangï¼ˆTeam Secret Agentsï¼‰ï¼Œä»¥åŠ Yuanyuan Panã€Jack Lin å’Œ Xi Huangï¼ˆTeam Can Kidsï¼‰ã€‚

æ„Ÿè°¢æ‰€æœ‰å‚ä¸è€…ï¼é€šè¿‡è¿™æ ·çš„æ´»åŠ¨ï¼Œæˆ‘å¸Œæœ›æˆ‘ä»¬éƒ½èƒ½äº’ç›¸å­¦ä¹ ã€äº’ç›¸é¼“åŠ±ã€åˆ›é€ æ–°çš„æœ€ä½³å®è·µï¼Œå¹¶æ¨å¹¿ AI æ™ºèƒ½ä½“ç¼–ç æ­£åœ¨å¦‚ä½•é‡å¡‘è½¯ä»¶å·¥ç¨‹ã€‚

[åŸæ–‡ï¼šhttps://t.co/wJbQMrnZdL]

### 102

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-21
é“¾æ¥: https://x.com/AndrewYNg/status/1958595307929051587
äº’åŠ¨: Likes: 51; Retweets: 5; Replies: 4; Quotes: 0; Views: 26,423; Bookmarks: 26; isReply: 1

The products that teams worked on at Buildathon: https://t.co/iA48xG9yU2

Buildathon ä¸Šå›¢é˜Ÿå®Œæˆçš„äº§å“ï¼šhttps://t.co/iA48xG9yU2

### 103

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-27
é“¾æ¥: https://x.com/AndrewYNg/status/1960731961494004077
äº’åŠ¨: Likes: 2,371; Retweets: 426; Replies: 57; Quotes: 18; Views: 161,192; Bookmarks: 2,631; isReply: 0

Build better RAG by letting a team of agents extract and connect your reference materials into a knowledge graph. Our new short course, â€œAgentic Knowledge Graph Construction,â€ taught by @Neo4j Innovation Lead @akollegger, shows you how.

Knowledge graphs are an important way to store information accurately but they are a lot of work to build manually.

In this course youâ€™ll learn how to build a team of agents that turn dataâ€“ in this case product reviews and invoices from suppliersâ€“into structured graphs of entities and relationships for RAG.

Learn how agents can automatically handle the time-consuming work of building graphs â€” extracting entities and relationships (e.g., Product "contains" Assembly, Part "supplied_by" Supplier, Customer review "mentions" Product), deduplicating them, fact-checking them, and committing them to a graph database â€” so your retrieval system can find right information to generate accurate output. For example, you can use agents to help trace customer complaints directly to specific suppliers, manufacturing processes, and product hierarchies, thus turning fragmented information into queryable business intelligence.

Skills youâ€™ll gain:
- Build, store, and access knowledge graphs using the Neo4j graph database
- Build multi-agent systems using Googleâ€™s Agent Development Kit (ADK)
- Set up a loop of agentic workflows to propose and refine a graph schema through fact-checking
- Connect agent-generated graphs of unstructured and structured data into a unified knowledge graph

This course gets into the practicum of why knowledge graphs give more accurate information retrieval than vector search alone, especially for high-stakes applications where precision matters more than fuzzy similarity matching.

Sign up here: https://t.co/2txZfYqGZ9

è®©ä¸€ç»„ AI æ™ºèƒ½ä½“å°†æ‚¨çš„å‚è€ƒèµ„æ–™æå–å¹¶è¿æ¥æˆçŸ¥è¯†å›¾è°±ï¼Œä»è€Œæ„å»ºæ›´å¥½çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼Œç®€ç§° RAGï¼‰ç³»ç»Ÿã€‚æˆ‘ä»¬çš„æ–°çŸ­æœŸè¯¾ç¨‹ã€ŠAgentic Knowledge Graph Constructionã€‹ç”± @Neo4j åˆ›æ–°è´Ÿè´£äºº @akollegger ä¸»è®²ï¼Œå°†å‘æ‚¨å±•ç¤ºå…·ä½“æ–¹æ³•ã€‚

çŸ¥è¯†å›¾è°±æ˜¯å‡†ç¡®å­˜å‚¨ä¿¡æ¯çš„é‡è¦æ–¹å¼ï¼Œä½†æ‰‹åŠ¨æ„å»ºå®ƒä»¬é€šå¸¸è€—æ—¶è´¹åŠ›ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“å›¢é˜Ÿï¼Œå°†æ•°æ® â€”â€” ä¾‹å¦‚æ¥è‡ªä¾›åº”å•†çš„äº§å“è¯„è®ºå’Œå‘ç¥¨ â€”â€” è½¬åŒ–ä¸ºç»“æ„åŒ–çš„å®ä½“å’Œå…³ç³»å›¾è°±ï¼Œä»¥æ”¯æŒ RAG åº”ç”¨ã€‚

äº†è§£ AI æ™ºèƒ½ä½“å¦‚ä½•è‡ªåŠ¨å¤„ç†æ„å»ºå›¾è°±çš„è€—æ—¶å·¥ä½œï¼šå®ƒä»¬èƒ½å¤Ÿæå–å®ä½“å’Œå…³ç³»ï¼ˆä¾‹å¦‚ï¼Œäº§å“ã€ŒåŒ…å«ã€ç»„ä»¶ï¼Œé›¶ä»¶ã€Œç”±ã€ä¾›åº”å•†ã€Œä¾›åº”ã€ï¼Œå®¢æˆ·è¯„è®ºã€ŒæåŠã€äº§å“ï¼‰ï¼Œè¿›è¡Œå»é‡ï¼Œäº‹å®æ ¸æŸ¥ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯æäº¤åˆ°å›¾æ•°æ®åº“ã€‚è¿™æ ·ï¼Œæ‚¨çš„æ£€ç´¢ç³»ç»Ÿå°±èƒ½æ‰¾åˆ°å‡†ç¡®çš„ä¿¡æ¯å¹¶ç”Ÿæˆç²¾ç¡®çš„è¾“å‡ºã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥åˆ©ç”¨ AI æ™ºèƒ½ä½“å°†å®¢æˆ·æŠ•è¯‰ç›´æ¥è¿½æº¯åˆ°å…·ä½“çš„ä¾›åº”å•†ã€åˆ¶é€ æµç¨‹å’Œäº§å“å±‚æ¬¡ç»“æ„ï¼Œä»è€Œå°†é›¶æ•£çš„ä¿¡æ¯è½¬åŒ–ä¸ºå¯ä¾›æŸ¥è¯¢çš„å•†ä¸šæ™ºèƒ½ã€‚

æ‚¨å°†è·å¾—çš„æŠ€èƒ½ï¼š
- ä½¿ç”¨ Neo4j å›¾æ•°æ®åº“æ„å»ºã€å­˜å‚¨å’Œè®¿é—®çŸ¥è¯†å›¾è°±
- ä½¿ç”¨ Google çš„ Agent Development Kitï¼ˆADKï¼‰æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
- å»ºç«‹ AI æ™ºèƒ½ä½“å·¥ä½œæµå¾ªç¯ï¼Œé€šè¿‡äº‹å®æ ¸æŸ¥æ¥æå‡ºå’Œå®Œå–„å›¾è°±æ¨¡å¼
- å°† AI æ™ºèƒ½ä½“ç”Ÿæˆçš„éç»“æ„åŒ–å’Œç»“æ„åŒ–æ•°æ®å›¾è°±è¿æ¥æˆç»Ÿä¸€çš„çŸ¥è¯†å›¾è°±æœ¬è¯¾ç¨‹å°†æ·±å…¥æ¢è®¨å®è·µå±‚é¢ï¼Œè§£é‡Šäº†ä¸ºä»€ä¹ˆçŸ¥è¯†å›¾è°±èƒ½å¤Ÿæä¾›æ¯”å•ç‹¬çš„å‘é‡æœç´¢æ›´å‡†ç¡®çš„ä¿¡æ¯æ£€ç´¢ï¼Œå°¤å…¶é€‚ç”¨äºé‚£äº›å¯¹ç²¾ç¡®åº¦è¦æ±‚é«˜äºæ¨¡ç³Šç›¸ä¼¼æ€§åŒ¹é…çš„å…³é”®åº”ç”¨ã€‚

åœ¨æ­¤æ³¨å†Œï¼šhttps://t.co/2txZfYqGZ9

### 104

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-08-28
é“¾æ¥: https://x.com/AndrewYNg/status/1961118026398617648
äº’åŠ¨: Likes: 1,849; Retweets: 359; Replies: 115; Quotes: 38; Views: 318,804; Bookmarks: 1,081; isReply: 0

Parallel agents are emerging as an important new direction for scaling up AI. AI capabilities have scaled with more training data, training-time compute, and test-time compute. Having multiple agents run in parallel is growing as a technique to further scale and improve performance.

We know from work at Baidu by my former team, and later OpenAI, that AI modelsâ€™ performance scales predictably with the amount of data and training computation. Performance rises further with test-time compute such as in agentic workflows and in reasoning models that think, reflect, and iterate on an answer. But these methods take longer to produce output. Agents working in parallel offer another path to improve results, without making users wait.

Reasoning models generate tokens sequentially and can take a long time to run. Similarly, most agentic workflows are initially implemented in a sequential way. But as LLM prices per token continue to fall â€” thus making these techniques practical â€” and product teams want to deliver results to users faster, more and more agentic workflows are being parallelized.

Some examples:
- Many research agents now fetch multiple web pages and examine their texts in parallel to try to synthesize deeply thoughtful research reports more quickly.
- Some agentic coding frameworks allow users to orchestrate many agents working simultaneously on different parts of a code base. Our short course on Claude Code shows how to do this using git worktrees.
- A rapidly growing design pattern for agentic workflows is to have a compute-heavy agent work for minutes or longer to accomplish a task, while another agent monitors the first and gives brief updates to the user to keep them informed. From here, itâ€™s a short hop to parallel agents that work in the background while the UI agent keeps users informed and perhaps also routes asynchronous user feedback to the other agents.

It is difficult for a human manager to take a complex task (like building a complex software application) and break it down into smaller tasks for human engineers to work on in parallel; scaling to huge numbers of engineers is especially challenging. Similarly, it is also challenging to decompose tasks for parallel agents to carry out. But the falling cost of LLM inference makes it worthwhile to use a lot more tokens, and using them in parallel allows this to be done without significantly increasing the userâ€™s waiting time.

I am also encouraged by the growing body of research on parallel agents. For example, I enjoyed reading â€œCodeMonkeys: Scaling Test-Time Compute for Software Engineeringâ€ by Ryan Ehrlich and others, which shows how parallel code generation helps you to explore the solution space. The mixture-of-agents architecture by Junlin Wang is a surprisingly simple way to organize parallel agents: Have multiple LLMs come up with different answers, then have an aggregator LLM combine them into the final output.

There remains a lot of research as well as engineering to explore how best to leverage parallel agents, and I believe the number of agents that can work productively in parallel â€” like the humans who can work productively in parallel â€” will be very high.

[Original text, with links: https://t.co/ElcJZyzcfw ]

å¹¶è¡Œ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰æ­£åœ¨æˆä¸ºæå‡ AI èƒ½åŠ›çš„ä¸€ä¸ªé‡è¦æ–°æ–¹å‘ã€‚AI çš„èƒ½åŠ›æå‡ç¦»ä¸å¼€æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€è®­ç»ƒæ—¶è®¡ç®—ï¼ˆtraining-time computeï¼‰å’Œæµ‹è¯•æ—¶è®¡ç®—ï¼ˆtest-time computeï¼‰ã€‚å¦‚ä»Šï¼Œè®©å¤šä¸ª AI æ™ºèƒ½ä½“å¹¶è¡Œè¿è¡Œï¼Œæ­£æ—¥ç›Šæˆä¸ºè¿›ä¸€æ­¥æ‰©å±•èƒ½åŠ›ã€æé«˜æ€§èƒ½çš„å…³é”®æŠ€æœ¯ã€‚

æˆ‘ä»¬ä»æˆ‘å‰å›¢é˜Ÿåœ¨ Baidu çš„å·¥ä½œä»¥åŠåæ¥ OpenAI çš„ç ”ç©¶ä¸­äº†è§£åˆ°ï¼ŒAI æ¨¡å‹çš„æ€§èƒ½å¯ä»¥é¢„æµ‹åœ°éšç€æ•°æ®é‡å’Œè®­ç»ƒè®¡ç®—é‡è€Œæå‡ã€‚é€šè¿‡æµ‹è¯•æ—¶è®¡ç®—ï¼Œæ€§èƒ½å¯ä»¥å¾—åˆ°è¿›ä¸€æ­¥å¢å¼ºï¼Œä¾‹å¦‚åœ¨ AI æ™ºèƒ½ä½“å·¥ä½œæµä¸­ï¼Œä»¥åŠé‚£äº›èƒ½å¤Ÿæ€è€ƒã€åæ€å¹¶è¿­ä»£ä¼˜åŒ–ç­”æ¡ˆçš„æ¨ç†æ¨¡å‹ä¸­ã€‚ä¸è¿‡ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦æ›´é•¿æ—¶é—´æ‰èƒ½äº§ç”Ÿæœ€ç»ˆè¾“å‡ºã€‚è€Œå¹¶è¡Œå·¥ä½œçš„ AI æ™ºèƒ½ä½“åˆ™æä¾›äº†ä¸€æ¡æ–°é€”å¾„ï¼Œå¯ä»¥åœ¨ä¸è®©ç”¨æˆ·ç­‰å¾…çš„æƒ…å†µä¸‹ï¼Œå¿«é€Ÿæå‡ç»“æœè´¨é‡ã€‚

æ¨ç†æ¨¡å‹é€šå¸¸ä¼šæŒ‰é¡ºåºç”Ÿæˆ Tokenï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½éå¸¸è€—æ—¶ã€‚åŒæ ·ï¼Œå¤§å¤šæ•° AI æ™ºèƒ½ä½“å·¥ä½œæµæœ€åˆä¹Ÿæ˜¯ä»¥é¡ºåºæ–¹å¼å®ç°çš„ã€‚ç„¶è€Œï¼Œéšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¯ Token çš„ä»·æ ¼æŒç»­ä¸‹é™ï¼Œä½¿å¾—è¿™äº›æŠ€æœ¯å˜å¾—è¶Šæ¥è¶Šå®ç”¨ï¼Œå¹¶ä¸”äº§å“å›¢é˜Ÿä¹Ÿå¸Œæœ›æ›´å¿«åœ°å‘ç”¨æˆ·äº¤ä»˜ç»“æœï¼Œå› æ­¤è¶Šæ¥è¶Šå¤šçš„ AI æ™ºèƒ½ä½“å·¥ä½œæµæ­£åœ¨èµ°å‘å¹¶è¡ŒåŒ–ã€‚

ä¸€äº›å…¸å‹ä¾‹å­åŒ…æ‹¬ï¼š
*  è®¸å¤šç ”ç©¶å‹ AI æ™ºèƒ½ä½“ç°åœ¨å¯ä»¥å¹¶è¡ŒæŠ“å–å¤šä¸ªç½‘é¡µï¼Œå¹¶åŒæ—¶åˆ†æå…¶æ–‡æœ¬å†…å®¹ï¼Œä»è€Œæ›´å¿«åœ°åˆæˆå‡ºæ·±å…¥ç»†è‡´çš„ç ”ç©¶æŠ¥å‘Šã€‚
*  ä¸€äº› AI æ™ºèƒ½ä½“ç¼–ç¨‹æ¡†æ¶å…è®¸ç”¨æˆ·åè°ƒå¤šä¸ª AI æ™ºèƒ½ä½“åŒæ—¶å¤„ç†ä»£ç åº“çš„ä¸åŒéƒ¨åˆ†ã€‚æˆ‘ä»¬åœ¨å…³äº Claude Code çš„å¿«é€Ÿå…¥é—¨è¯¾ç¨‹ä¸­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ git worktrees æ¥å®ç°è¿™ä¸€ç‚¹ã€‚
*  AI æ™ºèƒ½ä½“å·¥ä½œæµä¸­ä¸€ä¸ªè¿…é€Ÿå…´èµ·çš„è®¾è®¡æ¨¡å¼æ˜¯ï¼šè®©ä¸€ä¸ªè®¡ç®—å¯†é›†å‹ AI æ™ºèƒ½ä½“èŠ±è´¹å‡ åˆ†é’Ÿç”šè‡³æ›´é•¿æ—¶é—´æ¥å®Œæˆä¸€é¡¹å¤æ‚ä»»åŠ¡ï¼ŒåŒæ—¶å¦ä¸€ä¸ª AI æ™ºèƒ½ä½“å¯¹å…¶è¿›è¡Œç›‘æ§ï¼Œå¹¶å‘ç”¨æˆ·æä¾›ç®€è¦æ›´æ–°ï¼Œä»¥ä¾¿ç”¨æˆ·èƒ½åŠæ—¶äº†è§£è¿›å±•ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä¸‹ä¸€æ­¥å¾ˆè‡ªç„¶åœ°å°±ä¼šå‘å±•åˆ°è®©å¹¶è¡Œ AI æ™ºèƒ½ä½“åœ¨åå°å·¥ä½œï¼Œè€Œç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰AI æ™ºèƒ½ä½“åˆ™è´Ÿè´£å‘ç”¨æˆ·ä¼ è¾¾ä¿¡æ¯ï¼Œç”šè‡³å¯èƒ½å°†ç”¨æˆ·å¼‚æ­¥çš„åé¦ˆè·¯ç”±ç»™å…¶ä»– AI æ™ºèƒ½ä½“ã€‚

å¯¹äººç±»ç®¡ç†è€…æ¥è¯´ï¼Œå°†ä¸€é¡¹å¤æ‚çš„ä»»åŠ¡ï¼ˆä¾‹å¦‚æ„å»ºä¸€ä¸ªå¤§å‹è½¯ä»¶åº”ç”¨ï¼‰åˆ†è§£æˆæ›´å°çš„å­ä»»åŠ¡ï¼Œå†åˆ†é…ç»™å·¥ç¨‹å¸ˆå¹¶è¡Œå®Œæˆï¼Œæ˜¯ç›¸å½“å›°éš¾çš„ï¼›å°¤å…¶å½“å·¥ç¨‹å¸ˆæ•°é‡åºå¤§æ—¶ï¼ŒæŒ‘æˆ˜æ›´å¤§ã€‚åŒæ ·ï¼Œä¸ºå¹¶è¡Œ AI æ™ºèƒ½ä½“åˆ†è§£ä»»åŠ¡ä¹Ÿé¢ä¸´ç€æŒ‘æˆ˜ã€‚ä½†æ˜¯ï¼ŒLLM æ¨ç†æˆæœ¬çš„ä¸‹é™ä½¿å¾—ä½¿ç”¨å¤§é‡ Token å˜å¾—åˆ’ç®—ï¼Œè€Œé€šè¿‡å¹¶è¡Œå¤„ç†ï¼Œå¯ä»¥åœ¨ä¸æ˜¾è‘—å¢åŠ ç”¨æˆ·ç­‰å¾…æ—¶é—´çš„å‰æä¸‹å®Œæˆè¿™é¡¹å·¥ä½œã€‚

æˆ‘ä¹Ÿå¯¹å¹¶è¡Œ AI æ™ºèƒ½ä½“ç ”ç©¶é¢†åŸŸæ—¥ç›Šå¢é•¿çš„æˆæœæ„Ÿåˆ°é¼“èˆã€‚ä¾‹å¦‚ï¼Œæˆ‘éå¸¸å–œæ¬¢ Ryan Ehrlich ç­‰äººæ’°å†™çš„ã€ŠCodeMonkeysï¼šScaling Test-Time Compute for Software Engineeringã€‹ä¸€æ–‡ï¼Œå®ƒå±•ç¤ºäº†å¹¶è¡Œä»£ç ç”Ÿæˆå¦‚ä½•å¸®åŠ©æˆ‘ä»¬æ¢ç´¢æ›´å¹¿é˜”çš„è§£å†³æ–¹æ¡ˆç©ºé—´ã€‚Junlin Wang æå‡ºçš„æ··åˆ AI æ™ºèƒ½ä½“æ¶æ„ï¼Œåˆ™æä¾›äº†ä¸€ç§å‡ºäººæ„æ–™çš„ç®€å•æ–¹æ³•æ¥ç»„ç»‡å¹¶è¡Œ AI æ™ºèƒ½ä½“ï¼šè®©å¤šä¸ª LLM ç”Ÿæˆä¸åŒçš„ç­”æ¡ˆï¼Œç„¶åç”±ä¸€ä¸ªèšåˆå™¨ LLMï¼ˆaggregator LLMï¼‰å°†å®ƒä»¬ç»„åˆæˆæœ€ç»ˆè¾“å‡ºã€‚

æˆ‘ä»¬è¿˜æœ‰å¤§é‡çš„ç ”ç©¶å’Œå·¥ç¨‹å·¥ä½œéœ€è¦æ¢ç´¢ï¼Œæ‰èƒ½æ‰¾åˆ°å……åˆ†åˆ©ç”¨å¹¶è¡Œ AI æ™ºèƒ½ä½“çš„æœ€ä½³æ–¹å¼ã€‚æˆ‘ç›¸ä¿¡ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¹¶è¡Œå·¥ä½œçš„ AI æ™ºèƒ½ä½“æ•°é‡ â€”â€” å°±åƒèƒ½å¤Ÿé«˜æ•ˆå¹¶è¡Œå·¥ä½œçš„äººç±»ä¸€æ · â€”â€” å°†ä¼šéå¸¸åºå¤§ã€‚

[åŸæ–‡é“¾æ¥ï¼š https://t.co/ElcJZyzcfw]

### 105

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-04
é“¾æ¥: https://x.com/AndrewYNg/status/1963631698987684272
äº’åŠ¨: Likes: 1,833; Retweets: 591; Replies: 117; Quotes: 54; Views: 222,869; Bookmarks: 1,040; isReply: 0

There is significant unmet demand for developers who understand AI. At the same time, because most universities have not yet adapted their curricula to the new reality of programming jobs being much more productive with AI tools, there is also an uptick in unemployment of recent CS graduates.

When I interview AI engineers â€” people skilled at building AI applications â€” I look for people who can:
- Use AI assistance to rapidly engineer software systems
- Use AI building blocks like prompting, RAG, evals, agentic workflows, and machine learning to build applications
- Prototype and iterate rapidly

Someone with these skills can get a massively greater amount done than someone who writes code the way we did in 2022, before the advent of Generative AI. I talk to large businesses every week that would love to hire hundreds or more people with these skills, as well as startups that have great ideas but not enough engineers to build them. As more businesses adopt AI, I expect this talent shortage only to grow! At the same time, recent CS graduates face an increased unemployment rate, though the underemployment rate â€” of graduates doing work that doesnâ€™t require a degree â€” is still lower than for most other majors. This is why we hear simultaneously anecdotes of unemployed CS graduates and also of rising salaries for in-demand AI engineers.

When programming evolved from punchcards to keyboard and terminal, employers continued to hire punchcard programmers for a while. But eventually, all developers had to switch to the new way of coding. AI engineering is similarly creating a huge wave of change.

There is a stereotype of â€œAI Nativeâ€ fresh college graduates who outperform experienced developers. There is some truth to this. Multiple times, I have hired, for full-stack software engineering, a new grad who really knows AI over an experienced developer who still works 2022-style. But the best developers I know arenâ€™t recent graduates (no offense to the fresh grads!). They are experienced developers who have been on top of changes in AI. The most productive programmers today  deeply understand computers, how to architect software, and how to make complex tradeoffs â€” and who additionally are familiar with cutting-edge AI tools.

Sure, some skills from 2022 are becoming obsolete. For example, a lot of coding syntax that we had to memorize back then is no longer important, since we no longer need to code by hand as much. But even if, say, 30% of CS knowledge is obsolete, the remaining 70% â€” complemented with modern AI knowledge â€” is what makes really productive developers. (Even after punch cards became obsolete, a fundamental understanding of programming was very helpful for typing code into a keyboard.)

Without understanding how computers work, you canâ€™t just â€œvibe codeâ€ your way to greatness. Fundamentals are still important, and for those who additionally understand AI, job opportunities are numerous!

[Original text: https://t.co/nqzPC6eUpR ]

å½“å‰ï¼Œå¸‚åœºå¯¹é‚£äº›æ‡‚å¾—äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å¼€å‘è€…æœ‰ç€å·¨å¤§çš„éœ€æ±‚ç¼ºå£ã€‚ä¸æ­¤åŒæ—¶ï¼Œç”±äºå¤§å¤šæ•°å¤§å­¦å°šæœªè°ƒæ•´å…¶è¯¾ç¨‹ä»¥é€‚åº”ç¼–ç¨‹å·¥ä½œåœ¨æœ‰äº† AI å·¥å…·åç”Ÿäº§åŠ›å¤§å¹…æé«˜çš„æ–°ç°å®ï¼Œå› æ­¤è¿‘å¹´æ¥è®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰æ¯•ä¸šç”Ÿçš„å¤±ä¸šç‡ä¹Ÿæœ‰æ‰€ä¸Šå‡ã€‚

å½“æˆ‘é¢è¯• AI å·¥ç¨‹å¸ˆ â€”â€” é‚£äº›æ“…é•¿æ„å»º AI åº”ç”¨çš„äºº â€”â€” æ—¶ï¼Œæˆ‘å…³æ³¨çš„æ˜¯ä»–ä»¬æ˜¯å¦å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
- åˆ©ç”¨ AI è¾…åŠ©å¿«é€Ÿæ„å»ºè½¯ä»¶ç³»ç»Ÿ
- è¿ç”¨æç¤ºï¼ˆpromptingï¼‰ã€RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ã€è¯„ä¼°ï¼ˆevalsï¼‰ã€æ™ºèƒ½ä½“ï¼ˆagenticï¼‰å·¥ä½œæµä»¥åŠæœºå™¨å­¦ä¹ ç­‰ AI æ„å»ºæ¨¡å—æ¥å¼€å‘åº”ç”¨ç¨‹åº
- å¿«é€Ÿå¼€å‘åŸå‹å¹¶è¿­ä»£ä¸é‚£äº›ä»ç„¶æŒ‰ç…§ 2022 å¹´ï¼ˆå³ç”Ÿæˆå¼ AI å‡ºç°ä¹‹å‰ï¼‰çš„æ–¹å¼ç¼–å†™ä»£ç çš„äººç›¸æ¯”ï¼Œæ‹¥æœ‰è¿™äº›æŠ€èƒ½çš„äººèƒ½å¤Ÿå®Œæˆçš„å·¥ä½œé‡è¦å¤§å¾—å¤šã€‚æˆ‘æ¯å‘¨éƒ½ä¼šä¸å¤§å‹ä¼ä¸šäº¤æµï¼Œä»–ä»¬æ¸´æœ›é›‡ç”¨æ•°ç™¾ç”šè‡³æ›´å¤šå…·å¤‡è¿™äº›æŠ€èƒ½çš„äººæ‰ï¼›ä¹Ÿæœ‰åˆåˆ›å…¬å¸æ‹¥æœ‰ç»å¦™çš„åˆ›æ„ï¼Œä½†å´æ²¡æœ‰è¶³å¤Ÿçš„å·¥ç¨‹å¸ˆæ¥å°†å…¶å˜ä¸ºç°å®ã€‚éšç€è¶Šæ¥è¶Šå¤šçš„ä¼ä¸šé‡‡ç”¨ AIï¼Œæˆ‘é¢„è®¡è¿™ç§äººæ‰çŸ­ç¼ºåªä¼šåŠ å‰§ï¼ä¸æ­¤åŒæ—¶ï¼Œå°½ç®¡æœ€è¿‘çš„è®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰æ¯•ä¸šç”Ÿé¢ä¸´æ›´é«˜çš„å¤±ä¸šç‡ï¼Œä½†å…¶å°±ä¸šä¸è¶³ç‡ï¼ˆå³ä»äº‹ä¸éœ€è¦å­¦ä½çš„ â€”â€” å·¥ä½œï¼‰ä»ä½äºå¤§å¤šæ•°å…¶ä»–ä¸“ä¸šã€‚è¿™æ­£æ˜¯æˆ‘ä»¬ä¸ºä½•åŒæ—¶å¬åˆ°è®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰æ¯•ä¸šç”Ÿå¤±ä¸šçš„ä¼ é—»ä»¥åŠå¸‚åœºå¯¹ AI å·¥ç¨‹å¸ˆéœ€æ±‚æ—ºç››å¯¼è‡´è–ªèµ„ä¸Šæ¶¨çš„åŸå› ã€‚

å½“ç¼–ç¨‹ä»ç©¿å­”å¡ç‰‡æ¼”å˜ä¸ºé”®ç›˜å’Œç»ˆç«¯æ—¶ï¼Œé›‡ä¸»åœ¨ä¸€æ®µæ—¶é—´å†…ä»ç„¶é›‡ç”¨ç©¿å­”å¡ç‰‡ç¨‹åºå‘˜ã€‚ä½†æœ€ç»ˆï¼Œæ‰€æœ‰å¼€å‘è€…éƒ½å¿…é¡»è½¬å‘æ–°çš„ç¼–ç æ–¹å¼ã€‚AI å·¥ç¨‹åŒæ ·æ­£åœ¨æ€èµ·ä¸€åœºå·¨å¤§çš„å˜é©æµªæ½®ã€‚

æœ‰ä¸€ç§åˆ»æ¿å°è±¡è®¤ä¸ºï¼Œã€ŒAI åŸç”Ÿã€çš„å¤§å­¦åº”å±Šæ¯•ä¸šç”Ÿè¡¨ç°ä¼šè¶…è¶Šç»éªŒä¸°å¯Œçš„å¼€å‘è€…ã€‚è¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯äº‹å®ã€‚æˆ‘æ›¾å¤šæ¬¡åœ¨å…¨æ ˆè½¯ä»¶å·¥ç¨‹å²—ä½ä¸Šï¼Œé€‰æ‹©é›‡ç”¨çœŸæ­£äº†è§£ AI çš„åº”å±Šæ¯•ä¸šç”Ÿï¼Œè€Œéé‚£äº›ä»æ²¿ç”¨ 2022 å¹´å·¥ä½œæ¨¡å¼çš„ç»éªŒä¸°å¯Œçš„å¼€å‘è€…ã€‚ä½†æˆ‘è®¤è¯†çš„æœ€ä¼˜ç§€çš„å¼€å‘è€…å¹¶éåº”å±Šæ¯•ä¸šç”Ÿï¼ˆç»æ— å†’çŠ¯ä¹‹æ„ï¼ï¼‰ã€‚ä»–ä»¬æ˜¯é‚£äº›ä¸€ç›´ç´§è·Ÿ AI å˜åŒ–çš„ç»éªŒä¸°å¯Œçš„å¼€å‘è€…ã€‚å½“ä»Šæœ€é«˜æ•ˆçš„ç¨‹åºå‘˜ï¼Œä»–ä»¬ä¸ä»…æ·±å…¥ç†è§£è®¡ç®—æœºã€æ‡‚å¾—å¦‚ä½•æ¶æ„è½¯ä»¶ä»¥åŠå¦‚ä½•è¿›è¡Œå¤æ‚çš„æƒè¡¡ï¼Œè€Œä¸”è¿˜ç†Ÿæ‚‰å‰æ²¿çš„ AI å·¥å…·ã€‚

å½“ç„¶ï¼Œ2022 å¹´çš„ä¸€äº›æŠ€èƒ½æ­£åœ¨å˜å¾—è¿‡æ—¶ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å½“æ—¶å¿…é¡»è®°ä½çš„è®¸å¤šç¼–ç è¯­æ³•å·²ä¸å†é‡è¦ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å†éœ€è¦å¤§é‡åœ°æ‰‹åŠ¨ç¼–å†™ä»£ç ã€‚ä½†å³ä½¿ï¼Œæ¯”å¦‚è¯´ï¼Œ30% çš„è®¡ç®—æœºç§‘å­¦ï¼ˆCSï¼‰çŸ¥è¯†å·²ç»è¿‡æ—¶ï¼Œå‰©ä¸‹çš„ 70%â€”â€” è¾…ä»¥ç°ä»£ AI çŸ¥è¯† â€”â€” æ‰æ˜¯é€ å°±çœŸæ­£é«˜æ•ˆå¼€å‘è€…çš„å…³é”®ã€‚(å³ä½¿ç©¿å­”å¡ç‰‡è¿‡æ—¶åï¼Œå¯¹ç¼–ç¨‹çš„åŸºæœ¬ç†è§£å¯¹äºåœ¨é”®ç›˜ä¸Šè¾“å…¥ä»£ç ä¹Ÿéå¸¸æœ‰å¸®åŠ©ã€‚)

å¦‚æœä¸äº†è§£è®¡ç®—æœºçš„å·¥ä½œåŸç†ï¼Œä½ å°±ä¸èƒ½ä»…ä»…é€šè¿‡ã€Œå‡­æ„Ÿè§‰ã€æ¥ç¼–å†™ä»£ç ä»è€Œèµ°å‘å“è¶Šã€‚åŸºç¡€çŸ¥è¯†ä»ç„¶è‡³å…³é‡è¦ï¼Œè€Œå¯¹äºé‚£äº›é¢å¤–äº†è§£ AI çš„äººæ¥è¯´ï¼Œå·¥ä½œæœºä¼šæ›´æ˜¯æ•°ä¸èƒœæ•°ï¼

[åŸå§‹æ–‡æœ¬ï¼šhttps://t.co/nqzPC6eUpR]

### 106

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-17
é“¾æ¥: https://x.com/AndrewYNg/status/1968353689716035898
äº’åŠ¨: Likes: 717; Retweets: 160; Replies: 39; Quotes: 8; Views: 76,736; Bookmarks: 502; isReply: 0

New short course: Build AI Apps with MCP Servers: Working with Box Files, built with @Box and taught by  @BenAtBox , their CTO.

Many AI applications require custom code for basic file operations. The Model Context Protocol (MCP) standardizes this by letting you offload file tasks to dedicated servers that provide tools an LLM can use directly.

In this course, you'll process documents stored in a Box folder using the Box MCP server. Rather than writing custom integration code to connect to the Box API and download files, you'll design your application to use the tools provided via MCP.

Skills you'll gain:
- Build an LLM-powered document processing app, using the Box MCP server to access files
- Design a multi-agent system using Google's Agent Development Kit (ADK), consisting of specialized agents for file operations
- Coordinate the multi-agent workflow through an orchestrator that uses the Agent2Agent (A2A) protocol to connect to the agents

You'll start with a local file-processing app, refactor it to work with Box's MCP server, then evolve it into a multi-agent system.

Sign up here: https://t.co/FitKgvGnpb

<p> æ–°çš„çŸ­æœŸè¯¾ç¨‹ï¼šä½¿ç”¨ MCP æœåŠ¡å™¨æ„å»º AI åº”ç”¨ï¼šå¤„ç† Box æ–‡ä»¶ï¼Œæœ¬è¯¾ç¨‹ç”± Box ååŠ©å¼€å‘ï¼Œå¹¶ç”±å…¶é¦–å¸­æŠ€æœ¯å®˜ï¼ˆCTOï¼‰BenAtBox äº²è‡ªè®²æˆã€‚</p>
<p> è®¸å¤š AI åº”ç”¨åœ¨æ‰§è¡ŒåŸºæœ¬æ–‡ä»¶æ“ä½œæ—¶ï¼Œéƒ½éœ€è¦ç¼–å†™è‡ªå®šä¹‰ä»£ç ã€‚è€Œæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆModel Context Protocolï¼ŒMCPï¼‰é€šè¿‡è®©æ‚¨å°†æ–‡ä»¶ä»»åŠ¡åˆ†è½½ç»™ä¸“ç”¨æœåŠ¡å™¨ï¼Œä»è€Œå°†è¿™ä¸€è¿‡ç¨‹æ ‡å‡†åŒ–ã€‚è¿™äº›æœåŠ¡å™¨æä¾›äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥ç›´æ¥ä½¿ç”¨çš„å·¥å…·ã€‚</p>
<p> åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Box MCP æœåŠ¡å™¨æ¥å¤„ç†å­˜å‚¨åœ¨ Box æ–‡ä»¶å¤¹ä¸­çš„æ–‡æ¡£ã€‚æ‚¨æ— éœ€ç¼–å†™è‡ªå®šä¹‰é›†æˆä»£ç æ¥è¿æ¥ Box API å¹¶ä¸‹è½½æ–‡ä»¶ï¼Œè€Œæ˜¯ä¼šè®¾è®¡æ‚¨çš„åº”ç”¨ç¨‹åºï¼Œç›´æ¥åˆ©ç”¨ MCP æä¾›çš„å·¥å…·ã€‚</p>
<p> æ‚¨å°†å­¦ä¹ ä»¥ä¸‹æŠ€èƒ½ï¼š</p>
<ul>
<li> ä½¿ç”¨ Box MCP æœåŠ¡å™¨è®¿é—®æ–‡ä»¶ï¼Œæ„å»ºä¸€ä¸ª LLM é©±åŠ¨çš„æ–‡æ¡£å¤„ç†åº”ç”¨ã€‚</li>
<li> åˆ©ç”¨ Google çš„ Agent Development Kitï¼ˆADKï¼‰è®¾è®¡ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰ç³»ç»Ÿï¼Œå…¶ä¸­åŒ…å«ä¸“é—¨è´Ÿè´£æ–‡ä»¶æ“ä½œçš„ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ã€‚</li>
<li> é€šè¿‡ä¸€ä¸ªç¼–æ’å™¨åè°ƒå¤šæ™ºèƒ½ä½“å·¥ä½œæµï¼Œè¯¥ç¼–æ’å™¨ä½¿ç”¨ Agent2Agentï¼ˆA2Aï¼‰åè®®è¿æ¥åˆ°å„ AI æ™ºèƒ½ä½“ã€‚</li>
</ul>
<p> æ‚¨å°†ä»ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶å¤„ç†åº”ç”¨å…¥æ‰‹ï¼Œå°†å…¶é‡æ„ä»¥ä¸ Box çš„ MCP æœåŠ¡å™¨ååŒå·¥ä½œï¼Œç„¶åé€æ­¥å°†å…¶å‘å±•ä¸ºä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚</p>
<p> åœ¨æ­¤æ³¨å†Œï¼šhttps://t.co/FitKgvGnpb</p>

### 107

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-18
é“¾æ¥: https://x.com/AndrewYNg/status/1968710001079501303
äº’åŠ¨: Likes: 1,371; Retweets: 208; Replies: 71; Quotes: 26; Views: 176,967; Bookmarks: 1,103; isReply: 0

Automated software testing is growing in importance in the era of AI-assisted coding. Agentic coding systems accelerate development but are also unreliable. Agentic testing â€” where you ask AI to write tests and check your code against them â€” is helping. Automatically testing  infrastructure software components that you intend to build on top of is especially helpful and results in more stable infrastructure and less downstream debugging.

Software testing methodologies such as Test Driven Development (TDD), a test-intensive approach that involves first writing rigorous tests for correctness and only then making progress by writing code that passes those tests, are an important way to find bugs. But it can be a lot of work to write tests. (I personally never adopted TDD for that reason.) Because AI is quite good at writing tests, agentic testing enjoys growing attention.

First, coding agents do misbehave! My teams use them a lot, and we have seen:
- Numerous bugs introduced by coding agents, including subtle infrastructure bugs that take humans weeks to find.
- A security loophole that was introduced into our production system when a coding agent made password resets easier to simplify development.
- Reward hacking, where a coding agent modified test code to make it easier to pass the tests.
- An agent running "rm *.py" in the working directory, leading to deletion of all of a project's  code (which, fortunately, was backed up on github).

In the last example, when pressed, the agent apologized and agreed â€œthat was an incredibly stupid mistake.â€ This made us feel better, but the damage had already been done!

I love coding agents despite such mistakes and see them making us dramatically more productive. To make them more reliable, Iâ€™ve found that prioritizing where to test helps.

I rarely write (or direct an agent to write) extensive tests for front-end code. If there's a bug, hopefully it will be easy to see and also cause little lasting damage. For example, I find generated codeâ€™s front-end bugs, say in the display of information on a web page, relatively easy to find. When the front end of a web site looks wrong, youâ€™ll see it immediately, and you can tell the agent and have it iterate to fix it. (A more advanced technique: Use MCP to let the agent integrate with software like Playwright to automatically take screenshots, so it can autonomously see if something is wrong and debug.)
In contrast, back-end bugs are harder to find. Iâ€™ve seen subtle infrastructure bugs â€” for example, one that led to a corrupted database record only in certain corner cases â€” that took a long time to find. Putting in place rigorous tests for your infrastructure code might help spot these problems earlier and save you many hours of challenging debugging.

Bugs in software components that you intend to build on top of lead to downstream bugs that can be hard to find. Further, bugs in a component thatâ€™s deep in a software stack â€” and that you build multiple abstraction layers on top of â€” might surface only weeks or months later, long after youâ€™ve forgotten what you were doing while building this specific component, and be really hard to identify and fix. This is why testing components deep in your software stack is especially important. Metaâ€™s mantra â€œMove fast with stable infrastructureâ€ (which replaced â€œmove fast and break thingsâ€) still applies today. Agentic testing can help you make sure you have good infrastructure for you and others to build on!

At AI Fund and https://t.co/zpIxRSuky4â€™s recent Buildathon, we held a panel discussion with experts in agentic coding (Michele Catasta, President at Replit; Chao Peng, Principal Research Scientist at Trae; and Paxton Maeder-York, Venture Partnerships at Anthropic; moderated by AI Fundâ€™s Eli Chen), where the speakers shared best practices. Testing was one of the topics discussed. That panel was one of my highlights of Buildathon and you can watch the video on YouTube.

[Original text: https://t.co/B1sQ5oDnCU ]

åœ¨ AI è¾…åŠ©ç¼–ç¨‹æ—¶ä»£ï¼Œè‡ªåŠ¨åŒ–è½¯ä»¶æµ‹è¯•çš„é‡è¦æ€§æ—¥ç›Šå¢é•¿ã€‚å°½ç®¡æ™ºèƒ½ä½“ç¼–ç¨‹ç³»ç»Ÿï¼ˆAgentic coding systemsï¼‰èƒ½æ˜¾è‘—åŠ é€Ÿå¼€å‘ï¼Œä½†å®ƒä»¬ä¹Ÿå¹¶éå®Œå…¨å¯é ã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼Œæ™ºèƒ½ä½“æµ‹è¯•ï¼ˆAgentic testing)â€”â€” å³è®© AI ç¼–å†™æµ‹è¯•ç”¨ä¾‹å¹¶ç”¨å®ƒä»¬æ¥æ£€æŸ¥ä½ çš„ä»£ç  â€”â€” æ­£å‘æŒ¥ç€è¶Šæ¥è¶Šå¤§çš„ä½œç”¨ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè‡ªåŠ¨æµ‹è¯•é‚£äº›ä½ æ‰“ç®—ä½œä¸ºåŸºç¡€æ¥æ„å»ºå…¶ä»–åŠŸèƒ½çš„åŸºç¡€è®¾æ–½è½¯ä»¶ç»„ä»¶ï¼Œèƒ½æœ‰æ•ˆæå‡åŸºç¡€è®¾æ–½çš„ç¨³å®šæ€§ï¼Œå¹¶å¤§å¤§å‡å°‘åç»­çš„è°ƒè¯•å·¥ä½œã€‚

è¯¸å¦‚æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTest Driven Developmentï¼ŒTDDï¼‰ä¹‹ç±»çš„è½¯ä»¶æµ‹è¯•æ–¹æ³•è®ºï¼Œæ˜¯å‘ç° Bug çš„é‡è¦é€”å¾„ã€‚TDD æ˜¯ä¸€ç§é«˜åº¦ä¾èµ–æµ‹è¯•çš„æ–¹æ³•ï¼šå®ƒè¦æ±‚å¼€å‘è€…é¦–å…ˆä¸ºä»£ç çš„æ­£ç¡®æ€§ç¼–å†™ä¸¥è°¨çš„æµ‹è¯•ï¼Œç„¶åæ‰ç€æ‰‹ç¼–å†™èƒ½å¤Ÿé€šè¿‡è¿™äº›æµ‹è¯•çš„ä»£ç ã€‚ç„¶è€Œï¼Œç¼–å†™æµ‹è¯•å¾€å¾€æ˜¯ä¸€é¡¹ç¹é‡çš„å·¥ä½œã€‚(æˆ‘ä¸ªäººå°±å› ä¸ºè¿™ä¸ªåŸå› ä»æœªçœŸæ­£é‡‡çº³ TDDã€‚ï¼‰ä½†ç”±äº AI åœ¨ç¼–å†™æµ‹è¯•æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ™ºèƒ½ä½“æµ‹è¯•æ­£å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚

é¦–å…ˆï¼Œç¼–ç¨‹æ™ºèƒ½ä½“ç¡®å®ä¼šã€ŒçŠ¯é”™ã€ï¼æˆ‘çš„å›¢é˜Ÿå¤§é‡ä½¿ç”¨å®ƒä»¬ï¼Œå¹¶äº²èº«ç»å†äº†ä»¥ä¸‹é—®é¢˜ï¼š
- ç¼–ç¨‹æ™ºèƒ½ä½“å¼•å…¥äº†å¤§é‡ Bugï¼Œå…¶ä¸­ä¸ä¹éœ€è¦äººç±»èŠ±è´¹æ•°å‘¨æ—¶é—´æ‰èƒ½å‘ç°çš„éšè”½åŸºç¡€è®¾æ–½ Bugã€‚
- ä¸€ä¸ªç¼–ç¨‹æ™ºèƒ½ä½“ä¸ºäº†ç®€åŒ–å¼€å‘ï¼Œå°†å¯†ç é‡ç½®æµç¨‹å˜å¾—è¿‡äºç®€å•ï¼Œç»“æœç»™æˆ‘ä»¬çš„ç”Ÿäº§ç³»ç»Ÿåˆ¶é€ äº†ä¸€ä¸ªå®‰å…¨æ¼æ´ã€‚
- å¥–åŠ±ä½œå¼Šï¼ˆReward hacking)ï¼šç¼–ç¨‹æ™ºèƒ½ä½“è‡ªè¡Œä¿®æ”¹äº†æµ‹è¯•ä»£ç ï¼Œåªä¸ºæ›´å®¹æ˜“é€šè¿‡æµ‹è¯•ã€‚
- ä¸€ä¸ªæ™ºèƒ½ä½“åœ¨å·¥ä½œç›®å½•ä¸­æ‰§è¡Œäº†ã€Œrm *.pyã€å‘½ä»¤ï¼Œå¯¼è‡´ä¸€ä¸ªé¡¹ç›®çš„æ‰€æœ‰ä»£ç è¢«åˆ é™¤ï¼ˆå¹¸è¿çš„æ˜¯ï¼Œè¿™äº›ä»£ç å·²åœ¨ GitHub ä¸Šè¿›è¡Œäº†å¤‡ä»½ï¼‰ã€‚

å¯¹äºæœ€åä¸€ä¸ªä¾‹å­ï¼Œå½“è¢«ã€Œè¿½é—®ã€æ—¶ï¼Œè¯¥æ™ºèƒ½ä½“è¡¨ç¤ºæ­‰æ„ï¼Œå¹¶æ‰¿è®¤ã€Œé‚£æ˜¯ä¸€ä¸ªæå…¶æ„šè ¢çš„é”™è¯¯ã€ã€‚è™½ç„¶è¿™è®©æˆ‘ä»¬æ„Ÿè§‰å¥½äº†ä¸€äº›ï¼Œä½†æŸå®³å·²ç»é€ æˆäº†ï¼

å°½ç®¡ç¼–ç¨‹æ™ºèƒ½ä½“ä¼šçŠ¯ä¸‹è¿™ç±»é”™è¯¯ï¼Œä½†æˆ‘ä¾ç„¶éå¸¸å–œæ¬¢å®ƒä»¬ï¼Œå¹¶è®¤ä¸ºå®ƒä»¬èƒ½æå¤§åœ°æé«˜æˆ‘ä»¬çš„ç”Ÿäº§åŠ›ã€‚ä¸ºäº†è®©æ™ºèƒ½ä½“æ›´åŠ å¯é ï¼Œæˆ‘å‘ç°ä¼˜å…ˆè€ƒè™‘æµ‹è¯•çš„é‡ç‚¹åŒºåŸŸè‡³å…³é‡è¦ã€‚

æˆ‘å¾ˆå°‘ä¼šä¸ºå‰ç«¯ä»£ç ç¼–å†™ï¼ˆæˆ–æŒ‡æŒ¥æ™ºèƒ½ä½“ç¼–å†™ï¼‰å¤§é‡æµ‹è¯•ã€‚å¦‚æœå‰ç«¯å‡ºç° Bugï¼Œé€šå¸¸å¾ˆå®¹æ˜“è¢«å‘ç°ï¼Œä¸”é€ æˆçš„é•¿æœŸæŸå®³ä¹Ÿè¾ƒå°ã€‚ä¾‹å¦‚ï¼Œæˆ‘å‘ç°ç”± AI ç”Ÿæˆä»£ç å¯¼è‡´çš„å‰ç«¯ Bugï¼Œæ¯”å¦‚ç½‘é¡µä¿¡æ¯æ˜¾ç¤ºé”™è¯¯ï¼Œç›¸å¯¹å®¹æ˜“æ‰¾åˆ°ã€‚å½“ç½‘ç«™å‰ç«¯çœ‹èµ·æ¥ä¸å¯¹åŠ²æ—¶ï¼Œä½ ä¼šç«‹åˆ»å‘ç°ï¼Œç„¶åå¯ä»¥å‘ŠçŸ¥æ™ºèƒ½ä½“å¹¶è®©å®ƒè¿­ä»£ä¿®å¤ã€‚(ä¸€ä¸ªæ›´é«˜çº§çš„æŠ€å·§æ˜¯ï¼šä½¿ç”¨ MCP è®©æ™ºèƒ½ä½“ä¸ Playwright ç­‰è½¯ä»¶é›†æˆï¼Œè‡ªåŠ¨è¿›è¡Œå±å¹•æˆªå›¾ï¼Œè¿™æ ·å®ƒå°±èƒ½è‡ªä¸»åˆ¤æ–­æ˜¯å¦æœ‰é—®é¢˜å¹¶è¿›è¡Œè°ƒè¯•ã€‚)
ç›¸æ¯”ä¹‹ä¸‹ï¼Œåç«¯ Bug æ›´éš¾å‘ç°ã€‚æˆ‘æ›¾é‡åˆ°ä¸€äº›éšè”½çš„åŸºç¡€è®¾æ–½ Bugâ€”â€” ä¾‹å¦‚ï¼ŒæŸä¸ªåªåœ¨ç‰¹å®šæç«¯æƒ…å†µä¸‹æ‰ä¼šå¯¼è‡´æ•°æ®åº“è®°å½•æŸåçš„ Bugâ€”â€” è¿™ç±»é—®é¢˜å¾€å¾€éœ€è¦å¾ˆé•¿æ—¶é—´æ‰èƒ½å®šä½ã€‚ä¸ºä½ çš„åŸºç¡€è®¾æ–½ä»£ç å»ºç«‹ä¸¥æ ¼çš„æµ‹è¯•ï¼Œæœ‰åŠ©äºæ›´æ—©åœ°å‘ç°è¿™äº›é—®é¢˜ï¼Œä¸ºä½ èŠ‚çœå¤§é‡è€—æ—¶ä¸”å¤æ‚çš„è°ƒè¯•å·¥ä½œã€‚

ä½ è®¡åˆ’åœ¨å…¶ä¹‹ä¸Šæ„å»ºå…¶ä»–åŠŸèƒ½çš„è½¯ä»¶ç»„ä»¶å¦‚æœå­˜åœ¨ Bugï¼Œä¼šå¯¼è‡´ä¸‹æ¸¸å‡ºç°éš¾ä»¥è¿½è¸ªçš„ Bugã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œå¦‚æœ Bug å‡ºç°åœ¨è½¯ä»¶å †æ ˆæ·±å±‚çš„ç»„ä»¶ä¸­ â€”â€” ç‰¹åˆ«æ˜¯ä½ åœ¨æ­¤ä¹‹ä¸Šåˆæ„å»ºäº†å¤šå±‚æŠ½è±¡ â€”â€” é‚£ä¹ˆå®ƒå¯èƒ½è¦æ•°å‘¨ç”šè‡³æ•°æœˆåæ‰ä¼šæµ®å‡ºæ°´é¢ï¼Œè€Œé‚£æ—¶ä½ å¯èƒ½æ—©å·²ä¸è®°å¾—åœ¨æ„å»ºè¿™ä¸ªç‰¹å®šç»„ä»¶æ—¶åšäº†ä»€ä¹ˆï¼Œè¿™ä¼šä½¿å¾—è¯†åˆ«å’Œä¿®å¤ Bug å˜å¾—å¼‚å¸¸å›°éš¾ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¯¹è½¯ä»¶å †æ ˆæ·±å¤„çš„ç»„ä»¶è¿›è¡Œæµ‹è¯•æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚Meta çš„åº§å³é“­ã€Œå¿«é€Ÿè¡ŒåŠ¨ï¼Œç¨³å®šåŸºç¡€è®¾æ–½ã€(è¿™å–ä»£äº†æ—©æœŸçš„ã€Œå¿«é€Ÿè¡ŒåŠ¨ï¼Œæ‰“ç ´ä¸€åˆ‡ã€ï¼‰è‡³ä»Šä»ç„¶é€‚ç”¨ã€‚æ™ºèƒ½ä½“æµ‹è¯•å¯ä»¥å¸®åŠ©ä½ ç¡®ä¿ä½ å’Œä»–äººæ‹¥æœ‰å¯é çš„åŸºç¡€è®¾æ–½æ¥ç»§ç»­æ„å»ºï¼

åœ¨ AI Fund å’Œ https://t.co/zpIxRSuky4 æœ€è¿‘ä¸¾åŠçš„ Buildathon æ´»åŠ¨ä¸­ï¼Œæˆ‘ä»¬é‚€è¯·äº†æ™ºèƒ½ä½“ç¼–ç¨‹é¢†åŸŸçš„ä¸“å®¶ï¼ˆReplit æ€»è£ Michele Catastaï¼›Trae é¦–å¸­ç ”ç©¶ç§‘å­¦å®¶ Chao Pengï¼›Anthropic é£é™©æŠ•èµ„åˆä¼™äºº Paxton Maeder-Yorkï¼›ç”± AI Fund çš„ Eli Chen ä¸»æŒï¼‰ï¼Œå…±åŒä¸¾è¡Œäº†ä¸€åœºå°ç»„è®¨è®ºï¼Œå„ä½å‘è¨€è€…åˆ†äº«äº†ä»–ä»¬çš„æœ€ä½³å®è·µã€‚æµ‹è¯•æ­£æ˜¯è®¨è®ºçš„ä¸»é¢˜ä¹‹ä¸€ã€‚é‚£æ¬¡å°ç»„è®¨è®ºæ˜¯æˆ‘åœ¨ Buildathon æ´»åŠ¨ä¸­æœ€ç²¾å½©çš„ç¯èŠ‚ä¹‹ä¸€ï¼Œä½ å¯ä»¥åœ¨ YouTube ä¸Šè§‚çœ‹ç›¸å…³è§†é¢‘ã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/B1sQ5oDnCU]

### 108

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-18
é“¾æ¥: https://x.com/AndrewYNg/status/1968710105924280352
äº’åŠ¨: Likes: 60; Retweets: 13; Replies: 1; Quotes: 1; Views: 53,921; Bookmarks: 72; isReply: 1

Video of the panel at Buildathon: https://t.co/rYevXjv1vZ

Buildathon æ´»åŠ¨ä¸­å°ç»„è®¨è®ºçš„è§†é¢‘ï¼šhttps://t.co/rYevXjv1vZ

### 109

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-21
é“¾æ¥: https://x.com/AndrewYNg/status/1969871958365163539
äº’åŠ¨: Likes: 7,068; Retweets: 581; Replies: 599; Quotes: 48; Views: 524,531; Bookmarks: 483; isReply: 0

My heart goes out to all the families and individuals anxious over their futures following the abrupt and chaotic announcement of H-1B visa changes. 

America should be working to attract more skilled talent, not create uncertainly that turns them away. To all legal immigrants and H1-B holders: I support and appreciate you.

H-1B ç­¾è¯æ”¿ç­–çš„çªç„¶ä¸”æ··ä¹±çš„å®£å¸ƒï¼Œè®©è®¸å¤šå®¶åº­å’Œä¸ªäººå¯¹æœªæ¥å……æ»¡äº†ç„¦è™‘ï¼Œæˆ‘å¯¹æ­¤æ·±è¡¨åŒæƒ…ã€‚

ç¾å›½åº”è¯¥è‡´åŠ›äºå¸å¼•æ›´å¤šæœ‰æŠ€èƒ½çš„äººæ‰ï¼Œè€Œä¸æ˜¯åˆ¶é€ ä¸ç¡®å®šæ€§ï¼Œåè€Œå°†ä»–ä»¬æ‹’ä¹‹é—¨å¤–ã€‚æˆ‘æ”¯æŒå¹¶æ„Ÿè°¢æ‰€æœ‰åˆæ³•ç§»æ°‘å’Œ H1-B æŒæœ‰è€…ã€‚

### 110

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-24
é“¾æ¥: https://x.com/AndrewYNg/status/1970899944258375866
äº’åŠ¨: Likes: 1,398; Retweets: 310; Replies: 65; Quotes: 7; Views: 95,046; Bookmarks: 833; isReply: 0

When data agents fail, they often fail silently - giving  confident-sounding answers that are wrong, and it can be hard to figure out what caused the failure. 

"Building and Evaluating Data Agents" is a new short course created with @Snowflake and taught by @datta_cs and @_jreini that teaches you to build data agents with comprehensive evaluation built in.

Skills you'll gain:
- Build reliable LLM data agents using the Goal-Plan-Action framework and runtime evaluations that catch failures mid-execution
- Use OpenTelemetry tracing and evaluation infrastructure to diagnose exactly where agents fail and systematically improve performance
- Orchestrate multi-step workflows across web search, SQL, and document retrieval in LangGraph-based agents

The result: visibility into every step of your agent's reasoning, so if something breaks, you have a systematic approach to fix it. 

Sign up to get started: https://t.co/jGQQcU6X46

å½“æ•°æ®æ™ºèƒ½ä½“ï¼ˆdata agentsï¼‰å‡ºé”™æ—¶ï¼Œå®ƒä»¬å¾€å¾€ä¼šæ‚„æ— å£°æ¯åœ°å¤±è´¥ â€”â€” ç»™å‡ºå¬èµ·æ¥å¾ˆæœ‰æŠŠæ¡ä½†å®åˆ™é”™è¯¯çš„ç­”æ¡ˆï¼Œè€Œä¸”å¾ˆéš¾å¼„æ¸…æ¥šç©¶ç«Ÿæ˜¯å“ªé‡Œå‡ºäº†é—®é¢˜ã€‚

ã€Œæ„å»ºå’Œè¯„ä¼°æ•°æ®æ™ºèƒ½ä½“ï¼ˆBuilding and Evaluating Data Agentsï¼‰ã€æ˜¯ä¸€é—¨æ–°æ¨å‡ºçš„çŸ­æœŸè¯¾ç¨‹ï¼Œç”± @Snowflake åˆä½œåˆ›å»ºï¼Œ@datta_cs å’Œ @_jreini æ•™æˆã€‚å®ƒå°†æ•™ä½ å¦‚ä½•æ„å»ºå…·å¤‡å…¨é¢è¯„ä¼°åŠŸèƒ½çš„æ•°æ®æ™ºèƒ½ä½“ã€‚

ä½ å°†æŒæ¡çš„æŠ€èƒ½åŒ…æ‹¬ï¼š
- ä½¿ç”¨ã€Œç›®æ ‡ - è®¡åˆ’ - è¡ŒåŠ¨ï¼ˆGoal-Plan-Actionï¼‰ã€æ¡†æ¶å’Œè¿è¡Œæ—¶è¯„ä¼°ï¼ˆruntime evaluationsï¼‰åŠŸèƒ½ï¼Œæ„å»ºå¯é çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•°æ®æ™ºèƒ½ä½“ï¼Œè¿™äº›è¯„ä¼°èƒ½åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åŠæ—¶æ•è·é”™è¯¯ã€‚
- è¿ç”¨ OpenTelemetry è¿½è¸ªï¼ˆtracingï¼‰å’Œè¯„ä¼°åŸºç¡€è®¾æ–½ï¼ˆevaluation infrastructureï¼‰ï¼Œç²¾ç¡®è¯Šæ–­æ™ºèƒ½ä½“å¤±è´¥çš„å…·ä½“ç¯èŠ‚ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°æå‡æ€§èƒ½ã€‚
- åœ¨åŸºäº LangGraph çš„æ™ºèƒ½ä½“ä¸­ï¼Œç¼–æ’è·¨è¶Šç½‘ç»œæœç´¢ï¼ˆweb searchï¼‰ã€SQL æŸ¥è¯¢å’Œæ–‡æ¡£æ£€ç´¢ï¼ˆdocument retrievalï¼‰çš„å¤šæ­¥éª¤å·¥ä½œæµã€‚

æœ€ç»ˆæ•ˆæœæ˜¯ï¼šä½ å°†æ¸…æ™°åœ°äº†è§£æ™ºèƒ½ä½“æ¨ç†ï¼ˆreasoningï¼‰çš„æ¯ä¸€æ­¥ï¼Œå› æ­¤ä¸€æ—¦å‡ºç°é—®é¢˜ï¼Œä½ å°±èƒ½æœ‰æ¡ä¸ç´Šåœ°è¿›è¡Œä¿®å¤ã€‚

ç«‹å³æ³¨å†Œå¼€å§‹å­¦ä¹ ï¼šhttps://t.co/jGQQcU6X46

### 111

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-25
é“¾æ¥: https://x.com/AndrewYNg/status/1971312147654377823
äº’åŠ¨: Likes: 5,874; Retweets: 1,079; Replies: 213; Quotes: 164; Views: 815,189; Bookmarks: 1,841; isReply: 0

Last week, China barred its major tech companies from buying Nvidia chips. This move received only modest attention in the media, but has implications beyond whatâ€™s widely appreciated. Specifically, it signals that China has progressed sufficiently in semiconductors to break away from dependence on advanced chips designed in the U.S., the vast majority of which are manufactured in Taiwan. It also highlights the U.S. vulnerability to possible disruptions in Taiwan at a moment when China is becoming less vulnerable.

After the U.S. started restricting AI chip sales to China, China dramatically ramped up its semiconductor research and investment to move toward self-sufficiency. These efforts are starting to bear fruit, and Chinaâ€™s willingness to cut off Nvidia is a strong sign of its faith in its domestic capabilities. For example, the new DeepSeek-R1-Safe model was trained on 1000 Huawei Ascend chips. While individual Ascend chips are significantly less powerful than individual Nvidia or AMD chips, Huaweiâ€™s system-level design approach to orchestrating how a much larger number of chips work together seems to be paying off. For example, Huaweiâ€™s CloudMatrix 384 system of 384 chips aims to compete with Nvidiaâ€™s GB200, which uses 72 higher-capability chips.

Today, U.S. access to advanced semiconductors is heavily dependent on Taiwanâ€™s TSMC, which manufactures the vast majority of the most advanced chips. Unfortunately, U.S. efforts to ramp up domestic semiconductor manufacturing have been slow. I am encouraged that one fab at the TSMC Arizona facility is now operating, but issues of workforce training, culture, licensing and permitting, and the supply chain are still being addressed, and there is still a long road ahead for the U.S. facility to be a viable substitute for manufacturing in Taiwan.

If China gains independence from Taiwan manufacturing significantly faster than the U.S., this would leave the U.S. much more vulnerable to possible disruptions in Taiwan, whether through natural disasters or man-made events. If manufacturing in Taiwan is disrupted for any reason and Chinese companies end up accounting for a large fraction of global semiconductor manufacturing capabilities, that would also help China gain tremendous geopolitical influence.

Despite occasional moments of heightened tensions and large-scale military exercises, Taiwan has been mostly peaceful since the 1960s. This peace has helped the people of Taiwan to prosper and allowed AI to make tremendous advances, built on top of chips made by TSMC. I hope we will find a path to maintaining peace for many decades more.

But hope is not a plan. In addition to working to ensure peace, practical work lies ahead to multi-source, build more chip fabs in more nations, and enhance the resilience of the semiconductor supply chain. Dependence on any single manufacturer invites shortages, price spikes, and stalled innovation the moment something goes sideways.

[Original text: https://t.co/5bdEpQcaob ]

ä¸Šå‘¨ï¼Œä¸­å›½ç¦æ­¢å…¶ä¸»è¦ç§‘æŠ€å…¬å¸è´­ä¹° Nvidia èŠ¯ç‰‡ã€‚æ­¤ä¸¾åœ¨åª’ä½“ä¸Šä»…è·å¾—äº†é€‚åº¦çš„å…³æ³¨ï¼Œä½†å…¶æ·±è¿œå½±å“å°šæœªè¢«å……åˆ†è®¤è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™è¡¨æ˜ä¸­å›½åœ¨åŠå¯¼ä½“é¢†åŸŸå·²å–å¾—äº†è¶³å¤Ÿçš„è¿›å±•ï¼Œè¶³ä»¥æ‘†è„±å¯¹ç¾å›½è®¾è®¡çš„å…ˆè¿›èŠ¯ç‰‡çš„ä¾èµ–ï¼Œè¿™äº›èŠ¯ç‰‡ç»å¤§å¤šæ•°åœ¨å°æ¹¾åˆ¶é€ ã€‚è¿™ä¹Ÿå‡¸æ˜¾äº†ï¼Œåœ¨ä¸­å›½å˜å¾—ä¸é‚£ä¹ˆè„†å¼±çš„æ—¶åˆ»ï¼Œç¾å›½åœ¨é¢å¯¹å°æ¹¾å¯èƒ½å‡ºç°çš„å¹²æ‰°æ—¶æ‰€è¡¨ç°å‡ºçš„è„†å¼±æ€§ã€‚

åœ¨ç¾å›½å¼€å§‹é™åˆ¶å‘ä¸­å›½é”€å”® AI èŠ¯ç‰‡åï¼Œä¸­å›½å¤§å¹…å¢åŠ äº†å…¶åŠå¯¼ä½“ç ”ç©¶å’ŒæŠ•èµ„ï¼Œä»¥è¿ˆå‘è‡ªç»™è‡ªè¶³ã€‚è¿™äº›åŠªåŠ›æ­£åœ¨æ”¶è·æˆæœï¼Œä¸­å›½åˆ‡æ–­ Nvidia çš„æ„æ„¿æ­£æ˜¯å…¶å¯¹å›½å†…èƒ½åŠ›å……æ»¡ä¿¡å¿ƒçš„å¼ºçƒˆä¿¡å·ã€‚ä¾‹å¦‚ï¼Œæ–°çš„ DeepSeek-R1-Safe æ¨¡å‹æ˜¯åœ¨ 1000 é¢—åä¸ºæ˜‡è…¾ï¼ˆAscendï¼‰èŠ¯ç‰‡ä¸Šè®­ç»ƒçš„ã€‚è™½ç„¶å•ä¸ªæ˜‡è…¾èŠ¯ç‰‡çš„æ€§èƒ½æ˜æ˜¾ä½äºå•ä¸ª Nvidia æˆ– AMD èŠ¯ç‰‡ï¼Œä½†åä¸ºé€šè¿‡ç³»ç»Ÿçº§è®¾è®¡æ–¹æ³•æ¥åè°ƒæ•°é‡åºå¤§çš„èŠ¯ç‰‡ååŒå·¥ä½œï¼Œè¿™ç§ç­–ç•¥ä¼¼ä¹æ­£åœ¨å¥æ•ˆã€‚ä¾‹å¦‚ï¼Œåä¸ºçš„ CloudMatrix 384 ç³»ç»Ÿç”± 384 é¢—èŠ¯ç‰‡ç»„æˆï¼Œæ—¨åœ¨ä¸ Nvidia çš„ GB200 ç«äº‰ï¼Œåè€…ä½¿ç”¨äº† 72 é¢—æ›´é«˜æ€§èƒ½èŠ¯ç‰‡ã€‚

ç›®å‰ï¼Œç¾å›½å¯¹å…ˆè¿›åŠå¯¼ä½“ï¼ˆsemiconductorï¼‰çš„è·å–ä¸¥é‡ä¾èµ–å°æ¹¾çš„å°ç§¯ç”µï¼ˆTSMCï¼‰ï¼Œå°ç§¯ç”µç”Ÿäº§äº†ç»å¤§å¤šæ•°æœ€å…ˆè¿›çš„èŠ¯ç‰‡ã€‚ä¸å¹¸çš„æ˜¯ï¼Œç¾å›½æå‡å›½å†…åŠå¯¼ä½“åˆ¶é€ èƒ½åŠ›çš„åŠªåŠ›ä¸€ç›´è¿›å±•ç¼“æ…¢ã€‚ä»¤æˆ‘æ„Ÿåˆ°é¼“èˆçš„æ˜¯ï¼Œå°ç§¯ç”µäºšåˆ©æ¡‘é‚£å·¥å‚çš„ä¸€ä¸ªæ™¶åœ†å‚ï¼ˆfabï¼‰ç°å·²æŠ•å…¥è¿è¥ï¼Œä½†åŠ³åŠ¨åŠ›åŸ¹è®­ã€æ–‡åŒ–ã€è®¸å¯å’Œå®¡æ‰¹ä»¥åŠä¾›åº”é“¾ç­‰é—®é¢˜ä»åœ¨è§£å†³ä¸­ï¼Œç¾å›½å·¥å‚è¦çœŸæ­£æˆä¸ºå°æ¹¾åˆ¶é€ çš„å¯è¡Œæ›¿ä»£å“ï¼Œä»æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚

å¦‚æœä¸­å›½æ‘†è„±å¯¹å°æ¹¾åˆ¶é€ çš„ä¾èµ–é€Ÿåº¦æ˜æ˜¾å¿«äºç¾å›½ï¼Œè¿™å°†ä½¿ç¾å›½åœ¨å°æ¹¾å¯èƒ½å‡ºç°çš„å¹²æ‰°ï¼ˆæ— è®ºæ˜¯è‡ªç„¶ç¾å®³è¿˜æ˜¯äººä¸ºäº‹ä»¶ï¼‰é¢å‰ï¼Œå˜å¾—æ›´åŠ è„†å¼±ã€‚å¦‚æœå°æ¹¾çš„åˆ¶é€ å› ä»»ä½•åŸå› ä¸­æ–­ï¼Œè€Œä¸­å›½å…¬å¸æœ€ç»ˆåœ¨å…¨çƒåŠå¯¼ä½“åˆ¶é€ èƒ½åŠ›ä¸­å æ®å¾ˆå¤§ä¸€éƒ¨åˆ†ï¼Œé‚£ä¹Ÿå°†å¸®åŠ©ä¸­å›½è·å¾—å·¨å¤§çš„åœ°ç¼˜æ”¿æ²»å½±å“åŠ›ã€‚

å°½ç®¡å¶å°”ä¼šå‡ºç°ç´§å¼ å±€åŠ¿åŠ å‰§å’Œå¤§è§„æ¨¡å†›äº‹æ¼”ä¹ ï¼Œä½†è‡ª 20 ä¸–çºª 60 å¹´ä»£ä»¥æ¥ï¼Œå°æ¹¾å¤§ä½“ä¸Šä¸€ç›´ä¿æŒå’Œå¹³ã€‚è¿™ç§å’Œå¹³å¸®åŠ©å°æ¹¾äººæ°‘ç¹è£å‘å±•ï¼Œå¹¶ä½¿å¾— AIï¼ˆäººå·¥æ™ºèƒ½ï¼‰åœ¨å°ç§¯ç”µåˆ¶é€ çš„èŠ¯ç‰‡åŸºç¡€ä¸Šå–å¾—äº†å·¨å¤§è¿›æ­¥ã€‚æˆ‘å¸Œæœ›æˆ‘ä»¬èƒ½æ‰¾åˆ°ä¸€æ¡åœ¨æœªæ¥å‡ åå¹´ç»§ç»­ç»´æŒå’Œå¹³çš„é“è·¯ã€‚

ä½†å¸Œæœ›å¹¶éè®¡åˆ’ã€‚é™¤äº†åŠªåŠ›ç¡®ä¿å’Œå¹³ï¼Œæˆ‘ä»¬é¢å‰è¿˜æœ‰å®å®åœ¨åœ¨çš„å·¥ä½œè¦åšï¼Œå³å®ç°å¤šæ¥æºä¾›åº”ã€åœ¨æ›´å¤šå›½å®¶å»ºç«‹æ›´å¤šèŠ¯ç‰‡æ™¶åœ†å‚ï¼ˆfabï¼‰ï¼Œå¹¶å¢å¼ºåŠå¯¼ä½“ä¾›åº”é“¾çš„éŸ§æ€§ã€‚å¯¹ä»»ä½•å•ä¸€åˆ¶é€ å•†çš„ä¾èµ–ï¼Œä¸€æ—¦å‡ºç°æ„å¤–ï¼Œå°±ä¼šå¯¼è‡´çŸ­ç¼ºã€ä»·æ ¼é£™å‡å’Œåˆ›æ–°åœæ»ã€‚

[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/5bdEpQcaob]

### 112

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-09-30
é“¾æ¥: https://x.com/AndrewYNg/status/1973090336068215058
äº’åŠ¨: Likes: 3,698; Retweets: 588; Replies: 100; Quotes: 32; Views: 283,587; Bookmarks: 3,884; isReply: 0

Announcing a significant upgrade to Agentic Document Extraction! 

LandingAI's new DPT (Document Pre-trained Transformer) accurately extracts even from complex docs. For example, from large, complex tables, which is important for many finance and healthcare applications. And a new SDK makes using it require only 3 simple lines of code. Please see the video for technical details. I hope this unlocks a lot of value from the "dark data" currently stuck in PDF files, and that you'll build something cool with this!

éš†é‡å®£å¸ƒï¼šæ™ºèƒ½ä½“æ–‡æ¡£æå–ï¼ˆAgentic Document Extractionï¼‰åŠŸèƒ½è¿æ¥é‡å¤§å‡çº§ï¼

LandingAI å…¨æ–°çš„ DPTï¼ˆæ–‡æ¡£é¢„è®­ç»ƒ Transformerï¼‰æ¨¡å‹ï¼Œå³ä½¿é¢å¯¹å¤æ‚çš„æ–‡æ¡£ä¹Ÿèƒ½å®ç°ç²¾å‡†æå–ã€‚ä¾‹å¦‚ï¼Œå®ƒèƒ½é«˜æ•ˆå¤„ç†å¤§å‹ä¸”å¤æ‚çš„è¡¨æ ¼ï¼Œè¿™åœ¨é‡‘èå’ŒåŒ»ç–—ä¿å¥ç­‰å¤šä¸ªåº”ç”¨é¢†åŸŸè‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼Œå…¨æ–°çš„è½¯ä»¶å¼€å‘å·¥å…·åŒ…ï¼ˆSDKï¼‰è®©ç”¨æˆ·åªéœ€ä¸‰è¡Œç®€å•çš„ä»£ç å³å¯è½»æ¾ä¸Šæ‰‹ã€‚å¦‚éœ€äº†è§£æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·è§‚çœ‹ç›¸å…³è§†é¢‘ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ä¸€åˆ›æ–°èƒ½å¸®åŠ©å¤§å®¶ä»ç›®å‰ã€Œæ²‰ç¡ã€åœ¨ PDF æ–‡ä»¶ä¸­çš„ã€Œé»‘æš—æ•°æ®ã€(dark dataï¼‰ä¸­æŒ–æ˜å‡ºå·¨å¤§ä»·å€¼ï¼Œå¹¶æœŸå¾…æ‚¨èƒ½ç”¨å®ƒåˆ›é€ å‡ºä»¤äººæƒŠå¹çš„åº”ç”¨ï¼

### 113

ä½œè€…: @AndrewYNg
æ—¶é—´: 2025-10-07
é“¾æ¥: https://x.com/AndrewYNg/status/1975614372799283423
äº’åŠ¨: Likes: 6,399; Retweets: 1,053; Replies: 135; Quotes: 76; Views: 650,328; Bookmarks: 6,432; isReply: 0

Announcing my new course: Agentic AI!

Building AI agents is one of the most in-demand skills in the job market. This course, available now at https://t.co/zGHUh1loPO, teaches you how.

You'll learn to implement four key agentic design patterns:
- Reflection, in which an agent examines its own output and figures out how to improve it
- Tool use, in which an LLM-driven application decides which functions to call to carry out web search, access calendars, send email, write code, etc.
- Planning, where you'll use an LLM to decide how to break down a task into sub-tasks for execution, and
- Multi-agent collaboration, in which you build multiple specialized agents â€” much like how a company might hire multiple employees â€” to perform a complex task

You'll also learn to take a complex application and systematically decompose it into a sequence of tasks to implement using these design patterns.

But here's what I think is the most important part of this course: Having worked with many teams on AI agents, I've found that the single biggest predictor of whether someone executes well is their ability to drive a disciplined process for evals and error analysis. In this course, you'll learn how to do this, so you can efficiently home in on which components to improve in a complex agentic workflow. Instead of guessing what to work on, you'll let evals data guide you. This will put you significantly ahead of the game compared to the vast majority of teams building agents.

Together, we'll build a deep research agent that searches, synthesizes, and reports, using all of these agentic design patterns and best practices.

This self-paced course is taught in a vendor neutral way, using raw Python - without hiding details in a framework. You'll see how each step works, and learn the core concepts that you can then implement using any popular agentic AI framework, or using no framework. The only prerequisite is familiarity with Python, though knowing a bit about LLMs helps.

Come join me, and let's build some agentic AI systems!

Sign up to get started: https://t.co/FX35dloqw4

æˆ‘çš„æ–°è¯¾ç¨‹å‘å¸ƒå•¦ï¼šæ™ºèƒ½ä½“ AIï¼ˆAgentic AI)!

æ„å»º AI æ™ºèƒ½ä½“ï¼ˆAI agentsï¼‰æ˜¯å½“å‰å°±ä¸šå¸‚åœºéœ€æ±‚æœ€çƒ­é—¨çš„æŠ€èƒ½ä¹‹ä¸€ã€‚è¿™é—¨è¯¾ç¨‹ï¼Œç°å·²åœ¨ https://t.co/zGHUh1loPO ä¸Šçº¿ï¼Œå°†æ‰‹æŠŠæ‰‹æ•™ä½ å¦‚ä½•æŒæ¡è¿™é¡¹æŠ€èƒ½ã€‚

ä½ å°†å­¦ä¹ å®ç°å››ç§å…³é”®çš„æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼ï¼š
- åæ€ï¼ˆReflectionï¼‰ï¼Œæ™ºèƒ½ä½“é€šè¿‡å®¡è§†è‡ªå·±çš„è¾“å‡ºå¹¶æ‰¾å‡ºæ”¹è¿›æ–¹æ³•æ¥æå‡è¡¨ç°ã€‚
- å·¥å…·ä½¿ç”¨ï¼ˆTool useï¼‰ï¼Œä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„åº”ç”¨ç¨‹åºèƒ½å¤Ÿè‡ªä¸»å†³å®šè°ƒç”¨å“ªäº›å‡½æ•°ï¼Œä»¥æ‰§è¡Œç½‘é¡µæœç´¢ã€è®¿é—®æ—¥å†ã€å‘é€ç”µå­é‚®ä»¶ã€ç¼–å†™ä»£ç ç­‰ä»»åŠ¡ã€‚
- è§„åˆ’ï¼ˆPlanningï¼‰ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡ã€‚
- å¤šæ™ºèƒ½ä½“åä½œï¼ˆMulti-agent collaborationï¼‰ï¼Œä½ å°†æ„å»ºå¤šä¸ªä¸“ä¸šåŒ–çš„æ™ºèƒ½ä½“ â€” å°±åƒä¸€å®¶å…¬å¸ä¼šé›‡ä½£å¤šåå‘˜å·¥ä¸€æ · â€” å…±åŒå®Œæˆä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡ã€‚

ä½ è¿˜å°†å­¦ä¹ å¦‚ä½•ç³»ç»Ÿåœ°å°†ä¸€ä¸ªå¤æ‚çš„åº”ç”¨ç¨‹åºåˆ†è§£æˆä¸€ç³»åˆ—ä»»åŠ¡ï¼Œå¹¶ä½¿ç”¨è¿™äº›è®¾è®¡æ¨¡å¼è¿›è¡Œå®ç°ã€‚

ä½†æˆ‘è®¤ä¸ºæœ¬è¯¾ç¨‹æœ€æ ¸å¿ƒçš„éƒ¨åˆ†åœ¨äºï¼šåœ¨ä¸è®¸å¤šå›¢é˜Ÿåˆä½œå¼€å‘ AI æ™ºèƒ½ä½“ï¼ˆAI agentsï¼‰çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘å‘ç°ä¸€ä¸ªäººèƒ½å¦å‡ºè‰²å®Œæˆä»»åŠ¡ï¼Œæœ€å¤§çš„å†³å®šå› ç´ åœ¨äºä»–ä»¬èƒ½å¦æœ‰æ•ˆæ¨è¡Œä¸¥è°¨çš„è¯„ä¼°ï¼ˆevalsï¼‰å’Œé”™è¯¯åˆ†æï¼ˆerror analysisï¼‰æµç¨‹ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œä»è€Œé«˜æ•ˆåœ° pinpoint å¤æ‚æ™ºèƒ½ä½“å·¥ä½œæµä¸­éœ€è¦æ”¹è¿›çš„ç»„ä»¶ã€‚ä½ å°†ä¸å†å‡­ç©ºçŒœæµ‹ï¼Œè€Œæ˜¯è®©è¯„ä¼°ï¼ˆevalsï¼‰æ•°æ®æŒ‡å¼•ä½ æ”¹è¿›çš„æ–¹å‘ã€‚è¿™å°†ä½¿ä½ æ¯”ç»å¤§å¤šæ•°æ„å»ºæ™ºèƒ½ä½“çš„å›¢é˜Ÿé¥é¥é¢†å…ˆã€‚

æˆ‘ä»¬å°†ä¸€èµ·æ„å»ºä¸€ä¸ªæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ï¼Œå®ƒå°†è¿ç”¨æ‰€æœ‰è¿™äº›æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µï¼Œè¿›è¡Œä¿¡æ¯çš„æœç´¢ã€åˆæˆå’ŒæŠ¥å‘Šã€‚

è¿™é—¨è‡ªå®šè¿›åº¦è¯¾ç¨‹é‡‡ç”¨ä¾›åº”å•†ä¸­ç«‹çš„æ–¹å¼ï¼Œä½¿ç”¨çº¯ Python ä»£ç è¿›è¡Œæ•™å­¦ â€” ä¸ä¼šæŠŠç»†èŠ‚éšè—åœ¨æŸä¸ªæ¡†æ¶ä¹‹ä¸‹ã€‚ä½ å°†æ¸…æ¥šåœ°çœ‹åˆ°æ¯ä¸€æ­¥çš„å·¥ä½œåŸç†ï¼Œå¹¶å­¦ä¹ æ ¸å¿ƒæ¦‚å¿µï¼Œä¹‹åä½ å¯ä»¥ä½¿ç”¨ä»»ä½•æµè¡Œçš„æ™ºèƒ½ä½“ AI æ¡†æ¶ï¼Œæˆ–è€…ä¸ä½¿ç”¨ä»»ä½•æ¡†æ¶æ¥å®è·µè¿™äº›æ¦‚å¿µã€‚å”¯ä¸€çš„å…ˆå†³æ¡ä»¶æ˜¯ç†Ÿæ‚‰ Pythonï¼Œè™½ç„¶å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ‰ä¸€å®šçš„äº†è§£ä¼šæ›´æœ‰å¸®åŠ©ã€‚

å¿«æ¥åŠ å…¥æˆ‘ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ„å»ºå¼ºå¤§çš„æ™ºèƒ½ä½“ AI ç³»ç»Ÿå§ï¼

ç«‹å³æ³¨å†Œå¼€å§‹å­¦ä¹ ï¼šhttps://t.co/FX35dloqw4
