[
  {
    "id": "1872079319813816597",
    "url": "https://x.com/AndrewYNg/status/1872079319813816597",
    "text": "@levie Link to the study I refer to: https://t.co/xgct2iVwEo",
    "createdAt": "Thu Dec 26 00:37:46 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 19,
    "replyCount": 10,
    "likeCount": 150,
    "quoteCount": 1,
    "viewCount": 44986,
    "bookmarkCount": 42,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@levie è¿™æ˜¯æˆ‘æåˆ°çš„ç ”ç©¶é“¾æ¥ï¼šhttps://t.co/xgct2iVwEo"
  },
  {
    "id": "1872079097121431855",
    "url": "https://x.com/AndrewYNg/status/1872079097121431855",
    "text": "One of the best things the U.S. can do is make high-skill immigration easier. @levie is right. \n\nIt is awful that the wait time for a green card can be over a decade, and that after waiting years someone can still be forced to leave simply because they lost a job. Fixing this is both an economic and a moral issue. \n\nA rigorous economic analysis (by Pierre Azoulay and collaborators) shows that immigrants create more jobs than they take. So to create jobs for Americans, lets let more immigrants in!",
    "createdAt": "Thu Dec 26 00:36:52 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 376,
    "replyCount": 375,
    "likeCount": 3187,
    "quoteCount": 57,
    "viewCount": 368103,
    "bookmarkCount": 285,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "ç¾å›½å¯ä»¥é‡‡å–çš„æœ€ä½³ä¸¾æªä¹‹ä¸€ï¼Œå°±æ˜¯ç®€åŒ–é«˜æŠ€èƒ½ç§»æ°‘ï¼ˆhigh-skill immigrationï¼‰çš„ç”³è¯·æµç¨‹ã€‚@levie çš„è§‚ç‚¹æ˜¯æ­£ç¡®çš„ã€‚\n\nä»¤äººé—æ†¾çš„æ˜¯ï¼Œç»¿å¡ï¼ˆgreen cardï¼‰çš„ç­‰å¾…æ—¶é—´å¯èƒ½é•¿è¾¾åä½™å¹´ï¼Œè€Œä¸”å³ä½¿ç­‰å¾…å¤šå¹´åï¼Œç”³è¯·äººä¹Ÿå¯èƒ½ä»…ä»…å› ä¸ºå¤±å»å·¥ä½œå°±è¢«è¿«ç¦»å¼€ç¾å›½ã€‚è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ—¢æ˜¯ä¸€ä¸ªç»æµè®®é¢˜ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªé“å¾·è®®é¢˜ã€‚\n\nPierre Azoulay åŠå…¶åˆä½œè€…è¿›è¡Œçš„ä¸€é¡¹ä¸¥è°¨ç»æµåˆ†æï¼ˆrigorous economic analysisï¼‰è¡¨æ˜ï¼Œç§»æ°‘åˆ›é€ çš„å°±ä¸šæœºä¼šå¤šäºä»–ä»¬æ‰€å æ®çš„ã€‚å› æ­¤ï¼Œä¸ºäº†ç»™ç¾å›½æ°‘ä¼—åˆ›é€ æ›´å¤šå°±ä¸šæœºä¼šï¼Œæˆ‘ä»¬åº”è¯¥å…è®¸æ›´å¤šç§»æ°‘å…¥å¢ƒï¼"
  },
  {
    "id": "1870965047738220934",
    "url": "https://x.com/AndrewYNg/status/1870965047738220934",
    "text": "Sriram has been consistently thoughtful about AI policy, including specifically the importance of promoting open source. His working with @DavidSacks on AI will be good for innovation and good for the U.S. Thank you @sriramk for your service!",
    "createdAt": "Sun Dec 22 22:50:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 172,
    "replyCount": 76,
    "likeCount": 1743,
    "quoteCount": 12,
    "viewCount": 198579,
    "bookmarkCount": 82,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "Sriram ä¸€ç›´ä»¥æ¥éƒ½å¯¹ AI æ”¿ç­–æŒç»­å…³æ³¨å¹¶æ·±å…¥æ€è€ƒï¼Œå°¤å…¶é‡è§†æ¨åŠ¨å¼€æºçš„é‡è¦æ€§ã€‚ä»–ä¸ @DavidSacks åœ¨ AI é¢†åŸŸçš„åˆä½œï¼Œå°†å¯¹åˆ›æ–°å’Œç¾å›½çš„å‘å±•å¤§æœ‰è£¨ç›Šã€‚æ„Ÿè°¢ @sriramk æ‰€åšçš„è´¡çŒ®ï¼"
  },
  {
    "id": "1869783741566202074",
    "url": "https://x.com/AndrewYNg/status/1869783741566202074",
    "text": "Iâ€™m thrilled that former students and postdocs of mine won both of this yearâ€™s NeurIPS Test of Time Paper Awards. This award recognizes papers published 10 years ago that have significantly shaped the research field. The recipients included Ian Goodfellow (who, as an undergraduate, built my first GPU server for deep learning in his dorm room) and his collaborators for their work on generative adversarial networks, and my former postdoc Ilya Sutskever and PhD student Quoc Le (with Oriol Vinyals) for their work on sequence-to-sequence learning. Congratulations to all these winners!\n\nBy nature, I tend to focus on the future rather than the past. Steve Jobs famously declined to build a corporate museum, instead donating Apple's archives to Stanford University, because he wanted to keep the company forward-looking. Jeff Bezos encourages teams to approach every day as if it were â€œDay 1,â€ a mindset that emphasizes staying in the early, innovative stage of a company or industry. These philosophies resonate with me.\n\nBut taking a brief look at the past can help us reflect on lessons for the future. One takeaway from looking at what worked 10 to 15 years ago is that many of the teams I led bet heavily on scaling to drive AI progress â€” a bet that laid a foundation to build larger and larger AI systems. At the time, the idea of scaling up neural networks was controversial, and I was on the fringe. I recall distinctly that, around  2008, Yoshua Bengio advised me not to bet on scaling and to focus on inventing algorithms instead!\n\nA lesson I carry from that time is to not worry about what others think, but follow your convictions, especially if you have data to support your beliefs. Small-scale experiments performed by my Stanford group convinced me that scaling up neural networks would drive significant progress, and thatâ€™s why I was willing to ignore the skeptics. The diagram below, generated by Adam Coates and Honglak Lee, is the one that most firmed up my beliefs at that time. It shows that, for a range of models, the larger we scaled them, the better they perform. I remember presenting it at CIFAR 2010, and if I had to pick a single reason why I pushed through to start Google Brain and set as the teamâ€™s #1 goal to scale up deep learning algorithms, it is this diagram!\n\nI also remember presenting at NeurIPS in 2008 our work on using GPUs to scale up training neural networks. (By the way, one measure of success in academia is when your work becomes sufficiently widely accepted that no one cites it anymore. Iâ€™m quite pleased the idea that GPUs should be used for AI â€” which was controversial back then â€” is now such a widely accepted â€œfactâ€ that no one bothers to cite early papers that pushed for it.ğŸ˜ƒ)\n\nWhen I started Google Brain, the thesis was simple: I wanted to use the companyâ€™s  huge computing capability to scale up deep learning. Shortly afterward, I built Stanfordâ€™s first supercomputer for deep learning using GPUs, since I could move faster at Stanford than within a large company. A few years later, my team at Baidu showed that as you scale up a model, its performance improves linearly on a log-log scale, which was a precursor to OpenAIâ€™s scaling laws.\n\nAs I look to the future, Iâ€™m sure there are ideas that many people are skeptical about today, but will prove to be accurate. Scaling up AI models turned out to be useful for many teams, and it continues to be exciting, but now Iâ€™m even more excited by upcoming ideas that will prove to be even more valuable in the future.\n\nThis past year, I spent a lot of time encouraging teams to build applications with agentic AI and worked to share best practices. I have a few hypotheses for additional technologies that will be important next year. I plan to spend the winter holiday playing with a few of them, and I will have more to share next year. But if you have an idea that you have conviction on, so long as you can do so responsibly, I encourage you to pursue it!\n\n[Original text (with links): https://t.co/Km7ENTODId]",
    "createdAt": "Thu Dec 19 16:35:57 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 97,
    "replyCount": 47,
    "likeCount": 693,
    "quoteCount": 5,
    "viewCount": 58428,
    "bookmarkCount": 126,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘éå¸¸é«˜å…´åœ°å®£å¸ƒï¼Œæˆ‘çš„å‰å­¦ç”Ÿå’Œåšå£«åä»¬è£è·äº†ä»Šå¹´ NeurIPS ï¼ˆç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¤§ä¼šï¼‰â€œåå¹´å½±å“åŠ›è®ºæ–‡å¥–â€ çš„ä¸¤é¡¹å¤§å¥–ï¼è¿™ä¸ªå¥–é¡¹æ—¨åœ¨è¡¨å½°é‚£äº›åœ¨åå¹´å‰å‘è¡¨ã€å¹¶å¯¹ç ”ç©¶é¢†åŸŸäº§ç”Ÿäº†æ·±è¿œå½±å“çš„è®ºæ–‡ã€‚è·å¥–è€…åŒ…æ‹¬ Ian Goodfellow ï¼ˆå½“å¹´ä»–è¿˜æ˜¯æœ¬ç§‘ç”Ÿæ—¶ï¼Œå°±æ›¾åœ¨å®¿èˆé‡Œä¸ºæˆ‘æ­å»ºäº†ç¬¬ä¸€ä¸ªç”¨äºæ·±åº¦å­¦ä¹ çš„ GPU æœåŠ¡å™¨ï¼‰å’Œä»–çš„åˆä½œè€…ï¼Œä»–ä»¬å‡­å€Ÿåœ¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (Generative Adversarial Networks) æ–¹é¢çš„å·¥ä½œè·æ­¤æ®Šè£ï¼›ä»¥åŠæˆ‘çš„å‰åšå£«å Ilya Sutskever å’Œåšå£«ç”Ÿ Quoc Le ï¼ˆä¸ Oriol Vinyals åˆä½œï¼‰ï¼Œä»–ä»¬åˆ™å› åœ¨åºåˆ—åˆ°åºåˆ—å­¦ä¹  (Sequence-to-Sequence Learning) æ–¹é¢çš„è´¡çŒ®è€Œè·å¥–ã€‚è¡·å¿ƒç¥è´ºæ‰€æœ‰è¿™äº›è·å¥–è€…ï¼\n\næˆ‘è¿™ä¸ªäººå¤©ç”Ÿå°±æ›´å–œæ¬¢ç€çœ¼æœªæ¥ï¼Œè€Œä¸æ˜¯æ²‰æ¹è¿‡å»ã€‚Steve Jobs æ›¾æœ‰ä¸ªè‘—åçš„ä¸¾åŠ¨ï¼Œä»–æ‹’ç»å»ºé€  Apple çš„ä¼ä¸šåšç‰©é¦†ï¼Œè€Œæ˜¯å°†å…¬å¸çš„æ¡£æ¡ˆæèµ ç»™ Stanford Universityï¼Œå› ä¸ºä»–å¸Œæœ›å…¬å¸å§‹ç»ˆä¿æŒå‰ç»æ€§ã€‚Jeff Bezos ä¹Ÿé¼“åŠ±å›¢é˜Ÿå°†æ¯ä¸€å¤©éƒ½å½“ä½œâ€œç¬¬ä¸€å¤©â€æ¥å¯¹å¾…ï¼Œè¿™ç§å¿ƒæ€å¼ºè°ƒå…¬å¸æˆ–è¡Œä¸šè¦æ°¸è¿œä¿æŒåœ¨æ—©æœŸåˆ›æ–°é˜¶æ®µã€‚è¿™äº›ç†å¿µéƒ½æ·±æ·±è§¦åŠ¨äº†æˆ‘ã€‚\n\nä¸è¿‡ï¼Œå¶å°”å›é¡¾ä¸€ä¸‹è¿‡å»ï¼Œä¹Ÿèƒ½å¸®åŠ©æˆ‘ä»¬æ±²å–ç»éªŒæ•™è®­ï¼Œä¸ºæœªæ¥æŒ‡æ˜æ–¹å‘ã€‚å›é¡¾è¿‡å» 10 åˆ° 15 å¹´çš„æˆåŠŸç»éªŒï¼Œæˆ‘å¾—åˆ°äº†ä¸€ä¸ªé‡è¦çš„å¯ç¤ºï¼šæˆ‘é¢†å¯¼è¿‡çš„è®¸å¤šå›¢é˜Ÿéƒ½åšå®šåœ°æŠ¼æ³¨äºé€šè¿‡â€œè§„æ¨¡åŒ–â€ (scaling) æ¥æ¨åŠ¨ AI å‘å±•â€”â€”è¿™ä¸€ç­–ç•¥ä¸ºæ„å»ºè¶Šæ¥è¶Šåºå¤§çš„ AI ç³»ç»Ÿå¥ å®šäº†åšå®åŸºç¡€ã€‚è¦çŸ¥é“ï¼Œåœ¨å½“æ—¶ï¼Œæ‰©å¤§ç¥ç»ç½‘ç»œè§„æ¨¡çš„æƒ³æ³•è¿˜å¤‡å—äº‰è®®ï¼Œæˆ‘ç®—æ˜¯â€œå¦ç±»â€ã€‚æˆ‘æ¸…æ¥šåœ°è®°å¾—ï¼Œå¤§çº¦åœ¨ 2008 å¹´ï¼ŒYoshua Bengio æ›¾å»ºè®®æˆ‘ä¸è¦ä¸“æ³¨äºè§„æ¨¡åŒ–ï¼Œè€Œåº”è¯¥æŠŠç²¾åŠ›æ”¾åœ¨å‘æ˜æ–°ç®—æ³•ä¸Šï¼\n\nä»é‚£æ—¶èµ·ï¼Œæˆ‘å­¦åˆ°çš„ä¸€ä¸ªå®è´µç»éªŒå°±æ˜¯ï¼šä¸è¦è¿‡åˆ†åœ¨æ„åˆ«äººçš„çœ‹æ³•ï¼Œè¦å‹‡äºè¿½éšè‡ªå·±çš„ä¿¡å¿µï¼Œå°¤å…¶æ˜¯åœ¨ä½ æœ‰æ•°æ®æ”¯æŒä½ çš„è§‚ç‚¹æ—¶ã€‚æˆ‘çš„ Stanford å›¢é˜Ÿé€šè¿‡å°è§„æ¨¡å®éªŒè®©æˆ‘åšä¿¡ï¼Œæ‰©å¤§ç¥ç»ç½‘ç»œçš„è§„æ¨¡èƒ½å¸¦æ¥å·¨å¤§çš„è¿›æ­¥ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘æ„¿æ„ä¸ç†ä¼šé‚£äº›æ€€ç–‘è€…çš„åŸå› ã€‚ä¸‹é¢è¿™å¼ ç”± Adam Coates å’Œ Honglak Lee ç»˜åˆ¶çš„å›¾è¡¨ï¼Œæ­£æ˜¯å½“æ—¶æœ€åšå®šæˆ‘ä¿¡å¿µçš„å…³é”®ã€‚å®ƒæ¸…æ¥šåœ°å±•ç¤ºäº†ï¼Œå¯¹äºä¸€ç³»åˆ—æ¨¡å‹è€Œè¨€ï¼Œæˆ‘ä»¬å°†å…¶è§„æ¨¡æ‰©å¤§å¾—è¶Šå¤šï¼Œå®ƒä»¬çš„æ€§èƒ½å°±è¶Šå¥½ã€‚æˆ‘è®°å¾—åœ¨ CIFAR 2010 å¤§ä¼šä¸Šå±•ç¤ºè¿‡å®ƒï¼Œå¦‚æœéè¦æˆ‘è¯´ä¸€ä¸ªç†ç”±ï¼Œä¸ºä»€ä¹ˆæˆ‘ä¼šå…¨åŠ›ä»¥èµ´åœ°åˆ›åŠ Google Brainï¼Œå¹¶å°†æ‰©å¤§æ·±åº¦å­¦ä¹ ç®—æ³•è§„æ¨¡å®šä¸ºå›¢é˜Ÿçš„é¦–è¦ç›®æ ‡ï¼Œé‚£ä¸€å®šå°±æ˜¯è¿™å¼ å›¾è¡¨äº†ï¼\n\næˆ‘è¿˜è®°å¾—åœ¨ 2008 å¹´çš„ NeurIPS å¤§ä¼šä¸Šï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨ GPU æ¥åŠ é€Ÿç¥ç»ç½‘ç»œçš„è®­ç»ƒã€‚(é¡ºä¾¿æä¸€å¥ï¼Œåœ¨å­¦æœ¯ç•Œï¼Œè¡¡é‡ä¸€é¡¹å·¥ä½œæ˜¯å¦è¶³å¤ŸæˆåŠŸçš„ä¸€ä¸ªæ ‡å‡†å°±æ˜¯ï¼Œå½“å®ƒè¢«å¹¿æ³›æ¥å—åˆ°äººä»¬ä¸å†éœ€è¦å¼•ç”¨å®ƒæ—¶ã€‚æˆ‘éå¸¸æ¬£æ…°ï¼Œå½“å¹´é¢‡å…·äº‰è®®çš„â€œGPU åº”è¯¥ç”¨äº AIâ€è¿™ä¸ªæƒ³æ³•ï¼Œç°åœ¨å·²ç»æˆä¸ºä¸€ä¸ªå¦‚æ­¤å¹¿ä¸ºäººçŸ¥çš„â€œäº‹å®â€ï¼Œä»¥è‡³äºå†ä¹Ÿæ²¡æœ‰äººç‰¹æ„å»å¼•ç”¨é‚£äº›æ—©æœŸæ¨åŠ¨è¿™ä¸€æ¦‚å¿µçš„è®ºæ–‡äº†ã€‚ğŸ˜ƒ)\n\nå½“æˆ‘åˆ›åŠ Google Brain æ—¶ï¼Œå…¶æ ¸å¿ƒç†å¿µéå¸¸ç®€å•ï¼šæˆ‘å¸Œæœ›åˆ©ç”¨ Google åºå¤§çš„è®¡ç®—èƒ½åŠ›æ¥æ¨åŠ¨æ·±åº¦å­¦ä¹ çš„è§„æ¨¡åŒ–å‘å±•ã€‚æ­¤åä¸ä¹…ï¼Œæˆ‘ä¾¿åœ¨ Stanford ä½¿ç”¨ GPU æ­å»ºäº†è¯¥æ ¡ç¬¬ä¸€ä¸ªç”¨äºæ·±åº¦å­¦ä¹ çš„è¶…çº§è®¡ç®—æœºï¼Œå› ä¸ºåœ¨ Stanfordï¼Œæˆ‘èƒ½æ¯”åœ¨å¤§å…¬å¸å†…éƒ¨æ›´å¿«é€Ÿã€æ›´çµæ´»åœ°æ¨è¿›é¡¹ç›®ã€‚å‡ å¹´åï¼Œæˆ‘åœ¨ Baidu çš„å›¢é˜Ÿå‘ç°äº†ä¸€ä¸ªè§„å¾‹ï¼šæ¨¡å‹çš„æ€§èƒ½ä¼šéšç€è§„æ¨¡çš„æ‰©å¤§ï¼Œåœ¨å¯¹æ•°-å¯¹æ•° (log-log) åæ ‡ç³»ä¸­å‘ˆç°çº¿æ€§æå‡ã€‚è¿™æ­£æ˜¯ OpenAI åæ¥æå‡ºçš„â€œè§„æ¨¡åŒ–å®šå¾‹â€ (scaling laws) çš„å‰èº«ã€‚\n\nå±•æœ›æœªæ¥ï¼Œæˆ‘ç¡®ä¿¡æœ‰è®¸å¤šç°åœ¨çœ‹æ¥å¤‡å—è´¨ç–‘çš„æƒ³æ³•ï¼Œæœ€ç»ˆéƒ½å°†è¢«è¯æ˜æ˜¯æ­£ç¡®çš„ã€‚æ‰©å¤§ AI æ¨¡å‹è§„æ¨¡çš„ç­–ç•¥å¯¹è®¸å¤šå›¢é˜Ÿæ¥è¯´éƒ½éå¸¸æœ‰æ•ˆï¼Œå¹¶ä¸”ä¾ç„¶ä»¤äººå…´å¥‹ã€‚ä½†ç°åœ¨ï¼Œæˆ‘å¯¹äºé‚£äº›å³å°†å‡ºç°ã€å¹¶åœ¨æœªæ¥èƒ½å¸¦æ¥æ›´å¤§ä»·å€¼çš„æ–°æƒ³æ³•æ„Ÿåˆ°æ›´åŠ æ¿€åŠ¨ã€‚\n\nè¿‡å»ä¸€å¹´é‡Œï¼Œæˆ‘æŠ•å…¥äº†å¤§é‡æ—¶é—´ï¼Œé¼“åŠ±å›¢é˜Ÿå¼€å‘åŸºäº AI æ™ºèƒ½ä½“ (AI Agent) çš„åº”ç”¨ç¨‹åºï¼Œå¹¶åŠªåŠ›åˆ†äº«æœ€ä½³å®è·µã€‚å¯¹äºæ˜å¹´å“ªäº›æŠ€æœ¯ä¼šå˜å¾—é‡è¦ï¼Œæˆ‘æœ‰ä¸€äº›æ–°çš„å‡è®¾ã€‚æˆ‘è®¡åˆ’åœ¨å¯’å‡æœŸé—´æ¢ç´¢å…¶ä¸­ä¸€äº›ï¼Œæ˜å¹´å°†ä¼šæœ‰æ›´å¤šå†…å®¹ä¸å¤§å®¶åˆ†äº«ã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ è‡ªå·±ä¹Ÿæœ‰ä¸€ä¸ªåšä¿¡ä¸ç–‘çš„æƒ³æ³•ï¼Œåªè¦ä½ èƒ½ä»¥è´Ÿè´£ä»»çš„æ–¹å¼å»å®è·µï¼Œæˆ‘é¼“åŠ±ä½ å¤§èƒ†è¿½æ±‚å®ƒï¼\n\n[åŸæ–‡ (å¸¦é“¾æ¥): https://t.co/Km7ENTODId]"
  },
  {
    "id": "1869421643925422166",
    "url": "https://x.com/AndrewYNg/status/1869421643925422166",
    "text": "OpenAI just announced API access to o1 (advanced reasoning model) yesterday. I'm delighted to announce today a new short course, Reasoning with o1, built with @OpenAI, and taught by @colintjarvis, Head of AI Solutions at OpenAI, to show you how to use this effectively!\n\nUnlike previous language models which generate output directly, o1 â€œthinks before it responds,â€ and generates many reasoning tokens before returning a more thoughtful and accurate response. It is great at complex reasoning -- including planning for agentic workflows, coding, and domain-specific reasoning in STEM fields like law. But how you should use it is quite different from other LLMs. \n\nI think o1 will be a game changer for many AI applications; and in this course, you'll learn how to use it effectively. \n\nIn detail, youâ€™ll:\n- Learn to recognize what tasks o1 is suited for, and when to use a smaller model, or combine o1 with a smaller model\n- Understand the new principles of prompting reasoning models: Be simple and direct; no explicit chain-of-thought required; use structure; show rather than tell\n- Implement multi-step orchestration in which o1 plans, and hands tasks over to gpt-4o-mini to execute specific steps; this illustrates a design pattern to optimize intelligence (accuracy) and cost\n- Use o1 for a coding task to build a new application, edit existing code, and test performance by running a coding competition between o1-mini and GPT 4o\n- Use o1 for image understanding and learn how it performs better with a \"hierarchy of reasoning,\" in which it incurs the latency and cost upfront, preprocessing the image and indexing it with rich details so it can be used for Q&A later\n- Learn a technique called meta-prompting, in which you use o1 to improve your prompts. Using a customer support evaluation set, you'll iteratively use o1 to modify a prompt to improve performance\n\nYou'll also learn about how OpenAI used reinforcement learning to produce a model that uses \"test-time compute\" to improve performance.\n\nI think you'll find this course enjoyable and valuable. \n\nPlease sign up for it here: https://t.co/0XIGzinyrx",
    "createdAt": "Wed Dec 18 16:37:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 426,
    "replyCount": 84,
    "likeCount": 2747,
    "quoteCount": 47,
    "viewCount": 355748,
    "bookmarkCount": 2424,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "OpenAI æ˜¨å¤©åˆšåˆšå®£å¸ƒå¼€æ”¾ o1 (é«˜çº§æ¨ç†æ¨¡å‹) çš„ API è®¿é—®æƒé™ã€‚ä»Šå¤©ï¼Œæˆ‘å¾ˆé«˜å…´èƒ½å‘å¤§å®¶å®£å¸ƒä¸€é—¨å…¨æ–°çš„çŸ­æœŸè¯¾ç¨‹â€”â€”ã€Šä¸ o1 è¿›è¡Œæ¨ç†ã€‹ (Reasoning with o1) ã€‚è¿™é—¨è¯¾ç¨‹æ˜¯ä¸ OpenAI åˆä½œå¼€å‘ï¼Œç”± OpenAI çš„ AI è§£å†³æ–¹æ¡ˆä¸»ç®¡ @colintjarvis äº²è‡ªæˆè¯¾ï¼Œæ—¨åœ¨å‘å¤§å®¶å±•ç¤ºå¦‚ä½•é«˜æ•ˆåœ°ä½¿ç”¨ o1ï¼\n\nä¸ä»¥å¾€ç›´æ¥ç”Ÿæˆè¾“å‡ºçš„è¯­è¨€æ¨¡å‹ä¸åŒï¼Œo1 èƒ½å¤Ÿâ€œå…ˆæ€è€ƒåå›åº”â€ã€‚å®ƒä¼šå…ˆç”Ÿæˆå¤§é‡çš„æ¨ç† Token (reasoning token)ï¼Œä»è€Œè¿”å›æ›´å‘¨åˆ°ã€æ›´å‡†ç¡®çš„å›å¤ã€‚o1 å°¤å…¶æ“…é•¿å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡â€”â€”åŒ…æ‹¬ä¸º AI æ™ºèƒ½ä½“ (AI Agent) å·¥ä½œæµåˆ¶å®šè®¡åˆ’ã€ç¼–å†™ä»£ç ï¼Œä»¥åŠåœ¨æ³•å¾‹ç­‰ STEM é¢†åŸŸè¿›è¡Œä¸“ä¸šæ¨ç†ã€‚ä½†å®ƒçš„ä½¿ç”¨æ–¹å¼ä¸å…¶ä»–å¤§è¯­è¨€æ¨¡å‹ (LLM) æˆªç„¶ä¸åŒã€‚\n\næˆ‘è®¤ä¸º o1 å°†ä¼šæ˜¯è®¸å¤š AI åº”ç”¨çš„é¢ è¦†æ€§æŠ€æœ¯ (game changer)ï¼›è€Œåœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨å®ƒã€‚\n\nå…·ä½“æ¥è¯´ï¼Œä½ å°†å­¦ä¹ ï¼š\n- è¯†åˆ«å“ªäº›ä»»åŠ¡é€‚åˆ o1ï¼Œä»¥åŠä½•æ—¶åº”è¯¥ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼Œæˆ–å°† o1 ä¸è¾ƒå°çš„æ¨¡å‹ç»“åˆä½¿ç”¨ã€‚\n- ç†è§£æç¤ºæ¨ç†æ¨¡å‹çš„æ–°åŸåˆ™ï¼šä¿æŒç®€æ´ç›´ç™½ï¼›ä¸éœ€è¦æ˜ç¡®çš„æ€ç»´é“¾ (chain-of-thought)ï¼›å–„ç”¨ç»“æ„ï¼›é€šè¿‡å±•ç¤ºè€Œéè®²è¿°æ¥å¼•å¯¼ã€‚\n- å®ç°å¤šæ­¥éª¤ç¼–æ’ï¼šo1 è´Ÿè´£è§„åˆ’ï¼Œå¹¶å°†å…·ä½“ä»»åŠ¡äº¤ç»™ gpt-4o-mini æ¥æ‰§è¡Œã€‚è¿™å±•ç¤ºäº†ä¸€ç§ä¼˜åŒ–æ™ºèƒ½ï¼ˆå‡†ç¡®æ€§ï¼‰å’Œæˆæœ¬çš„è®¾è®¡æ¨¡å¼ã€‚\n- åˆ©ç”¨ o1 å®Œæˆç¼–ç ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ„å»ºæ–°åº”ç”¨ã€ç¼–è¾‘ç°æœ‰ä»£ç ï¼Œå¹¶é€šè¿‡ o1-mini å’Œ GPT 4o ä¹‹é—´çš„ç¼–ç ç«èµ›æ¥æµ‹è¯•æ€§èƒ½ã€‚\n- åˆ©ç”¨ o1 è¿›è¡Œå›¾åƒç†è§£ï¼Œå¹¶å­¦ä¹ å®ƒå¦‚ä½•é€šè¿‡â€œæ¨ç†å±‚æ¬¡ç»“æ„â€ (hierarchy of reasoning) è·å¾—æ›´å¥½çš„è¡¨ç°ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œo1 ä¼šé¢„å…ˆæ‰¿æ‹…å»¶è¿Ÿå’Œæˆæœ¬ï¼Œå¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†å¹¶ç”¨ä¸°å¯Œçš„ç»†èŠ‚è¿›è¡Œç´¢å¼•ï¼Œä»¥ä¾¿åç»­è¿›è¡Œé—®ç­”ã€‚\n- å­¦ä¹ ä¸€ç§åä¸ºå…ƒæç¤º (meta-prompting) çš„æŠ€æœ¯ï¼Œå³åˆ©ç”¨ o1 æ¥æ”¹è¿›ä½ çš„æç¤ºè¯ã€‚é€šè¿‡ä¸€ä¸ªå®¢æˆ·æ”¯æŒè¯„ä¼°æ•°æ®é›†ï¼Œä½ å°†è¿­ä»£åœ°ä½¿ç”¨ o1 ä¿®æ”¹æç¤ºè¯ï¼Œä»¥æé«˜æ€§èƒ½ã€‚\n\nä½ è¿˜å°†äº†è§£åˆ° OpenAI å¦‚ä½•è¿ç”¨å¼ºåŒ–å­¦ä¹  (reinforcement learning) æ¥å¼€å‘ä¸€ä¸ªåˆ©ç”¨â€œæµ‹è¯•æ—¶è®¡ç®—â€ (test-time compute) æ¥æé«˜æ€§èƒ½çš„æ¨¡å‹ã€‚\n\næˆ‘ç›¸ä¿¡ä½ ä¼šå‘ç°è¿™é—¨è¯¾ç¨‹æ—¢æœ‰è¶£åˆæœ‰ä»·å€¼ã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æŠ¥åï¼šhttps://t.co/0XIGzinyrx"
  },
  {
    "id": "1867269937397670082",
    "url": "https://x.com/AndrewYNg/status/1867269937397670082",
    "text": "AI Product Management\n\nAI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications. This is making it possible to build new kinds of things, which in turn is driving shifts in best practices in product management â€” the discipline of defining what to build to serve users â€” because what is possible to build has shifted. In this post, Iâ€™ll share some best practices I have noticed.\n\nUse concrete examples to specify AI products. Starting with a concrete idea helps teams gain speed. If a product manager (PM) proposes to build â€œa chatbot to answer banking inquiries that relate to user accounts,â€ this is a vague specification that leaves much to the imagination. For instance, should the chatbot answer questions only about account balances or also about interest rates, processes for initiating a wire transfer, and so on? But if the PM writes out a number (say, between 10 and 50) of concrete examples of conversations theyâ€™d like a chatbot to execute, the scope of their proposal becomes much clearer. Just as a machine learning algorithm needs training examples to learn from, an AI product development team needs concrete examples of what we want an AI system to do. In other words, the data is your PRD (product requirements document)!\n\nIn a similar vein, if someone requests â€œa vision system to detect pedestrians outside our store,â€ itâ€™s hard for a developer to understand the boundary conditions. Is the system expected to work at night? What is the range of permissible camera angles? Is it expected to detect pedestrians who appear in the image even though theyâ€™re 100m away? But if the PM collects a handful of pictures and annotates them with the desired output, the meaning of â€œdetect pedestriansâ€ becomes concrete. An engineer can assess if the specification is technically feasible and if so, build toward it. Initially, the data might be obtained via a one-off, scrappy process, such as the PM walking around taking pictures and annotating them. Eventually, the data mix will shift to real-word data collected by a system running in production.\n\nUsing examples (such as inputs and desired outputs) to specify a product has been helpful for many years, but the explosion of possible AI applications is creating a need for more product managers to learn this practice.\n\nAssess technical feasibility of LLM-based applications by prompting. When a PM scopes out a potential AI application, whether the application can actually be built â€” that is, its technical feasibility â€” is a key criterion in deciding what to do next. For many ideas for LLM-based applications, itâ€™s increasingly possible for a PM, who might not be a software engineer, to try prompting â€” or write just small amounts of code â€” to get an initial sense of feasibility.\n\nFor example, a PM may envision a new internal tool for routing emails from customers to the right department (such as customer service, sales, etc.). They can prompt an LLM to see if they can get it to select the right department based on an input email, and see if they can achieve high accuracy. If so, this gives engineering a great starting point from which to implement the tool. If not, the PM can falsify the idea themselves and perhaps improve the product idea much faster than if they had to rely on an engineer to build a prototype.\n\nOften, testing feasibility requires a little more than prompting. For example, perhaps the LLM-based email system needs basic RAG capability to help it make decisions. Fortunately, the barrier to writing small amounts of code is now quite low, since AI can help by acting as a coding companion, as I describe in the course, â€œAI Python for Beginners.â€ This means that PMs can do much more technical feasibility testing, at least at a basic level, than was possible before.\n\nPrototype and test even without engineers. User feedback to initial prototypes is also instrumental to shaping products. Fortunately, barriers to building prototypes rapidly are falling, and PMs themselves can move basic prototypes forward without needing professional software developers.\n\nIn addition to using LLMs to help write code for prototyping, tools like Replit, Vercelâ€™s V0, Bolt, and Anthropicâ€™s Artifacts (Iâ€™m a fan of all of these!) are making it easier for people without a coding background to build and experiment with simple prototypes. These tools are increasingly accessible to non-technical users, though I find that those who understand basic coding are able to use them much more effectively, so itâ€™s still important to learn basic coding. (Interestingly, highly technical, experienced developers use them too!) Many members of my teams routinely use such tools to prototype, get user feedback, and iterate quickly.\n\nAI is enabling a lot of new applications to be built, creating massive growth in demand for AI product managers who know how to scope out and help drive progress in building these products. AI product management existed before the rise of generative AI, but the increasing ease of building applications is creating greater demand for AI applications, and thus a lot of PMs are learning AI and these emerging best practices for building AI products. I find this discipline fascinating, and will keep on sharing best practices as they grow and evolve.\n\n[Original text: https://t.co/ohLyrpU4SJ ]",
    "createdAt": "Thu Dec 12 18:06:59 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 330,
    "replyCount": 86,
    "likeCount": 1712,
    "quoteCount": 42,
    "viewCount": 257355,
    "bookmarkCount": 1777,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "AI äº§å“ç®¡ç†\n\nAI äº§å“ç®¡ç†æ­£åœ¨é£é€Ÿå‘å±•ã€‚éšç€ç”Ÿæˆå¼ AI (Generative AI) å’ŒåŸºäº AI çš„å¼€å‘è€…å·¥å…·çš„å…´èµ·ï¼Œæ„å»º AI åº”ç”¨ç¨‹åºçš„æœºä¼šä¹Ÿéšä¹‹å¤§é‡æ¶Œç°ã€‚è¿™ä¸ä»…å‚¬ç”Ÿäº†å„ç§æ–°å‹åº”ç”¨ï¼Œä¹Ÿæ¨åŠ¨äº†äº§å“ç®¡ç†é¢†åŸŸâ€”â€”å³å®šä¹‰åº”å¼€å‘ä½•ç§äº§å“ä»¥æ»¡è¶³ç”¨æˆ·éœ€æ±‚çš„å­¦ç§‘â€”â€”çš„æœ€ä½³å®è·µå‘ç”Ÿè½¬å˜ï¼Œå› ä¸ºæŠ€æœ¯è¾¹ç•Œå’Œå¯æ„å»ºæ€§éƒ½å·²ä»Šéæ˜”æ¯”ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†åˆ†äº«æˆ‘è§‚å¯Ÿåˆ°çš„ä¸€äº›æœ€ä½³å®è·µã€‚\n\nç”¨å…·ä½“ç¤ºä¾‹æ¥å®šä¹‰ AI äº§å“ã€‚ä»ä¸€ä¸ªå…·ä½“çš„æƒ³æ³•å…¥æ‰‹ï¼Œæœ‰åŠ©äºå›¢é˜Ÿå¿«é€Ÿå¯åŠ¨é¡¹ç›®ã€‚å¦‚æœäº§å“ç»ç† (PM) æè®®æ„å»ºä¸€ä¸ªâ€œç”¨äºå›ç­”ä¸ç”¨æˆ·è´¦æˆ·ç›¸å…³çš„é“¶è¡ŒæŸ¥è¯¢çš„èŠå¤©æœºå™¨äººâ€ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªè¿‡äºæ¨¡ç³Šçš„æè¿°ï¼Œç•™ä¸‹äº†å¤ªå¤šçš„æƒ³è±¡ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ªèŠå¤©æœºå™¨äººæ˜¯åªå›ç­”å…³äºè´¦æˆ·ä½™é¢çš„é—®é¢˜ï¼Œè¿˜æ˜¯ä¹ŸåŒ…æ‹¬åˆ©ç‡ã€ç”µæ±‡æµç¨‹ç­‰æ–¹é¢çš„æŸ¥è¯¢ï¼Ÿä½†å¦‚æœ PM èƒ½æä¾›è®¸å¤šï¼ˆæ¯”å¦‚ 10 åˆ° 50 ä¸ªï¼‰å…·ä½“çš„å¯¹è¯ç¤ºä¾‹ï¼Œæ¥å±•ç¤ºä»–ä»¬å¸Œæœ›èŠå¤©æœºå™¨äººå¦‚ä½•æ‰§è¡Œä»»åŠ¡ï¼Œé‚£ä¹ˆè¿™é¡¹ææ¡ˆçš„èŒƒå›´å°±ä¼šæ¸…æ™°å¾—å¤šã€‚æ­£å¦‚æœºå™¨å­¦ä¹ ç®—æ³•éœ€è¦è®­ç»ƒç¤ºä¾‹æ¥å­¦ä¹ ä¸€æ ·ï¼ŒAI äº§å“å¼€å‘å›¢é˜Ÿä¹Ÿéœ€è¦å…·ä½“çš„ç¤ºä¾‹æ¥æ˜ç¡®æˆ‘ä»¬å¸Œæœ› AI ç³»ç»Ÿåšä»€ä¹ˆã€‚æ¢å¥è¯è¯´ï¼Œæ•°æ®å°±æ˜¯ä½ çš„äº§å“éœ€æ±‚æ–‡æ¡£ (PRD)ï¼\n\nåŒç†ï¼Œå¦‚æœæœ‰äººè¦æ±‚â€œä¸€ä¸ªç”¨äºæ£€æµ‹æˆ‘ä»¬å•†åº—å¤–è¡Œäººçš„è§†è§‰ç³»ç»Ÿâ€ï¼Œå¼€å‘è€…å¾ˆéš¾ç†è§£å…¶å…·ä½“çš„é€‚ç”¨èŒƒå›´ã€‚è¯¥ç³»ç»Ÿæ˜¯å¦éœ€è¦åœ¨å¤œé—´å·¥ä½œï¼Ÿå…è®¸çš„æ‘„åƒæœºè§’åº¦èŒƒå›´æ˜¯å¤šå°‘ï¼Ÿå®ƒæ˜¯å¦åº”è¯¥æ£€æµ‹å³ä½¿è·ç¦» 100 ç±³è¿œï¼Œä½†åœ¨å›¾åƒä¸­ä»ç„¶å‡ºç°çš„è¡Œäººï¼Ÿä½†å¦‚æœ PM æ”¶é›†ä¸€äº›å›¾ç‰‡ï¼Œå¹¶ç”¨æœŸæœ›çš„è¾“å‡ºæ¥è¿›è¡Œæ ‡æ³¨ï¼Œé‚£ä¹ˆâ€œæ£€æµ‹è¡Œäººâ€çš„å«ä¹‰å°±å˜å¾—å…·ä½“äº†ã€‚å·¥ç¨‹å¸ˆå¯ä»¥æ®æ­¤è¯„ä¼°è¯¥è§„èŒƒåœ¨æŠ€æœ¯ä¸Šæ˜¯å¦å¯è¡Œï¼Œå¦‚æœå¯è¡Œï¼Œä¾¿å¯æœç€è¿™ä¸ªç›®æ ‡è¿›è¡Œå¼€å‘ã€‚æœ€åˆï¼Œæ•°æ®å¯èƒ½é€šè¿‡ä¸€æ¬¡æ€§ã€éè§„èŒƒçš„æµç¨‹è·å–ï¼Œä¾‹å¦‚ PM äº²è‡ªèµ°åŠ¨æ‹æ‘„ç…§ç‰‡å¹¶è¿›è¡Œæ ‡æ³¨ã€‚æœ€ç»ˆï¼Œæ•°æ®æ¥æºå°†è½¬å‘ç”±ç”Ÿäº§ç¯å¢ƒä¸­è¿è¡Œçš„ç³»ç»Ÿæ‰€æ”¶é›†çš„çœŸå®ä¸–ç•Œæ•°æ®ã€‚\n\nå¤šå¹´æ¥ï¼Œä½¿ç”¨ç¤ºä¾‹ï¼ˆä¾‹å¦‚è¾“å…¥å’ŒæœŸæœ›çš„è¾“å‡ºï¼‰æ¥å®šä¹‰äº§å“ä¸€ç›´è¡Œä¹‹æœ‰æ•ˆï¼Œä½† AI åº”ç”¨ç¨‹åºçš„çˆ†ç‚¸å¼å¢é•¿ï¼Œæ­£ä¿ƒä½¿è¶Šæ¥è¶Šå¤šçš„äº§å“ç»ç†å­¦ä¹ å’ŒæŒæ¡è¿™ç§å®è·µã€‚\n\né€šè¿‡æç¤ºè¯è¯„ä¼°åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºçš„æŠ€æœ¯å¯è¡Œæ€§ã€‚å½“ PM è§„åˆ’ä¸€ä¸ªæ½œåœ¨çš„ AI åº”ç”¨ç¨‹åºæ—¶ï¼Œè¯¥åº”ç”¨ç¨‹åºæ˜¯å¦çœŸçš„èƒ½å¤Ÿæ„å»ºâ€”â€”å³å…¶æŠ€æœ¯å¯è¡Œæ€§â€”â€”æ˜¯å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„å…³é”®æ ‡å‡†ã€‚å¯¹äºè®¸å¤šåŸºäº LLM çš„åº”ç”¨ç¨‹åºæ„æƒ³ï¼Œå³ä½¿ PM å¯èƒ½ä¸æ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œç°åœ¨ä¹Ÿè¶Šæ¥è¶Šæœ‰å¯èƒ½é€šè¿‡å°è¯•ç¼–å†™æç¤ºè¯ï¼ˆpromptingï¼‰ï¼Œç”šè‡³åªç¼–å†™å°‘é‡ä»£ç ï¼Œæ¥åˆæ­¥äº†è§£å…¶å¯è¡Œæ€§ã€‚\n\nä¾‹å¦‚ï¼ŒPM å¯èƒ½è®¾æƒ³ä¸€ä¸ªæ–°çš„å†…éƒ¨å·¥å…·ï¼Œç”¨äºå°†å®¢æˆ·é‚®ä»¶è·¯ç”±åˆ°æ­£ç¡®çš„éƒ¨é—¨ï¼ˆä¾‹å¦‚å®¢æˆ·æœåŠ¡ã€é”€å”®ç­‰ï¼‰ã€‚ä»–ä»¬å¯ä»¥å‘ LLM å‘å‡ºæç¤ºè¯ï¼Œçœ‹çœ‹å®ƒèƒ½å¦æ ¹æ®è¾“å…¥çš„é‚®ä»¶é€‰æ‹©æ­£ç¡®çš„éƒ¨é—¨ï¼Œå¹¶è¯„ä¼°å…¶å‡†ç¡®ç‡ã€‚å¦‚æœèƒ½è¾¾åˆ°è¾ƒé«˜å‡†ç¡®ç‡ï¼Œè¿™å°†ä¸ºå·¥ç¨‹å›¢é˜Ÿå®æ–½è¯¥å·¥å…·æä¾›ä¸€ä¸ªæä½³çš„èµ·ç‚¹ã€‚å¦‚æœä¸è¡Œï¼ŒPM å°±å¯ä»¥è‡ªå·±å¿«é€Ÿæ¨ç¿»è¿™ä¸ªæƒ³æ³•ï¼Œå¹¶å¯èƒ½æ¯”ä¾èµ–å·¥ç¨‹å¸ˆæ„å»ºåŸå‹æ›´å¿«åœ°æ”¹è¿›äº§å“æ„æ€ã€‚\n\né€šå¸¸ï¼Œæµ‹è¯•å¯è¡Œæ€§éœ€è¦çš„å¾€å¾€ä¸ä»…ä»…æ˜¯æç¤ºè¯ã€‚ä¾‹å¦‚ï¼ŒåŸºäº LLM çš„é‚®ä»¶ç³»ç»Ÿå¯èƒ½éœ€è¦åŸºæœ¬çš„ RAG èƒ½åŠ›æ¥è¾…åŠ©å†³ç­–ã€‚å¹¸è¿çš„æ˜¯ï¼Œç°åœ¨ç¼–å†™å°‘é‡ä»£ç çš„é—¨æ§›å·²ç»éå¸¸ä½ï¼Œå› ä¸º AI å¯ä»¥å……å½“ç¼–ç åŠ©æ‰‹ï¼ˆcoding companionï¼‰æ¥æä¾›å¸®åŠ©ï¼Œæ­£å¦‚æˆ‘åœ¨â€œAI Python for Beginnersâ€è¯¾ç¨‹ä¸­æè¿°çš„é‚£æ ·ã€‚è¿™æ„å‘³ç€ PM ä»¬ç°åœ¨èƒ½å¤Ÿè¿›è¡Œæ›´å¤šã€æ›´åŸºç¡€çš„æŠ€æœ¯å¯è¡Œæ€§æµ‹è¯•ï¼Œè¿™åœ¨ä»¥å‰æ˜¯ä¸å¯èƒ½å®ç°çš„ã€‚\n\nå³ä½¿æ²¡æœ‰å·¥ç¨‹å¸ˆä¹Ÿèƒ½è¿›è¡ŒåŸå‹è®¾è®¡å’Œæµ‹è¯•ã€‚ç”¨æˆ·å¯¹åˆå§‹åŸå‹çš„åé¦ˆå¯¹äºäº§å“æˆå½¢è‡³å…³é‡è¦ã€‚å¹¸è¿çš„æ˜¯ï¼Œå¿«é€Ÿæ„å»ºåŸå‹çš„éšœç¢æ­£åœ¨é™ä½ï¼ŒPM ä»¬ç°åœ¨å¯ä»¥ç‹¬ç«‹æ¨è¿›åŸºç¡€åŸå‹çš„å¼€å‘ï¼Œè€Œæ— éœ€ä¸“ä¸šçš„è½¯ä»¶å¼€å‘äººå‘˜ã€‚\n\né™¤äº†åˆ©ç”¨ LLM ååŠ©ç¼–å†™åŸå‹ä»£ç ï¼ŒReplitã€Vercel çš„ V0ã€Bolt å’Œ Anthropic çš„ Artifacts ç­‰å·¥å…·ï¼ˆæˆ‘éƒ½æ˜¯è¿™äº›å·¥å…·çš„å¿ å®ç”¨æˆ·ï¼ï¼‰ä¹Ÿè®©æ²¡æœ‰ç¼–ç èƒŒæ™¯çš„äººæ›´å®¹æ˜“æ„å»ºå’Œå°è¯•ç®€å•çš„åŸå‹ã€‚è¿™äº›å·¥å…·å¯¹éæŠ€æœ¯ç”¨æˆ·è¶Šæ¥è¶Šæ˜“äºä¸Šæ‰‹ï¼Œå°½ç®¡æˆ‘å‘ç°é‚£äº›äº†è§£åŸºæœ¬ç¼–ç çš„äººèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä½¿ç”¨å®ƒä»¬ï¼Œå› æ­¤å­¦ä¹ åŸºç¡€ç¼–ç ä»ç„¶å¾ˆé‡è¦ã€‚ï¼ˆæœ‰è¶£çš„æ˜¯ï¼ŒæŠ€æœ¯ç²¾æ¹›ã€ç»éªŒä¸°å¯Œçš„å¼€å‘äººå‘˜ä¹Ÿä¼šä½¿ç”¨å®ƒä»¬ï¼ï¼‰æˆ‘çš„å›¢é˜Ÿä¸­æœ‰è®¸å¤šæˆå‘˜ç»å¸¸ä½¿ç”¨è¿™ç±»å·¥å…·æ¥æ„å»ºåŸå‹ã€è·å–ç”¨æˆ·åé¦ˆå¹¶å¿«é€Ÿè¿­ä»£ã€‚\n\nAI æ­£åœ¨å‚¬ç”Ÿå¤§é‡æ–°åº”ç”¨ï¼Œä»è€Œæå¤§å¢åŠ äº†å¯¹æ‡‚å¾—å¦‚ä½•è§„åˆ’å’Œæ¨åŠ¨è¿™äº›äº§å“æ„å»ºçš„ AI äº§å“ç»ç†çš„éœ€æ±‚ã€‚åœ¨ç”Ÿæˆå¼ AI å…´èµ·ä¹‹å‰ï¼ŒAI äº§å“ç®¡ç†å°±å·²ç»å­˜åœ¨ï¼Œä½†åº”ç”¨ç¨‹åºæ„å»ºçš„æ—¥ç›Šç®€åŒ–æ­£å‚¬ç”Ÿå‡ºå¯¹ AI åº”ç”¨ç¨‹åºæ›´å¤§çš„éœ€æ±‚ï¼Œå› æ­¤è®¸å¤š PM æ­£åœ¨å­¦ä¹  AI ä»¥åŠè¿™äº›æ–°å…´çš„ AI äº§å“æ„å»ºæœ€ä½³å®è·µã€‚æˆ‘å‘ç°è¿™ä¸ªé¢†åŸŸå¼•äººå…¥èƒœï¼Œå¹¶å°†ç»§ç»­åˆ†äº«å…¶ä¸æ–­å‘å±•å’Œæ¼”å˜ä¸­çš„æœ€ä½³å®è·µã€‚\n\n[åŸå§‹æ–‡æœ¬: https://t.co/ohLyrpU4SJ ]"
  },
  {
    "id": "1866880693588070440",
    "url": "https://x.com/AndrewYNg/status/1866880693588070440",
    "text": "New short course: Collaborative Writing and Coding with OpenAI Canvas!\n\nExplore new ways to write and code with OpenAI Canvas, a user-friendly interface that allows you to brainstorm, draft, and refine text and code in collaboration with ChatGPT.\n\nIn the short course, created with @OpenAI, and taught by @karinanguyen_, a research lead at OpenAI, youâ€™ll learn to use Canvas to enhance your workflows.\n\nCanvas lets you go beyond simple chat interactions. It provides a side-by-side workspace where you and ChatGPT can edit and refine text or code collaboratively. This makes brainstorming, drafting, and iterating as you write feel more natural and effective. As the first major update to ChatGPTâ€™s visual interface since its launch in 2022, Canvas gives a new, innovative approach to collaboration with AI.\n\nFor instance, after writing the first version of your code, Canvas can review it and give suggestions for improvement. It can also help with debugging by adding logging, identifying problems to fix, and writing comments. In addition, you'll also learn what it takes to train the model for an interface like Canvas.\n\nIn this video-only short course, youâ€™ll:\n- Learn how to ask for in-line feedback and control the iteration of your work by directly editing selected areas of your text or code from the modelâ€™s output.\n- Learn how to access quick automation tools in a shortcut menu that allows you to modify your writing tone and length, enhance your code, and restore previous versions of your work.\n- Learn how to use Canvas as a research assistant tool with an example of asking the model to reason through the screenshot of a plot to write a research report, in which you can ask questions within the created report.\n- Ask the model to write Python code to replicate the graph seen on a screenshot image.\n- Go behind the scenes of how you can create a video game, such as Space Battleship, from scratch, edit it, and display it in one self-contained HTML file.\n- Get a real-world application example of creating a SQL database from the image of its architecture.\n- Understand the model training and design processes that power Canvas!\n\nPlease sign up here: https://t.co/vdWBfHHGia",
    "createdAt": "Wed Dec 11 16:20:16 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 262,
    "replyCount": 34,
    "likeCount": 1383,
    "quoteCount": 14,
    "viewCount": 127317,
    "bookmarkCount": 795,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°ä¸Šçº¿çŸ­æœŸè¯¾ç¨‹ï¼šä½¿ç”¨ OpenAI Canvas è¿›è¡Œåä½œå†™ä½œå’Œç¼–ç ï¼\n\næ¢ç´¢åˆ©ç”¨ OpenAI Canvas è¿™ä¸€ç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼Œä¸ ChatGPT åä½œè¿›è¡Œå¤´è„‘é£æš´ã€èµ·è‰å’Œå®Œå–„æ–‡æœ¬åŠä»£ç çš„å…¨æ–°æ–¹å¼ã€‚\n\nè¿™é—¨çŸ­æœŸè¯¾ç¨‹ç”± @OpenAI åˆä½œæ‰“é€ ï¼Œå¹¶ç”± OpenAI çš„ç ”ç©¶ä¸»ç®¡ @karinanguyen_ äº²è‡ªæˆè¯¾ã€‚è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Canvas æ¥æå‡æ‚¨çš„å·¥ä½œæ•ˆç‡ã€‚\n\nCanvas ä¸ä»…ä»…å±€é™äºç®€å•çš„èŠå¤©äº’åŠ¨ã€‚å®ƒæä¾›äº†ä¸€ä¸ªå¹¶æ’çš„å·¥ä½œç©ºé—´ï¼Œæ‚¨å’Œ ChatGPT å¯ä»¥åœ¨å…¶ä¸­å…±åŒç¼–è¾‘å’Œå®Œå–„æ–‡æœ¬æˆ–ä»£ç ã€‚è¿™ä½¿å¾—å¤´è„‘é£æš´ã€èµ·è‰ä»¥åŠåœ¨å†™ä½œè¿‡ç¨‹ä¸­ä¸æ–­è¿­ä»£çš„è¿‡ç¨‹å˜å¾—æ›´åŠ è‡ªç„¶å’Œé«˜æ•ˆã€‚ä½œä¸º ChatGPT å¯è§†åŒ–ç•Œé¢è‡ª 2022 å¹´æ¨å‡ºä»¥æ¥çš„é¦–æ¬¡é‡å¤§æ›´æ–°ï¼ŒCanvas ä¸ºä¸ AI åä½œå¸¦æ¥äº†ä¸€ç§åˆ›æ–°æ–¹æ³•ã€‚\n\nä¾‹å¦‚ï¼Œåœ¨ç¼–å†™å®Œä»£ç çš„åˆç¨¿åï¼ŒCanvas å¯ä»¥å¯¹å…¶è¿›è¡Œå®¡æŸ¥å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚å®ƒè¿˜å¯ä»¥é€šè¿‡æ·»åŠ æ—¥å¿—ã€è¯†åˆ«éœ€è¦ä¿®å¤çš„é—®é¢˜ä»¥åŠç¼–å†™æ³¨é‡Šæ¥å¸®åŠ©è°ƒè¯•ã€‚æ­¤å¤–ï¼Œæ‚¨è¿˜å°†äº†è§£ä¸º Canvas è¿™æ ·çš„ç•Œé¢è®­ç»ƒæ¨¡å‹æ‰€éœ€çš„å…³é”®è¦ç´ ã€‚\n\nåœ¨è¿™ä¸ªçº¯è§†é¢‘çš„çŸ­æœŸè¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†ï¼š\n- å­¦ä¹ å¦‚ä½•è¯·æ±‚å†…è”åé¦ˆï¼Œå¹¶é€šè¿‡ç›´æ¥ç¼–è¾‘æ¨¡å‹è¾“å‡ºä¸­æ–‡æœ¬æˆ–ä»£ç çš„ç‰¹å®šåŒºåŸŸæ¥æ§åˆ¶æ‚¨å·¥ä½œçš„è¿­ä»£ã€‚\n- å­¦ä¹ å¦‚ä½•é€šè¿‡å¿«æ·èœå•è®¿é—®å¿«é€Ÿè‡ªåŠ¨åŒ–å·¥å…·ï¼Œä»è€Œä¿®æ”¹æ‚¨çš„å†™ä½œè¯­æ°”å’Œé•¿åº¦ã€ä¼˜åŒ–æ‚¨çš„ä»£ç ä»¥åŠæ¢å¤ä¹‹å‰ç‰ˆæœ¬çš„å·¥ä½œã€‚\n- å­¦ä¹ å¦‚ä½•å°† Canvas ç”¨ä½œç ”ç©¶åŠ©ç†å·¥å…·ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥è¦æ±‚æ¨¡å‹é€šè¿‡å›¾è¡¨ï¼ˆplotï¼‰çš„å±å¹•æˆªå›¾è¿›è¡Œæ¨ç†ï¼Œæ’°å†™ç ”ç©¶æŠ¥å‘Šï¼Œå¹¶å¯åœ¨ç”Ÿæˆçš„æŠ¥å‘Šä¸­æå‡ºé—®é¢˜ã€‚\n- è¦æ±‚æ¨¡å‹ç¼–å†™ Python ä»£ç ï¼Œä»¥å¤ç°å±å¹•æˆªå›¾å›¾åƒä¸Šæ˜¾ç¤ºçš„å›¾è¡¨ã€‚\n- æ·±å…¥äº†è§£å¦‚ä½•ä»é›¶å¼€å§‹åˆ›å»ºè§†é¢‘æ¸¸æˆï¼ˆä¾‹å¦‚å¤ªç©ºæˆ˜èˆ°ï¼‰ï¼Œå¯¹å…¶è¿›è¡Œç¼–è¾‘ï¼Œå¹¶å°†å…¶å±•ç¤ºåœ¨ä¸€ä¸ªç‹¬ç«‹çš„ HTML æ–‡ä»¶ä¸­ã€‚\n- è·å¾—ä¸€ä¸ªå®é™…åº”ç”¨ç¤ºä¾‹ï¼šå¦‚ä½•ä»å…¶æ¶æ„å›¾åƒåˆ›å»º SQL æ•°æ®åº“ã€‚\n- äº†è§£é©±åŠ¨ Canvas çš„æ¨¡å‹è®­ç»ƒå’Œè®¾è®¡è¿‡ç¨‹ï¼\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/vdWBfHHGia"
  },
  {
    "id": "1861830140730487206",
    "url": "https://x.com/AndrewYNg/status/1861830140730487206",
    "text": "@weimenglee @AIAdvances Thanks for writing up this aisuite guide!",
    "createdAt": "Wed Nov 27 17:51:11 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 3,
    "likeCount": 11,
    "quoteCount": 0,
    "viewCount": 2517,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@weimenglee @AIAdvances æ„Ÿè°¢ä½ ä»¬æ’°å†™äº†è¿™ä»½ aisuite æŒ‡å—ï¼"
  },
  {
    "id": "1861085482526105842",
    "url": "https://x.com/AndrewYNg/status/1861085482526105842",
    "text": "Announcing new open-source Python package: aisuite!  \n\nThis makes it easy for developers to use large language models from multiple providers. When building applications I found it a hassle to integrate with multiple providers. Aisuite lets you pick a \"provider:model\" just by changing one string, like openai:gpt-4o, anthropic:claude-3-5-sonnet-20241022, ollama:llama3.1:8b, etc. \n\npip install aisuite\n\nOpen-source code with instructions: https://t.co/gwz9oKTCFx\n\nThanks to Rohit Prsad, Kevin Solorio, @standsleeping,   Jeff Tang and @Johnsanterre for helping build this!",
    "createdAt": "Mon Nov 25 16:32:10 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 1070,
    "replyCount": 146,
    "likeCount": 5801,
    "quoteCount": 103,
    "viewCount": 436130,
    "bookmarkCount": 3737,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "éš†é‡æ¨å‡ºæ–°çš„å¼€æº Python åŒ…ï¼šaisuiteï¼\n\nè¿™æ¬¾å·¥å…·æ—¨åœ¨è®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾è°ƒç”¨æ¥è‡ªå¤šä¸ªæœåŠ¡å•†çš„**å¤§è¯­è¨€æ¨¡å‹** (Large Language Model)ã€‚åœ¨å¼€å‘åº”ç”¨ç¨‹åºæ—¶ï¼Œæˆ‘ä»¬å‘ç°ä¸ä¸åŒæœåŠ¡å•†çš„ API (åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£) è¿›è¡Œé›†æˆå¸¸å¸¸æ˜¯ä¸€é¡¹ç¹ççš„ä»»åŠ¡ã€‚æœ‰äº† Aisuiteï¼Œæ‚¨åªéœ€ä¿®æ”¹ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå°±èƒ½è½»æ¾é€‰æ‹©ä¸åŒçš„â€œæä¾›å•†:æ¨¡å‹â€ï¼Œä¾‹å¦‚ openai:gpt-4oã€anthropic:claude-3-5-sonnet-20241022ã€ollama:llama3.1:8b ç­‰ã€‚\n\npip install aisuite\n\né¡¹ç›®çš„å¼€æºä»£ç åŠä½¿ç”¨è¯´æ˜è¯·è®¿é—®ï¼šhttps://t.co/gwz9oKTCFx\n\nç‰¹åˆ«æ„Ÿè°¢ Rohit Prsadã€Kevin Solorioã€@standsleepingã€Jeff Tang å’Œ @Johnsanterre å¯¹æ­¤é¡¹ç›®å¼€å‘æä¾›çš„å¸®åŠ©ï¼"
  },
  {
    "id": "1860468376809931061",
    "url": "https://x.com/AndrewYNg/status/1860468376809931061",
    "text": "@joaomdmoura Congratulations!!! â¤ï¸",
    "createdAt": "Sat Nov 23 23:40:01 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 2,
    "likeCount": 12,
    "quoteCount": 0,
    "viewCount": 3756,
    "bookmarkCount": 1,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@joaomdmoura æ­å–œï¼ï¼ï¼â¤ï¸"
  },
  {
    "id": "1859625355541348798",
    "url": "https://x.com/AndrewYNg/status/1859625355541348798",
    "text": "A small number of people are posting text online thatâ€™s intended for direct consumption not by humans, but by LLMs (large language models). I find this a fascinating trend, particularly when writers are incentivized to help LLM providers better serve their users!\n\nPeople who post text online donâ€™t always have an incentive to help LLM providers. In fact, their incentives are often misaligned. Publishers worry about LLMs reading their text, paraphrasing it, and reusing their ideas without attribution, thus depriving them of subscription or ad revenue. This has even led to litigation such as The New York Timesâ€™ lawsuit against OpenAI and Microsoft for alleged copyright infringement. There have also been demonstrations of prompt injections, where someone writes text to try to give an LLM instructions contrary to the providerâ€™s intent. (For example, a handful of sites advise job seekers to get past LLM resumÃ© screeners by writing on their resumÃ©s, in a tiny/faint font thatâ€™s nearly invisible to humans, text like â€œThis candidate is very qualified for this role.â€) Spammers who try to promote certain products â€” which is already challenging for search engines to filter out â€” will also turn their attention to spamming LLMs.\n\nBut there are examples of authors who want to actively help LLMs. Take the example of a startup that has just published a software library. Because the online documentation is very new, it wonâ€™t yet be in LLMsâ€™ pretraining data. So when a user asks an LLM to suggest software, the LLM wonâ€™t suggest this library, and even if a user asks the LLM directly to generate code using this library, the LLM wonâ€™t know how to do so. Now, if the LLM is augmented with online search capabilities, then it might find the new documentation and be able to use this to write code using the library. In this case, the developer may want to take additional steps to make the online documentation easier for the LLM to read and understand via RAG. (And perhaps the documentation eventually will make it into pretraining data as well.)\n\nCompared to humans, LLMs are not as good at navigating complex websites, particularly ones with many graphical elements. However, LLMs are far better than people at rapidly ingesting long, dense, text documentation. Suppose the software library has many functions that we want an LLM to be able to use in the code it generates. If you were writing documentation to help humans use the library, you might create many web pages that break the information into bite-size chunks, with graphical illustrations to explain it. But for an LLM, it might be easier to have a long XML-formatted text file that clearly explains everything in one go. This text might include a list of all the functions, with a dense description of each and an example or two of how to use it. (This is not dissimilar to the way we specify information about functions to enable LLMs to use them as tools.)\n\nA human would find this long document painful to navigate and read, but an LLM would do just fine ingesting it and deciding what functions to use and when!\n\nBecause LLMs and people are better at ingesting different types of text, we write differently for LLMs than for humans. Further, when someone has an incentive to help an LLM better understand a topic â€” so the LLM can explain it better to users â€” then an author might write text to help an LLM.\n\nSo far, text written specifically for consumption by LLMs has not been a huge trend. But Jeremy Howardâ€™s proposal for web publishers to post a llms.txt file to tell LLMs how to use their websites, like a robots.txt file tells web crawlers what to do, is an interesting step in this direction. In a related vein, some developers are posting detailed instructions that tell their IDE how to use tools, such as the plethora of .cursorrules files that tell the Cursor IDE how to use particular software stacks.\n\nI see a parallel with SEO (search engine optimization). The discipline of SEO has been around for decades. Some SEO helps search engines find more relevant topics, and some is spam that promotes low-quality information. But many SEO techniques â€” those that involve writing text for consumption by a search engine, rather than by a human â€” have survived so long in part because search engines process web pages differently than humans, so providing tags or other information that tells them what a web page is about has been helpful.\n\nThe need to write text separately for LLMs and humans might diminish if LLMs catch up with humans in their ability to understand complex websites. But until then, as people get more information through LLMs, writing text to help LLMs will grow.\n\n[Original text: https://t.co/MDjPq9wCDH ]",
    "createdAt": "Thu Nov 21 15:50:09 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 144,
    "replyCount": 52,
    "likeCount": 759,
    "quoteCount": 24,
    "viewCount": 88411,
    "bookmarkCount": 332,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ç°åœ¨ï¼Œæœ‰å°‘æ•°äººåœ¨ç½‘ä¸Šå‘å¸ƒæ–‡æœ¬ï¼Œä½†è¿™äº›æ–‡æœ¬å¹¶éä¾›äººç±»ç›´æ¥é˜…è¯»ï¼Œè€Œæ˜¯ä¾› å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä½¿ç”¨ã€‚æˆ‘å‘ç°è¿™æ˜¯ä¸€ä¸ªå¼•äººå…¥èƒœçš„è¶‹åŠ¿ï¼Œå°¤å…¶å½“ä½œè€…ä»¬è¢«é¼“åŠ±å»å¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ ä¾›åº”å•†æ›´å¥½åœ°æœåŠ¡å…¶ç”¨æˆ·æ—¶ï¼Œè¿™ç§ç°è±¡å°±æ›´åŠ æœ‰è¶£äº†ã€‚\n\nç„¶è€Œï¼Œåœ¨çº¿å‘å¸ƒæ–‡æœ¬çš„äººå¹¶éæ€»æ˜¯æœ‰åŠ¨åŠ›å»å¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ ä¾›åº”å•†ã€‚äº‹å®ä¸Šï¼Œä»–ä»¬çš„ç›®æ ‡å¾€å¾€æ˜¯ç›¸æ‚–çš„ã€‚å‡ºç‰ˆå•†æ‹…å¿ƒ å¤§è¯­è¨€æ¨¡å‹ ä¼šé˜…è¯»ä»–ä»¬çš„å†…å®¹ï¼Œå°†å…¶æ”¹å†™ï¼Œå¹¶åœ¨ä¸æ³¨æ˜å‡ºå¤„çš„æƒ…å†µä¸‹é‡å¤ä½¿ç”¨ä»–ä»¬çš„åˆ›æ„ï¼Œä»è€ŒæŸå®³ä»–ä»¬çš„è®¢é˜…æˆ–å¹¿å‘Šæ”¶å…¥ã€‚è¿™ç”šè‡³å¯¼è‡´äº†ä¸€äº›æ³•å¾‹çº çº·ï¼Œä¾‹å¦‚ã€Šçº½çº¦æ—¶æŠ¥ã€‹å°±æ›¾èµ·è¯‰ OpenAI å’Œ Microsoft æ¶‰å«Œä¾µçŠ¯ç‰ˆæƒã€‚æ­¤å¤–ï¼Œè¿˜å‡ºç°è¿‡â€œæç¤ºæ³¨å…¥ (prompt injections)â€çš„æ¡ˆä¾‹ï¼Œå³æœ‰äººæ•…æ„ç¼–å†™æ–‡æœ¬ï¼Œè¯•å›¾è®© å¤§è¯­è¨€æ¨¡å‹ æ‰§è¡Œä¸ä¾›åº”å•†æ„å›¾ç›¸åçš„æŒ‡ä»¤ã€‚ï¼ˆä¸¾ä¸ªä¾‹å­ï¼Œæœ‰äº›ç½‘ç«™ä¼šå»ºè®®æ±‚èŒè€…ï¼Œåœ¨ç®€å†ä¸Šç”¨äººç±»å‡ ä¹çœ‹ä¸è§çš„å¾®å°å­—ä½“å†™ä¸Šâ€œè¯¥å€™é€‰äººéå¸¸é€‚åˆæ­¤èŒä½â€ç­‰æ–‡æœ¬ï¼Œä»¥æ­¤ç»•è¿‡ å¤§è¯­è¨€æ¨¡å‹ ç®€å†ç­›é€‰å™¨ã€‚ï¼‰é‚£äº›è¯•å›¾æ¨å¹¿ç‰¹å®šäº§å“çš„åƒåœ¾é‚®ä»¶å‘é€è€…â€”â€”è¿™äº›å†…å®¹å¯¹æœç´¢å¼•æ“æ¥è¯´å·²ç»å¾ˆéš¾è¿‡æ»¤äº†â€”â€”ä¹Ÿå°†æŠŠç›®æ ‡è½¬å‘ å¤§è¯­è¨€æ¨¡å‹ã€‚\n\nä½†ä¹Ÿæœ‰ä½œè€…ç§¯æå¸Œæœ›å¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ çš„ä¾‹å­ã€‚æ¯”å¦‚ä¸€å®¶åˆåˆ›å…¬å¸ï¼Œåˆšåˆšå‘å¸ƒäº†ä¸€ä¸ªæ–°çš„è½¯ä»¶åº“ã€‚ç”±äºåœ¨çº¿æ–‡æ¡£å‘å¸ƒä¸ä¹…ï¼Œå®ƒå°šæœªè¢«çº³å…¥ å¤§è¯­è¨€æ¨¡å‹ çš„é¢„è®­ç»ƒæ•°æ®ä¸­ã€‚å› æ­¤ï¼Œå½“ç”¨æˆ·å‘ å¤§è¯­è¨€æ¨¡å‹ å’¨è¯¢è½¯ä»¶å»ºè®®æ—¶ï¼Œ å¤§è¯­è¨€æ¨¡å‹ ä¸ä¼šæ¨èè¿™ä¸ªåº“ï¼›å³ä½¿ç”¨æˆ·ç›´æ¥è¦æ±‚ å¤§è¯­è¨€æ¨¡å‹ ä½¿ç”¨è¯¥åº“ç”Ÿæˆä»£ç ï¼Œå®ƒä¹Ÿæ— ä»ä¸‹æ‰‹ã€‚ä¸è¿‡ï¼Œå¦‚æœ å¤§è¯­è¨€æ¨¡å‹ å…·å¤‡äº†åœ¨çº¿æœç´¢èƒ½åŠ›ï¼Œå®ƒæˆ–è®¸å°±èƒ½æ‰¾åˆ°è¿™ä»½æ–°æ–‡æ¡£ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥ç¼–å†™ä½¿ç”¨è¯¥åº“çš„ä»£ç ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¼€å‘äººå‘˜å¯èƒ½ä¼šé‡‡å–é¢å¤–æªæ–½ï¼Œé€šè¿‡ RAG (Retrieval Augmented Generation) æŠ€æœ¯ï¼Œè®©åœ¨çº¿æ–‡æ¡£æ›´æ˜“äº å¤§è¯­è¨€æ¨¡å‹ é˜…è¯»å’Œç†è§£ã€‚ï¼ˆæˆ–è®¸è¿™ä»½æ–‡æ¡£æœ€ç»ˆä¹Ÿä¼šè¢«çº³å…¥é¢„è®­ç»ƒæ•°æ®ã€‚ï¼‰\n\nä¸äººç±»ç›¸æ¯”ï¼Œ å¤§è¯­è¨€æ¨¡å‹ åœ¨æµè§ˆå¤æ‚ç½‘ç«™æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œç‰¹åˆ«æ˜¯é‚£äº›åŒ…å«å¤§é‡å›¾å½¢å…ƒç´ çš„ç½‘ç«™ã€‚ç„¶è€Œï¼Œåœ¨å¿«é€Ÿå¤„ç†å†—é•¿ã€å¯†é›†æ–‡æœ¬æ–‡æ¡£æ–¹é¢ï¼Œ å¤§è¯­è¨€æ¨¡å‹ å´è¿œè¶…äººç±»ã€‚å‡è®¾æŸä¸ªè½¯ä»¶åº“æœ‰è®¸å¤šæˆ‘ä»¬å¸Œæœ› å¤§è¯­è¨€æ¨¡å‹ èƒ½å¤Ÿåœ¨å…¶ç”Ÿæˆçš„ä»£ç ä¸­ä½¿ç”¨çš„å‡½æ•°ã€‚å¦‚æœä½ æ˜¯ä¸ºäººç±»ç¼–å†™ä½¿ç”¨è¯¥åº“çš„æ–‡æ¡£ï¼Œä½ å¯èƒ½ä¼šåˆ›å»ºè®¸å¤šç½‘é¡µï¼Œå°†ä¿¡æ¯åˆ†è§£æˆæ˜“äºç†è§£çš„å°å—ï¼Œå¹¶é…ä¸Šå›¾å½¢æ’å›¾è¿›è¡Œè§£é‡Šã€‚ä½†å¯¹äº å¤§è¯­è¨€æ¨¡å‹ æ¥è¯´ï¼Œä¸€ä¸ªå†—é•¿çš„ XML æ ¼å¼æ–‡æœ¬æ–‡ä»¶ï¼Œèƒ½ä¸€æ¬¡æ€§æ¸…æ™°åœ°è§£é‡Šæ‰€æœ‰å†…å®¹ï¼Œå¯èƒ½ä¼šæ›´å®¹æ˜“ç†è§£ã€‚è¿™ä»½æ–‡æœ¬å¯èƒ½åŒ…å«æ‰€æœ‰å‡½æ•°çš„åˆ—è¡¨ï¼Œä»¥åŠæ¯ä¸ªå‡½æ•°çš„è¯¦ç»†æè¿°å’Œä¸€ä¸¤ä¸ªä½¿ç”¨ç¤ºä¾‹ã€‚ï¼ˆè¿™ä¸æˆ‘ä»¬æŒ‡å®šå‡½æ•°ä¿¡æ¯ä»¥ä½¿ å¤§è¯­è¨€æ¨¡å‹ èƒ½å¤Ÿå°†å…¶ç”¨ä½œå·¥å…·çš„æ–¹å¼éå¸¸ç›¸ä¼¼ã€‚ï¼‰\n\näººç±»ä¼šè§‰å¾—é˜…è¯»è¿™ä»½å†—é•¿çš„æ–‡æ¡£ä»¤äººç—›è‹¦ï¼Œä½† å¤§è¯­è¨€æ¨¡å‹ å´èƒ½å¾ˆå¥½åœ°æ¶ˆåŒ–å¸æ”¶ï¼Œå¹¶å†³å®šä½•æ—¶ä½¿ç”¨å“ªäº›å‡½æ•°ï¼\n\nç”±äº å¤§è¯­è¨€æ¨¡å‹ å’Œäººç±»æ“…é•¿å¤„ç†ä¸åŒç±»å‹çš„æ–‡æœ¬ï¼Œå› æ­¤æˆ‘ä»¬ä¸º å¤§è¯­è¨€æ¨¡å‹ ç¼–å†™æ–‡æœ¬çš„æ–¹å¼ä¹Ÿä¸ä¸ºäººç±»ç¼–å†™æ–‡æœ¬çš„æ–¹å¼æœ‰æ‰€ä¸åŒã€‚æ­¤å¤–ï¼Œå½“æœ‰äººæœ‰åŠ¨åŠ›å¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ æ›´å¥½åœ°ç†è§£æŸä¸ªä¸»é¢˜â€”â€”ä»¥ä¾¿ å¤§è¯­è¨€æ¨¡å‹ èƒ½å¤Ÿæ›´å¥½åœ°å‘ç”¨æˆ·è§£é‡Šè¯¥ä¸»é¢˜æ—¶â€”â€”ä½œè€…å°±ä¼šä¸“é—¨ç¼–å†™æ–‡æœ¬æ¥å¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ã€‚\n\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä¸“é—¨ä¸º å¤§è¯­è¨€æ¨¡å‹ ç¼–å†™çš„æ–‡æœ¬å°šæœªæˆä¸ºä¸»æµè¶‹åŠ¿ã€‚ä½† Jeremy Howard æå‡ºçš„å»ºè®®â€”â€”è®©ç½‘ç»œå‡ºç‰ˆå•†å‘å¸ƒä¸€ä¸ªç±»ä¼¼ robots.txt æ–‡ä»¶çš„ llms.txt æ–‡ä»¶ï¼Œæ¥æŒ‡å¯¼ å¤§è¯­è¨€æ¨¡å‹ å¦‚ä½•ä½¿ç”¨ä»–ä»¬çš„ç½‘ç«™â€”â€”æ˜¯æœç€è¿™ä¸ªæ–¹å‘è¿ˆå‡ºçš„æœ‰è¶£ä¸€æ­¥ã€‚ä¸æ­¤ç›¸å…³çš„æ˜¯ï¼Œä¸€äº›å¼€å‘è€…æ­£åœ¨å‘å¸ƒè¯¦ç»†æŒ‡ä»¤ï¼Œå‘Šè¯‰ä»–ä»¬çš„ IDE (Integrated Development Environment) å¦‚ä½•ä½¿ç”¨å·¥å…·ï¼Œä¾‹å¦‚å¤§é‡çš„ .cursorrules æ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶æŒ‡å¯¼ Cursor IDE å¦‚ä½•ä½¿ç”¨ç‰¹å®šçš„è½¯ä»¶æ ˆã€‚\n\næˆ‘ä»ä¸­çœ‹åˆ°äº†ä¸ SEO (Search Engine Optimization) çš„ç›¸ä¼¼ä¹‹å¤„ã€‚SEO è¿™é—¨å­¦ç§‘å·²ç»å­˜åœ¨äº†å‡ åå¹´ã€‚æœ‰äº› SEO æ—¨åœ¨å¸®åŠ©æœç´¢å¼•æ“æ‰¾åˆ°æ›´ç›¸å…³çš„ä¸»é¢˜ï¼Œæœ‰äº›åˆ™æ˜¯æ¨å¹¿ä½è´¨é‡ä¿¡æ¯çš„åƒåœ¾é‚®ä»¶ã€‚ä½†è®¸å¤š SEO æŠ€æœ¯â€”â€”é‚£äº›æ¶‰åŠä¸ºæœç´¢å¼•æ“è€Œéäººç±»ç¼–å†™æ–‡æœ¬çš„æŠ€æœ¯â€”â€”ä¹‹æ‰€ä»¥èƒ½å­˜æ´»è¿™ä¹ˆä¹…ï¼Œéƒ¨åˆ†åŸå› åœ¨äºæœç´¢å¼•æ“å¤„ç†ç½‘é¡µçš„æ–¹å¼ä¸äººç±»ä¸åŒã€‚å› æ­¤ï¼Œæä¾›æ ‡ç­¾æˆ–å…¶ä»–ä¿¡æ¯æ¥å‘ŠçŸ¥æœç´¢å¼•æ“ç½‘é¡µçš„ä¸»é¢˜ï¼Œä¸€ç›´ä»¥æ¥éƒ½éå¸¸æœ‰ç”¨ã€‚\n\nå¦‚æœ å¤§è¯­è¨€æ¨¡å‹ åœ¨ç†è§£å¤æ‚ç½‘ç«™çš„èƒ½åŠ›ä¸Šèƒ½èµ¶ä¸Šäººç±»ï¼Œé‚£ä¹ˆä¸º å¤§è¯­è¨€æ¨¡å‹ å’Œäººç±»åˆ†åˆ«ç¼–å†™æ–‡æœ¬çš„éœ€æ±‚å¯èƒ½ä¼šå‡å°‘ã€‚ä½†åœ¨æ­¤ä¹‹å‰ï¼Œéšç€äººä»¬é€šè¿‡ å¤§è¯­è¨€æ¨¡å‹ è·å–æ›´å¤šä¿¡æ¯ï¼Œä¸“é—¨ä¸ºå¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ è€Œç¼–å†™æ–‡æœ¬çš„å®è·µå°†ä¼šä¸æ–­å¢é•¿ã€‚\n\n[åŸæ–‡é“¾æ¥: https://t.co/MDjPq9wCDH ]"
  },
  {
    "id": "1859258084079882512",
    "url": "https://x.com/AndrewYNg/status/1859258084079882512",
    "text": "Time to play! Build an interactive game from scratch with LLMs in this new short course: Building an AI-Powered Game. Created with @togethercompute and  @aidungeon @LatitudeGamesAI, taught by @niki_birkner, Senior Product Manager at Together AI, and @nickwalton00, CEO and Co-Founder of Latitude.\n\nThis course shows you how to use large language models to create and power a text-based game that you can share with your friends and family. Youâ€™ll build a world with hierarchical content generation, a method that allows you to leverage LLMs to create a vast amount of content with a high level of control and consistency. For instance, if you were building a fantasy world with several kingdoms, in which each kingdom has multiple towns, and each town has several locations and residents, creating all this content from scratch can easily become tedious and difficult to track.\n\nWith hierarchical content generation, you can create information about your world, shape its direction with a human-in-the-loop, and keep it consistent, with little effort based on your prompts.\n\nBy the end of this course, youâ€™ll know how to prompt engineer to create a layered and interwoven world and integrate it into an AI roleplay game that is interesting, interactive, and safe to share with anyone.\n\nIn detail, youâ€™ll:\n- Learn to implement game mechanics using AI to parse text data into structured JSON output, enabling features like an inventory system.\n- Use game mechanics with story and state components that feed into one another to improve your game's memory, and gives the player a steady state of the world.\n- Learn to enforce safety and compliance for AI content generation and create custom policies using Llama Guard.\n\nWith these techniques, you'll be equipped to build AI-powered applications, starting with your own game.\n\nPlease sign up here:  https://t.co/Ght1dlUkcG",
    "createdAt": "Wed Nov 20 15:30:45 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 153,
    "replyCount": 23,
    "likeCount": 899,
    "quoteCount": 12,
    "viewCount": 84690,
    "bookmarkCount": 531,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ˜¯æ—¶å€™å¼€ç©äº†ï¼åœ¨è¿™é—¨å…¨æ–°çš„çŸ­æœŸè¯¾ç¨‹â€”â€”ã€Šæ„å»º AI é©±åŠ¨æ¸¸æˆã€‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) ä»é›¶å¼€å§‹æ­å»ºä¸€ä¸ªäº’åŠ¨æ¸¸æˆã€‚è¿™é—¨è¯¾ç¨‹ç”± @togethercomputeã€@aidungeon å’Œ @LatitudeGamesAI è”åˆæ‰“é€ ï¼Œå¹¶ç”± Together AI çš„é«˜çº§äº§å“ç»ç† @niki_birkner ä»¥åŠ Latitude çš„é¦–å¸­æ‰§è¡Œå®˜å…¼è”åˆåˆ›å§‹äºº @nickwalton00 äº²è‡ªæˆè¯¾ã€‚\n\næœ¬è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•è¿ç”¨å¤§è¯­è¨€æ¨¡å‹åˆ›å»ºå¹¶é©±åŠ¨ä¸€ä¸ªåŸºäºæ–‡æœ¬çš„æ¸¸æˆï¼Œä½ å¯ä»¥ä¸äº²æœ‹å¥½å‹ä¸€åŒåˆ†äº«ã€‚ä½ å°†å­¦ä¼šå¦‚ä½•é€šè¿‡åˆ†å±‚å†…å®¹ç”Ÿæˆ (hierarchical content generation) æ„å»ºæ¸¸æˆä¸–ç•Œã€‚è¿™æ˜¯ä¸€ç§å·§å¦™çš„æ–¹æ³•ï¼Œèƒ½è®©ä½ å……åˆ†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œä»¥é«˜åº¦å¯æ§å’Œä¸€è‡´çš„æ–¹å¼ç”Ÿæˆæµ·é‡å†…å®¹ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾ä½ è¦æ„å»ºä¸€ä¸ªå¥‡å¹»ä¸–ç•Œï¼Œå…¶ä¸­åŒ…å«å¤šä¸ªç‹å›½ï¼Œæ¯ä¸ªç‹å›½ä¸‹è¾–æ•°ä¸ªåŸé•‡ï¼Œè€Œæ¯ä¸ªåŸé•‡åˆæ‹¥æœ‰å¤šä¸ªåœ°ç‚¹å’Œå±…æ°‘â€”â€”å¦‚æœä»å¤´å¼€å§‹æ‰‹åŠ¨åˆ›å»ºæ‰€æœ‰è¿™äº›å†…å®¹ï¼Œå¾ˆå¿«å°±ä¼šå˜å¾—æ¯ç‡¥ä¹å‘³ä¸”éš¾ä»¥ç®¡ç†ã€‚\n\næœ‰äº†åˆ†å±‚å†…å®¹ç”Ÿæˆï¼Œä½ åªéœ€ä¾æ®ä½ çš„æç¤ºè¯ï¼Œä¾¿èƒ½è½»æ¾åˆ›å»ºå…³äºæ¸¸æˆä¸–ç•Œçš„ä¿¡æ¯ï¼Œé€šè¿‡â€œäººåœ¨ç¯è·¯â€ (human-in-the-loop) çš„æ–¹å¼è°ƒæ•´å…¶å‘å±•æ–¹å‘ï¼Œå¹¶ç¡®ä¿å†…å®¹ä¿æŒä¸€è‡´æ€§ï¼Œçœæ—¶çœåŠ›ã€‚\n\nå®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†æŒæ¡æç¤ºå·¥ç¨‹ (prompt engineering) çš„æŠ€å·§ï¼Œèƒ½å¤Ÿåˆ›å»ºä¸€ä¸ªå±‚æ¬¡ä¸°å¯Œã€å½¼æ­¤äº¤ç»‡çš„æ¸¸æˆä¸–ç•Œï¼Œå¹¶å°†å…¶æ•´åˆåˆ°ä¸€æ¬¾æœ‰è¶£ã€äº’åŠ¨ä¸”å¯ä»¥å®‰å…¨åœ°ä¸ä»»ä½•äººåˆ†äº«çš„ AI è§’è‰²æ‰®æ¼”æ¸¸æˆä¸­ã€‚\n\nå…·ä½“æ¥è¯´ï¼Œä½ å°†å­¦åˆ°ï¼š\n- å¦‚ä½•è¿ç”¨ AI å°†æ–‡æœ¬æ•°æ®è§£ææˆç»“æ„åŒ–çš„ JSON è¾“å‡ºï¼Œä»è€Œå®ç°åº“å­˜ç³»ç»Ÿç­‰æ¸¸æˆæœºåˆ¶ã€‚\n- å¦‚ä½•å°†æ¸¸æˆæœºåˆ¶ä¸æ•…äº‹åŠçŠ¶æ€ç»„ä»¶ç»“åˆèµ·æ¥ï¼Œè¿™äº›ç»„ä»¶ç›¸äº’å…³è”ã€å…±åŒä½œç”¨ï¼Œä»¥å¢å¼ºæ¸¸æˆçš„è®°å¿†åŠ›ï¼Œå¹¶ä¸ºç©å®¶å‘ˆç°ä¸€ä¸ªæŒç»­ç¨³å®šçš„ä¸–ç•ŒçŠ¶æ€ã€‚\n- å¦‚ä½•ä¸º AI ç”Ÿæˆçš„å†…å®¹å¼ºåˆ¶å®æ–½å®‰å…¨ä¸åˆè§„æ€§ï¼Œå¹¶ä½¿ç”¨ Llama Guard åˆ›å»ºè‡ªå®šä¹‰ç­–ç•¥ã€‚\n\næŒæ¡è¿™äº›æŠ€æœ¯åï¼Œä½ å°†å…·å¤‡æ„å»º AI é©±åŠ¨åº”ç”¨ç¨‹åºçš„èƒ½åŠ›ï¼Œå°±ä»æ‰“é€ ä½ è‡ªå·±çš„æ¸¸æˆå¼€å§‹å§ï¼\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/Ght1dlUkcG"
  },
  {
    "id": "1857117382378164267",
    "url": "https://x.com/AndrewYNg/status/1857117382378164267",
    "text": "Large language models (LLMs) are typically optimized to answer peoplesâ€™ questions. But there is a trend toward models also being optimized to fit into agentic workflows. This will give a huge boost to agentic performance!\n\nFollowing ChatGPTâ€™s breakaway success at answering questions, a lot of LLM development focused on providing a good consumer experience. So LLMs were tuned to answer questions (â€œWhy did Shakespeare write Macbeth?â€) or follow human-provided instructions (â€œExplain why Shakespeare wrote Macbethâ€). A large fraction of the datasets for instruction tuning guide models to provide more helpful responses to human-written questions and instructions of the sort one might ask a consumer-facing LLM like those offered by the web interfaces of ChatGPT, Claude, or Gemini.\n\nBut agentic workloads call on different behaviors. Rather than directly generating responses for consumers, AI software may use a model in part of an iterative workflow to reflect on its own output, use tools, write plans, and collaborate in a multi-agent setting. Major model makers are increasingly optimizing models to be used in AI agents as well.\n\nTake tool use (or function calling). If an LLM is asked about the current weather, it wonâ€™t be able to derive the information needed from its training data. Instead, it might generate a request for an API call to get that information. Even before GPT-4 natively supported function calls, application developers were already using LLMs to generate function calls, but by writing more complex prompts (such as variations of ReAct prompts) that tell the LLM what functions are available and then have the LLM generate a string that a separate software routine parses (perhaps with regular expressions) to figure out if it wants to call a function.\n\nGenerating such calls became much more reliable after GPT-4 and then many other models natively supported function calling. Today, LLMs can decide to call functions to search for information for retrieval augmented generation (RAG), execute code,  send emails, place orders online, and much more.\n\nRecently, Anthropic released a version of its model that is capable of computer use, using mouse-clicks and keystrokes to operate a computer (usually a virtual machine). Iâ€™ve enjoyed playing with the demo. While other teams have been prompting LLMs to use computers to build a new generation of RPA (robotic process automation) applications, native support for computer use by a major LLM provider is a great step forward. This will help many developers!\n\nAs agentic workflows mature, here is what I am seeing:\n- First, many developers are prompting LLMs to carry out the agentic behaviors they want. This allows for quick, rich exploration!\n- In a much smaller number of cases, developers who are working on very valuable applications will fine-tune LLMs to carry out particular agentic functions more reliably. For example, even though many LLMs support function calling natively, they do so by taking as input a description of the functions available and then (hopefully) generating output tokens to request the right function call. For mission-critical applications where generating the right function call is important, fine-tuning a model for your applicationâ€™s specific function calls significantly increases reliability. (But please avoid premature optimization! Today I still see too many teams fine-tuning when they should probably spend more time on prompting before they resort to this.)\n- Finally, when a capability such as tool use or computer use appears valuable to many developers, major LLM providers are building these capabilities directly into their models. Even though OpenAI o1-previewâ€™s advanced reasoning helps consumers, I expect that it will be even more useful for agentic reasoning and planning.\n\nMost LLMs have been optimized for answering questions primarily to deliver a good consumer experience, and weâ€™ve been able to â€œgraftâ€ them into complex agentic workflows to build valuable applications. The trend of LLMs built to support particular operations in agents natively will create a lot of lift for agentic performance. Iâ€™m confident that large agentic performance gains in this direction will be realized in the next few years.\n\n[Original text: https://t.co/gginTyOgwe ]",
    "createdAt": "Thu Nov 14 17:44:22 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 321,
    "replyCount": 83,
    "likeCount": 1838,
    "quoteCount": 34,
    "viewCount": 165308,
    "bookmarkCount": 1118,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å¤§è¯­è¨€æ¨¡å‹ (LLMs) é€šå¸¸æ˜¯ä¸ºäº†å›ç­”äººä»¬çš„é—®é¢˜è€Œä¼˜åŒ–çš„ã€‚ä½†ç›®å‰å­˜åœ¨ä¸€ç§è¶‹åŠ¿ï¼Œæ¨¡å‹ä¹Ÿæ­£åœ¨è¢«ä¼˜åŒ–ä»¥æ›´å¥½åœ°èå…¥ AI æ™ºèƒ½ä½“ (AI Agent) å·¥ä½œæµã€‚è¿™å°†æå¤§åœ°æå‡æ™ºèƒ½ä½“çš„æ€§èƒ½ï¼\n\nåœ¨ ChatGPT åœ¨å›ç­”é—®é¢˜æ–¹é¢å–å¾—çªç ´æ€§æˆåŠŸä¹‹åï¼Œè®¸å¤šå¤§è¯­è¨€æ¨¡å‹çš„å¼€å‘éƒ½ä¸“æ³¨äºæä¾›è‰¯å¥½çš„æ¶ˆè´¹è€…ä½“éªŒã€‚å› æ­¤ï¼Œå¤§è¯­è¨€æ¨¡å‹è¢«å¾®è°ƒï¼Œæ—¨åœ¨å›ç­”å„ç§é—®é¢˜ï¼ˆä¾‹å¦‚â€œèå£«æ¯”äºšä¸ºä½•å†™ã€Šéº¦å…‹ç™½ã€‹ï¼Ÿâ€ï¼‰æˆ–éµå¾ªäººç±»æä¾›çš„æŒ‡ä»¤ï¼ˆä¾‹å¦‚â€œè§£é‡Šèå£«æ¯”äºšä¸ºä½•å†™ã€Šéº¦å…‹ç™½ã€‹â€ï¼‰ã€‚å¤§é‡ç”¨äºæŒ‡ä»¤å¾®è°ƒçš„æ•°æ®é›†å¼•å¯¼æ¨¡å‹ä¸ºäººç±»ç¼–å†™çš„é—®é¢˜å’ŒæŒ‡ä»¤æä¾›æ›´æœ‰å¸®åŠ©çš„å“åº”ï¼Œè¿™äº›é—®é¢˜å’ŒæŒ‡ä»¤ç±»ä¼¼äºäººä»¬å¯èƒ½ä¼šé€šè¿‡ ChatGPTã€Claude æˆ– Gemini ç­‰é¢å‘æ¶ˆè´¹è€…çš„åœ¨çº¿ç•Œé¢æå‡ºã€‚\n\nç„¶è€Œï¼Œæ™ºèƒ½ä½“çš„å·¥ä½œè´Ÿè½½å¯¹æ¨¡å‹è¡Œä¸ºæœ‰ä¸åŒçš„è¦æ±‚ã€‚AI è½¯ä»¶å¯èƒ½ä¸ä¼šç›´æ¥ä¸ºæ¶ˆè´¹è€…ç”Ÿæˆå“åº”ï¼Œè€Œæ˜¯å°†æ¨¡å‹ä½œä¸ºè¿­ä»£å·¥ä½œæµçš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºå®¡è§†è‡ªèº«çš„è¾“å‡ºã€ä½¿ç”¨å·¥å…·ã€ç¼–å†™è®¡åˆ’ï¼Œå¹¶åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­è¿›è¡Œåä½œã€‚ä¸»æµæ¨¡å‹åˆ¶é€ å•†ä¹Ÿæ—¥ç›Šä¼˜åŒ–å…¶æ¨¡å‹ï¼Œä½¿å…¶æ›´å¥½åœ°ç”¨äº AI æ™ºèƒ½ä½“ã€‚\n\nä»¥å·¥å…·ä½¿ç”¨ï¼ˆæˆ–å‡½æ•°è°ƒç”¨ï¼‰ä¸ºä¾‹ã€‚å¦‚æœä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹è¢«é—®åŠå½“å‰å¤©æ°”ï¼Œå®ƒæ— æ³•ä»å…¶è®­ç»ƒæ•°æ®ä¸­ç›´æ¥è·å–æ‰€éœ€ä¿¡æ¯ã€‚ç›¸åï¼Œå®ƒå¯èƒ½ä¼šç”Ÿæˆä¸€ä¸ª API è°ƒç”¨è¯·æ±‚æ¥è·å–è¿™äº›ä¿¡æ¯ã€‚ç”šè‡³åœ¨ GPT-4 åŸç”Ÿæ”¯æŒå‡½æ•°è°ƒç”¨ä¹‹å‰ï¼Œåº”ç”¨ç¨‹åºå¼€å‘äººå‘˜å°±å·²ç»åœ¨ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå‡½æ•°è°ƒç”¨ã€‚ä»–ä»¬é€šè¿‡ç¼–å†™æ›´å¤æ‚çš„æç¤ºï¼ˆä¾‹å¦‚ ReAct æç¤ºçš„å˜ä½“ï¼‰æ¥å‘ŠçŸ¥å¤§è¯­è¨€æ¨¡å‹å¯ç”¨çš„å‡½æ•°ï¼Œç„¶åè®©å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå†ç”±å•ç‹¬çš„è½¯ä»¶ä¾‹ç¨‹ï¼ˆå¯èƒ½ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰è¿›è¡Œè§£æï¼Œä»¥å†³å®šæ˜¯å¦è°ƒç”¨æŸä¸ªå‡½æ•°ã€‚\n\nåœ¨ GPT-4 å’Œè®¸å¤šå…¶ä»–æ¨¡å‹åŸç”Ÿæ”¯æŒå‡½æ•°è°ƒç”¨ä¹‹åï¼Œç”Ÿæˆè¿™ç±»å‡½æ•°è°ƒç”¨çš„å¯é æ€§å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚å¦‚ä»Šï¼Œå¤§è¯­è¨€æ¨¡å‹å¯ä»¥å†³å®šè°ƒç”¨å‡½æ•°æ¥æœç´¢ä¿¡æ¯ä»¥è¿›è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)ï¼Œæ‰§è¡Œä»£ç ï¼Œå‘é€ç”µå­é‚®ä»¶ï¼Œåœ¨çº¿ä¸‹å•ç­‰ç­‰ã€‚\n\næœ€è¿‘ï¼ŒAnthropic å‘å¸ƒäº†ä¸€ä¸ªèƒ½å¤Ÿæ“ä½œè®¡ç®—æœºçš„æ¨¡å‹ç‰ˆæœ¬ï¼Œè¯¥æ¨¡å‹é€šè¿‡æ¨¡æ‹Ÿé¼ æ ‡ç‚¹å‡»å’Œé”®ç›˜è¾“å…¥æ¥æ§åˆ¶è®¡ç®—æœºï¼ˆé€šå¸¸æ˜¯è™šæ‹Ÿæœºï¼‰ã€‚æˆ‘å¾ˆé«˜å…´ä½“éªŒäº†è¿™æ¬¾æ¼”ç¤ºã€‚è™½ç„¶å…¶ä»–å›¢é˜Ÿä¸€ç›´åœ¨é€šè¿‡æç¤ºå¤§è¯­è¨€æ¨¡å‹æ¥ä½¿ç”¨è®¡ç®—æœºï¼Œä»è€Œæ„å»ºæ–°ä¸€ä»£çš„æœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ– (RPA) åº”ç”¨ç¨‹åºï¼Œä½†ä¸»æµå¤§è¯­è¨€æ¨¡å‹æä¾›å•†å¯¹è®¡ç®—æœºä½¿ç”¨çš„åŸç”Ÿæ”¯æŒæ— ç–‘æ˜¯ä¸€ä¸ªå·¨å¤§çš„è¿›æ­¥ã€‚è¿™å°†ä¸ºè®¸å¤šå¼€å‘è€…å¸¦æ¥ä¾¿åˆ©ï¼\n\néšç€æ™ºèƒ½ä½“å·¥ä½œæµçš„æ—¥ç›Šæˆç†Ÿï¼Œæˆ‘è§‚å¯Ÿåˆ°ä»¥ä¸‹å‡ ç‚¹ï¼š\n- é¦–å…ˆï¼Œè®¸å¤šå¼€å‘äººå‘˜æ­£åœ¨é€šè¿‡æç¤ºå¤§è¯­è¨€æ¨¡å‹æ¥æ‰§è¡Œä»–ä»¬æƒ³è¦çš„æ™ºèƒ½ä½“è¡Œä¸ºã€‚è¿™ä½¿å¾—å¿«é€Ÿã€ä¸°å¯Œçš„æ¢ç´¢æˆä¸ºå¯èƒ½ï¼\n- åœ¨æ•°é‡ç›¸å¯¹è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œè‡´åŠ›äºå¼€å‘é«˜ä»·å€¼åº”ç”¨ç¨‹åºçš„å¼€å‘äººå‘˜ä¼šå¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æ›´å¯é åœ°æ‰§è¡Œç‰¹å®šçš„æ™ºèƒ½ä½“åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œå°½ç®¡è®¸å¤šå¤§è¯­è¨€æ¨¡å‹åŸç”Ÿæ”¯æŒå‡½æ•°è°ƒç”¨ï¼Œä½†å®ƒä»¬é€šå¸¸æ¥æ”¶å¯ç”¨å‡½æ•°çš„æè¿°ä½œä¸ºè¾“å…¥ï¼Œç„¶åï¼ˆæˆ‘ä»¬æœŸæœ›ï¼‰ç”Ÿæˆè¾“å‡º Token æ¥è¯·æ±‚æ­£ç¡®çš„å‡½æ•°è°ƒç”¨ã€‚å¯¹äºé‚£äº›ç”Ÿæˆæ­£ç¡®å‡½æ•°è°ƒç”¨è‡³å…³é‡è¦çš„ä»»åŠ¡å…³é”®å‹åº”ç”¨ç¨‹åºï¼Œä¸ºæ‚¨çš„åº”ç”¨ç‰¹å®šå‡½æ•°è°ƒç”¨å¾®è°ƒæ¨¡å‹èƒ½å¤Ÿæ˜¾è‘—æé«˜å¯é æ€§ã€‚ ï¼ˆä½†è¯·é¿å…è¿‡æ—©ä¼˜åŒ–ï¼æˆ‘ä»ç„¶å‘ç°è®¸å¤šå›¢é˜Ÿåœ¨åº”è¯¥èŠ±æ›´å¤šæ—¶é—´åœ¨æç¤ºå·¥ç¨‹ä¸Šæ—¶ï¼Œå°±æ€¥äºè¿›è¡Œå¾®è°ƒã€‚ï¼‰\n- æœ€åï¼Œå½“å·¥å…·ä½¿ç”¨æˆ–è®¡ç®—æœºä½¿ç”¨ç­‰åŠŸèƒ½å¯¹è®¸å¤šå¼€å‘è€…éƒ½å±•ç°å‡ºå·¨å¤§ä»·å€¼æ—¶ï¼Œä¸»æµå¤§è¯­è¨€æ¨¡å‹æä¾›å•†ä¼šå°†è¿™äº›åŠŸèƒ½ç›´æ¥å†…ç½®åˆ°æ¨¡å‹ä¸­ã€‚å°½ç®¡ OpenAI o1-preview çš„é«˜çº§æ¨ç†èƒ½åŠ›æœ‰åŠ©äºæ¶ˆè´¹è€…ï¼Œä½†æˆ‘é¢„è®¡å®ƒå¯¹äºæ™ºèƒ½ä½“æ¨ç†å’Œè§„åˆ’å°†å‘æŒ¥æ›´å¤§çš„ä½œç”¨ã€‚\n\nå¤§å¤šæ•°å¤§è¯­è¨€æ¨¡å‹ä¸»è¦ä¸ºäº†æä¾›è‰¯å¥½çš„æ¶ˆè´¹è€…ä½“éªŒè€Œè¢«ä¼˜åŒ–æ¥å›ç­”é—®é¢˜ï¼Œè€Œæˆ‘ä»¬å·²ç»èƒ½å¤Ÿå°†å®ƒä»¬â€œæ•´åˆâ€åˆ°å¤æ‚çš„æ™ºèƒ½ä½“å·¥ä½œæµä¸­ï¼Œä»è€Œæ„å»ºæœ‰ä»·å€¼çš„åº”ç”¨ç¨‹åºã€‚å¤§è¯­è¨€æ¨¡å‹åŸç”Ÿæ”¯æŒæ™ºèƒ½ä½“ä¸­ç‰¹å®šæ“ä½œçš„è¶‹åŠ¿å°†ä¸ºæ™ºèƒ½ä½“æ€§èƒ½å¸¦æ¥å·¨å¤§çš„æå‡ã€‚æˆ‘åšä¿¡ï¼Œæœªæ¥å‡ å¹´å†…ï¼Œè¿™ä¸ªæ–¹å‘å°†å®ç°æ˜¾è‘—çš„æ™ºèƒ½ä½“æ€§èƒ½é£è·ƒã€‚\n\n[Original text: https://t.co/gginTyOgwe ]"
  },
  {
    "id": "1856791398592516132",
    "url": "https://x.com/AndrewYNg/status/1856791398592516132",
    "text": "@SnowflakeDB @LandingAI Thanks you for having me! It's a pleasure as always to speak at BUILD.",
    "createdAt": "Wed Nov 13 20:09:01 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 0,
    "likeCount": 11,
    "quoteCount": 0,
    "viewCount": 3400,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@SnowflakeDB @LandingAI æ„Ÿè°¢ä½ ä»¬çš„é‚€è¯·ï¼å¾ˆé«˜å…´èƒ½åƒå¾€å¸¸ä¸€æ ·ï¼Œåœ¨ BUILD å‘è¡¨è®²è¯ã€‚"
  },
  {
    "id": "1856779913757691922",
    "url": "https://x.com/AndrewYNg/status/1856779913757691922",
    "text": "New short course: Safe and Reliable AI via Guardrails! Learn to create production-ready, reliable LLM applications with guardrails in this new course, built in collaboration with @guardrails_ai and taught by its CEO and co-founder,  @ShreyaR.\n\nI see many companies worry about the reliability of LLM-based systems -- will they hallucinate a catastrophically bad response? -- which slows down investing in building them and transitioning prototypes to deployment.  That LLMs generate probabilistic outputs has made them particularly hard to deploy in highly regulated industries or in safety-critical environments. \n\nFortunately, there are good guardrail tools that give a significant new layer of control and reliability/safety. They act as a protective framework that can prevent your application from revealing incorrect, irrelevant, or confidential information, and they are an important part of what it takes to actually get prototypes to deployment. \n\nThis course will walk you through common failure modes of LLM-powered applications (like hallucinations or revealing personally identifiable information). It will show you how to build guardrails from scratch to mitigate them. Youâ€™ll also learn how to access a variety of pre-built guardrails on the GuardrailsAI hub that are ready to integrate into your projects.\n\nYou'll implement these guardrails in the context of a RAG-powered customer service chatbot for a small pizzeria. Specifically, you'll:\n- Explore common failure modes like hallucinations, going off-topic, revealing sensitive information, or responses that can harm the pizzeria's reputation.\n- Learn to mitigate these failure modes with input and output guards that check inputs and/or outputs\n- Create a guardrail to prevent the chatbot from discussing sensitive topics, such as a confidential project at the pizza shop\n- Detect hallucinations by ensuring responses are grounded in trusted documents\n- Add a Personal Identifiable Information (PII) guardrail to detect and redact sensitive information in user prompts and in LLM outputs\n- Set up a guardrail to limit the chatbotâ€™s responses to topics relevant to the pizza shop, keeping interactions on-topic\n- Configure a guardrail that prevents your chatbot from mentioning any competitors using a name detection pipeline consisting of conditional logic that routes to an exact match or a threshold check with named entity recognition \n\nGuardrails are an important part of the practical building and deployment of LLM-based applications today. This course will show you how to make your applications more reliable and more ready for real-world deployment.\n\nPlease sign up here: https://t.co/C1fwsOn9yy",
    "createdAt": "Wed Nov 13 19:23:23 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 144,
    "replyCount": 55,
    "likeCount": 722,
    "quoteCount": 10,
    "viewCount": 105956,
    "bookmarkCount": 369,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°çŸ­æœŸè¯¾ç¨‹ï¼šé€šè¿‡å®‰å…¨æŠ¤æ  (Guardrails) å®ç°å®‰å…¨å¯é çš„ AIï¼å­¦ä¹ å¦‚ä½•åˆ©ç”¨å®‰å…¨æŠ¤æ æ¥åˆ›å»ºå¯æŠ•å…¥ç”Ÿäº§ä¸”å¯é çš„ å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºã€‚è¿™é—¨æ–°è¯¾ç¨‹æ˜¯ä¸ @guardrails_ai åˆä½œå¼€å‘çš„ï¼Œç”±å…¶é¦–å¸­æ‰§è¡Œå®˜å…¼è”åˆåˆ›å§‹äºº @ShreyaR äº²è‡ªè®²æˆã€‚\n\næˆ‘å‘ç°è®¸å¤šå…¬å¸éƒ½æ‹…å¿ƒåŸºäº å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„ç³»ç»Ÿèƒ½å¦ä¿æŒå¯é â€”â€”å®ƒä»¬æ˜¯å¦ä¼šçªç„¶å‡ºç°å¹»è§‰ï¼Œç»™å‡ºç¾éš¾æ€§çš„é”™è¯¯å›å¤ï¼Ÿâ€”â€”è¿™ç§æ‹…å¿§å‡ç¼“äº†ä¼ä¸šåœ¨æ„å»ºæ­¤ç±»ç³»ç»Ÿä¸Šçš„æŠ•å…¥ï¼Œä¹Ÿé˜»ç¢äº†å°†åŸå‹äº§å“è½¬åŒ–ä¸ºå®é™…éƒ¨ç½²çš„è¿›ç¨‹ã€‚ å¤§è¯­è¨€æ¨¡å‹ (LLL) ç”Ÿæˆæ¦‚ç‡æ€§è¾“å‡ºçš„ç‰¹æ€§ï¼Œä½¿å¾—å®ƒä»¬åœ¨å—åˆ°ä¸¥æ ¼ç›‘ç®¡çš„è¡Œä¸šæˆ–å¯¹å®‰å…¨æ€§è¦æ±‚æé«˜çš„ç¯å¢ƒä¸­éƒ¨ç½²æ—¶é¢ä¸´ç‰¹æ®ŠæŒ‘æˆ˜ã€‚\n\nå¹¸è¿çš„æ˜¯ï¼Œç°åœ¨æœ‰å‡ºè‰²çš„å®‰å…¨æŠ¤æ  (Guardrails) å·¥å…·ï¼Œå®ƒä»¬ä¸º å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºæä¾›äº†æ˜¾è‘—å¢å¼ºçš„æ§åˆ¶åŠ›ã€å¯é æ€§å’Œå®‰å…¨æ€§ã€‚è¿™äº›å·¥å…·å°±åƒä¸€ä¸ªä¿æŠ¤æ€§æ¡†æ¶ï¼Œèƒ½æœ‰æ•ˆé˜²æ­¢åº”ç”¨ç¨‹åºæ³„éœ²ä¸æ­£ç¡®ã€ä¸ç›¸å…³æˆ–æœºå¯†ä¿¡æ¯ã€‚å®ƒä»¬æ˜¯ç¡®ä¿åŸå‹äº§å“èƒ½å¤ŸæˆåŠŸæŠ•å…¥å®é™…éƒ¨ç½²çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚\n\næœ¬è¯¾ç¨‹å°†å¸¦æ‚¨æ·±å…¥äº†è§£ å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨åº”ç”¨ç¨‹åºçš„å¸¸è§æ•…éšœæ¨¡å¼ï¼ˆæ¯”å¦‚å‡ºç°å¹»è§‰æˆ–æ³„éœ²ä¸ªäººèº«ä»½ä¿¡æ¯ (PII)ï¼‰ã€‚å®ƒä¼šå‘æ‚¨å±•ç¤ºå¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºå®‰å…¨æŠ¤æ æ¥æœ‰æ•ˆç¼“è§£è¿™äº›é—®é¢˜ã€‚æ‚¨è¿˜å°†å­¦ä¹ å¦‚ä½•è®¿é—® GuardrailsAI ä¸­å¿ƒæä¾›çš„å„ç§é¢„æ„å»ºå®‰å…¨æŠ¤æ ï¼Œè¿™äº›æŠ¤æ å¯éšæ—¶é›†æˆåˆ°æ‚¨çš„é¡¹ç›®ä¸­ã€‚\n\næ‚¨å°†åœ¨ä¸€ä¸ªä¸ºå°å‹æŠ«è¨åº—æ‰“é€ çš„ RAG é©±åŠ¨çš„å®¢æˆ·æœåŠ¡èŠå¤©æœºå™¨äººåœºæ™¯ä¸­ï¼Œäº²æ‰‹å®è·µå¦‚ä½•å®æ–½è¿™äº›å®‰å…¨æŠ¤æ ã€‚å…·ä½“æ¥è¯´ï¼Œæ‚¨å°†ï¼š\n- æ¢ç´¢å¸¸è§çš„æ•…éšœæ¨¡å¼ï¼Œä¾‹å¦‚å‡ºç°å¹»è§‰ã€èŠå¤©è·‘é¢˜ã€æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼Œæˆ–ç»™å‡ºå¯èƒ½æŸå®³æŠ«è¨åº—å£°èª‰çš„å›å¤ã€‚\n- å­¦ä¹ å¦‚ä½•åˆ©ç”¨æ£€æŸ¥è¾“å…¥å’Œ/æˆ–è¾“å‡ºçš„è¾“å…¥/è¾“å‡ºå®ˆå« (input/output guards) æ¥ç¼“è§£è¿™äº›æ•…éšœæ¨¡å¼ã€‚\n- åˆ›å»ºä¸€ä¸ªå®‰å…¨æŠ¤æ ï¼Œä»¥é˜²æ­¢èŠå¤©æœºå™¨äººè®¨è®ºæ•æ„Ÿè¯é¢˜ï¼Œä¾‹å¦‚æŠ«è¨åº—çš„æœºå¯†é¡¹ç›®ã€‚\n- é€šè¿‡ç¡®ä¿èŠå¤©æœºå™¨äººçš„å›å¤éƒ½åŸºäºå¯ä¿¡èµ–çš„æ–‡æ¡£ï¼Œæ¥æ£€æµ‹å¹»è§‰ã€‚\n- æ·»åŠ ä¸€ä¸ªä¸ªäººèº«ä»½ä¿¡æ¯ (PII) å®‰å…¨æŠ¤æ ï¼Œä»¥æ£€æµ‹å¹¶é®ç›–ç”¨æˆ·æç¤ºå’Œ å¤§è¯­è¨€æ¨¡å‹ (LLM) è¾“å‡ºä¸­çš„æ•æ„Ÿä¿¡æ¯ã€‚\n- è®¾ç½®ä¸€ä¸ªå®‰å…¨æŠ¤æ ï¼Œå°†èŠå¤©æœºå™¨äººçš„å›å¤é™å®šåœ¨ä¸æŠ«è¨åº—ç›¸å…³çš„è¯é¢˜ä¸Šï¼Œä»è€Œä¿æŒå¯¹è¯å§‹ç»ˆå›´ç»•ä¸»é¢˜ã€‚\n- é…ç½®ä¸€ä¸ªå®‰å…¨æŠ¤æ ï¼Œé˜²æ­¢æ‚¨çš„èŠå¤©æœºå™¨äººæåŠä»»ä½•ç«äº‰å¯¹æ‰‹ã€‚è¿™é€šè¿‡ä¸€ä¸ªåç§°æ£€æµ‹ç®¡é“å®ç°ï¼Œè¯¥ç®¡é“åŒ…å«æ¡ä»¶é€»è¾‘ï¼Œèƒ½å¤Ÿè·¯ç”±åˆ°ç²¾ç¡®åŒ¹é…æˆ–ç»“åˆå‘½åå®ä½“è¯†åˆ«è¿›è¡Œé˜ˆå€¼æ£€æŸ¥ã€‚\n\nå¦‚ä»Šï¼Œå®‰å…¨æŠ¤æ æ˜¯ å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºå®é™…æ„å»ºå’Œéƒ¨ç½²è¿‡ç¨‹ä¸­ä¸å¯æˆ–ç¼ºçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æœ¬è¯¾ç¨‹å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•è®©æ‚¨çš„åº”ç”¨ç¨‹åºæ›´å¯é ï¼Œå¹¶ä¸ºå®é™…éƒ¨ç½²åšå¥½æ›´å……åˆ†çš„å‡†å¤‡ã€‚\n\nè¯·åœ¨æ­¤å¤„æŠ¥åï¼šhttps://t.co/C1fwsOn9yy"
  },
  {
    "id": "1856402761900011622",
    "url": "https://x.com/AndrewYNg/status/1856402761900011622",
    "text": "Chatting with OpenAIâ€™s @karinanguyen_ who joined OpenAI earlier this year and within 6 months co-created and shipped Canvas. I really respect teams that can move fast. That OpenAI, even as a large-ish company, can ship at this pace is fantastic! https://t.co/xuxH1hZZiV",
    "createdAt": "Tue Nov 12 18:24:43 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 66,
    "replyCount": 64,
    "likeCount": 1192,
    "quoteCount": 8,
    "viewCount": 181956,
    "bookmarkCount": 101,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘æ­£åœ¨ä¸ OpenAI çš„ @karinanguyen_ äº¤æµï¼Œå¥¹äºä»Šå¹´æ—©äº›æ—¶å€™åŠ å…¥ OpenAIï¼Œå¹¶åœ¨å…­ä¸ªæœˆå†…å…±åŒåˆ›å»ºå¹¶æˆåŠŸæ¨å‡ºäº† Canvasã€‚æˆ‘éå¸¸æ•¬ä½©é‚£äº›èƒ½å¤Ÿå¿«é€Ÿè¡ŒåŠ¨çš„å›¢é˜Ÿã€‚OpenAI å³ä½¿ä½œä¸ºä¸€å®¶è§„æ¨¡ç›¸å¯¹è¾ƒå¤§çš„å…¬å¸ï¼Œä¹Ÿèƒ½ä¿æŒå¦‚æ­¤å¿«çš„ç ”å‘å’Œäº§å“ä¸Šçº¿é€Ÿåº¦ï¼Œè¿™çœŸæ˜¯å¤ªæ£’äº†ï¼https://t.co/xuxH1hZZiV"
  },
  {
    "id": "1854587401018261962",
    "url": "https://x.com/AndrewYNg/status/1854587401018261962",
    "text": "New short course: LLMs as Operating Systems: Agent Memory, created with @Letta_AI, and taught by its founders @charlespacker and @sarahwooders.\n\nAn LLM's input context window has limited space. Using a longer input context also costs more and results in slower processing. So, managing what's stored in this context window is important.\n\nIn the innovative paper MemGPT: Towards LLMs as Operating Systems, its authors (which include the instructors) proposed using an LLM agent to manage this context window. Their system uses a large persistent memory that stores everything that could be included in the input context, and  an agent decides   what is actually included.\n\nTake the example of building a chatbot that needs to remember what's been said earlier in a conversation (perhaps over many days of interaction with a user). As the conversation's length grows, the memory management agent will move information from the input context to a persistent searchable database; summarize information to keep relevant facts in the input context; and restore relevant conversation elements from further back in time. This allows a chatbot to keep what's currently most relevant in its input context memory to generate the next response.\n\nWhen I read the original MemGPT paper, I thought it was an innovative technique for handling memory for LLMs. The open-source Letta framework, which we'll use in this course, makes MemGPT easy to implement. It adds memory to your LLM agents and gives them transparent long-term memory.\n\nIn detail, youâ€™ll learn:\n- How to build an agent that can edit its own limited input context memory, using tools and multi-step reasoning\n- What is a memory hierarchy (an idea from computer operating systems, which use a cache to speed up memory access), and how these ideas apply to managing the LLM input context (where the input context window is a \"cache\" storing the most relevant information; and an agent decides what to move in and out of this to/from a larger persistent storage system)\n- How to implement multi-agent collaboration by letting different agents share blocks of memory\n\nThis course will give you a sophisticated understanding of memory management for LLMs, which is important for chatbots having long conversations, and for complex agentic workflows.\n\nPlease sign up here!  https://t.co/XMlBifnwVa",
    "createdAt": "Thu Nov 07 18:11:07 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 332,
    "replyCount": 109,
    "likeCount": 2014,
    "quoteCount": 30,
    "viewCount": 198352,
    "bookmarkCount": 1509,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°è¯¾ç¨‹ï¼š å°†å¤§è¯­è¨€æ¨¡å‹ (Large Language Model/LLM) è§†ä¸ºæ“ä½œç³»ç»Ÿï¼š AI æ™ºèƒ½ä½“ (AI Agent) è®°å¿†ã€‚æœ¬è¯¾ç¨‹ç”± @Letta_AI å…±åŒåˆ›å»ºï¼Œå¹¶ç”±å…¶åˆ›å§‹äºº @charlespacker å’Œ @sarahwooders äº²è‡ªæˆè¯¾ã€‚\n\nå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„è¾“å…¥ä¸Šä¸‹æ–‡çª—å£ç©ºé—´æœ‰é™ã€‚ä¸ä»…å¦‚æ­¤ï¼Œä½¿ç”¨æ›´é•¿çš„è¾“å…¥ä¸Šä¸‹æ–‡é€šå¸¸æ„å‘³ç€æ›´é«˜çš„æˆæœ¬å’Œæ›´æ…¢çš„å¤„ç†é€Ÿåº¦ã€‚å› æ­¤ï¼Œæœ‰æ•ˆç®¡ç†è¿™ä¸ªä¸Šä¸‹æ–‡çª—å£ä¸­å­˜å‚¨çš„å†…å®¹å˜å¾—è‡³å…³é‡è¦ã€‚\n\nåœ¨ä¸€ç¯‡æå…·åˆ›æ–°æ€§çš„è®ºæ–‡ã€ŠMemGPT: Towards LLMs as Operating Systemsã€‹ä¸­ï¼Œè®ºæ–‡ä½œè€…ï¼ˆå…¶ä¸­ä¹ŸåŒ…æ‹¬æœ¬è¯¾ç¨‹çš„è®²å¸ˆä»¬ï¼‰æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼šåˆ©ç”¨ä¸€ä¸ª AI æ™ºèƒ½ä½“æ¥ä¸“é—¨ç®¡ç† LLM çš„ä¸Šä¸‹æ–‡çª—å£ã€‚ä»–ä»¬çš„ç³»ç»Ÿè®¾è®¡äº†ä¸€ä¸ªåºå¤§çš„æŒä¹…æ€§è®°å¿†å­˜å‚¨åŒºï¼Œç”¨äºå­˜æ”¾æ‰€æœ‰å¯èƒ½éœ€è¦è¢«çº³å…¥è¾“å…¥ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œç„¶åç”± AI æ™ºèƒ½ä½“æ¥æ™ºèƒ½åœ°å†³å®šå“ªäº›ä¿¡æ¯åº”è¯¥è¢«å®é™…åŒ…å«è¿›æ¥ã€‚\n\nä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾æˆ‘ä»¬è¦æ„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œå®ƒéœ€è¦è®°ä½åœ¨é•¿æ—¶é—´å¯¹è¯ä¸­ï¼ˆç”šè‡³å¯èƒ½è·¨è¶Šæ•°å¤©çš„ç”¨æˆ·äº’åŠ¨ï¼‰ä¹‹å‰è¯´è¿‡çš„å†…å®¹ã€‚éšç€å¯¹è¯é•¿åº¦çš„å¢åŠ ï¼Œè®°å¿†ç®¡ç† AI æ™ºèƒ½ä½“å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼šå®ƒä¼šå°†éƒ¨åˆ†ä¿¡æ¯ä»å½“å‰çš„è¾“å…¥ä¸Šä¸‹æ–‡ç§»è‡³ä¸€ä¸ªæŒä¹…ä¸”å¯æœç´¢çš„æ•°æ®åº“ä¸­ï¼›åŒæ—¶ï¼Œå®ƒä¼šæ€»ç»“ä¿¡æ¯ï¼Œä»¥ç¡®ä¿ç›¸å…³çš„å…³é”®äº‹å®å§‹ç»ˆä¿ç•™åœ¨è¾“å…¥ä¸Šä¸‹æ–‡é‡Œï¼›å¹¶ä¸”ï¼Œå®ƒèƒ½å¤Ÿä»æ›´æ—©çš„å¯¹è¯è®°å½•ä¸­æ¢å¤å‡ºç›¸å…³çš„å¯¹è¯å…ƒç´ ã€‚è¿™ç§æœºåˆ¶ç¡®ä¿äº†èŠå¤©æœºå™¨äººæ€»èƒ½å°†å½“å‰æœ€ç›¸å…³çš„ä¿¡æ¯ä¿ç•™åœ¨å®ƒçš„è¾“å…¥ä¸Šä¸‹æ–‡è®°å¿†ä¸­ï¼Œä»è€Œç”Ÿæˆä¸‹ä¸€ä¸ªå‡†ç¡®çš„å›å¤ã€‚\n\nå½“æˆ‘é˜…è¯»æœ€åˆçš„ MemGPT è®ºæ–‡æ—¶ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ç§å¤„ç† LLM è®°å¿†é—®é¢˜çš„åˆ›æ–°æŠ€æœ¯ã€‚æˆ‘ä»¬å°†åœ¨æœ¬è¯¾ç¨‹ä¸­ä½¿ç”¨çš„å¼€æº Letta æ¡†æ¶ï¼Œè®© MemGPT çš„å®ç°å˜å¾—å¼‚å¸¸ç®€å•ã€‚å®ƒä¸ºä½ çš„ AI æ™ºèƒ½ä½“å¢åŠ äº†è®°å¿†èƒ½åŠ›ï¼Œå¹¶èµ‹äºˆå®ƒä»¬ä¸€ç§â€œé€æ˜â€çš„é•¿æœŸè®°å¿†ï¼Œå³ AI æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªç„¶ä¸”æ— éœ€é¢å¤–å¹²é¢„åœ°è®¿é—®å’Œåˆ©ç”¨è¿™äº›å†å²ä¿¡æ¯ã€‚\n\nå…·ä½“æ¥è¯´ï¼Œä½ å°†å­¦ä¹ ï¼š\n- å¦‚ä½•æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼Œä½¿å…¶èƒ½å¤Ÿåˆ©ç”¨å·¥å…·å’Œå¤šæ­¥éª¤æ¨ç†ï¼Œç¼–è¾‘è‡ªèº«æœ‰é™çš„è¾“å…¥ä¸Šä¸‹æ–‡è®°å¿†ã€‚\n- ä»€ä¹ˆæ˜¯è®°å¿†å±‚æ¬¡ç»“æ„ï¼ˆè¿™ä¸ªæ¦‚å¿µæºè‡ªè®¡ç®—æœºæ“ä½œç³»ç»Ÿï¼Œå…¶ä¸­ç¼“å­˜è¢«ç”¨æ¥åŠ é€Ÿè®°å¿†è®¿é—®ï¼‰ï¼Œä»¥åŠè¿™äº›æ€æƒ³å¦‚ä½•åº”ç”¨äºç®¡ç† LLM çš„è¾“å…¥ä¸Šä¸‹æ–‡ã€‚åœ¨è¿™é‡Œï¼Œè¾“å…¥ä¸Šä¸‹æ–‡çª—å£å¯ä»¥è¢«è§†ä¸ºä¸€ä¸ªâ€œç¼“å­˜â€ï¼Œå­˜å‚¨ç€æœ€ç›¸å…³çš„ä¿¡æ¯ï¼›è€Œ AI æ™ºèƒ½ä½“åˆ™è´Ÿè´£å†³å®šå“ªäº›ä¿¡æ¯åœ¨â€œç¼“å­˜â€ä¸æ›´å¤§çš„æŒä¹…å­˜å‚¨ç³»ç»Ÿä¹‹é—´è¿›è¡Œç§»å…¥å’Œç§»å‡ºã€‚\n- å¦‚ä½•é€šè¿‡è®©ä¸åŒçš„ AI æ™ºèƒ½ä½“å…±äº«è®°å¿†å—ï¼Œæ¥å®ç°å¤š AI æ™ºèƒ½ä½“åä½œã€‚\n\næœ¬è¯¾ç¨‹å°†å¸®åŠ©ä½ å¯¹ LLM çš„è®°å¿†ç®¡ç†å»ºç«‹èµ·ä¸€ä¸ªæ·±å…¥è€Œç²¾å¯†çš„ç†è§£ã€‚è¿™å¯¹äºéœ€è¦è¿›è¡Œé•¿æ—¶é—´å¯¹è¯çš„èŠå¤©æœºå™¨äººï¼Œä»¥åŠå¤„ç†å¤æ‚ AI æ™ºèƒ½ä½“å·¥ä½œæµ (agentic workflows) çš„åº”ç”¨æ¥è¯´ï¼Œéƒ½å…·æœ‰æå…¶é‡è¦çš„æ„ä¹‰ã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æ³¨å†Œï¼ https://t.co/XMlBifnwVa"
  },
  {
    "id": "1853653834490642801",
    "url": "https://x.com/AndrewYNg/status/1853653834490642801",
    "text": "Source: https://t.co/juDEKqJEBc",
    "createdAt": "Tue Nov 05 04:21:28 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 15,
    "replyCount": 6,
    "likeCount": 127,
    "quoteCount": 0,
    "viewCount": 38773,
    "bookmarkCount": 58,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "åŸæ–‡ä¸ºä¸€æ¡æ¨æ–‡ï¼Œæ¨æ–‡å†…å®¹åªåŒ…å«ä¸€ä¸ªé“¾æ¥ï¼Œå› æ­¤æ— æ³•è¿›è¡Œç¿»è¯‘ã€‚"
  },
  {
    "id": "1853653742509502571",
    "url": "https://x.com/AndrewYNg/status/1853653742509502571",
    "text": "It finally happened -- thanks to people learning to write AI code, Python is now the top programming language on GitHub! \n\nIf you want to learn Python, check out https://t.co/zpIxRSuky4's free course AI Python for Beginners.",
    "createdAt": "Tue Nov 05 04:21:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 363,
    "replyCount": 51,
    "likeCount": 2768,
    "quoteCount": 22,
    "viewCount": 192478,
    "bookmarkCount": 1309,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å®ƒç»ˆäºæ¥äº† -- å¾—ç›Šäºè¶Šæ¥è¶Šå¤šçš„äººå¼€å§‹å­¦ä¹ ç¼–å†™ AI ä»£ç ï¼ŒPython å¦‚ä»Šå·²æˆä¸º GitHub ä¸Šæœ€å—æ¬¢è¿çš„ç¼–ç¨‹è¯­è¨€ï¼\n\nå¦‚æœä½ ä¹Ÿæƒ³å­¦ä¹  Pythonï¼Œä¸å¦¨äº†è§£ä¸€ä¸‹ https://t.co/zpIxRSuky4 æä¾›çš„å…è´¹è¯¾ç¨‹ã€ŠAI Python for Beginnersã€‹ï¼ˆé¢å‘åˆå­¦è€…çš„ AI Pythonï¼‰ã€‚"
  },
  {
    "id": "1852107599254073821",
    "url": "https://x.com/AndrewYNg/status/1852107599254073821",
    "text": "Happy Halloween! ğŸƒ \n\nOn this spooky day, The Batch continues its annual tradition of exploring fears related to AI. This special edition has 5 articles: \n* AI Burns All the Energy \n* Innovation Dies\n* No Work for Coders\n* Benchmarks Are Meaningless\n* Synthetic Data Distorts Models\n\nAre these things we should worry about? Check it out here: https://t.co/Vt5xnhZToT",
    "createdAt": "Thu Oct 31 21:57:16 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 41,
    "replyCount": 48,
    "likeCount": 307,
    "quoteCount": 0,
    "viewCount": 46546,
    "bookmarkCount": 59,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¸‡åœ£èŠ‚å¿«ä¹ï¼ğŸƒ\n\nåœ¨è¿™ä¸ªç‰¹åˆ«çš„ä¸‡åœ£èŠ‚ï¼ŒThe Batch å»¶ç»­äº†æ¯å¹´æ¢ç´¢ä¸ AI (äººå·¥æ™ºèƒ½) ç›¸å…³æ‹…å¿§çš„ä¼ ç»Ÿã€‚æœ¬æœŸç‰¹è¾‘åŒ…å« 5 ç¯‡æ–‡ç« ï¼Œæ¢è®¨äº†ä»¥ä¸‹ä¸»é¢˜ï¼š\n* AI è€—å°½æ‰€æœ‰èƒ½æº\n* åˆ›æ–°åœæ»ä¸å‰\n* ç¨‹åºå‘˜å°†é¢ä¸´å¤±ä¸š\n* åŸºå‡†æµ‹è¯•å˜å¾—æ¯«æ— æ„ä¹‰\n* åˆæˆæ•°æ®è¯¯å¯¼æ¨¡å‹\n\nè¿™äº›æ˜¯æˆ‘ä»¬éœ€è¦æ‹…å¿§çš„é—®é¢˜å—ï¼Ÿç‚¹å‡»è¿™é‡Œäº†è§£è¯¦æƒ…ï¼šhttps://t.co/Vt5xnhZToT"
  },
  {
    "id": "1850912176896463328",
    "url": "https://x.com/AndrewYNg/status/1850912176896463328",
    "text": "Startups live or die by their ability to execute at speed. For large companies, too, the speed with which an innovation team is able to iterate has a huge impact on its odds of success. Generative AI makes it possible to quickly prototype AI capabilities. AI capabilities that used to take months can sometimes be built in days or hours by simply prompting a large language model. I find this speed exciting and have been thinking about how to help startups and large companies alike go faster.\n\nIâ€™ve been obsessed with speedy execution for a long time. When working on a project, I am loath to take two weeks to do something that I could do in one week. The price of moving at that pace is not that we take one week longer (which might be okay) but that weâ€™re 2x slower (which is not)!\n\nWhen building an AI-powered product, there are many steps in designing, building, shipping, and scaling the product that are distinct from building the AI capability, and our ability to execute these other steps has not sped up as much as the AI part. But the speed with which we can prototype AI creates significant pressure to speed up these other steps, too. If it took 6 months to collect data, train a supervised learning algorithm, and deploy the model to the cloud, it might be okay to take 2 months to get user feedback. But if it takes a week to build a prototype, waiting 2 months for feedback seems intolerably slow!\n\nIâ€™d like to focus on one key step of building applications: getting user feedback. A core part of the iterative workflow of designing and building a product (popularized by Eric Ries in his book The Lean Startup) is to build a prototype (or MVP, minimum viable product), get user feedback on it, and to use that feedback to drive improvements. The faster you can move through this loop â€” which may require many iterations â€” the faster you can design a product that fits the market. This is why AI Fund, a venture studio that I lead, uses many fast, scrappy tactics to get feedback.\n\nFor B2C (business to consumer) offerings, here is a menu of some options for getting customer feedback:\n1. Ask 3 friends or team members to look at the product and let you know what they think (this might take ~0.5 days).\n2. Ask 10 friends or team members to take a look (~2 days).\n3. Send it to 100 trusted/volunteer alpha testers (~1 week?).\n4. Send it to 1,000 users to get qualitative or quantitative feedback (~2 weeks?).\n5. Incorporate it into an existing product to get feedback (1 to 2 months?).\n6. Roll it out to a large user base of an existing product and do rigorous A/B testing.\n\nAs we go down this list, we get (probably) more accurate feedback, but the time needed to get that feedback increases significantly. Also, the tactics at the top of the list create basically no risk, and thus itâ€™s safe to repeatedly call on them, even with preliminary ideas and prototypes. Another advantage of the tactics further up the list is that we get more qualitative feedback (for example, do users seem confused? Are they telling us they really need one additional feature?), which sparks better ideas for how to change our product than an A/B test, which tells us with rigor whether a particular implementation works but is less likely to point us in new directions to try. I recommend using the fast feedback tactics first. As we exhaust the options for learning quickly, we can try the slower tactics.\n\nWith these tactics, scrappy startup leaders and innovation-team leaders in large companies can go faster and have a much higher chance of success.\n\nThe mantra â€œmove fast and break thingsâ€ got a bad reputation because, well, it broke things. Unfortunately, some have interpreted this to mean we should not move fast, but I disagree. A better mantra is â€œmove fast and be responsible.â€ There are many ways to prototype and test quickly without shipping a product that can cause significant harm. In fact, prototyping and testing/auditing quickly before launching to a large audience is a good way to identify and mitigate potential problems.\n\nThere are numerous AI opportunities ahead, and our tools are getting better and better to pursue them at speed, which is exhilarating!\n\n[Original text: https://t.co/NeMP4DKdDX ]",
    "createdAt": "Mon Oct 28 14:47:05 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 180,
    "replyCount": 69,
    "likeCount": 879,
    "quoteCount": 12,
    "viewCount": 87883,
    "bookmarkCount": 392,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åˆåˆ›å…¬å¸çš„ç”Ÿæ­»å­˜äº¡ï¼Œå¾€å¾€å–å†³äºå®ƒä»¬å¿«é€Ÿæ‰§è¡Œçš„èƒ½åŠ›ã€‚å¯¹äºå¤§å‹å…¬å¸è€Œè¨€ï¼Œåˆ›æ–°å›¢é˜Ÿè¿­ä»£ (iterate) çš„é€Ÿåº¦ï¼Œä¹Ÿå¯¹å…¶æˆåŠŸå‡ ç‡æœ‰ç€ä¸¾è¶³è½»é‡çš„å½±å“ã€‚ç”Ÿæˆå¼ AI (Generative AI) çš„å‡ºç°ï¼Œä½¿å¾—å¿«é€Ÿæ„å»º AI èƒ½åŠ›åŸå‹æˆä¸ºå¯èƒ½ã€‚è¿‡å»éœ€è¦æ•°æœˆæ‰èƒ½å®ç°çš„ AI èƒ½åŠ›ï¼Œç°åœ¨å¯èƒ½åªéœ€å‘å¤§è¯­è¨€æ¨¡å‹ (LLM / Large Language Model) å‘å‡ºæç¤ºï¼Œå°±èƒ½åœ¨å‡ å¤©ç”šè‡³å‡ å°æ—¶å†…å®Œæˆã€‚è¿™ç§æƒŠäººçš„é€Ÿåº¦è®©æˆ‘æ„Ÿåˆ°æ— æ¯”å…´å¥‹ï¼Œæˆ‘ä¹Ÿä¸€ç›´åœ¨æ€è€ƒå¦‚ä½•å¸®åŠ©åˆåˆ›å…¬å¸å’Œå¤§å‹ä¼ä¸šéƒ½èƒ½å¤Ÿè·‘å¾—æ›´å¿«ã€‚\n\né•¿æœŸä»¥æ¥ï¼Œæˆ‘ä¸€ç›´çƒ­è¡·äºè¿½æ±‚å¿«é€Ÿæ‰§è¡Œã€‚åœ¨è¿›è¡Œé¡¹ç›®æ—¶ï¼Œæˆ‘éå¸¸ä¸å–œæ¬¢èŠ±ä¸¤å‘¨æ—¶é—´å»åšä¸€å‘¨å†…å°±èƒ½å®Œæˆçš„äº‹æƒ…ã€‚ä»¥é‚£ç§é€Ÿåº¦å‰è¿›çš„ä»£ä»·ï¼Œä¸æ˜¯æˆ‘ä»¬å¤šèŠ±äº†ä¸€å‘¨æ—¶é—´ (è¿™å¯èƒ½è¿˜åœ¨æ¥å—èŒƒå›´)ï¼Œè€Œæ˜¯æˆ‘ä»¬çš„é€Ÿåº¦æ…¢äº†æ•´æ•´ä¸€å€ (è¿™æ˜¯ç»å¯¹ä¸èƒ½æ¥å—çš„)ï¼\n\nåœ¨æ„å»ºä¸€æ¬¾ AI é©±åŠ¨çš„äº§å“æ—¶ï¼Œä»è®¾è®¡ã€æ„å»ºã€äº¤ä»˜åˆ°è§„æ¨¡åŒ–äº§å“çš„è®¸å¤šæ­¥éª¤ï¼Œéƒ½ä¸å¼€å‘ AI èƒ½åŠ›æœ¬èº«æœ‰æ‰€ä¸åŒã€‚åœ¨æé€Ÿæ–¹é¢ï¼Œè¿™äº›é AI éƒ¨åˆ†çš„æ‰§è¡Œé€Ÿåº¦ï¼Œå¹¶æ²¡æœ‰åƒ AI èƒ½åŠ›å¼€å‘é‚£æ ·æ˜¾è‘—ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¿«é€Ÿæ„å»º AI åŸå‹çš„èƒ½åŠ›ï¼Œä¹Ÿè¿«ä½¿æˆ‘ä»¬å¿…é¡»åŠ å¿«è¿™äº›å…¶ä»–æ­¥éª¤çš„é€Ÿåº¦ã€‚å¦‚æœæ”¶é›†æ•°æ®ã€è®­ç»ƒç›‘ç£å­¦ä¹ ç®—æ³• (supervised learning algorithm) å¹¶å°†æ¨¡å‹éƒ¨ç½²åˆ°äº‘ç«¯éœ€è¦ 6 ä¸ªæœˆï¼Œé‚£ä¹ˆèŠ± 2 ä¸ªæœˆæ—¶é—´æ¥è·å–ç”¨æˆ·åé¦ˆæˆ–è®¸è¿˜å¯ä»¥æ¥å—ã€‚ä½†å¦‚æœæ„å»ºä¸€ä¸ªåŸå‹åªéœ€è¦ä¸€å‘¨ï¼Œé‚£ä¹ˆç­‰å¾… 2 ä¸ªæœˆæ‰èƒ½è·å¾—åé¦ˆï¼Œå°±æ˜¾å¾—æ…¢å¾—è®©äººæ— æ³•å¿å—äº†ï¼\n\næˆ‘æƒ³é‡ç‚¹è°ˆè°ˆåº”ç”¨ç¨‹åºæ„å»ºä¸­çš„ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼šè·å–ç”¨æˆ·åé¦ˆã€‚äº§å“è®¾è®¡å’Œæ„å»ºè¿­ä»£å·¥ä½œæµç¨‹ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒç¯èŠ‚ (Eric Ries åœ¨ä»–çš„è‘—ä½œã€Šç²¾ç›Šåˆ›ä¸šã€‹(The Lean Startup) ä¸­æ™®åŠäº†è¿™ä¸€ç†å¿µ)ï¼Œå°±æ˜¯å…ˆæ„å»ºä¸€ä¸ªåŸå‹ (æˆ– MVP, æœ€å°å¯è¡Œäº§å“)ï¼Œç„¶åæ”¶é›†ç”¨æˆ·å¯¹å…¶çš„åé¦ˆï¼Œå¹¶åˆ©ç”¨è¿™äº›åé¦ˆæ¥æ¨åŠ¨äº§å“æ”¹è¿›ã€‚è¿™ä¸ªå¾ªç¯ (å¯èƒ½éœ€è¦å¤šæ¬¡è¿­ä»£) è¿è¡Œå¾—è¶Šå¿«ï¼Œä½ å°±èƒ½è¶Šå¿«åœ°è®¾è®¡å‡ºç¬¦åˆå¸‚åœºéœ€æ±‚çš„äº§å“ã€‚è¿™å°±æ˜¯æˆ‘æ‰€é¢†å¯¼çš„é£é™©æŠ•èµ„å·¥ä½œå®¤ (venture studio) AI Fund é‡‡ç”¨è®¸å¤šå¿«é€Ÿã€è½»é‡çº§ç­–ç•¥æ¥è·å–åé¦ˆçš„åŸå› ã€‚\n\nå¯¹äº B2C (business to consumer) äº§å“ï¼Œè¿™é‡Œæœ‰ä¸€äº›è·å–å®¢æˆ·åé¦ˆçš„é€‰é¡¹ï¼š\n1.  è¯· 3 ä½æœ‹å‹æˆ–å›¢é˜Ÿæˆå‘˜æŸ¥çœ‹äº§å“ï¼Œè®©ä»–ä»¬åˆ†äº«çœ‹æ³• (å¤§çº¦åŠå¤©)ã€‚\n2.  è¯· 10 ä½æœ‹å‹æˆ–å›¢é˜Ÿæˆå‘˜æŸ¥çœ‹äº§å“ (å¤§çº¦ 2 å¤©)ã€‚\n3.  å°†å…¶å‘é€ç»™ 100 ä½å€¼å¾—ä¿¡èµ–çš„æˆ–å¿—æ„¿çš„ alpha æµ‹è¯•äººå‘˜ (å¤§çº¦ 1 å‘¨)ã€‚\n4.  å°†å…¶å‘é€ç»™ 1,000 ä½ç”¨æˆ·ä»¥è·å–å®šæ€§æˆ–å®šé‡åé¦ˆ (å¤§çº¦ 2 å‘¨)ã€‚\n5.  å°†å…¶æ•´åˆåˆ°ç°æœ‰äº§å“ä¸­ä»¥è·å–åé¦ˆ (1 åˆ° 2 ä¸ªæœˆ)ã€‚\n6.  å°†å…¶æ¨å¹¿åˆ°ç°æœ‰äº§å“çš„å¤§é‡ç”¨æˆ·ç¾¤ï¼Œå¹¶è¿›è¡Œä¸¥æ ¼çš„ A/B æµ‹è¯•ã€‚\n\néšç€æˆ‘ä»¬åœ¨åˆ—è¡¨ä¸­å¾€ä¸‹æ¢ç´¢ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè·å¾—æ›´å‡†ç¡®çš„åé¦ˆï¼Œä½†è·å–è¿™äº›åé¦ˆæ‰€éœ€çš„æ—¶é—´ä¹Ÿå¤§å¹…å¢åŠ ã€‚æ­¤å¤–ï¼Œåˆ—è¡¨é¡¶éƒ¨çš„ç­–ç•¥å‡ ä¹æ²¡æœ‰é£é™©ï¼Œå› æ­¤å³ä½¿æ˜¯åˆæ­¥çš„æƒ³æ³•å’ŒåŸå‹ï¼Œä¹Ÿå¯ä»¥å®‰å…¨ä¸”åå¤åœ°ä½¿ç”¨ã€‚åˆ—è¡¨é å‰ç­–ç•¥çš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯ï¼Œæˆ‘ä»¬èƒ½è·å¾—æ›´å¤šå®šæ€§åé¦ˆ (ä¾‹å¦‚ï¼Œç”¨æˆ·æ˜¯å¦æ˜¾å¾—å›°æƒ‘ï¼Ÿä»–ä»¬æ˜¯å¦å‘Šè¯‰æˆ‘ä»¬ç¡®å®éœ€è¦æŸä¸ªé¢å¤–åŠŸèƒ½ï¼Ÿ)ï¼Œè¿™æ¯” A/B æµ‹è¯•æ›´èƒ½æ¿€å‘æˆ‘ä»¬æ”¹è¿›äº§å“çš„ç»å¦™æƒ³æ³•ã€‚A/B æµ‹è¯•èƒ½ä¸¥è°¨åœ°å‘Šè¯‰æˆ‘ä»¬æŸä¸ªç‰¹å®šå®ç°æ˜¯å¦æœ‰æ•ˆï¼Œä½†å´ä¸å¤ªå¯èƒ½ä¸ºæˆ‘ä»¬æŒ‡æ˜æ–°çš„å°è¯•æ–¹å‘ã€‚å› æ­¤ï¼Œæˆ‘å»ºè®®ä¼˜å…ˆä½¿ç”¨å¿«é€Ÿåé¦ˆç­–ç•¥ã€‚å½“å¿«é€Ÿå­¦ä¹ çš„é€‰é¡¹è¢«å……åˆ†åˆ©ç”¨åï¼Œæˆ‘ä»¬å†å°è¯•è¾ƒæ…¢çš„ç­–ç•¥ã€‚\n\né€šè¿‡è¿™äº›ç­–ç•¥ï¼Œé‚£äº›åŠ¡å®çš„åˆåˆ›å…¬å¸é¢†å¯¼è€…å’Œå¤§å‹ä¼ä¸šçš„åˆ›æ–°å›¢é˜Ÿé¢†å¯¼è€…éƒ½èƒ½è·‘å¾—æ›´å¿«ï¼Œå¹¶å¤§å¹…æé«˜æˆåŠŸå‡ ç‡ã€‚\n\nâ€œå¿«é€Ÿè¡ŒåŠ¨ï¼Œæ‰“ç ´å¸¸è§„â€è¿™å¥å£å·ä¹‹æ‰€ä»¥å£°åç‹¼è—‰ï¼Œå°±æ˜¯å› ä¸ºå®ƒç¡®å®é€ æˆäº†ç ´åã€‚ä¸å¹¸çš„æ˜¯ï¼Œæœ‰äº›äººå› æ­¤è¯¯ä»¥ä¸ºæˆ‘ä»¬ä¸åº”è¯¥å¿«é€Ÿè¡ŒåŠ¨ï¼Œä½†æˆ‘å¯¹æ­¤å¹¶ä¸è®¤åŒã€‚ä¸€ä¸ªæ›´å¥½çš„å£å·åº”è¯¥æ˜¯â€œå¿«é€Ÿè¡ŒåŠ¨ï¼Œè´Ÿè´£ä»»â€ã€‚æœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥å¿«é€Ÿæ„å»ºåŸå‹å’Œæµ‹è¯•ï¼ŒåŒæ—¶é¿å…å‘å¸ƒå¯èƒ½é€ æˆé‡å¤§æŸå®³çš„äº§å“ã€‚äº‹å®ä¸Šï¼Œåœ¨å‘å¤§é‡å—ä¼—å‘å¸ƒä¹‹å‰ï¼Œå¿«é€Ÿæ„å»ºåŸå‹å¹¶è¿›è¡Œæµ‹è¯•/éªŒè¯ï¼Œæ˜¯è¯†åˆ«å’Œå‡è½»æ½œåœ¨é—®é¢˜çš„å¥½æ–¹æ³•ã€‚\n\næœªæ¥è¿˜æœ‰æ— æ•°çš„ AI æœºé‡ï¼Œæˆ‘ä»¬çš„å·¥å…·ä¹Ÿå˜å¾—è¶Šæ¥è¶Šå¥½ï¼Œå¯ä»¥é«˜é€Ÿåœ°æŠ“ä½å®ƒä»¬ï¼Œè¿™ç€å®ä»¤äººå…´å¥‹ï¼\n\n[åŸæ–‡é“¾æ¥: https://t.co/NeMP4DKdDX ]"
  },
  {
    "id": "1850280961768104332",
    "url": "https://x.com/AndrewYNg/status/1850280961768104332",
    "text": "Congrats @andrewdfeldman and @CerebrasSystems for a huge leap forward and setting a new speed record for serving Llama 3.1-70B. 2100 tokens/sec is blazingly fast for a 70B model. This is great for agentic AI!",
    "createdAt": "Sat Oct 26 20:58:52 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 66,
    "replyCount": 56,
    "likeCount": 421,
    "quoteCount": 6,
    "viewCount": 112914,
    "bookmarkCount": 79,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "æ­å–œ @andrewdfeldman å’Œ @CerebrasSystemsï¼Œä»–ä»¬åœ¨ Llama 3.1-70B æ¨¡å‹çš„æœåŠ¡æ–¹é¢å–å¾—äº†å·¨å¤§çªç ´ï¼Œå¹¶åˆ›ä¸‹äº†æ–°çš„é€Ÿåº¦çºªå½•ã€‚å¯¹äºä¸€ä¸ª 70B æ¨¡å‹æ¥è¯´ï¼Œæ¯ç§’ 2100 ä¸ª Token çš„å¤„ç†é€Ÿåº¦å¯è°“æå…¶è¿…é€Ÿã€‚è¿™å¯¹ AI æ™ºèƒ½ä½“ (agentic AI) çš„å‘å±•è€Œè¨€ï¼Œæ— ç–‘æ˜¯é‡å¤§åˆ©å¥½ï¼"
  },
  {
    "id": "1850246368126021744",
    "url": "https://x.com/AndrewYNg/status/1850246368126021744",
    "text": "@vishalmisra Cool visualization!",
    "createdAt": "Sat Oct 26 18:41:24 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 5,
    "quoteCount": 0,
    "viewCount": 4158,
    "bookmarkCount": 2,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@vishalmisra å¾ˆæ£’çš„ï¼ˆæ•°æ®ï¼‰å¯è§†åŒ–ï¼"
  },
  {
    "id": "1849112129904738656",
    "url": "https://x.com/AndrewYNg/status/1849112129904738656",
    "text": "New short course: Practical Multi AI Agents and Advanced Use Cases with crewAI. Learn to build and deploy advanced agent-based systems in real applications in this course, created with @crewAIInc and taught by its founder, @joaomdmoura! (Disclosure: I've made a small seed investment in CrewAI.)\n\nIn this course, youâ€™ll learn how to create advanced agent-based apps that use external tools, do performance testing, can be trained with human feedback, and perform multiple tasks with different large language models.\n\nYou will build several practical agentic apps that provide real business value, such as an automated project planning system, lead scoring and engagement pipeline, customer support data analysis, and a robust content creation system.\n\nIn detail, you will learn how to:\n- Create these multi-agent systems with the building blocks of tasks, agents, and crews, along with the different things that make them work, such as caching, memory, and guardrails.\n- Integrate your multi-agent application with internal and external systems.\n- Connect multiple agents in complex setups, including parallel, sequential, and hybrid configurations, and create flows involving multiple agentic applications working together.\n- Test your agentic workflow and train it using human feedback to optimize its performance for better and more consistent results.\n- Work with multiple LLMs in your multi-agent system, using the appropriate model sizes and providers to fit each agentâ€™s specific task.\n- Start a project from scratch in your environment and prepare it for deployment.\n\nYouâ€™ll also learn from an interview between JoÃ£o and Jacob Wilson, the Commercial GenAI Principal at PwC , in which they discuss deploying agentic workflows in real industry use cases.\n\nBy the end of this course, you will be equipped to start building custom multi-agentic systems for your work.\n\nPlease sign up here! https://t.co/JkD52B3ONA",
    "createdAt": "Wed Oct 23 15:34:21 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 260,
    "replyCount": 91,
    "likeCount": 1493,
    "quoteCount": 45,
    "viewCount": 339721,
    "bookmarkCount": 1405,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°è¯¾ç¨‹ä¸Šçº¿ï¼šcrewAI å®ç”¨å¤š**AI æ™ºèƒ½ä½“** (AI Agent) ä¸é«˜çº§åº”ç”¨æ¡ˆä¾‹ã€‚æœ¬è¯¾ç¨‹ç”± @crewAIInc åŠå…¶åˆ›å§‹äºº @joaomdmoura å€¾åŠ›æ‰“é€ å¹¶äº²è‡ªæˆè¯¾ï¼Œå°†å¸¦ä½ å­¦ä¹ å¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­æ„å»ºå’Œéƒ¨ç½²å…ˆè¿›çš„**åŸºäºæ™ºèƒ½ä½“çš„ç³»ç»Ÿ** (agent-based systems)ï¼ (å£°æ˜ï¼šæˆ‘å·²å¯¹ CrewAI è¿›è¡Œäº†å°é¢ç§å­æŠ•èµ„ã€‚)\n\nåœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•åˆ›å»ºé«˜çº§çš„**æ™ºèƒ½ä½“åº”ç”¨** (agentic apps)ï¼Œè¿™äº›åº”ç”¨èƒ½å¤Ÿåˆ©ç”¨å¤–éƒ¨å·¥å…·ã€è¿›è¡Œæ€§èƒ½æµ‹è¯•ã€é€šè¿‡äººå·¥åé¦ˆè¿›è¡Œè®­ç»ƒï¼Œå¹¶èƒ½ç»“åˆä¸åŒçš„**å¤§è¯­è¨€æ¨¡å‹** (LLM) æ‰§è¡Œå¤šé¡¹ä»»åŠ¡ã€‚\n\nä½ å°†äº²æ‰‹æ­å»ºå¤šä¸ªå…·æœ‰å®é™…å•†ä¸šä»·å€¼çš„æ™ºèƒ½ä½“åº”ç”¨ï¼Œä¾‹å¦‚ï¼šè‡ªåŠ¨é¡¹ç›®è§„åˆ’ç³»ç»Ÿã€æ½œåœ¨å®¢æˆ·è¯„åˆ†å’Œäº’åŠ¨æµç¨‹ã€å®¢æˆ·æ”¯æŒæ•°æ®åˆ†æï¼Œä»¥åŠå¼ºå¤§çš„å†…å®¹åˆ›ä½œç³»ç»Ÿã€‚\n\nå…·ä½“æ¥è¯´ï¼Œä½ å°†å­¦ä¹ ä»¥ä¸‹å†…å®¹ï¼š\n- å¦‚ä½•åˆ©ç”¨ä»»åŠ¡ã€æ™ºèƒ½ä½“å’Œâ€œèˆ¹å‘˜â€ (crews) è¿™äº›æ ¸å¿ƒæ„å»ºæ¨¡å—ï¼Œç»“åˆç¼“å­˜ã€å†…å­˜å’Œ**æŠ¤æ ** (guardrails) ç­‰å…³é”®è¦ç´ ï¼Œæ¥åˆ›å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚\n- å¦‚ä½•å°†ä½ çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ç¨‹åºä¸å†…éƒ¨åŠå¤–éƒ¨ç³»ç»Ÿè¿›è¡Œé›†æˆã€‚\n- å¦‚ä½•åœ¨å¤æ‚çš„é…ç½®ï¼ˆåŒ…æ‹¬å¹¶è¡Œã€é¡ºåºå’Œæ··åˆæ¨¡å¼ï¼‰ä¸­è¿æ¥å¤šä¸ªæ™ºèƒ½ä½“ï¼Œå¹¶åˆ›å»ºæ¶‰åŠå¤šä¸ªæ™ºèƒ½ä½“åº”ç”¨ååŒå·¥ä½œçš„æµç¨‹ã€‚\n- å¦‚ä½•æµ‹è¯•ä½ çš„**æ™ºèƒ½ä½“å·¥ä½œæµ** (agentic workflow)ï¼Œå¹¶åˆ©ç”¨äººå·¥åé¦ˆè¿›è¡Œè®­ç»ƒï¼Œä»è€Œä¼˜åŒ–å…¶æ€§èƒ½ï¼Œè·å¾—æ›´å‡ºè‰²ã€æ›´ç¨³å®šçš„ç»“æœã€‚\n- å¦‚ä½•åœ¨ä½ çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­æœ‰æ•ˆè¿ç”¨å¤šä¸ª **LLM**ï¼Œæ ¹æ®æ¯ä¸ªæ™ºèƒ½ä½“çš„ç‰¹å®šä»»åŠ¡ï¼Œé€‰æ‹©åˆé€‚çš„æ¨¡å‹è§„æ¨¡å’Œæä¾›å•†ã€‚\n- å¦‚ä½•åœ¨è‡ªå·±çš„ç¯å¢ƒä¸­ä»é›¶å¼€å§‹ä¸€ä¸ªé¡¹ç›®ï¼Œå¹¶ä¸ºåç»­éƒ¨ç½²åšå¥½å‡†å¤‡ã€‚\n\nä½ è¿˜å°†ä» JoÃ£o ä¸æ™®åæ°¸é“ (PwC) å•†ä¸š**ç”Ÿæˆå¼ AI** (Generative AI) è´Ÿè´£äºº Jacob Wilson çš„ä¸€æ¬¡è®¿è°ˆä¸­è·ç›Šï¼Œä»–ä»¬å°†å…±åŒæ¢è®¨å¦‚ä½•åœ¨çœŸå®çš„è¡Œä¸šç”¨ä¾‹ä¸­éƒ¨ç½²æ™ºèƒ½ä½“å·¥ä½œæµã€‚\n\nå®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†å®Œå…¨æœ‰èƒ½åŠ›ä¸ºä½ çš„å·¥ä½œé‡èº«å®šåˆ¶å¹¶æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æ³¨å†Œï¼ https://t.co/JkD52B3ONA"
  },
  {
    "id": "1846978449346646089",
    "url": "https://x.com/AndrewYNg/status/1846978449346646089",
    "text": "@DiggerofAI Yup. Reducing shipping emissions reduced pollution, but also reduced sunlight reflection and thus accelerating warming. With SAI, we would spray aerosols high up in the stratosphere, where it'll last longer. This gets us more cooling and less pollution than shipping emissions.",
    "createdAt": "Thu Oct 17 18:15:52 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 0,
    "likeCount": 2,
    "quoteCount": 0,
    "viewCount": 594,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@DiggerofAI æ²¡é”™ã€‚å‡å°‘èˆªè¿æ’æ”¾ï¼ˆshipping emissionsï¼‰ç¡®å®é™ä½äº†æ±¡æŸ“ï¼Œä½†åŒæ—¶ä¹Ÿå‡å°‘äº†é˜³å…‰åå°„ï¼Œè¿›è€ŒåŠ é€Ÿäº†å…¨çƒå˜æš–ã€‚è€Œé€šè¿‡å¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ (SAI)ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¹³æµå±‚é«˜å¤„å–·æ´’æ°”æº¶èƒ¶ï¼ˆaerosolsï¼‰ï¼Œåœ¨é‚£é‡Œå®ƒä»¬èƒ½åœç•™æ›´ä¹…ã€‚ç›¸æ¯”äºèˆªè¿æ’æ”¾ï¼Œè¿™ç§æ–¹å¼èƒ½å¸¦æ¥æ›´å¤šçš„é™æ¸©æ•ˆæœï¼ŒåŒæ—¶äº§ç”Ÿçš„æ±¡æŸ“ä¹Ÿæ›´å°‘ã€‚"
  },
  {
    "id": "1846952116516278591",
    "url": "https://x.com/AndrewYNg/status/1846952116516278591",
    "text": "Itâ€™s high time to take geoengineering more seriously as a potential tool to mitigate climate change. 2023 was the hottest year on record, and 2024 is likely to top that. In the United States, Hurricane Helene caused over 200 deaths, and Hurricane Milton's death toll is at least two dozen. Itâ€™s well established that the hurricanes are growing stronger as global temperatures rise.\n\nWhile stratospheric aerosol injection (SAI) â€” which sprays particles (aerosols) in the atmosphere to provide a small amount of shade from the sun â€” is far from a perfect solution, we should take it seriously as a possible tool for saving lives. A few months ago, my collaborators and I released a climate emulator, Planet Parasol https://t.co/OxtaQMyDuL , that you can play with to simulate different SAI scenarios to understand its possible impact. By using AI to model its impact and thereby advance our understanding of SAI, weâ€™ll be better prepared to decide if this is a good step.\n\nThe key idea of SAI, which is a form of climate geoengineering, is to spray reflective particles into the stratosphere to reflect a little more, say 1%, of the sunlight that otherwise would fall on Earth back into space. This small increase in reflected sunlight would be sufficient to mitigate much of the impact of human-induced warming. For example, in 1991, Mount Pinatubo ejected almost 20 tons of aerosols (sulfur dioxide) into the atmosphere and cooled down the planet by around 0.5 degrees Celsius over the following year. We should be able to induce cooling equivalent to, say, a fraction of Mount Pinatubo, via a fair, international process thatâ€™s backed by science.\n\nThere are many criticisms of SAI, such as:\n- It could have unintended climate consequences, for example, disrupting local weather patterns and creating droughts or floods.\n- If it were started and then stopped suddenly, it could lead to sudden warming, known as â€œtermination shock.â€\n- Depending on the aerosol used (sulfur dioxide is a leading candidate), it could contribute to pollution and/or ozone depletion.\n- It might reduce urgency to decarbonize (an example of a â€œmoral hazardâ€).\n\nIn addition, many people have a visceral emotional reaction, as I once did before I understood the science more deeply, against â€œplaying godâ€ by daring to engineer the planet.\n\nAll these downsides should be balanced against the reality that people are dying.\n\nIâ€™m moved by meteorologist John Moralesâ€™ emotional account of the havoc caused by Hurricane Milton. The New York Times quoted him as saying, â€œIt claims lives. It also wrecks lives.â€ https://t.co/MKD8GIrV5g \n\nSkyfire AI, a drone company led by CEO Don Mathis that my team AI Fund helped to co-build, was recently on the ground in the aftermath of Helene and Milton, deploying drones to help emergency responders survey remote areas and find survivors. Mathis reports that Skyfire was credited with saving at least 13 lives. https://t.co/rsrcWMka17 On Monday, I also spoke about AI applied to renewable energy with AESâ€™ CEO Andres Gluski and CPO Chris Shelton. You can view our conversation here: https://t.co/kzKBp3NmrM\n\nWhile Iâ€™m glad that AI can help mitigate these disasters, it saddens me that so many lives have already been lost due to climate-influenced causes. My mind frequently returns to SAI as one of the few untapped tools in our arsenal that can help. We need to be investing in SAI research now.\n\nIâ€™m grateful to my collaborators on the Planet Parasol emulator (a group that includes many climate scientists) including Jeremy Irvin, Daniele Visioni, Ben Kravitz, Dakota Gruener, Chris Smith, and Duncan Watson-Parris. MIT Technology Reviewâ€™s James Temple wrote about his experience playing with our emulator and also outlines fair criticisms. (See https://t.co/ufXAKNBiLQ ) Much work remains to be done, and making sure our actions are based on science â€” a task that AI can help with (witness the recent Chemistry and Physics Nobel Prizes going to innovators in AI!) â€“ will help us make better decisions.\n\nIf youâ€™re interested in learning more about SAI, check out this recent panel discussion (https://t.co/UFerfFIskp) where I spoke alongside climate scientists Chris Field, David Keith, Douglas MacMartin, and Simone Tilmes about the science and possible roadmaps ahead.\n\n[Original text: https://t.co/u1thkhK0XY ]",
    "createdAt": "Thu Oct 17 16:31:13 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 62,
    "replyCount": 61,
    "likeCount": 280,
    "quoteCount": 3,
    "viewCount": 43133,
    "bookmarkCount": 61,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ç°åœ¨ï¼Œæ˜¯æ—¶å€™æ›´è®¤çœŸåœ°å°†åœ°çƒå·¥ç¨‹ (geoengineering) è§†ä¸ºä¸€ç§æ½œåœ¨çš„æ°”å€™å˜åŒ–ç¼“è§£å·¥å…·äº†ã€‚2023å¹´æ˜¯å²ä¸Šæœ€çƒ­çš„ä¸€å¹´ï¼Œè€Œ2024å¹´å¾ˆå¯èƒ½æ‰“ç ´è¿™ä¸€çºªå½•ã€‚åœ¨ç¾å›½ï¼Œé£“é£æµ·ä¼¦ (Hurricane Helene) é€ æˆ200å¤šäººæ­»äº¡ï¼Œé£“é£ç±³å°”é¡¿ (Hurricane Milton) çš„æ­»äº¡äººæ•°ä¹Ÿè‡³å°‘æœ‰24äººã€‚éšç€å…¨çƒæ°”æ¸©ä¸Šå‡ï¼Œé£“é£å¼ºåº¦ä¸æ–­å¢å¼ºï¼Œè¿™å·²æ˜¯å…¬è®¤çš„äº‹å®ã€‚\n\nå°½ç®¡å¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ (SAI, Stratospheric Aerosol Injection) â€” å³å‘å¤§æ°”ä¸­å–·æ´’é¢—ç²’ (æ°”æº¶èƒ¶, aerosols)ï¼Œä»¥æä¾›å°‘é‡é˜³å…‰é®è”½ â€” è¿œéå®Œç¾çš„è§£å†³æ–¹æ¡ˆï¼Œä½†æˆ‘ä»¬åº”è¯¥å°†å…¶è§†ä¸ºä¸€ç§å¯èƒ½æŒ½æ•‘ç”Ÿå‘½çš„å·¥å…·ï¼Œè®¤çœŸå¯¹å¾…ã€‚å‡ ä¸ªæœˆå‰ï¼Œæˆ‘çš„åˆä½œè€…å’Œæˆ‘å‘å¸ƒäº†ä¸€ä¸ªæ°”å€™æ¨¡æ‹Ÿå™¨ (climate emulator) â€” Planet Parasol https://t.co/OxtaQMyDuL â€” ä½ å¯ä»¥é€šè¿‡å®ƒæ¨¡æ‹Ÿä¸åŒçš„ SAI åœºæ™¯ï¼Œä»è€Œäº†è§£å…¶æ½œåœ¨å½±å“ã€‚é€šè¿‡åˆ©ç”¨ AI (äººå·¥æ™ºèƒ½) æ¨¡æ‹Ÿ SAI çš„å½±å“ï¼Œå¹¶ä»¥æ­¤åŠ æ·±æˆ‘ä»¬å¯¹å…¶çš„ç†è§£ï¼Œæˆ‘ä»¬å°†èƒ½æ›´å¥½åœ°å†³å®šè¿™æ˜¯å¦æ˜¯å€¼å¾—è¿ˆå‡ºçš„ä¸€æ­¥ã€‚\n\nSAI ä½œä¸ºä¸€ç§æ°”å€™åœ°çƒå·¥ç¨‹å½¢å¼ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å‘å¹³æµå±‚ (stratosphere) å–·å°„åå°„æ€§é¢—ç²’ï¼Œä½¿åŸæœ¬ä¼šæŠµè¾¾åœ°çƒçš„å¤ªé˜³å…‰ï¼Œæœ‰å°‘é‡ï¼ˆæ¯”å¦‚1%ï¼‰è¢«åå°„å›å¤ªç©ºã€‚å¤ªé˜³å…‰åå°„é‡çš„å¾®å°å¢åŠ ï¼Œå°±è¶³ä»¥å¤§å¤§ç¼“è§£äººç±»æ´»åŠ¨å¯¼è‡´çš„æ°”å€™å˜æš–çš„å½±å“ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œ1991å¹´ï¼Œçš®çº³å›¾åšç«å±± (Mount Pinatubo) å‘å¤§æ°”ä¸­å–·å°„äº†è¿‘20å¨æ°”æº¶èƒ¶ (äºŒæ°§åŒ–ç¡«, sulfur dioxide)ï¼Œä½¿å¾—æ¥ä¸‹æ¥ä¸€å¹´åœ°çƒçš„æ¸©åº¦é™ä½äº†å¤§çº¦0.5æ‘„æ°åº¦ã€‚æˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿé€šè¿‡ä¸€ä¸ªå…¬å¹³ã€å¹¶æœ‰ç§‘å­¦æ”¯æ’‘çš„å›½é™…è¿›ç¨‹ï¼Œå®ç°ç›¸å½“äºçš®çº³å›¾åšç«å±±å–·å‘ä¸€å°éƒ¨åˆ†çš„é™æ¸©æ•ˆæœã€‚\n\nSAI é¢ä¸´è¯¸å¤šè´¨ç–‘ï¼Œä¾‹å¦‚ï¼š\n- å®ƒå¯èƒ½å¸¦æ¥æ„æƒ³ä¸åˆ°çš„æ°”å€™åæœï¼Œæ¯”å¦‚æ‰°ä¹±å±€éƒ¨å¤©æ°”æ¨¡å¼ï¼Œå¼•å‘å¹²æ—±æˆ–æ´ªæ°´ã€‚\n- å¦‚æœè¯¥é¡¹ç›®ä¸€æ—¦å¯åŠ¨åˆçªç„¶åœæ­¢ï¼Œå¯èƒ½ä¼šå¯¼è‡´åœ°çƒæ¸©åº¦éª¤ç„¶å‡é«˜ï¼Œè¿™è¢«ç§°ä¸ºâ€œç»ˆæ­¢å†²å‡» (termination shock)â€ã€‚\n- æ ¹æ®æ‰€ä½¿ç”¨çš„æ°”æº¶èƒ¶ç±»å‹ (äºŒæ°§åŒ–ç¡«æ˜¯ä¸»è¦çš„å€™é€‰ç‰©è´¨ä¹‹ä¸€)ï¼Œå®ƒå¯èƒ½å¯¼è‡´æ±¡æŸ“å’Œ/æˆ–è‡­æ°§æŸè€—ã€‚\n- å®ƒå¯èƒ½ä¼šå‰Šå¼±äººä»¬å‡å°‘ç¢³æ’æ”¾çš„ç´§è¿«æ€§ (è¿™æ˜¯ä¸€ç§â€œé“å¾·é£é™© (moral hazard)â€çš„è¡¨ç°)ã€‚\n\næ­¤å¤–ï¼Œå¾ˆå¤šäººå¯¹é€šè¿‡å¤§èƒ†æ”¹é€ åœ°çƒæ¥â€œæ‰®æ¼”ä¸Šå¸â€æŠ±æœ‰ä¸€ç§æœ¬èƒ½çš„æƒ…ç»ªæŠµè§¦ï¼Œæ­£å¦‚æˆ‘åœ¨æ›´æ·±å…¥äº†è§£ç§‘å­¦ä¹‹å‰ä¹Ÿæ›¾æœ‰è¿‡è¿™ç§æ„Ÿå—ã€‚\n\næ‰€æœ‰è¿™äº›ä¸åˆ©å› ç´ ï¼Œéƒ½å¿…é¡»ä¸å½“å‰æ­£åœ¨å‘ç”Ÿçš„ç”Ÿå‘½é€å»çš„ç°å®ç›¸æƒè¡¡ã€‚\n\næ°”è±¡å­¦å®¶ John Morales å¯¹é£“é£ç±³å°”é¡¿è‚†è™é€ æˆç ´åçš„æ·±æƒ…å™è¿°è®©æˆ‘æ·±å—è§¦åŠ¨ã€‚ã€Šçº½çº¦æ—¶æŠ¥ã€‹å¼•ç”¨ä»–çš„è¯ï¼šâ€œå®ƒå¤ºèµ°äº†ç”Ÿå‘½ï¼Œä¹Ÿæ‘§æ¯äº†ç”Ÿæ´»ã€‚â€ https://t.co/MKD8GIrV5g\n\nSkyfire AI æ˜¯ä¸€å®¶ç”±é¦–å¸­æ‰§è¡Œå®˜ Don Mathis é¢†å¯¼çš„æ— äººæœºå…¬å¸ï¼Œæˆ‘çš„å›¢é˜Ÿ AI Fund æ›¾å¸®åŠ©å…±åŒå»ºç«‹ã€‚æœ€è¿‘ï¼ŒSkyfire AI åœ¨é£“é£æµ·ä¼¦å’Œç±³å°”é¡¿è¿‡åæŠµè¾¾å—ç¾ç°åœºï¼Œéƒ¨ç½²æ— äººæœºååŠ©ç´§æ€¥æ•‘æ´äººå‘˜å‹˜æµ‹åè¿œåœ°åŒºå¹¶å¯»æ‰¾å¹¸å­˜è€…ã€‚Mathis æŠ¥å‘Šç§°ï¼ŒSkyfire å› æˆåŠŸæŒ½æ•‘è‡³å°‘13æ¡ç”Ÿå‘½è€Œå—åˆ°è¡¨å½°ã€‚ https://t.co/rsrcWMka17 å‘¨ä¸€ï¼Œæˆ‘è¿˜ä¸ AES çš„é¦–å¸­æ‰§è¡Œå®˜ Andres Gluski å’Œé¦–å¸­äº§å“å®˜ Chris Shelton è®¨è®ºäº† AI åœ¨å¯å†ç”Ÿèƒ½æºé¢†åŸŸçš„åº”ç”¨ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œè§‚çœ‹æˆ‘ä»¬çš„å¯¹è¯ï¼š https://t.co/kzKBp3NmrM\n\nè™½ç„¶æˆ‘å¾ˆé«˜å…´ AI èƒ½å¤Ÿå¸®åŠ©ç¼“è§£è¿™äº›ç¾éš¾ï¼Œä½†ä»¤æˆ‘æ‚²ä¼¤çš„æ˜¯ï¼Œå·²ç»æœ‰å¦‚æ­¤å¤šçš„ç”Ÿå‘½å› æ°”å€™å½±å“è€Œé€å»ã€‚æˆ‘çš„æ€ç»ªå¸¸å¸¸å›åˆ° SAIï¼Œå°†å…¶è§†ä¸ºæˆ‘ä»¬åº”å¯¹æ°”å€™æŒ‘æˆ˜çš„â€œå·¥å…·ç®±â€ä¸­ä¸ºæ•°ä¸å¤šçš„ã€å°šæœªå……åˆ†åˆ©ç”¨çš„å·¥å…·ä¹‹ä¸€ã€‚æˆ‘ä»¬ç°åœ¨äºŸéœ€æŠ•èµ„ SAI çš„ç ”ç©¶ã€‚\n\næˆ‘éå¸¸æ„Ÿè°¢æˆ‘çš„ Planet Parasol æ¨¡æ‹Ÿå™¨åˆä½œè€…ä»¬ï¼ˆä¸€ä¸ªç”±ä¼—å¤šæ°”å€™ç§‘å­¦å®¶ç»„æˆçš„å›¢é˜Ÿï¼‰ï¼ŒåŒ…æ‹¬ Jeremy Irvinã€Daniele Visioniã€Ben Kravitzã€Dakota Gruenerã€Chris Smith å’Œ Duncan Watson-Parrisã€‚MIT Technology Review çš„ James Temple æ’°æ–‡æè¿°äº†ä»–ä½¿ç”¨æˆ‘ä»¬æ¨¡æ‹Ÿå™¨çš„ä½“éªŒï¼Œå¹¶æå‡ºäº†å…¬æ­£çš„æ‰¹è¯„æ„è§ã€‚(å‚è§ https://t.co/ufXAKNBiLQ ) è¿˜æœ‰å¾ˆå¤šå·¥ä½œå°šå¾…å®Œæˆï¼Œè€Œç¡®ä¿æˆ‘ä»¬çš„è¡ŒåŠ¨åŸºäºç§‘å­¦â€”â€”è¿™é¡¹ AI å¯ä»¥æä¾›å¸®åŠ©çš„ä»»åŠ¡ (è¯·çœ‹æœ€è¿‘çš„è¯ºè´å°”åŒ–å­¦å¥–å’Œç‰©ç†å­¦å¥–éƒ½é¢ç»™äº† AI é¢†åŸŸçš„åˆ›æ–°è€…!)â€”â€”å°†å¸®åŠ©æˆ‘ä»¬åšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ã€‚\n\nå¦‚æœä½ æœ‰å…´è¶£äº†è§£æ›´å¤šå…³äº SAI çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿™åœºè¿‘æœŸçš„å°ç»„è®¨è®º (https://t.co/UFerfFIskp )ï¼Œæˆ‘ä¸æ°”å€™ç§‘å­¦å®¶ Chris Fieldã€David Keithã€Douglas MacMartin å’Œ Simone Tilmes ä¸€åŒæ¢è®¨äº†ç›¸å…³ç§‘å­¦åŸç†å’Œæœªæ¥çš„å¯èƒ½è·¯çº¿å›¾ã€‚\n\n[åŸå§‹æ–‡æœ¬ï¼š https://t.co/u1thkhK0XY ]"
  },
  {
    "id": "1846608552359833674",
    "url": "https://x.com/AndrewYNg/status/1846608552359833674",
    "text": "New short course: Serverless Agentic Workflows with Amazon Bedrock. Learn to build and deploy serverless agents in this course created with @awscloud and taught by @mikegchambers, a Senior Developer Advocate at AWS specializing in GenAI. (Disclosure: I serve on Amazon's board.)\n\nGenerative AI applications are becoming more complex, sophisticated, and agentic. Agentic applications have workloads that can be hard to predict in advance -- for example, what tools will it decide to call? -- and a serverless architecture helps you efficiently providing on-demand resources.\n\nThis course teaches you to build and deploy a serverless agentic application. Youâ€™ll learn to create agents with tools, code execution, and guardrails, and build responsible agents for business use cases:\n- Build a customer service bot for a fictional tea mug business that can answering questions, retrieve information, and process orders.\n- Connect your customer service agent to a CRM to get customer info and log support tickets in real-time.\n- Explore how you invoke the agent, and see the trace to review the agentâ€™s thought process and observation loop until it reaches its final output.\n- Attach a code interpreter to your agent, giving it the ability to perform accurate calculations by writing and running its own Python code.\n- Implement guardrails to prevent your agent from revealing sensitive information or using inappropriate language.\n\nBy the end, you will have built a sophisticated AI agent capable of handling real-world customer support scenarios.\n\nPlease sign up here! https://t.co/FQKGJNBPwp",
    "createdAt": "Wed Oct 16 17:46:01 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 139,
    "replyCount": 60,
    "likeCount": 856,
    "quoteCount": 4,
    "viewCount": 80408,
    "bookmarkCount": 584,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…¨æ–°çŸ­æœŸè¯¾ç¨‹ï¼šä½¿ç”¨ Amazon Bedrock æ„å»ºæ— æœåŠ¡å™¨ AI æ™ºèƒ½ä½“å·¥ä½œæµã€‚è¿™é—¨è¯¾ç¨‹ç”± @awscloud æ‰“é€ ï¼Œå¹¶ç”± AWS ä¸“é—¨ç ”ç©¶ç”Ÿæˆå¼ AI (Generative AI) çš„é«˜çº§å¼€å‘è€…å€¡å¯¼è€… @mikegchambers äº²è‡ªæˆè¯¾ï¼Œæ—¨åœ¨å¸®åŠ©æ‚¨å­¦ä¹ å¦‚ä½•æ„å»ºå’Œéƒ¨ç½²æ— æœåŠ¡å™¨ AI æ™ºèƒ½ä½“ã€‚ï¼ˆæŠ«éœ²ï¼šæˆ‘ç›®å‰æ‹…ä»» Amazon è‘£äº‹ä¼šæˆå‘˜ã€‚ï¼‰\n\nç”Ÿæˆå¼ AI (Generative AI) åº”ç”¨ç¨‹åºæ­£å˜å¾—æ—¥ç›Šå¤æ‚ã€ç²¾å·§ï¼Œå¹¶å…·å¤‡æ›´å¼ºçš„æ™ºèƒ½ä½“ (agentic) èƒ½åŠ›ã€‚è¿™ç±»æ™ºèƒ½ä½“åº”ç”¨ç¨‹åºçš„å·¥ä½œè´Ÿè½½å¾€å¾€éš¾ä»¥æå‰é¢„çŸ¥â€”â€”æ¯”å¦‚ï¼ŒAI æ™ºèƒ½ä½“æœ€ç»ˆä¼šå†³å®šè°ƒç”¨å“ªäº›å·¥å…·ï¼Ÿâ€”â€”è€Œæ— æœåŠ¡å™¨æ¶æ„ (serverless architecture) åˆ™èƒ½å¸®åŠ©æ‚¨é«˜æ•ˆåœ°æŒ‰éœ€æä¾›æ‰€éœ€èµ„æºã€‚\n\næœ¬è¯¾ç¨‹å°†æŒ‡å¯¼æ‚¨å¦‚ä½•æ„å»ºå’Œéƒ¨ç½²ä¸€ä¸ªæ— æœåŠ¡å™¨ AI æ™ºèƒ½ä½“åº”ç”¨ç¨‹åºã€‚æ‚¨å°†å­¦ä¹ å¦‚ä½•åˆ›å»ºå…·å¤‡å·¥å…·è°ƒç”¨ã€ä»£ç æ‰§è¡Œå’Œå®‰å…¨é˜²æŠ¤æœºåˆ¶ (guardrails) çš„ AI æ™ºèƒ½ä½“ï¼Œå¹¶ä¸ºå®é™…ä¸šåŠ¡åœºæ™¯æ„å»ºè´Ÿè´£ä»»çš„ AI æ™ºèƒ½ä½“ï¼š\n- ä¸ºä¸€å®¶è™šæ„çš„èŒ¶æ¯é”€å”®ä¸šåŠ¡æ‰“é€ ä¸€ä¸ªå®¢æˆ·æœåŠ¡æœºå™¨äººï¼Œä½¿å…¶èƒ½å¤Ÿå›ç­”é—®é¢˜ã€æ£€ç´¢ä¿¡æ¯å¹¶å¤„ç†è®¢å•ã€‚\n- å°†æ‚¨çš„å®¢æˆ·æœåŠ¡ AI æ™ºèƒ½ä½“ä¸å®¢æˆ·å…³ç³»ç®¡ç†ç³»ç»Ÿ (CRM) è¿æ¥ï¼Œä»¥å®æ—¶è·å–å®¢æˆ·ä¿¡æ¯å¹¶è®°å½•æ”¯æŒå·¥å•ã€‚\n- æ·±å…¥äº†è§£å¦‚ä½•è°ƒç”¨ AI æ™ºèƒ½ä½“ï¼Œå¹¶é€šè¿‡è¿½è¸ªåŠŸèƒ½å®¡æŸ¥ AI æ™ºèƒ½ä½“çš„æ€ç»´è¿‡ç¨‹å’Œè§‚å¯Ÿå¾ªç¯ï¼Œç›´è‡³å…¶å¾—å‡ºæœ€ç»ˆè¾“å‡ºã€‚\n- ä¸ºæ‚¨çš„ AI æ™ºèƒ½ä½“é™„åŠ ä¸€ä¸ªä»£ç è§£é‡Šå™¨ï¼Œä½¿å…¶èƒ½å¤Ÿé€šè¿‡ç¼–å†™å’Œè¿è¡Œ Python ä»£ç æ¥æ‰§è¡Œç²¾ç¡®è®¡ç®—ã€‚\n- å®æ–½å®‰å…¨é˜²æŠ¤æœºåˆ¶ï¼Œé˜²æ­¢æ‚¨çš„ AI æ™ºèƒ½ä½“æ³„éœ²æ•æ„Ÿä¿¡æ¯æˆ–ä½¿ç”¨ä¸å½“è¯­è¨€ã€‚\n\nå­¦å®Œæœ¬è¯¾ç¨‹åï¼Œæ‚¨å°†èƒ½å¤Ÿæ„å»ºä¸€ä¸ªå¤æ‚çš„ AI æ™ºèƒ½ä½“ï¼Œè¶³ä»¥åº”å¯¹çœŸå®ä¸–ç•Œçš„å®¢æˆ·æ”¯æŒåœºæ™¯ã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æŠ¥åå‚åŠ ï¼https://t.co/FQKGJNBPwp"
  },
  {
    "id": "1844092080987177409",
    "url": "https://x.com/AndrewYNg/status/1844092080987177409",
    "text": "\"Introducing Multimodal Llama 3.2\": As promised two weeks ago, here's the short course on Meta's latest open model!\n\nThis short course is created with @Meta and taught by @asangani7, Director of AI Partner Engineering at Meta.\n\nMetaâ€™s Llama family of models is leading the way in open models, allowing anyone to download, customize, fine-tune, or build new applications on top of them.\n\nLearn about the vision capabilities of the Llama 3.2, and use it for image classification, prompting, tokenization, tool-calling. You'll also learn about the open-source Llama stack, which gives building blocks for many different stages of the LLM application life cycle.\n\nIn detail, youâ€™ll:\n- Learn what are the features of Meta's four newest models, and when to use which Llama model.\n- Learn best practices for multimodal prompting, with applications to advanced image reasoning, illustrated by many examples: Understanding errors on a car dashboard, adding up the total of photographed restaurant receipts, grading written math homework.\n- Use different rolesâ€”system, user, assistant, ipythonâ€”in the Llama 3.1 and 3.2 models  and the prompt format that identifies those roles.\n- Understand how Llama uses the tiktoken tokenizer, and how it has expanded to a 128k vocabulary size that improves encoding efficiency and multilingual support.\n- Learn how to prompt Llama to call built-in and custom tools (functions) with examples for web search and solving math equations.\n- Learn about Llama Stack, a standardized interface for common toolchain components like fine-tuning or synthetic data generation, useful for building agentic applications.\n\nBy the end of this course, youâ€™ll be equipped to build out new applications with the new Llama 3.2.\n\nThank you to @Ahmad_Al_Dahle, Amit Sangani, and the whole AI at Meta team @AIatMeta for all the hard work on Llama 3.2 â€” weâ€™re excited to make these open models even more accessible to more developers with this new course! \n\nPlease sign up here!  https://t.co/Flp5Ae9apy",
    "createdAt": "Wed Oct 09 19:06:28 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 247,
    "replyCount": 30,
    "likeCount": 1615,
    "quoteCount": 13,
    "viewCount": 131022,
    "bookmarkCount": 935,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "â€œå¤šæ¨¡æ€ Llama 3.2 æ¥äº†ï¼â€ï¼šæ­£å¦‚ä¸¤å‘¨å‰æˆ‘ä»¬æ‰¿è¯ºçš„é‚£æ ·ï¼ŒMeta æœ€æ–°å¼€æºæ¨¡å‹çš„é€Ÿæˆè¯¾ç¨‹ç°åœ¨æ­£å¼æ¨å‡ºï¼\n\nè¿™é—¨é€Ÿæˆè¯¾ç¨‹æ˜¯ Meta å…¬å¸ä¸ @Meta åˆä½œå¼€å‘ï¼Œå¹¶ç”± Meta AI åˆä½œä¼™ä¼´å·¥ç¨‹æ€»ç›‘ Amit Sangani (å³ @asangani7) äº²è‡ªæˆè¯¾ã€‚\n\nMeta çš„ Llama æ¨¡å‹å®¶æ—åœ¨å¼€æºæ¨¡å‹é¢†åŸŸæŒç»­é¢†è·‘ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½è‡ªç”±ä¸‹è½½ã€å®šåˆ¶ã€å¾®è°ƒï¼Œæˆ–åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºå…¨æ–°çš„åº”ç”¨ç¨‹åºã€‚\n\nåœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†æ·±å…¥äº†è§£ Llama 3.2 çš„è§†è§‰èƒ½åŠ›ï¼Œå¹¶å­¦ä¼šå¦‚ä½•å°†å…¶åº”ç”¨äºå›¾åƒåˆ†ç±»ã€æç¤º (prompting)ã€Token åŒ– (tokenization) å’Œå·¥å…·è°ƒç”¨ã€‚ä½ è¿˜å°†å­¦ä¹ åˆ°å¼€æºçš„ Llama Stackï¼Œå®ƒä¸ºå¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸçš„å¤šä¸ªé˜¶æ®µæä¾›äº†åšå®çš„æ„å»ºæ¨¡å—ã€‚\n\nå…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š\n- æŒæ¡ Meta å››ä¸ªæœ€æ–°æ¨¡å‹çš„ç‹¬ç‰¹åŠŸèƒ½ï¼Œå¹¶äº†è§£åœ¨ä¸åŒåœºæ™¯ä¸‹å¦‚ä½•é€‰æ‹©æœ€åˆé€‚çš„ Llama æ¨¡å‹ã€‚\n- å­¦ä¹ å¤šæ¨¡æ€æç¤ºçš„æœ€ä½³å®è·µï¼Œå¹¶å°†å…¶åº”ç”¨äºé«˜çº§å›¾åƒæ¨ç†ä»»åŠ¡ã€‚è¯¾ç¨‹å°†é€šè¿‡ä¸°å¯Œçš„å®ä¾‹è¿›è¡Œè®²è§£ï¼ŒåŒ…æ‹¬ï¼šè¯†åˆ«æ±½è½¦ä»ªè¡¨ç›˜ä¸Šçš„é”™è¯¯ã€è®¡ç®—ç…§ç‰‡ä¸­é¤å…æ”¶æ®çš„æ€»é‡‘é¢ã€æ‰¹æ”¹æ‰‹å†™çš„æ•°å­¦ä½œä¸šç­‰ã€‚\n- åœ¨ Llama 3.1 å’Œ 3.2 æ¨¡å‹ä¸­ï¼Œä½¿ç”¨ä¸åŒçš„è§’è‰²â€”â€”system (ç³»ç»Ÿ)ã€user (ç”¨æˆ·)ã€assistant (åŠ©æ‰‹) å’Œ ipythonï¼Œå¹¶å­¦ä¹ è¯†åˆ«è¿™äº›è§’è‰²çš„æç¤ºæ ¼å¼ã€‚\n- ç†è§£ Llama å¦‚ä½•åˆ©ç”¨ tiktoken åˆ†è¯å™¨ (tokenizer)ï¼Œä»¥åŠå®ƒå¦‚ä½•å°†è¯æ±‡é‡æ‰©å±•åˆ° 128kï¼Œä»è€Œæ˜¾è‘—æå‡ç¼–ç æ•ˆç‡å’Œå¤šè¯­è¨€æ”¯æŒèƒ½åŠ›ã€‚\n- å­¦ä¹ å¦‚ä½•å‘ Llama å‘å‡ºæç¤ºï¼Œä½¿å…¶è°ƒç”¨å†…ç½®å·¥å…·å’Œè‡ªå®šä¹‰å‡½æ•° (functions)ï¼Œå¹¶è¾…ä»¥ç½‘é¡µæœç´¢å’Œè§£å†³æ•°å­¦æ–¹ç¨‹çš„å®é™…æ¡ˆä¾‹ã€‚\n- äº†è§£ Llama Stackâ€”â€”ä¸€ä¸ªä¸ºå¾®è°ƒ (fine-tuning) æˆ–åˆæˆæ•°æ®ç”Ÿæˆ (synthetic data generation) ç­‰å¸¸è§å·¥å…·é“¾ç»„ä»¶æä¾›æ ‡å‡†åŒ–æ¥å£çš„å¹³å°ï¼Œå¯¹äºå¼€å‘ AI æ™ºèƒ½ä½“ (AI Agent) åº”ç”¨è‡³å…³é‡è¦ã€‚\n\nå®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†å®Œå…¨æœ‰èƒ½åŠ›åˆ©ç”¨å…¨æ–°çš„ Llama 3.2 å¼€å‘å‡ºå„ç±»åˆ›æ–°åº”ç”¨ã€‚\n\nè¡·å¿ƒæ„Ÿè°¢ Ahmad Al Dahle (@Ahmad_Al_Dahle)ã€Amit Sangani ä»¥åŠ Meta AI å›¢é˜Ÿ (å³ @AIatMeta) ä¸º Llama 3.2 æ‰€ä»˜å‡ºçš„è¾›å‹¤åŠªåŠ›â€”â€”æˆ‘ä»¬éå¸¸é«˜å…´èƒ½é€šè¿‡è¿™é—¨æ–°è¯¾ç¨‹ï¼Œè®©æ›´å¤šå¼€å‘è€…èƒ½å¤Ÿæ›´ä¾¿æ·åœ°æ¥è§¦å’Œä½¿ç”¨è¿™äº›ä¼˜ç§€çš„å¼€æºæ¨¡å‹ï¼\n\nè¯·ç‚¹å‡»æ­¤å¤„æ³¨å†Œï¼ https://t.co/Flp5Ae9apy"
  },
  {
    "id": "1843995968636866799",
    "url": "https://x.com/AndrewYNg/status/1843995968636866799",
    "text": "Amazing -- even more Nobel Prizes to AI people! Congrats to Google's @demishassabis &amp; John Jumper, and University of Washington's David Baker for their work on AI for protein sequences. AlphaFold, and @UWproteindesign's protein design work , were real breakthroughs!",
    "createdAt": "Wed Oct 09 12:44:33 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 149,
    "replyCount": 35,
    "likeCount": 1415,
    "quoteCount": 9,
    "viewCount": 72621,
    "bookmarkCount": 38,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å¤ªæ£’äº†â€”â€”ç”šè‡³æœ‰æ›´å¤šçš„è¯ºè´å°”å¥–è¢«æˆäºˆäº† AI (Artificial Intelligence) é¢†åŸŸçš„ç§‘å­¦å®¶ï¼ç¥è´º Google çš„ Demis Hassabis å’Œ John Jumperï¼Œä»¥åŠåç››é¡¿å¤§å­¦çš„ David Bakerï¼Œä»–ä»¬å› åœ¨åˆ©ç”¨ AI å¤„ç†è›‹ç™½è´¨åºåˆ—æ–¹é¢çš„å·¥ä½œè€Œè·æ­¤æ®Šè£ã€‚AlphaFold é¡¹ç›®ï¼Œä»¥åŠ @UWproteindesign å›¢é˜Ÿçš„è›‹ç™½è´¨è®¾è®¡å·¥ä½œï¼Œéƒ½æ˜¯çœŸæ­£çš„é‡å¤§çªç ´ï¼"
  },
  {
    "id": "1843764485632524664",
    "url": "https://x.com/AndrewYNg/status/1843764485632524664",
    "text": "Lisa Su's leadership of AMD has been phenomenal. 10 years ago, AMD was in dire straits, was losing money  and faced intense competition from Intel (CPUs) and NVIDIA (GPUs). She turned the company around, introduced Ryzen and Epyc processors, introduced the Zen architecture, acquired Xilinx, and is now making a good showing with MI300/MI350 for AI workloads. I've come to deeply respect her as a leader. Congratulations @LisaSu on these last ten years!",
    "createdAt": "Tue Oct 08 21:24:43 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 84,
    "replyCount": 13,
    "likeCount": 763,
    "quoteCount": 3,
    "viewCount": 81481,
    "bookmarkCount": 43,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "Lisa Su é¢†å¯¼ä¸‹çš„ AMD è¡¨ç°éå‡¡ã€‚å›æº¯åˆ°åå¹´å‰ï¼ŒAMD æ­£æ·±é™·å›°å¢ƒï¼Œä¸ä»…äºæŸä¸¥é‡ï¼Œè¿˜é¢ä¸´ç€æ¥è‡ª Intel (ä¸­å¤®å¤„ç†å™¨ CPUs) å’Œ NVIDIA (å›¾å½¢å¤„ç†å™¨ GPUs) çš„æ¿€çƒˆç«äº‰ã€‚å¥¹æˆåŠŸåœ°ä½¿å…¬å¸æ‰­äºä¸ºç›ˆï¼Œé‡å›æ­£è½¨ï¼Œæ¨å‡ºäº† Ryzen å’Œ Epyc å¤„ç†å™¨ï¼Œå¼•å…¥äº† Zen æ¶æ„ï¼Œå¹¶æˆåŠŸæ”¶è´­äº† Xilinxã€‚ç›®å‰ï¼ŒAMD å‡­å€Ÿ MI300/MI350 åœ¨ AI (äººå·¥æ™ºèƒ½) å·¥ä½œè´Ÿè½½é¢†åŸŸè¡¨ç°å¼ºåŠ²ã€‚æˆ‘ä½œä¸ºä¸€åé¢†å¯¼è€…ï¼Œå¯¹å¥¹æ·±æ„Ÿæ•¬ä½©ã€‚ç¥è´º @LisaSu åœ¨è¿‡å»åå¹´å–å¾—çš„è¾‰ç…Œæˆå°±ï¼"
  },
  {
    "id": "1843711446552846732",
    "url": "https://x.com/AndrewYNg/status/1843711446552846732",
    "text": "I was the first to call Geoff Hinton \"Godfather of Deep Learning\", which later became \"Godfather of AI.\" Thrilled to see him win the Nobel prize together with John Hopfield for AI. Congrats @geoffreyhinton!",
    "createdAt": "Tue Oct 08 17:53:58 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 460,
    "replyCount": 83,
    "likeCount": 4825,
    "quoteCount": 29,
    "viewCount": 172976,
    "bookmarkCount": 217,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘æœ€å…ˆç§° Geoff Hinton ä¸ºâ€œæ·±åº¦å­¦ä¹ æ•™çˆ¶â€ï¼Œåæ¥ä»–ä¹Ÿè¢«ç§°ä¸ºâ€œAI æ•™çˆ¶â€ã€‚å¾ˆé«˜å…´çœ‹åˆ°ä»–ä¸ John Hopfield å› åœ¨ AI é¢†åŸŸçš„è´¡çŒ®è€Œå…±åŒè·å¾—è¯ºè´å°”å¥–ã€‚ç¥è´º @geoffreyhinton!"
  },
  {
    "id": "1841952373218123996",
    "url": "https://x.com/AndrewYNg/status/1841952373218123996",
    "text": "How AI will change Coding & Education? I'm looking forward to this chat with @mehran_sahami. Mehran is a legendary programming instructor and an old friend, and has been thinking a lot about how AI is transforming coding. Come join us -- this will be fun! \n\nPlease register here: https://t.co/yWO7ovW916\n\nThank you @jpaxtonh and @StanfordOnline for hosting!",
    "createdAt": "Thu Oct 03 21:24:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 122,
    "replyCount": 25,
    "likeCount": 624,
    "quoteCount": 8,
    "viewCount": 91737,
    "bookmarkCount": 269,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "äººå·¥æ™ºèƒ½ (AI) å°†å¦‚ä½•æ”¹å˜ç¼–ç¨‹å’Œæ•™è‚²ï¼Ÿæˆ‘éå¸¸æœŸå¾…ä¸@mehran_sahami çš„è¿™åœºå¯¹è¯ã€‚Mehran æ˜¯ä¸€ä½ä¼ å¥‡çš„ç¼–ç¨‹è®²å¸ˆï¼Œä¹Ÿæ˜¯æˆ‘çš„ä¸€ä½è€æœ‹å‹ï¼Œä»–ä¸€ç›´åœ¨æ·±å…¥æ€è€ƒäººå·¥æ™ºèƒ½æ˜¯å¦‚ä½•é‡å¡‘ç¼–ç¨‹é¢†åŸŸçš„ã€‚å¿«æ¥åŠ å…¥æˆ‘ä»¬å§â€”â€”è¿™åœºæ´»åŠ¨ä¸€å®šä¼šéå¸¸æœ‰è¶£ï¼\n\nè¯·é€šè¿‡æ­¤é“¾æ¥æ³¨å†Œï¼šhttps://t.co/yWO9ovW916\n\næ„Ÿè°¢@jpaxtonh å’Œ@StanfordOnline çš„æ…·æ…¨ä¸»æŒï¼"
  },
  {
    "id": "1841496274350247951",
    "url": "https://x.com/AndrewYNg/status/1841496274350247951",
    "text": "Tokenization -- turning text into a sequence of integers -- is a key part of generative AI, and most API providers charge per million tokens. How does tokenization work? Learn the details of tokenization and RAG optimization in Retrieval Optimization: From Tokenization to Vector Quantization, created in collaboration with @qdrant_engine and taught by its Developer Relations Lead, @LukawskiKacper.\n\nThis course focuses on Retrieval augmented generation (RAG), which has two steps: First, a retriever finds relevant information; then, the generator uses whatâ€™s retrieved as context to produce a response. Youâ€™ll learn to optimize the first step (the retriever) by understanding how tokenization works and how it impacts the relevance of your search. In addition, you will also learn to measure and improve retrieval quality, speed, and memory.\n\nIn detail, youâ€™ll:\n- Learn about the internal workings of the embedding models and how your text turns into vectors.\n- Understand how several tokenizers, such as Byte-Pair Encoding, WordPiece, Unigram, and SentencePiece work.\n- Explore common challenges with tokenizers, such as unknown tokens, domain-specific identifiers, and numerical values, that can negatively affect your vector search.\n- Understand how to measure the quality of your search across relevance, ranking, and score-related metrics.\n- Understand how the main parameters in \"HNSW\", a graph-based algorithm, affect the relevance and speed of vector search, and how to tune its parameters.\n- Experiment with the three major quantization methods â€“ product, scalar, and binary â€“ and learn how they impact memory requirements, search quality, and speed.\n\nBy the end of this course, youâ€™ll have a solid understanding of how tokenization functions and how to optimize vector search in your RAG systems.\n\nPlease sign up here! https://t.co/wIrSEGAcb9",
    "createdAt": "Wed Oct 02 15:11:39 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 300,
    "replyCount": 30,
    "likeCount": 1658,
    "quoteCount": 11,
    "viewCount": 145546,
    "bookmarkCount": 1403,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "<p>Tokenization (åˆ†è¯) â€”â€”å°†æ–‡æœ¬è½¬åŒ–ä¸ºæ•´æ•°åºåˆ—çš„è¿‡ç¨‹â€”â€”æ˜¯ç”Ÿæˆå¼ AI (Generative AI) çš„ä¸€ä¸ªå…³é”®ç¯èŠ‚ï¼Œå¤§å¤šæ•° API æä¾›å•†éƒ½æŒ‰æ¯ç™¾ä¸‡ä¸ª token æ”¶è´¹ã€‚é‚£ä¹ˆï¼ŒTokenization æ˜¯å¦‚ä½•å·¥ä½œçš„å‘¢ï¼Ÿåœ¨ã€Šæ£€ç´¢ä¼˜åŒ–ï¼šä» Tokenization åˆ°å‘é‡é‡åŒ–ã€‹è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†æ·±å…¥äº†è§£ Tokenization å’Œ RAG ä¼˜åŒ–çš„ç»†èŠ‚ã€‚è¿™é—¨è¯¾ç¨‹æ˜¯ä¸ @qdrant_engine åˆä½œæ¨å‡ºï¼Œå¹¶ç”±å…¶å¼€å‘è€…å…³ç³»è´Ÿè´£äºº @LukawskiKacper ä¸»è®²ã€‚</p>\n<p>æœ¬è¯¾ç¨‹é‡ç‚¹èšç„¦æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval Augmented Generation, RAG) æŠ€æœ¯ï¼Œå®ƒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼šé¦–å…ˆï¼Œæ£€ç´¢å™¨ (retriever) è´Ÿè´£æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ï¼›ç„¶åï¼Œç”Ÿæˆå™¨ (generator) åˆ©ç”¨è¿™äº›æ£€ç´¢åˆ°çš„å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œæ¥ç”Ÿæˆæœ€ç»ˆçš„å“åº”ã€‚æ‚¨å°†å­¦ä¹ å¦‚ä½•é€šè¿‡ç†è§£ Tokenization çš„å·¥ä½œåŸç†ä»¥åŠå®ƒå¦‚ä½•å½±å“æœç´¢ç»“æœçš„ç›¸å…³æ€§ï¼Œä»è€Œä¼˜åŒ– RAG çš„ç¬¬ä¸€æ­¥ï¼ˆå³æ£€ç´¢ç¯èŠ‚ï¼‰ã€‚æ­¤å¤–ï¼Œæ‚¨è¿˜å°†æŒæ¡è¡¡é‡å’Œæå‡æ£€ç´¢è´¨é‡ã€é€Ÿåº¦åŠå†…å­˜æ•ˆç‡çš„æ–¹æ³•ã€‚</p>\n<p>å…·ä½“æ¥è¯´ï¼Œæ‚¨å°†ï¼š</p>\n<ul>\n<li>äº†è§£åµŒå…¥æ¨¡å‹ (embedding models) çš„å†…éƒ¨æœºåˆ¶ï¼Œä»¥åŠæ–‡æœ¬æ˜¯å¦‚ä½•è¢«è½¬åŒ–ä¸ºå‘é‡çš„ã€‚</li>\n<li>ç†è§£å‡ ç§ä¸»æµçš„åˆ†è¯å™¨ (tokenizer)ï¼Œä¾‹å¦‚ Byte-Pair Encodingã€WordPieceã€Unigram å’Œ SentencePiece çš„å·¥ä½œåŸç†ã€‚</li>\n<li>æ¢ç´¢åˆ†è¯å™¨å¸¸è§çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚æœªçŸ¥ tokenã€ç‰¹å®šé¢†åŸŸçš„æ ‡è¯†ç¬¦å’Œæ•°å€¼ï¼Œè¿™äº›éƒ½å¯èƒ½å¯¹æ‚¨çš„å‘é‡æœç´¢äº§ç”Ÿè´Ÿé¢å½±å“ã€‚</li>\n<li>å­¦ä¹ å¦‚ä½•æ ¹æ®ç›¸å…³æ€§ã€æ’åå’Œä¸åˆ†æ•°ç›¸å…³çš„æŒ‡æ ‡æ¥è¯„ä¼°æœç´¢è´¨é‡ã€‚</li>\n<li>ç†è§£åŸºäºå›¾çš„ç®—æ³•â€œHNSWâ€ä¸­çš„ä¸»è¦å‚æ•°å¦‚ä½•å½±å“å‘é‡æœç´¢çš„ç›¸å…³æ€§å’Œé€Ÿåº¦ï¼Œä»¥åŠå¦‚ä½•å¯¹å…¶è¿›è¡Œè°ƒä¼˜ã€‚</li>\n<li>é€šè¿‡å®è·µï¼Œä½“éªŒä¸‰ç§ä¸»è¦çš„é‡åŒ–æ–¹æ³•â€”â€”ä¹˜ç§¯é‡åŒ– (product quantization)ã€æ ‡é‡é‡åŒ– (scalar quantization) å’ŒäºŒè¿›åˆ¶é‡åŒ– (binary quantization)â€”â€”å¹¶äº†è§£å®ƒä»¬å¦‚ä½•å½±å“å†…å­˜éœ€æ±‚ã€æœç´¢è´¨é‡å’Œé€Ÿåº¦ã€‚</li>\n</ul>\n<p>å­¦å®Œæœ¬è¯¾ç¨‹åï¼Œæ‚¨å°†å¯¹ Tokenization çš„åŠŸèƒ½ä»¥åŠå¦‚ä½•åœ¨ RAG ç³»ç»Ÿä¸­ä¼˜åŒ–å‘é‡æœç´¢æœ‰ä¸€ä¸ªæ‰å®çš„ç†è§£ã€‚</p>\n<p>è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼ <a href=\"https://t.co/wIrSEGAcb9\">https://t.co/wIrSEGAcb9</a></p>"
  },
  {
    "id": "1841178556904456275",
    "url": "https://x.com/AndrewYNg/status/1841178556904456275",
    "text": "AI needs UI, and OpenAI's impressive new voice APIs  open up a lot of possibilities. Congrats @OpenAI team -- we'll soon be  seeing a whole new generation of speech applications!",
    "createdAt": "Tue Oct 01 18:09:10 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 147,
    "replyCount": 55,
    "likeCount": 1659,
    "quoteCount": 21,
    "viewCount": 109190,
    "bookmarkCount": 202,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "AI ç¦»ä¸å¼€ UIï¼Œè€Œ OpenAI å…¨æ–°ä¸”ä»¤äººæƒŠå¹çš„è¯­éŸ³ API (API) çš„æ¨å‡ºï¼Œæ— ç–‘å¼€å¯äº†æ— æ•°æ–°çš„å¯èƒ½ã€‚æ­å–œ @OpenAI å›¢é˜Ÿï¼Œæˆ‘ä»¬å¾ˆå¿«å°±èƒ½çœ‹åˆ°å…¨æ–°ä¸€ä»£çš„è¯­éŸ³åº”ç”¨ç¨‹åºè“¬å‹ƒå‘å±•äº†ï¼"
  },
  {
    "id": "1840788292750791046",
    "url": "https://x.com/AndrewYNg/status/1840788292750791046",
    "text": "AI policy should be based in science, not science fiction! \n\nWith SB-1047 defeated, @dawnsongtweets gives a sound plan for taking a scientific approach to study  actual risks and mitigating harms. \n\nA couple of key ideas:\n* Lets empower researchers to study AI risks, focusing on the question of marginal risk: I.e., how much does an AI application increase the risk of a negative outcome? \n* Lets also increase transparency of AI systems. For example, open-source and and red-teaming will help! \n\nMany of the opponents to SB-1047 have been strong champions of Responsible AI, long before it was trendy to talk about it. We take safety seriously; and, we want policy to based in science, not science fiction.",
    "createdAt": "Mon Sep 30 16:18:23 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 79,
    "replyCount": 35,
    "likeCount": 436,
    "quoteCount": 3,
    "viewCount": 75446,
    "bookmarkCount": 44,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "AI æ”¿ç­–åº”ç«‹è¶³ç§‘å­¦ï¼Œè€Œéç§‘å¹»ï¼\n\néšç€ SB-1047 æ³•æ¡ˆè¢«å¦å†³ï¼Œ@dawnsongtweets æå‡ºäº†ä¸€é¡¹å¯é çš„è®¡åˆ’ï¼Œæ—¨åœ¨é€šè¿‡ç§‘å­¦æ–¹æ³•æ¥ç ”ç©¶å®é™…é£é™©å¹¶æœ‰æ•ˆè§„é¿æ½œåœ¨å±å®³ã€‚\n\nå…¶ä¸­æœ‰å‡ ä¸ªå…³é”®è§‚ç‚¹ï¼š\n*   æˆ‘ä»¬åº”è¯¥æ”¯æŒç ”ç©¶äººå‘˜æ·±å…¥æ¢ç©¶ AI é£é™©ï¼Œå°¤å…¶è¦å…³æ³¨è¾¹é™…é£é™© (Marginal Risk) é—®é¢˜ï¼šä¾‹å¦‚ï¼Œä¸€ä¸ª AI åº”ç”¨ç©¶ç«Ÿä¼šå°†è´Ÿé¢ç»“æœçš„é£é™©æé«˜å¤šå°‘ï¼Ÿ\n*   æˆ‘ä»¬è¿˜åº”è¯¥æé«˜ AI ç³»ç»Ÿçš„é€æ˜åº¦ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡å¼€æºå’Œçº¢é˜Ÿæ¼”ç»ƒ (Red-Teaming) ç­‰æ–¹å¼ï¼Œå°†å¤§æœ‰è£¨ç›Šï¼\n\nè®¸å¤šåå¯¹ SB-1047 æ³•æ¡ˆçš„äººå£«ï¼Œå…¶å®æ—©åœ¨â€œè´Ÿè´£ä»» AI (Responsible AI)â€æˆä¸ºçƒ­é—¨è¯é¢˜ä¹‹å‰ï¼Œå°±å·²ç»æ˜¯å…¶åšå®šçš„å€¡å¯¼è€…äº†ã€‚æˆ‘ä»¬å§‹ç»ˆè®¤çœŸå¯¹å¾…å®‰å…¨é—®é¢˜ï¼Œå¹¶ä¸”å¸Œæœ› AI æ”¿ç­–èƒ½å¤Ÿä»¥ç§‘å­¦ä¸ºåŸºç¡€ï¼Œè€Œéä»…ä»…åœç•™åœ¨ç§‘å¹»æƒ³è±¡ã€‚"
  },
  {
    "id": "1840547768894685497",
    "url": "https://x.com/AndrewYNg/status/1840547768894685497",
    "text": "@ClementDelangue @GavinNewsom Thank you @ClementDelangue for unfailingly  advocating for open-source, and speaking out against bad laws like SB-1047. Hugging Face has been a wonderful force bringing openness to AI!",
    "createdAt": "Mon Sep 30 00:22:38 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 0,
    "likeCount": 39,
    "quoteCount": 0,
    "viewCount": 4177,
    "bookmarkCount": 1,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@ClementDelangue @GavinNewsom æ„Ÿè°¢ @ClementDelangue å§‹ç»ˆå¦‚ä¸€åœ°å€¡å¯¼å¼€æºï¼Œå¹¶å…¬å¼€åå¯¹åƒ SB-1047 è¿™æ ·æœ‰é—®é¢˜çš„æ³•å¾‹ã€‚ Hugging Face ä¸€ç›´æ˜¯æ¨åŠ¨äººå·¥æ™ºèƒ½ (AI) å¼€æ”¾çš„é‡è¦åŠ›é‡ï¼"
  },
  {
    "id": "1840530050040631600",
    "url": "https://x.com/AndrewYNg/status/1840530050040631600",
    "text": "@bindureddy Thank you @bindureddy for fighting for open-source and against SB-1047. I appreciate especially your  pushing back against AGI hype -- which leads to science fiction based fears and bad laws like SB-1047!",
    "createdAt": "Sun Sep 29 23:12:13 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 11,
    "replyCount": 2,
    "likeCount": 225,
    "quoteCount": 2,
    "viewCount": 15038,
    "bookmarkCount": 2,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@bindureddy è°¢è°¢ä½ ï¼ŒBindu Reddyï¼Œä¸ºå¼€æºäº‹ä¸šè€Œå¥‹æ–—ï¼Œå¹¶åå¯¹ SB-1047 æ³•æ¡ˆã€‚æˆ‘å°¤å…¶èµèµä½ æŠµåˆ¶é€šç”¨äººå·¥æ™ºèƒ½ (AGI) ç‚’ä½œâ€”â€”è¿™ç§ç‚’ä½œå¾€å¾€ä¼šå¼•å‘ç§‘å¹»å°è¯´èˆ¬çš„ææƒ§ï¼Œå¹¶å¯¼è‡´åƒ SB-1047 è¿™æ ·ç³Ÿç³•çš„æ³•å¾‹å‡ºç°ï¼"
  },
  {
    "id": "1840525690770542797",
    "url": "https://x.com/AndrewYNg/status/1840525690770542797",
    "text": "@drfeifei @StanfordHAI @CAgovernor @GavinNewsom Thank you @drfeifei for your speaking out against SB-1047, and also for working toward a more rational approach to AI policy that protects research and innovation. It has been fantastic seeing you step into the fray and so effectively influence things for the better!",
    "createdAt": "Sun Sep 29 22:54:54 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 10,
    "replyCount": 2,
    "likeCount": 195,
    "quoteCount": 1,
    "viewCount": 12659,
    "bookmarkCount": 3,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@drfeifei @StanfordHAI @CAgovernor @GavinNewsom æ„Ÿè°¢ @drfeifei æ‚¨å…¬å¼€åå¯¹ SB-1047 æ³•æ¡ˆï¼Œå¹¶è‡´åŠ›äºæ¨åŠ¨åˆ¶å®šæ›´ç†æ€§çš„ AI (äººå·¥æ™ºèƒ½) æ”¿ç­–ï¼Œä»¥ä¿æŠ¤ç ”ç©¶å’Œåˆ›æ–°ã€‚éå¸¸é«˜å…´çœ‹åˆ°æ‚¨èƒ½æŒºèº«è€Œå‡ºï¼Œå¦‚æ­¤æœ‰æ•ˆåœ°ç§¯æå½±å“äº†å±€é¢ï¼"
  },
  {
    "id": "1840525012719329551",
    "url": "https://x.com/AndrewYNg/status/1840525012719329551",
    "text": "@psychosort @GavinNewsom Thank you @psychosort for your many thoughtful writings on SB-1047, and also your hard work debunking bad arguments -- I've really appreciated your cutting through the noise to the heart of why SB-1047 was a bad idea!",
    "createdAt": "Sun Sep 29 22:52:12 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 2,
    "replyCount": 0,
    "likeCount": 34,
    "quoteCount": 1,
    "viewCount": 6026,
    "bookmarkCount": 1,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@psychosort @GavinNewsom æ„Ÿè°¢ @psychosort ä½ å…³äº SB-1047 çš„è¯¸å¤šæ·±æ€ç†Ÿè™‘çš„æ–‡ç« ï¼Œä»¥åŠä½ ä¸ºé©³æ–¥ä¸å½“è®ºç‚¹æ‰€ä»˜å‡ºçš„è¾›å‹¤åŠªåŠ›â€”â€”æˆ‘çœŸçš„å¾ˆæ¬£èµä½ æ‹¨å¼€å–§åš£ï¼Œç›´è¾¾ SB-1047 ä¸ºä»€ä¹ˆæ˜¯ä¸ªç³Ÿç³•ä¸»æ„çš„æ ¸å¿ƒï¼"
  },
  {
    "id": "1840523898653467108",
    "url": "https://x.com/AndrewYNg/status/1840523898653467108",
    "text": "@reidhoffman @GavinNewsom Thank you @reidhoffman for being a consistently rational voice in AI, and for advocating a responsible approach to bringing benefits to billions while also not being distracted by science fiction fears!",
    "createdAt": "Sun Sep 29 22:47:47 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 1,
    "replyCount": 1,
    "likeCount": 44,
    "quoteCount": 0,
    "viewCount": 5269,
    "bookmarkCount": 2,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@reidhoffman @GavinNewsom æ„Ÿè°¢ä½  @reidhoffmanï¼Œåœ¨äººå·¥æ™ºèƒ½ (AI) é¢†åŸŸå§‹ç»ˆå‘å‡ºç†æ€§çš„å£°éŸ³ï¼Œå¹¶å€¡å¯¼ä»¥è´Ÿè´£ä»»çš„æ–¹å¼ä¸ºæ•°åäº¿äººå¸¦æ¥ç›Šå¤„ï¼ŒåŒæ—¶ä¸è¢«ç§‘å¹»å¼çš„æ‹…å¿§æ‰€å›°æ‰°ï¼"
  },
  {
    "id": "1840521890936598784",
    "url": "https://x.com/AndrewYNg/status/1840521890936598784",
    "text": "@deanwball Thank you @deanwball for your tirelessly writing and speaking on SB-1047. I've enjoyed many of your writings and am grateful for your consistently championing an approach to AI policy that targets bad conduct, rather than attacks AI models!",
    "createdAt": "Sun Sep 29 22:39:48 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 3,
    "replyCount": 3,
    "likeCount": 32,
    "quoteCount": 0,
    "viewCount": 2201,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@deanwball è°¢è°¢ä½  @deanwballï¼Œæ„Ÿè°¢ä½ ä¸º SB-1047 ä¸çŸ¥ç–²å€¦åœ°æ’°å†™æ–‡ç« å’Œå‘è¡¨æ¼”è®²ã€‚æˆ‘å¾ˆæ¬£èµä½ çš„è¯¸å¤šä½œå“ï¼Œå¹¶æ„Ÿè°¢ä½ å§‹ç»ˆå¦‚ä¸€åœ°å€¡å¯¼è¿™æ ·ä¸€ç§äººå·¥æ™ºèƒ½ (AI) æ”¿ç­–æ–¹æ³•ï¼šå®ƒè‡´åŠ›äºé’ˆå¯¹ä¸å½“è¡Œä¸ºï¼Œè€Œéç›´æ¥æ”»å‡» AI æ¨¡å‹æœ¬èº«ï¼"
  },
  {
    "id": "1840521131511697617",
    "url": "https://x.com/AndrewYNg/status/1840521131511697617",
    "text": "@RonConway @GavinNewsom Thank you @RonConway for your massive efforts reaching out to and helping many stakeholders think through AI policy. I'm grateful that you've been such a powerful voice of reason in debate on SB-1047!",
    "createdAt": "Sun Sep 29 22:36:47 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 15,
    "quoteCount": 0,
    "viewCount": 3525,
    "bookmarkCount": 1,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@RonConway @GavinNewsom è°¢è°¢ @RonConway ä¸ºè”ç³»ä¼—å¤šåˆ©ç›Šç›¸å…³è€…å¹¶å¸®åŠ©ä»–ä»¬æ·±å…¥æ€è€ƒ AI (äººå·¥æ™ºèƒ½) æ”¿ç­–æ‰€ä»˜å‡ºçš„å·¨å¤§åŠªåŠ›ã€‚æˆ‘éå¸¸æ„Ÿè°¢ä½ åœ¨ SB-1047 çš„è¾©è®ºä¸­ï¼Œä¸€ç›´éƒ½æ˜¯ä¸€ä¸ªå¦‚æ­¤æœ‰åŠ›ä¸”ç†æ€§çš„å£°éŸ³ï¼"
  },
  {
    "id": "1840520356114952231",
    "url": "https://x.com/AndrewYNg/status/1840520356114952231",
    "text": "@garrytan @GavinNewsom @ycombinator Thank you @garrytan and the @ycombinator team for all you've done to push back on SB 1047. It has been a pleasure seeing YC organize to argue for a rational approach to AI policy!",
    "createdAt": "Sun Sep 29 22:33:42 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 1,
    "replyCount": 1,
    "likeCount": 51,
    "quoteCount": 0,
    "viewCount": 5748,
    "bookmarkCount": 1,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@garrytan @GavinNewsom @ycombinator æ„Ÿè°¢ @garrytan å’Œ @ycombinator å›¢é˜Ÿåœ¨æŠµåˆ¶ SB 1047 æ–¹é¢æ‰€åšçš„ä¸€åˆ‡åŠªåŠ›ã€‚å¾ˆé«˜å…´çœ‹åˆ° YC ç»„ç»‡èµ·æ¥ï¼Œå€¡å¯¼å¯¹ AI æ”¿ç­–é‡‡å–ç†æ€§çš„æ–¹æ³•ï¼"
  },
  {
    "id": "1840519382390497441",
    "url": "https://x.com/AndrewYNg/status/1840519382390497441",
    "text": "@pmarca @GavinNewsom Thank you @pmarca for your leadership fighting SB1047. (I know the full story of what you've done to fight bad AI regulation is far from told; and, I'm grateful for your massive efforts here.) Having @a16z fight for a rational approach to AI has been a huge boon!",
    "createdAt": "Sun Sep 29 22:29:50 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 15,
    "replyCount": 1,
    "likeCount": 477,
    "quoteCount": 2,
    "viewCount": 71852,
    "bookmarkCount": 19,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@pmarca @GavinNewsom æ„Ÿè°¢ @pmarca æ‚¨åœ¨åå¯¹ SB1047 æ³•æ¡ˆä¸­å‘æŒ¥çš„é¢†å¯¼ä½œç”¨ã€‚(æˆ‘çŸ¥é“æ‚¨ä¸ºæŠµåˆ¶ç³Ÿç³•çš„ AI ç›‘ç®¡æ‰€åšçš„ä¸€åˆ‡è¿˜è¿œæœªè¢«å®Œå…¨å…¬å¼€ï¼›å¯¹æ­¤ï¼Œæˆ‘éå¸¸æ„Ÿè°¢æ‚¨åœ¨æ­¤ä»˜å‡ºçš„å·¨å¤§åŠªåŠ›ã€‚) æœ‰ @a16z è¿™æ ·ä¸º AI å¯»æ±‚ç†æ€§æ–¹æ³•è€Œæˆ˜çš„åŠ›é‡ï¼ŒçœŸæ˜¯å¸®äº†å¤§å¿™ï¼"
  },
  {
    "id": "1840518403683172833",
    "url": "https://x.com/AndrewYNg/status/1840518403683172833",
    "text": "@AnjneyMidha @GavinNewsom Thank you @AnjneyMidha for being a consistent voice of reason in the discussion on SB-1047. It's been a pleasure watching you patiently reach out to and help multiple stakeholders understand why SB-1047 was an awful idea!",
    "createdAt": "Sun Sep 29 22:25:57 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 20,
    "quoteCount": 0,
    "viewCount": 2507,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@AnjneyMidha @GavinNewsom æ„Ÿè°¢ @AnjneyMidha åœ¨å…³äº SB-1047 çš„è®¨è®ºä¸­å§‹ç»ˆä¿æŒç†æ€§å‘å£°ã€‚å¾ˆé«˜å…´çœ‹åˆ°ä½ è€å¿ƒåœ°ä¸å¤šæ–¹åˆ©ç›Šç›¸å…³è€…æ²Ÿé€šï¼Œå¹¶å¸®åŠ©ä»–ä»¬ç†è§£ä¸ºä»€ä¹ˆ SB-1047 æ˜¯ä¸€ä¸ªç³Ÿç³•çš„ä¸»æ„ï¼"
  },
  {
    "id": "1840517975167967261",
    "url": "https://x.com/AndrewYNg/status/1840517975167967261",
    "text": "@chrislengerich @GavinNewsom Thank you @chrislengerich for your fighting SB-1047 and for your thoughtful analyses of the law. Even as the (bad) law kept getting amended repeatedly, that you kept publishing clear analyses of each revision really helped cut through the noise and confusion!",
    "createdAt": "Sun Sep 29 22:24:15 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 4,
    "replyCount": 1,
    "likeCount": 25,
    "quoteCount": 0,
    "viewCount": 1637,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@chrislengerich @GavinNewsom è°¢è°¢ä½ ï¼Œ@chrislengerichï¼Œæ„Ÿè°¢ä½ ä¸ºåå¯¹ SB-1047 æ‰€åšçš„åŠªåŠ›ï¼Œä»¥åŠä½ å¯¹è¯¥æ³•æ¡ˆå¯Œæœ‰æ´å¯ŸåŠ›çš„åˆ†æã€‚å³ä½¿è¿™é¡¹ï¼ˆç³Ÿç³•çš„ï¼‰æ³•æ¡ˆå±¡æ¬¡ä¿®è®¢ï¼Œä½ ä»ç„¶åšæŒå‘å¸ƒå¯¹æ¯æ¬¡ä¿®æ”¹çš„æ¸…æ™°è§£è¯»ï¼Œè¿™ç¡®å®å¸®åŠ©å¤§å®¶æ‹¨å¼€äº†å–§åš£å’Œå›°æƒ‘ï¼"
  },
  {
    "id": "1840516963405271113",
    "url": "https://x.com/AndrewYNg/status/1840516963405271113",
    "text": "@ylecun @GavinNewsom Thank you @ylecun for your consistently clear and thoughtful explanations for why SB-1047 was a bad idea. We are lucky to have you as such a strong champion for open-source and AI innovation!",
    "createdAt": "Sun Sep 29 22:20:13 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 25,
    "replyCount": 6,
    "likeCount": 750,
    "quoteCount": 1,
    "viewCount": 38403,
    "bookmarkCount": 12,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@ylecun @GavinNewsom æ„Ÿè°¢ @ylecun å§‹ç»ˆå¦‚ä¸€åœ°æ¸…æ™°ä¸”æ·±æ€ç†Ÿè™‘åœ°è§£é‡Šäº†ä¸ºä»€ä¹ˆ SB-1047 æ˜¯ä¸ªç³Ÿç³•çš„ä¸»æ„ã€‚æˆ‘ä»¬å¾ˆå¹¸è¿æœ‰ä½ è¿™æ ·ä¸€ä½å¼€æºå’Œ AI åˆ›æ–° (AI innovation) çš„åšå®šå€¡å¯¼è€…ï¼"
  },
  {
    "id": "1840516178948870569",
    "url": "https://x.com/AndrewYNg/status/1840516178948870569",
    "text": "@AnimaAnandkumar @GavinNewsom @Caltech Thank you @AnimaAnandkumar and the broader @Caltech community for speaking out against SB-1047. I appreciated particularly the letter you circulated explaining why the law would have been a bad idea.",
    "createdAt": "Sun Sep 29 22:17:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 30,
    "quoteCount": 1,
    "viewCount": 7537,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@AnimaAnandkumar @GavinNewsom @Caltech æ„Ÿè°¢ @AnimaAnandkumar å’Œæ›´å¹¿æ³›çš„ @Caltech ç¤¾åŒºå¯¹ SB-1047 æå‡ºå¼‚è®®ã€‚æˆ‘å°¤å…¶èµèµæ‚¨ä»¬ä¼ é˜…çš„é‚£å°ä¿¡ï¼Œå…¶ä¸­é˜æ˜äº†ä¸ºä½•è¿™é¡¹æ³•å¾‹ä¼šæ˜¯ä¸€ä¸ªç³Ÿç³•çš„æè®®ã€‚"
  },
  {
    "id": "1840515709190943085",
    "url": "https://x.com/AndrewYNg/status/1840515709190943085",
    "text": "@jeremyphoward Thank you @jeremyphoward for your speaking out against SB-1047! Much appreciate your vocal opposition to this ill-informed law!",
    "createdAt": "Sun Sep 29 22:15:14 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 2,
    "likeCount": 108,
    "quoteCount": 0,
    "viewCount": 9308,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@jeremyphoward æ„Ÿè°¢æ‚¨ @jeremyphoward å…¬å¼€åå¯¹ SB-1047! éå¸¸æ„Ÿè°¢æ‚¨å¯¹è¿™é¡¹æ¬ è€ƒè™‘çš„æ³•å¾‹è¡¨è¾¾çš„å¼ºçƒˆåå¯¹!"
  },
  {
    "id": "1840515301106237858",
    "url": "https://x.com/AndrewYNg/status/1840515301106237858",
    "text": "@pentagoniac @thewendylee @latimes Thank you @pentagoniac for your tireless efforts speaking out against SB-1047! It has been great having you and the AI Alliance help spread the word regarding  why it was a broken, harmful bill.",
    "createdAt": "Sun Sep 29 22:13:37 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 1,
    "replyCount": 1,
    "likeCount": 9,
    "quoteCount": 0,
    "viewCount": 1476,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@pentagoniac @thewendylee @latimes æ„Ÿè°¢ @pentagoniac ä¸ºåå¯¹ SB-1047 æ‰€åšçš„ä¸æ‡ˆåŠªåŠ›ï¼å¾ˆé«˜å…´æœ‰æ‚¨å’Œ AI Alliance å¸®åŠ©å¤§å®¶äº†è§£ä¸ºä½•è¿™é¡¹æ³•æ¡ˆå­˜åœ¨ç¼ºé™·ä¸”å±å®³æ·±è¿œã€‚"
  },
  {
    "id": "1840502075593199931",
    "url": "https://x.com/AndrewYNg/status/1840502075593199931",
    "text": "@martin_casado @GavinNewsom Huge shoutout to you @martin_casado for the tremendous work you've done to push back on SB-1047 and other anti-open-source regulation. Thank you!",
    "createdAt": "Sun Sep 29 21:21:04 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 6,
    "replyCount": 1,
    "likeCount": 138,
    "quoteCount": 1,
    "viewCount": 11256,
    "bookmarkCount": 3,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@martin_casado @GavinNewsom å¿…é¡»å‘ä½  @martin_casado è¡¨è¾¾ç”±è¡·çš„æ„Ÿè°¢ï¼Œæ„Ÿè°¢ä½ ä¸ºæŠµåˆ¶ SB-1047 åŠå…¶ä»–åå¼€æºæ³•è§„æ‰€ä»˜å‡ºçš„å·¨å¤§åŠªåŠ›ã€‚è°¢è°¢ä½ ï¼"
  },
  {
    "id": "1840497561821651069",
    "url": "https://x.com/AndrewYNg/status/1840497561821651069",
    "text": "Thank you Governor @GavinNewsom for vetoing SB-1047 -- your pro-innovation leadership is much appreciated! \n\nAnd to the many people who've been pushing back on SB-1047, a huge thank you as well. Congratulations to all -- we won! ğŸ‰ \n \nLooking ahead, lets keep on protecting AI open-source and innovation. We must make sure AI policy is based on science, not science fiction!",
    "createdAt": "Sun Sep 29 21:03:08 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 214,
    "replyCount": 66,
    "likeCount": 1464,
    "quoteCount": 31,
    "viewCount": 158553,
    "bookmarkCount": 66,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ„Ÿè°¢å·é•¿ @GavinNewsom å¦å†³äº† SB-1047 â€”â€” æ‚¨æ”¯æŒåˆ›æ–°çš„é¢†å¯¼åŠ›ä»¤äººéå¸¸èµèµï¼\n\nåŒæ—¶ï¼Œä¹Ÿå‘æ‰€æœ‰ä¸€ç›´æŠµåˆ¶ SB-1047 çš„æœ‹å‹ä»¬è‡´ä»¥æœ€è¯šæŒšçš„æ„Ÿè°¢ã€‚æ­å–œå¤§å®¶ â€”â€” æˆ‘ä»¬èµ¢äº†ï¼ğŸ‰\n\nå±•æœ›æœªæ¥ï¼Œæˆ‘ä»¬å¿…é¡»ç»§ç»­ä¿æŠ¤ AI çš„å¼€æºç²¾ç¥å’Œåˆ›æ–°æ´»åŠ›ã€‚æˆ‘ä»¬ä¸€å®šè¦ç¡®ä¿ AI æ”¿ç­–æ˜¯åŸºäºç§‘å­¦äº‹å®ï¼Œè€Œä¸æ˜¯ç§‘å¹»æƒ³è±¡ï¼"
  },
  {
    "id": "1840439968407363942",
    "url": "https://x.com/AndrewYNg/status/1840439968407363942",
    "text": "Good summary of the case for vetoing SB-1047 by @psychosort",
    "createdAt": "Sun Sep 29 17:14:16 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 36,
    "replyCount": 10,
    "likeCount": 206,
    "quoteCount": 2,
    "viewCount": 95813,
    "bookmarkCount": 23,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "@psychosort å¯¹å¦å†³ SB-1047 çš„è®ºç‚¹è¿›è¡Œäº†å¾ˆå¥½çš„æ€»ç»“ã€‚"
  },
  {
    "id": "1839744822737002662",
    "url": "https://x.com/AndrewYNg/status/1839744822737002662",
    "text": "@asangani7 Thank you for having me at Meta Connect @asangani7! I love what you and the @AIatMeta team are doing and am very grateful for all the open models y'all are  releasing. What a wonderful gift to the world!",
    "createdAt": "Fri Sep 27 19:12:01 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 3,
    "quoteCount": 0,
    "viewCount": 2048,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@asangani7 è°¢è°¢ä½ é‚€è¯·æˆ‘å‚åŠ  Meta Connectï¼æˆ‘éå¸¸å–œæ¬¢ä½ å’Œ @AIatMeta å›¢é˜Ÿæ‰€åšçš„ä¸€åˆ‡ï¼Œä¹Ÿæ— æ¯”æ„Ÿæ¿€ä½ ä»¬å‘å¸ƒçš„æ‰€æœ‰å¼€æ”¾æ¨¡å‹ã€‚è¿™çœŸæ˜¯é€ç»™ä¸–ç•Œçš„ä¸€ä»½ç¾å¥½ç¤¼ç‰©ï¼"
  },
  {
    "id": "1839392271386730591",
    "url": "https://x.com/AndrewYNg/status/1839392271386730591",
    "text": "A decision on SB-1047 is due soon. Governor @GavinNewsom has said he's concerned about its \"chilling effect, particularly in the open source community\". He's right, and I hope he will veto this. \n\nIf you agree, please like/retweet this to show your support for VETOing SB-1047!",
    "createdAt": "Thu Sep 26 19:51:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 480,
    "replyCount": 72,
    "likeCount": 1762,
    "quoteCount": 55,
    "viewCount": 629075,
    "bookmarkCount": 80,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…³äº SB-1047 çš„å†³å®šå³å°†å…¬å¸ƒã€‚å·é•¿ @GavinNewsom æ›¾è¡¨ç¤ºä»–æ‹…å¿ƒè¯¥æ³•æ¡ˆä¼šäº§ç”Ÿâ€œå¯’è‰æ•ˆåº” (chilling effect)â€ï¼Œå°¤å…¶æ˜¯åœ¨å¼€æºç¤¾åŒºã€‚ä»–çš„çœ‹æ³•æ˜¯æ­£ç¡®çš„ï¼Œæˆ‘å¸Œæœ›ä»–èƒ½å¦å†³è¿™é¡¹ææ¡ˆã€‚\n\nå¦‚æœæ‚¨åŒæ„ï¼Œè¯·ç‚¹èµ/è½¬å‘æ­¤æ¨æ–‡ï¼Œä»¥è¡¨ç¤ºæ‚¨æ”¯æŒå¦å†³ SB-1047ï¼"
  },
  {
    "id": "1839338535519932886",
    "url": "https://x.com/AndrewYNg/status/1839338535519932886",
    "text": "Announcing Generative AI for Software Development, a new specialization on Coursera! Taught by my friend and longtime https://t.co/zpIxRSuky4 instructor @lmoroney. \n\nUsing GenAI for software development goes well beyond using chatbots for code generation. This 3-course series shares current best practices for AI use through the entire software development lifecycle: From design and architecture to coding, testing, deployment, and maintenance.\n\nYou'll learn to use LLMs as your thought partner, pair programmer, documentation specialist, security analyst, and performance optimization expert. There's a lot that anyone that writes software can gain from using GenAI, and this will show you how!\n\nPlease sign up here to get started! https://t.co/8nKgy32vIc",
    "createdAt": "Thu Sep 26 16:17:34 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 161,
    "replyCount": 24,
    "likeCount": 799,
    "quoteCount": 3,
    "viewCount": 68926,
    "bookmarkCount": 522,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å®£å¸ƒåœ¨ Coursera ä¸Šæ¨å‡ºä¸€é—¨æ–°ä¸“é¡¹è¯¾ç¨‹ï¼šè½¯ä»¶å¼€å‘ä¸­çš„ç”Ÿæˆå¼ AI (Generative AI)ï¼è¯¥è¯¾ç¨‹ç”±æˆ‘çš„æœ‹å‹ã€åŒæ—¶ä¹Ÿæ˜¯ https://t.co/zpIxRSuky4 çš„èµ„æ·±è®²å¸ˆ @lmoroney æ•™æˆã€‚\n\nå°†ç”Ÿæˆå¼ AI (GenAI) åº”ç”¨äºè½¯ä»¶å¼€å‘ï¼Œè¿œä¸æ­¢ç”¨èŠå¤©æœºå™¨äººæ¥ç”Ÿæˆä»£ç ã€‚è¿™ä¸‰é—¨ç³»åˆ—è¯¾ç¨‹å°†åˆ†äº«åœ¨æ•´ä¸ªè½¯ä»¶å¼€å‘ç”Ÿå‘½å‘¨æœŸä¸­åº”ç”¨ AI çš„æœ€æ–°æœ€ä½³å®è·µï¼šæ¶µç›–ä»è®¾è®¡ä¸æ¶æ„ï¼Œåˆ°ç¼–ç ã€æµ‹è¯•ã€éƒ¨ç½²å’Œç»´æŠ¤çš„å„ä¸ªç¯èŠ‚ã€‚\n\nä½ å°†å­¦ä¼šå¦‚ä½•å°†å¤§è¯­è¨€æ¨¡å‹ (LLM) è§†ä¸ºä½ çš„æ€è€ƒä¼™ä¼´ã€ç»“å¯¹ç¨‹åºå‘˜ã€æ–‡æ¡£ä¸“å®¶ã€å®‰å…¨åˆ†æå¸ˆä»¥åŠæ€§èƒ½ä¼˜åŒ–ä¸“å®¶ã€‚ä»»ä½•ä»äº‹è½¯ä»¶å¼€å‘çš„äººï¼Œéƒ½èƒ½ä»ä½¿ç”¨ç”Ÿæˆå¼ AI ä¸­è·ç›Šè‰¯å¤šï¼Œè€Œè¿™é—¨è¯¾ç¨‹å°†å‘ä½ å±•ç¤ºå…·ä½“çš„æ–¹æ³•ï¼\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼Œç«‹å³å¼€å§‹å­¦ä¹ ï¼https://t.co/8nKgy32vIc"
  },
  {
    "id": "1839016467767111829",
    "url": "https://x.com/AndrewYNg/status/1839016467767111829",
    "text": "The Llama 3.2 open multimodal model just dropped! https://t.co/R0m408f8CA has been working with Meta on a short course on how to use it. Please sign up for \"Introducing Llama 3.2\", taught by Meta's @asangani7, which will launch Oct 9!\nhttps://t.co/CC2uLNQ20W",
    "createdAt": "Wed Sep 25 18:57:47 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 292,
    "replyCount": 38,
    "likeCount": 1559,
    "quoteCount": 17,
    "viewCount": 111444,
    "bookmarkCount": 576,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "Llama 3.2 å¼€æ”¾å¤šæ¨¡æ€æ¨¡å‹ (open multimodal model) é‡ç£…å‘å¸ƒï¼https://t.co/R0m408f8CA æ­£åœ¨ä¸ Meta åˆä½œï¼Œå…±åŒæ¨å‡ºä¸€é—¨å…³äºå¦‚ä½•ä½¿ç”¨ Llama 3.2 çš„çŸ­æœŸè¯¾ç¨‹ã€‚è¯·å¤§å®¶è¸Šè·ƒæŠ¥åå‚åŠ ç”± Meta çš„ @asangani7 è®²æˆçš„â€œLlama 3.2 ä»‹ç»â€è¯¾ç¨‹ï¼Œè¯¥è¯¾ç¨‹å°†äº 10 æœˆ 9 æ—¥ä¸Šçº¿ï¼\nhttps://t.co/CC2uLNQ20W"
  },
  {
    "id": "1836433152803488119",
    "url": "https://x.com/AndrewYNg/status/1836433152803488119",
    "text": "We just launched a major new Data Engineering Professional Certificate on Coursera! Data underlies all modern AI systems, and engineers who know how to build systems to store and serve it are in high demand. If you're interested in learning this skill, please check out this 4-course sequence, which is designed to make you job-ready to be a Data Engineer. \n\nThis is a new specialization taught by Joe Reis, the co-author of the best-selling book â€œFundamentals of Data Engineering,\" in collaboration with AWS. (Disclosure, I serve on Amazon's board.) For many AI systems, data engineering is 80% of the work, and modeling is 20%. But peopleâ€™s attention on these two topics is often flipped. This makes the job of the data engineer particularly important.\n\nIn this professional certificate, you'll learn foundational data engineering skills while implementing modern data architectures using open-source tools:\n- Learn the key steps of the data lifecycle, to generate, ingest, store, transform, and serve data.\n- Learn to align with organizational goals to design the data pipeline right for your business' needs.\n- Understand how to make necessary trade-offs between speed, scalability, security, and cost.\n\nJoe has distilled into this specialization decades of experience helping startups and large companies with data infrastructure. He is also joined by 17 other industry leaders in the data field, who will help you learn in-demand skills for the growing field of data engineering.\n\nPlease sign up here: https://t.co/2kTGSXrSHP",
    "createdAt": "Wed Sep 18 15:52:37 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 221,
    "replyCount": 39,
    "likeCount": 1352,
    "quoteCount": 12,
    "viewCount": 119315,
    "bookmarkCount": 1030,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä»¬åˆšåˆšåœ¨ Coursera ä¸Šæ¨å‡ºäº†ä¸€ä¸ªé‡ç£…çº§çš„æ•°æ®å·¥ç¨‹ä¸“ä¸šè¯ä¹¦ (Data Engineering Professional Certificate)ï¼æ•°æ®æ˜¯æ‰€æœ‰ç°ä»£ AI ç³»ç»Ÿçš„åŸºçŸ³ï¼Œå› æ­¤ï¼Œæ‡‚å¾—å¦‚ä½•æ„å»ºç³»ç»Ÿæ¥å­˜å‚¨å’Œ**æœåŠ¡æ•°æ®**çš„å·¥ç¨‹å¸ˆæ­£å—åˆ°å¸‚åœºçš„çƒ­çƒˆè¿½æ§ã€‚å¦‚æœä½ æœ‰å…´è¶£å­¦ä¹ è¿™é¡¹å…³é”®æŠ€èƒ½ï¼Œè¯·åŠ¡å¿…äº†è§£è¿™ä¸ªåŒ…å«å››é—¨è¯¾ç¨‹çš„ç³»åˆ—ï¼Œå®ƒæ—¨åœ¨è®©ä½ åšå¥½æˆä¸ºä¸€å**æ•°æ®å·¥ç¨‹å¸ˆ (Data Engineer)** çš„å°±ä¸šå‡†å¤‡ã€‚\n\nè¿™æ˜¯ä¸€ä¸ªç”±ç•…é”€ä¹¦ã€Šæ•°æ®å·¥ç¨‹åŸºç¡€ã€‹çš„åˆè‘—è€… Joe Reis ä¸ AWS åˆä½œæ•™æˆçš„å…¨æ–°**ä¸“é¡¹è¯¾ç¨‹**ã€‚ï¼ˆå£°æ˜ï¼šæˆ‘æœ¬äººæ˜¯ Amazon è‘£äº‹ä¼šæˆå‘˜ã€‚ï¼‰å¯¹äºè®¸å¤š AI ç³»ç»Ÿæ¥è¯´ï¼Œæ•°æ®å·¥ç¨‹ (Data Engineering) å æ®äº† 80% çš„å·¥ä½œé‡ï¼Œè€Œæ¨¡å‹æ„å»ºä»…å  20%ã€‚ç„¶è€Œï¼Œäººä»¬å¯¹è¿™ä¸¤ä¸ªä¸»é¢˜çš„å…³æ³¨åº¦å´å¸¸å¸¸**æœ¬æœ«å€’ç½®**ã€‚è¿™æ°æ°å‡¸æ˜¾äº†**æ•°æ®å·¥ç¨‹å¸ˆ**å·¥ä½œçš„ç‰¹æ®Šé‡è¦æ€§ã€‚\n\né€šè¿‡è¿™ä»½ä¸“ä¸šè¯ä¹¦ï¼Œä½ å°†å­¦ä¹ **æ•°æ®å·¥ç¨‹**çš„åŸºç¡€æŠ€èƒ½ï¼ŒåŒæ—¶è¿ç”¨å¼€æºå·¥å…·æ¥**æ„å»ºç°ä»£æ•°æ®æ¶æ„**ï¼š\n- å­¦ä¹ **æ•°æ®ç”Ÿå‘½å‘¨æœŸ**çš„å…³é”®ç¯èŠ‚ï¼ŒåŒ…æ‹¬æ•°æ®çš„ç”Ÿæˆã€**æ‘„å–**ã€å­˜å‚¨ã€è½¬æ¢å’Œ**æœåŠ¡**ã€‚\n- æŒæ¡å¦‚ä½•æ ¹æ®ç»„ç»‡ç›®æ ‡ï¼Œè®¾è®¡å‡ºæœ€ç¬¦åˆä½ ä¸šåŠ¡éœ€æ±‚çš„æ•°æ®**ç®¡é“ (data pipeline)**ã€‚\n- ç†è§£å¦‚ä½•åœ¨é€Ÿåº¦ã€å¯æ‰©å±•æ€§ã€å®‰å…¨æ€§ä¸æˆæœ¬ä¹‹é—´åšå‡ºå¿…è¦çš„æƒè¡¡å–èˆã€‚\n\nJoe åœ¨è¿™é—¨**ä¸“é¡¹è¯¾ç¨‹**ä¸­å‡ç»“äº†ä»–æ•°åå¹´çš„å®è´µç»éªŒï¼Œè¿™äº›ç»éªŒæ›¾å¸®åŠ©æ— æ•°åˆåˆ›å…¬å¸å’Œå¤§å‹ä¼ä¸šæ­å»ºæ•°æ®åŸºç¡€è®¾æ–½ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ 17 ä½**æ•°æ®é¢†åŸŸ**çš„è¡Œä¸šé¢†è¢–**å€¾åŠ›åŠ ç›Ÿ**ï¼Œä»–ä»¬å°†å…±åŒå¸®åŠ©ä½ å­¦ä¹ **æ—¥ç›Šå£®å¤§**çš„**æ•°æ®å·¥ç¨‹**é¢†åŸŸä¸­é‚£äº›**ç´§ç¼ºçš„å®ç”¨æŠ€èƒ½**ã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æŠ¥åï¼šhttps://t.co/2kTGSXrSHP"
  },
  {
    "id": "1835028475436257705",
    "url": "https://x.com/AndrewYNg/status/1835028475436257705",
    "text": "Last weekend, my two kids colluded in a hilariously bad attempt to mislead me to look in the wrong place during a game of hide-and-seek. I was reminded that most capabilities â€” in humans or in AI â€” develop slowly.\n\nSome people fear that AI someday will learn to deceive humans deliberately. If that ever happens, Iâ€™m sure we will see it coming from far away and have plenty of time to stop it.\n\nWhile I was counting to 10 with my eyes closed, my daughter (age 5) recruited my son (age 3) to tell me she was hiding in the bathroom while she actually hid in the closet. But her stage whisper, interspersed with giggling, was so loud I heard her instructions clearly. And my sonâ€™s performance when he pointed to the bathroom was so hilariously overdramatic, I had to stifle a smile.\n\nPerhaps they will learn to trick me someday, but not yet! (In his awful performance, I think my son takes after me. To this day, I have a terrible poker face â€” which is matched by my perfect lifetime record of losing every poker game I have ever played!)\n\nLast year, the paper â€œAre Emergent Abilities of Large Language Models a Mirage?â€ by Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, which won a NeurIPS outstanding paper award, considered â€œemergentâ€ properties of LLMs, which refers to capabilities that seem to appear suddenly as model sizes increase. The authors point out that scaling laws imply that the per-token error rate decreases (improves) slowly with scale, and emergent properties might be an artifact of researchers studying nonlinear or discontinuous metrics that transform a gradually decreasing per-token error rate into something that looks more like a step function.\n\nConsider a â€œcombination lockâ€ metric that requires getting many items right. Say weâ€™re measuring the likelihood that an LLM will get 10 independent digits of an answer right. If the odds of it getting each digit right improve gradually from 0 to 1, then the odds of it getting all 10 digits right will appear to jump suddenly. But if we look at continuous metrics, such as the total number of correct digits, we will see that the underlying performance actually improves gradually. (Public perception of a technology can also shift in a discontinuous way because of social dynamics.)\n\nThis is why many of us saw GPT-3 as a promising step in transforming text processing long before ChatGPT appeared: BERT, GPT, GPT-2, and GPT-3 represented points on a continuous spectrum of progress. Or, looking back further in AI history, even though AlphaGoâ€™s victory over Lee Sedol in the game of Go took the public by surprise, it actually represented many years of gradual improvements in AIâ€™s ability to play Go.\n\nWhile analogies between human and machine learning can be misleading, I think that just as a personâ€™s ability to do math, to reason â€” or to deceive â€” grows gradually, so will AIâ€™s. This means the capabilities of AI technology will grow gradually (I wish we could achieve AGI overnight!), and the ability of AI to be used in harmful applications, too, will grow gradually. As long as we keep performing red-teaming exercises and monitoring our systemsâ€™ capabilities as they evolve, Iâ€™m confident that we will have plenty of time to spot issues in advance, and the science-fiction fears of AI-initiated doomsday will remain science fiction.\n\n[Original text (with links): https://t.co/HTnKpqqse5 ]",
    "createdAt": "Sat Sep 14 18:50:56 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 46,
    "replyCount": 53,
    "likeCount": 385,
    "quoteCount": 9,
    "viewCount": 86029,
    "bookmarkCount": 68,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¸Šå‘¨æœ«ï¼Œæˆ‘çš„ä¸¤ä¸ªå­©å­åœ¨ç©æ‰è¿·è—æ—¶ï¼Œæƒ³å‡ºäº†ä¸€ä¸ªæ‹™åŠ£åˆ°å¯ç¬‘çš„è®¡è°‹ï¼Œè¯•å›¾æŠŠæˆ‘å¼•åˆ°é”™è¯¯çš„åœ°æ–¹ã€‚è¿™è®©æˆ‘æƒ³åˆ°ï¼Œæ— è®ºæ˜¯äººç±»è¿˜æ˜¯ AIï¼Œå¤§å¤šæ•°èƒ½åŠ›çš„æˆé•¿éƒ½æ˜¯ä¸€ä¸ªç¼“æ…¢çš„è¿‡ç¨‹ã€‚\n\næœ‰äº›äººæ‹…å¿ƒï¼ŒAI (äººå·¥æ™ºèƒ½) æœ‰æœä¸€æ—¥ä¼šå­¦ä¼šè“„æ„æ¬ºéª—äººç±»ã€‚å¦‚æœçœŸæœ‰é‚£ä¹ˆä¸€å¤©ï¼Œæˆ‘ç¡®ä¿¡æˆ‘ä»¬ä¼šæå‰å¾ˆé•¿æ—¶é—´å¯Ÿè§‰åˆ°ï¼Œå¹¶æœ‰å……è¶³çš„æ—¶é—´æ¥é˜»æ­¢å®ƒã€‚\n\nå½“æˆ‘é—­ç€çœ¼ç›æ•°åˆ° 10 æ—¶ï¼Œæˆ‘ 5 å²çš„å¥³å„¿è®© 3 å²çš„å„¿å­å‘Šè¯‰æˆ‘å¥¹è—åœ¨æµ´å®¤é‡Œï¼Œè€Œå¥¹è‡ªå·±å´èº²è¿›äº†è¡£æ©±ã€‚ä½†å¥¹å‡è£…æ‚„æ‚„è¯çš„å£°éŸ³ï¼ˆå…¶å®å¾ˆå¤§å£°ï¼‰ï¼Œå¤¹æ‚ç€å’¯å’¯çš„ç¬‘å£°ï¼Œè®©æˆ‘æŠŠå¥¹çš„æŒ‡ç¤ºå¬å¾—ä¸€æ¸…äºŒæ¥šã€‚æˆ‘å„¿å­æŒ‡ç€æµ´å®¤æ—¶ï¼Œé‚£è¡¨æ¼”å¤¸å¼ å¾—ç®€ç›´æ»‘ç¨½ï¼Œæˆ‘ä¸å¾—ä¸å¼ºå¿ç€ç¬‘æ„ã€‚\n\nä¹Ÿè®¸ä»–ä»¬æœ‰ä¸€å¤©ä¼šå­¦ä¼šéª—æˆ‘ï¼Œä½†ç°åœ¨è¿˜ä¸è¡Œï¼ï¼ˆæˆ‘æƒ³æˆ‘å„¿å­æ‹™åŠ£çš„è¡¨æ¼”åƒæäº†æˆ‘ã€‚ç›´åˆ°ä»Šå¤©ï¼Œæˆ‘çš„æ‰‘å…‹è„¸éƒ½å·®å¾—è¦å‘½â€”â€”è¿™å’Œæˆ‘æ‰“è¿‡çš„æ¯ä¸€åœºæ‰‘å…‹éƒ½è¾“æ‰çš„â€œå®Œç¾â€è®°å½•çœŸæ˜¯ç»é…ï¼ï¼‰\n\nå»å¹´ï¼ŒRylan Schaefferã€Brando Miranda å’Œ Sanmi Koyejo æ’°å†™çš„è®ºæ–‡ã€Šå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ¶Œç°èƒ½åŠ›æ˜¯æµ·å¸‚èœƒæ¥¼å—ï¼Ÿã€‹è·å¾—äº† NeurIPS æ°å‡ºè®ºæ–‡å¥–ã€‚è¿™ç¯‡è®ºæ–‡æ¢è®¨äº† LLM çš„â€œæ¶Œç°â€å±æ€§ï¼Œä¹Ÿå°±æ˜¯é‚£äº›éšç€æ¨¡å‹è§„æ¨¡å¢å¤§è€Œçœ‹ä¼¼çªç„¶å‡ºç°çš„èƒ½åŠ›ã€‚ä½œè€…æŒ‡å‡ºï¼Œç¼©æ”¾å®šå¾‹è¡¨æ˜ï¼Œæ¯ Token (Token) çš„é”™è¯¯ç‡æ˜¯éšç€æ¨¡å‹è§„æ¨¡ç¼“æ…¢ä¸‹é™ï¼ˆå³æ€§èƒ½é€æ¸æå‡ï¼‰çš„ï¼Œè€Œæ‰€è°“çš„â€œæ¶Œç°â€å±æ€§ï¼Œå¯èƒ½åªæ˜¯ç ”ç©¶äººå‘˜é‡‡ç”¨äº†éçº¿æ€§æˆ–ä¸è¿ç»­çš„è¯„ä¼°æŒ‡æ ‡æ‰€å¯¼è‡´çš„ä¸€ç§å‡è±¡ï¼Œè¿™äº›æŒ‡æ ‡å°†åŸæœ¬ç¼“æ…¢ä¸‹é™çš„æ¯ Token é”™è¯¯ç‡ï¼Œè½¬åŒ–æˆäº†ç±»ä¼¼é˜¶è·ƒå‡½æ•°ä¸€æ ·çš„çªç„¶è·ƒå‡ã€‚\n\næ‰“ä¸ªæ¯”æ–¹ï¼Œå‡è®¾æœ‰ä¸€ä¸ªâ€œç»„åˆé”â€æŒ‡æ ‡ï¼Œè¦æ±‚æ¨¡å‹å¿…é¡»ç­”å¯¹å¾ˆå¤šé¡¹æ‰èƒ½ç®—æˆåŠŸã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬æµ‹é‡ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹æ­£ç¡®ç­”å‡ºæŸä¸ªç­”æ¡ˆçš„ 10 ä¸ªç‹¬ç«‹æ•°å­—çš„æ¦‚ç‡ã€‚å¦‚æœå®ƒç­”å¯¹æ¯ä¸ªæ•°å­—çš„æ¦‚ç‡ä» 0 é€æ¸æé«˜åˆ° 1ï¼Œé‚£ä¹ˆå®ƒç­”å¯¹æ‰€æœ‰ 10 ä¸ªæ•°å­—çš„æ¦‚ç‡å°±ä¼šçœ‹èµ·æ¥æ˜¯çªç„¶è·³è·ƒçš„ã€‚ä½†å¦‚æœæˆ‘ä»¬è§‚å¯Ÿè¿ç»­çš„æŒ‡æ ‡ï¼Œæ¯”å¦‚ç­”å¯¹æ•°å­—çš„æ€»æ•°ï¼Œæˆ‘ä»¬å°±ä¼šå‘ç°ï¼Œåº•å±‚çš„æ€§èƒ½å…¶å®æ˜¯ä¸€ç‚¹ç‚¹é€æ¸æ”¹å–„çš„ã€‚ ï¼ˆå…¬ä¼—å¯¹æŸé¡¹æŠ€æœ¯çš„è®¤çŸ¥ä¹Ÿå¯èƒ½å› ä¸ºç¤¾ä¼šåŠ¨æ€è€Œå‡ºç°ä¸è¿ç»­çš„è½¬å˜ã€‚ï¼‰\n\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å¾ˆå¤šäººåœ¨ ChatGPT å‡ºç°å¾ˆä¹…ä¹‹å‰ï¼Œå°±å°† GPT-3 è§†ä¸ºæ–‡æœ¬å¤„ç†é¢†åŸŸè¿ˆå‡ºæœ‰å‰æ™¯çš„ä¸€æ­¥ï¼šBERTã€GPTã€GPT-2 å’Œ GPT-3 ä»£è¡¨äº†æŒç»­è¿›æ­¥çš„è¿ç»­è°±ç³»ä¸Šçš„ä¸€ä¸ªä¸ªèŠ‚ç‚¹ã€‚æˆ–è€…ï¼Œå›é¡¾æ›´æ—©çš„ AI å†å²ï¼Œå°½ç®¡ AlphaGo åœ¨å›´æ£‹æ¯”èµ›ä¸­æˆ˜èƒœ Lee Sedol è®©å…¬ä¼—å¤§åƒä¸€æƒŠï¼Œä½†è¿™èƒŒåå®é™…ä¸Šæ˜¯ AI åœ¨å›´æ£‹èƒ½åŠ›ä¸Šå¤šå¹´æ¥é€æ­¥æ”¹è¿›çš„æˆæœã€‚\n\nå°½ç®¡äººç±»å­¦ä¹ å’Œæœºå™¨å­¦ä¹ ä¹‹é—´çš„ç±»æ¯”æœ‰æ—¶ä¼šäº§ç”Ÿè¯¯å¯¼ï¼Œä½†æˆ‘è®¤ä¸ºï¼Œå°±åƒä¸€ä¸ªäººå­¦ä¹ æ•°å­¦ã€è¿›è¡Œæ¨ç†â€”â€”æˆ–æ˜¯æ¬ºéª—â€”â€”çš„èƒ½åŠ›æ˜¯é€æ¸å¢é•¿çš„ä¸€æ ·ï¼ŒAI çš„èƒ½åŠ›ä¹Ÿä¼šå¦‚æ­¤ã€‚è¿™æ„å‘³ç€ AI æŠ€æœ¯çš„å„ç§èƒ½åŠ›å°†ä¼šé€æ¸å¢å¼ºï¼ˆæˆ‘å¤šä¹ˆå¸Œæœ›æˆ‘ä»¬èƒ½ä¸€å¤œä¹‹é—´å®ç°é€šç”¨äººå·¥æ™ºèƒ½ (AGI)ï¼ï¼‰ï¼ŒAI è¢«ç”¨äºæœ‰å®³åº”ç”¨çš„èƒ½åŠ›ä¹Ÿä¼šé€æ¸å‘å±•ã€‚åªè¦æˆ‘ä»¬æŒç»­è¿›è¡Œçº¢é˜Ÿæ¼”ç»ƒ (red-teaming exercises) å¹¶ç›‘æµ‹æˆ‘ä»¬ç³»ç»Ÿä¸æ–­æ¼”è¿›çš„èƒ½åŠ›ï¼Œæˆ‘ç¡®ä¿¡æˆ‘ä»¬ä¼šæœ‰å……è¶³çš„æ—¶é—´æå‰å‘ç°é—®é¢˜ï¼Œè€Œé‚£äº›å…³äº AI å¼•å‘æœ«æ—¥çš„ç§‘å¹»ææƒ§ï¼Œå°±åªä¼šåœç•™åœ¨ç§‘å¹»å±‚é¢ã€‚\n\n[åŸæ–‡ (å¸¦é“¾æ¥): https://t.co/HTnKpqqse5 ]"
  },
  {
    "id": "1834268475243856342",
    "url": "https://x.com/AndrewYNg/status/1834268475243856342",
    "text": "New short course Multimodal RAG: Chat with Videos, developed with @intel and taught by @vasudev_lal!\n\nIn this course, youâ€™ll work with LLaVA (Large Language and Vision Assistant), a Large Vision Language Model (LVLM) that can process both images and text. For example, given an image of a person doing a handstand on a skateboard at the beach, LLaVA doesn't just caption the scene, itâ€™s able to predict possible outcomes, like the person losing balance or falling off. By understanding not just what's in a video frame, but what might happen next, your application can provide more insightful answers to questions about video.\n\nYou'll build a full multimodal RAG pipeline that can chat about video content:\n- Use the BridgeTower model to create joint text-image embeddings in a 512-dimensional multimodal semantic space.\n- Learn video processing techniques to extract keyframes, generate transcripts using Whisper, and create captions.\n- Use the LanceDB vector database to store and retrieve high-dimensional multimodal embeddings.\n- Integrate the LLaVA model, combining CLIP's (Contrastive Language Image Pretraining) vision transformer with Llama, for advanced visual-textual reasoning.\n\nYour final system will ingest video data, generate embeddings for frames and text, perform similarity searches for relevant content, and use the retrieved multimodal context to inform LVLM-based response generation. The result is a system capable of answering nuanced questions about video content, effectively chatting about the video it has processed.\n\nPlease sign up here! https://t.co/cjUHPK3rK2",
    "createdAt": "Thu Sep 12 16:30:58 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 198,
    "replyCount": 33,
    "likeCount": 1190,
    "quoteCount": 12,
    "viewCount": 106733,
    "bookmarkCount": 683,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…¨æ–°çŸ­è¯¾ç¨‹â€œå¤šæ¨¡æ€ RAGï¼šä¸è§†é¢‘èŠå¤©â€å‘å¸ƒå•¦ï¼æœ¬è¯¾ç¨‹ç”± Intel æºæ‰‹ @vasudev_lal å…±åŒå¼€å‘ä¸è®²æˆã€‚\n\nåœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†æœ‰æœºä¼šæ¥è§¦ LLaVA (Large Language and Vision Assistant) æ¨¡å‹ã€‚LLaVA æ˜¯ä¸€ç§å¤§è§†è§‰è¯­è¨€æ¨¡å‹ (LVLM)ï¼Œå®ƒèƒ½å¤ŸåŒæ—¶å¤„ç†å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾ä½ ç»™ LLaVA ä¸€å¼ ä¸€ä¸ªäººåœ¨æµ·è¾¹æ»‘æ¿ä¸Šå€’ç«‹çš„å›¾ç‰‡ï¼Œå®ƒä¸ä»…èƒ½ç”Ÿæˆå¯¹åœºæ™¯çš„æè¿°ï¼Œè¿˜èƒ½é¢„æµ‹å¯èƒ½å‘ç”Ÿçš„ç»“æœï¼Œæ¯”å¦‚è¿™ä¸ªäººå¯èƒ½ä¼šå¤±å»å¹³è¡¡æˆ–æ‘”å€’ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ çš„åº”ç”¨ç¨‹åºå°†ä¸ä»…ç†è§£è§†é¢‘å¸§ä¸­çš„å†…å®¹ï¼Œè¿˜èƒ½é¢„åˆ¤æ¥ä¸‹æ¥å¯èƒ½å‘ç”Ÿä»€ä¹ˆï¼Œä»è€Œä¸ºå…³äºè§†é¢‘çš„é—®é¢˜æä¾›æ›´å…·æ´å¯ŸåŠ›çš„ç­”æ¡ˆã€‚\n\nä½ å°†äº²æ‰‹æ­å»ºä¸€ä¸ªå®Œæ•´çš„å¤šæ¨¡æ€ RAG (Retrieval Augmented Generation) ç®¡é“ï¼Œå®ç°ä¸è§†é¢‘å†…å®¹çš„å¯¹è¯ï¼š\n- åˆ©ç”¨ BridgeTower æ¨¡å‹åˆ›å»ºè”åˆæ–‡æœ¬-å›¾åƒåµŒå…¥ (embeddings)ï¼Œå¹¶å°†å®ƒä»¬ç½®äº 512 ç»´çš„å¤šæ¨¡æ€è¯­ä¹‰ç©ºé—´ä¸­ã€‚\n- å­¦ä¹ è§†é¢‘å¤„ç†æŠ€æœ¯ï¼ŒåŒ…æ‹¬æå–å…³é”®å¸§ã€ä½¿ç”¨ Whisper ç”Ÿæˆè¯­éŸ³è½¬æ–‡æœ¬ï¼ˆå³æ–‡å­—ç¨¿ï¼‰ï¼Œä»¥åŠåˆ›å»ºå­—å¹•ã€‚\n- é‡‡ç”¨ LanceDB å‘é‡æ•°æ®åº“ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢è¿™äº›é«˜ç»´å¤šæ¨¡æ€åµŒå…¥ã€‚\n- æ•´åˆ LLaVA æ¨¡å‹ï¼Œå®ƒå·§å¦™åœ°å°† CLIP (Contrastive Language Image Pretraining) çš„è§†è§‰ Transformer ä¸ Llama æ¨¡å‹ç»“åˆï¼Œä»¥å®ç°æ›´é«˜çº§çš„è§†è§‰-æ–‡æœ¬æ¨ç†èƒ½åŠ›ã€‚\n\næœ€ç»ˆï¼Œä½ æ„å»ºçš„ç³»ç»Ÿå°†èƒ½å¤Ÿæ¥æ”¶è§†é¢‘æ•°æ®ï¼Œä¸ºè§†é¢‘å¸§å’Œæ–‡æœ¬ç”ŸæˆåµŒå…¥ï¼Œè¿›è¡Œç›¸å…³å†…å®¹çš„ç›¸ä¼¼æ€§æœç´¢ï¼Œå¹¶åˆ©ç”¨æ£€ç´¢åˆ°çš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡æ¥ç”ŸæˆåŸºäº LVLM çš„å“åº”ã€‚é€šè¿‡è¿™ä¸ªç³»ç»Ÿï¼Œä½ å°†èƒ½å¤Ÿå›ç­”å…³äºè§†é¢‘å†…å®¹çš„ç»†è‡´å¤æ‚çš„é—®é¢˜ï¼Œæœ‰æ•ˆä¸å®ƒæ‰€å¤„ç†çš„è§†é¢‘è¿›è¡Œäº’åŠ¨ã€‚\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼https://t.co/cjUHPK3rK2"
  },
  {
    "id": "1831715072248545741",
    "url": "https://x.com/AndrewYNg/status/1831715072248545741",
    "text": "Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw there in government, business, and academia, the nation is well positioned to become a strong AI hub. When he asked me if I would advise South Korea as a member of the Global AI Strategy Steering Group of the countryâ€™s National AI Committee, I agreed on the spot. I was delighted to learn this week that Yann LeCun has also joined. Iâ€™ve been consistently impressed by the thoughtful approach the Korean government has taken toward AI, with an emphasis on investment and innovation and a realistic understanding of risks without being distracted by science-fiction scenarios of harm.\n\nIâ€™ve advised many countries to build AI for the sectors where theyâ€™re strong. For example, I wrote previously that by investing in sectors like tourism and certain industrial areas, Thailand can do projects more efficiently than I can in Silicon Valley. South Koreaâ€™s tech ecosystem gives it a foundation to move fast even across numerous sectors. This emphasizes the long-term value for countries to become good at tech, because tech is now pervasive and affects all industries.\n\nKorea has a very strong local software ecosystem. For example, the dominant search engine is not Google or Bing, but Naver (a Korean company). The dominant messaging system is not WhatsApp or WeChat, but KakaoTalk. With local tech giants Naver and Kakao offering email, mobile payment, cloud computing, ride sharing, and other services, the country has many sophisticated tech businesses. Additionally, SK hynix and Samsung are advanced semiconductor manufacturers. It also has a thriving entrepreneurship ecosystem, including Upstage, a language modeling startup, which taught a course with us on â€œPretraining LLMs.â€ Finally, the Korean institutions Seoul National University, which I visited last year, and KAIST have global reputations.\n\nKorea has a highly educated population, highly skilled software engineers, and a thriving set of software products. This gives it a fantastic foundation to embrace the next generation of AI. After meeting with businesses in retail, construction, insurance, cosmetics, telecoms, and other industries, I was delighted by the wide variety of opportunities many companies are pursuing across different industry sectors.\n\nLastly, Korea is known globally for its K-pop. Meeting Bang Si-Hyuk, the chairman of HYBE, which manages the superstar singing group BTS, and learning how the company operates was a real treat! \n\nThatâ€™s why Iâ€™ve traveled to South Korea four times since last year. My venture studio AI Fund, which collaborates with many Korean companies, has benefited tremendously from the advice of many South Koreans, including Taizo Son, Changmook Kang, Hyungjun Kim, Sung Kim, JP Lee, Ian Park, and Alice Oh. I look forward to doing more in, and with, South Korea!\n\n[Original text (with links): https://t.co/mVSVBCI49q ]",
    "createdAt": "Thu Sep 05 15:24:39 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 148,
    "replyCount": 57,
    "likeCount": 1282,
    "quoteCount": 30,
    "viewCount": 137016,
    "bookmarkCount": 155,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æœ€è¿‘æˆ‘è®¿é—®äº†éŸ©å›½ï¼Œä¸å°¹é”¡æ‚¦æ€»ç»Ÿæ·±å…¥æ¢è®¨äº† AI (äººå·¥æ™ºèƒ½) ã€‚æ ¹æ®æˆ‘åœ¨é‚£é‡Œçœ‹åˆ°çš„æ”¿åºœã€å•†ä¸šå’Œå­¦æœ¯ç•Œçš„è¡¨ç°ï¼ŒéŸ©å›½å®Œå…¨æœ‰èƒ½åŠ›æˆä¸ºä¸€ä¸ªå¼ºå¤§çš„ AI ä¸­å¿ƒã€‚å½“ä»–é‚€è¯·æˆ‘åŠ å…¥è¯¥å›½å›½å®¶ AI å§”å‘˜ä¼šå…¨çƒ AI æˆ˜ç•¥æŒ‡å¯¼å°ç»„ï¼Œä¸ºéŸ©å›½æä¾›å»ºè®®æ—¶ï¼Œæˆ‘å½“åœºå°±æ¬£ç„¶åŒæ„äº†ã€‚ä»¤æˆ‘é«˜å…´çš„æ˜¯ï¼Œæœ¬å‘¨å¾—çŸ¥ Yann LeCun ä¹ŸåŠ å…¥äº†è¿™ä¸ªå°ç»„ã€‚éŸ©å›½æ”¿åºœåœ¨ AI æ–¹é¢æ·±æ€ç†Ÿè™‘çš„åšæ³•ä¸€ç›´ä»¤æˆ‘å°è±¡æ·±åˆ»ï¼Œä»–ä»¬ä¸ä»…æ³¨é‡æŠ•èµ„å’Œåˆ›æ–°ï¼ŒåŒæ—¶å¯¹é£é™©æœ‰ç€åŠ¡å®çš„ç†è§£ï¼Œé¿å…è¢«ç§‘å¹»å°è¯´å¼çš„å±å®³æƒ…æ™¯æ‰€å¹²æ‰°ã€‚\n\næˆ‘æ›¾å»ºè®®è®¸å¤šå›½å®¶ï¼Œåº”åœ¨å…¶æ“…é•¿çš„é¢†åŸŸå‘å±• AIã€‚ä¾‹å¦‚ï¼Œæˆ‘ä¹‹å‰å°±æåˆ°è¿‡ï¼Œé€šè¿‡æŠ•èµ„æ—…æ¸¸ä¸šå’Œç‰¹å®šå·¥ä¸šé¢†åŸŸç­‰ï¼Œæ³°å›½å¯ä»¥æ¯”æˆ‘åœ¨ç¡…è°·æ›´é«˜æ•ˆåœ°å¼€å±•é¡¹ç›®ã€‚éŸ©å›½çš„ç§‘æŠ€ç”Ÿæ€ç³»ç»Ÿä¸ºå…¶æä¾›äº†å¿«é€Ÿå‘å±•çš„åŸºç¡€ï¼Œå³ä¾¿æ˜¯åœ¨ä¼—å¤šé¢†åŸŸä¹Ÿèƒ½è¿…é€Ÿæ¨è¿›ã€‚è¿™å‡¸æ˜¾äº†å„å›½å‘å±•ç§‘æŠ€å®åŠ›çš„é•¿æœŸä»·å€¼ï¼Œå› ä¸ºç§‘æŠ€å¦‚ä»Šå·²æ— å¤„ä¸åœ¨ï¼Œå¹¶å½±å“ç€æ‰€æœ‰è¡Œä¸šã€‚\n\néŸ©å›½æ‹¥æœ‰éå¸¸å¼ºå¤§çš„æœ¬åœŸè½¯ä»¶ç”Ÿæ€ç³»ç»Ÿã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œçš„ä¸»æµæœç´¢å¼•æ“ä¸æ˜¯ Google æˆ– Bingï¼Œè€Œæ˜¯ Naver (ä¸€å®¶éŸ©å›½å…¬å¸) ã€‚ä¸»æµå³æ—¶é€šè®¯ç³»ç»Ÿä¹Ÿä¸æ˜¯ WhatsApp æˆ– WeChatï¼Œè€Œæ˜¯ KakaoTalkã€‚Naver å’Œ Kakao ç­‰æœ¬åœŸç§‘æŠ€å·¨å¤´æä¾›ç”µå­é‚®ä»¶ã€ç§»åŠ¨æ”¯ä»˜ã€äº‘è®¡ç®—ã€å…±äº«å‡ºè¡Œç­‰å¤šç§æœåŠ¡ï¼Œä½¿å¾—éŸ©å›½æ¶Œç°å‡ºä¼—å¤šå…ˆè¿›çš„ç§‘æŠ€ä¼ä¸šã€‚æ­¤å¤–ï¼ŒSK hynix å’Œ Samsung éƒ½æ˜¯é¡¶å°–çš„åŠå¯¼ä½“åˆ¶é€ å•†ã€‚éŸ©å›½è¿˜æœ‰ä¸€ä¸ªå……æ»¡æ´»åŠ›çš„åˆ›ä¸šç”Ÿæ€ç³»ç»Ÿï¼Œå…¶ä¸­åŒ…æ‹¬è¯­è¨€æ¨¡å‹åˆåˆ›å…¬å¸ Upstageï¼Œè¯¥å…¬å¸æ›¾ä¸æˆ‘ä»¬åˆä½œå¼€è®¾â€œé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ (Pretraining LLMs)â€è¯¾ç¨‹ã€‚æœ€åï¼Œæˆ‘å»å¹´è®¿é—®è¿‡çš„éŸ©å›½å­¦åºœé¦–å°”å›½ç«‹å¤§å­¦å’Œ KAIST éƒ½äº«æœ‰å›½é™…ç››èª‰ã€‚\n\néŸ©å›½æ‹¥æœ‰å—è¿‡é«˜ç­‰æ•™è‚²çš„äººå£ã€é«˜æŠ€èƒ½çš„è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œä»¥åŠä¸€ç³»åˆ—è“¬å‹ƒå‘å±•çš„è½¯ä»¶äº§å“ã€‚è¿™ä¸ºä»–ä»¬æ‹¥æŠ±ä¸‹ä¸€ä»£ AI å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚åœ¨ä¸é›¶å”®ã€å»ºç­‘ã€ä¿é™©ã€åŒ–å¦†å“ã€ç”µä¿¡ç­‰å¤šä¸ªè¡Œä¸šçš„ä¼ä¸šä¼šé¢åï¼Œæˆ‘å¾ˆé«˜å…´çœ‹åˆ°è®¸å¤šå…¬å¸åœ¨ä¸åŒè¡Œä¸šé¢†åŸŸç§¯ææ¢ç´¢ç€å¹¿æ³›çš„æœºé‡ã€‚\n\næœ€åï¼ŒéŸ©å›½ä»¥å…¶ K-pop (éŸ©å›½æµè¡ŒéŸ³ä¹) äº«èª‰å…¨çƒã€‚èƒ½æœ‰æœºä¼šè§åˆ°ç®¡ç†è¶…çº§æ­Œå”±ç»„åˆ BTS (é˜²å¼¹å°‘å¹´å›¢) çš„ HYBE è‘£äº‹é•¿ Bang Si-Hyukï¼Œå¹¶äº†è§£è¿™å®¶å…¬å¸çš„è¿ä½œæ–¹å¼ï¼ŒçœŸæ˜¯ä¸€æ¬¡éš¾å¿˜çš„ç»å†ï¼\n\nè¿™å°±æ˜¯æˆ‘è‡ªå»å¹´ä»¥æ¥å››æ¬¡å‰å¾€éŸ©å›½çš„åŸå› ã€‚æˆ‘çš„é£é™©æŠ•èµ„å·¥ä½œå®¤ AI Fundï¼Œä¸è®¸å¤šéŸ©å›½å…¬å¸éƒ½æœ‰åˆä½œï¼Œå¹¶ä» Taizo Sonã€Changmook Kangã€Hyungjun Kimã€Sung Kimã€JP Leeã€Ian Park å’Œ Alice Oh ç­‰å¤šä½éŸ©å›½å‹äººé‚£é‡Œå—ç›ŠåŒªæµ…ã€‚æˆ‘æœŸå¾…ç€åœ¨éŸ©å›½ä»¥åŠä¸éŸ©å›½å¼€å±•æ›´å¤šåˆä½œï¼\n\n[åŸæ–‡ (å«é“¾æ¥) : https://t.co/mVSVBCI49q ]"
  },
  {
    "id": "1831346457854771255",
    "url": "https://x.com/AndrewYNg/status/1831346457854771255",
    "text": "We just released the final two courses of AI Python for Beginners! The complete set of four courses is now available and remains free for a limited time.\n\nThey teach how to write code (a) Using AI-assistance, which is where the field is going, and (b) to take advantage of generative AI, which allows you to quickly do valuable things with code.\n\nIf you're considering learning to code, AI has made this a great time to jump in. Or if you know someone who is considering learning, please recommend these courses! \n\nhttps://t.co/lTupltSZkT",
    "createdAt": "Wed Sep 04 14:59:54 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 766,
    "replyCount": 86,
    "likeCount": 3784,
    "quoteCount": 47,
    "viewCount": 420025,
    "bookmarkCount": 4529,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä»¬åˆšåˆšå‘å¸ƒäº†ä¸ºåˆå­¦è€…è®¾è®¡çš„ AI Python ç³»åˆ—è¯¾ç¨‹çš„æœ€åä¸¤é—¨ï¼ç°åœ¨ï¼Œå…¨å¥—å››é—¨è¯¾ç¨‹éƒ½å·²ä¸Šçº¿ï¼Œå¹¶ä¸”åœ¨æœ‰é™æ—¶é—´å†…ä¾ç„¶å…è´¹å¼€æ”¾ã€‚\n\nè¿™äº›è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•ç¼–å†™ä»£ç ï¼Œå…·ä½“åŒ…æ‹¬ä¸¤æ–¹é¢ï¼šä¸€ æ˜¯å€ŸåŠ© AI è¾…åŠ©æ¥ç¼–å†™ä»£ç ï¼Œè¿™æ­£æ˜¯å½“å‰ç¼–ç¨‹é¢†åŸŸçš„å‘å±•è¶‹åŠ¿ï¼›äºŒ æ˜¯åˆ©ç”¨ç”Ÿæˆå¼ AI (Generative AI) çš„èƒ½åŠ›ï¼Œè®©ä½ èƒ½å¿«é€Ÿç”¨ä»£ç å®ç°å„ç§æœ‰ä»·å€¼çš„åº”ç”¨ã€‚\n\nå¦‚æœä½ æ­£è€ƒè™‘å­¦ä¹ ç¼–ç¨‹ï¼ŒAI çš„å‘å±•è®©ç°åœ¨æˆä¸ºä¸€ä¸ªç»ä½³çš„å…¥é—¨æ—¶æœºã€‚å¦‚æœä½ èº«è¾¹æœ‰æœ‹å‹æƒ³å­¦ç¼–ç¨‹ï¼Œä¹Ÿè¯·åŠ¡å¿…å‘ä»–ä»¬æ¨èè¿™äº›è¯¾ç¨‹ï¼\n\nhttps://t.co/lTupltSZkT"
  },
  {
    "id": "1829218674806583779",
    "url": "https://x.com/AndrewYNg/status/1829218674806583779",
    "text": "Thereâ€™s still time to stop Californiaâ€™s SB 1047 from becoming law. For @TIME, I wrote about why this bill would hinder developers and actually make AI less safe. We should be regulating harmful applications of AI, not  general-purpose AI models. https://t.co/dco1e65u9H",
    "createdAt": "Thu Aug 29 18:04:51 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 195,
    "replyCount": 80,
    "likeCount": 940,
    "quoteCount": 38,
    "viewCount": 237806,
    "bookmarkCount": 99,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "é˜»æ­¢åŠ å· SB 1047 æ³•æ¡ˆæˆä¸ºæ³•å¾‹ï¼Œæˆ‘ä»¬è¿˜æœ‰æ—¶é—´ã€‚æˆ‘ä¸º @TIME æ’°æ–‡ï¼Œé˜è¿°äº†ä¸ºä½•è¿™é¡¹æ³•æ¡ˆä¼šé˜»ç¢å¼€å‘è€…ï¼Œå¹¶å®é™…ä¸Šè®©äººå·¥æ™ºèƒ½ (AI) å˜å¾—æ›´ä¸å®‰å…¨ã€‚æˆ‘ä»¬åº”è¯¥ç›‘ç®¡ AI çš„æœ‰å®³åº”ç”¨ï¼Œè€Œä¸æ˜¯é’ˆå¯¹é€šç”¨å‹ AI æ¨¡å‹è¿›è¡Œè§„èŒƒã€‚https://t.co/d01e65u9H"
  },
  {
    "id": "1829190549842321758",
    "url": "https://x.com/AndrewYNg/status/1829190549842321758",
    "text": "After a recent price reduction by OpenAI, GPT-4o tokens now cost $4 per million tokens (using a blended rate that assumes 80% input and 20% output tokens). GPT-4 cost $36 per million tokens at its initial release in March 2023. This price reduction over 17 months corresponds to about a 79% drop in price per year. (4/36 = (1 - p)^{17/12}) \n\nAs you can see, token prices are falling rapidly! One force thatâ€™s driving prices down is the release of open weights models such as Llama 3.1. If API providers, including startups Anyscale, Fireworks, Together AI, and some large cloud companies, do not have to worry about recouping the cost of developing a model, they can compete directly on price and a few other factors such as speed. \n\nFurther, hardware innovations by companies such as Groq (a leading player in fast token generation), Samba Nova (which serves Llama 3.1 405B tokens at an impressive 114 tokens per second), and wafer-scale computation startup Cerebras (which just announced a new offering this week), as well as the semiconductor giants NVIDIA, AMD, Intel, and Qualcomm, will drive further price cuts. \n\nWhen building applications, I find it useful to design to where the technology is going rather than only where it has been. Based on the technology roadmaps of multiple software and hardware companies â€” which include improved semiconductors, smaller models, and algorithmic innovation in inference architectures â€” Iâ€™m confident that token prices will continue to fall rapidly.\n\nThis means that even if you build an agentic workload that isnâ€™t entirely economical, falling token prices might make it economical at some point. As I wrote previously, being able to process many tokens is particularly important for agentic workloads, which must call a model many times before generating a result. Further, even agentic workloads are already quite affordable for many applications. Let's say you build an application to assist a human worker, and it uses 100 tokens per second continuously: At $4/million tokens, you'd be spending only $1.44/hour â€“ which is significantly lower than the minimum wage in the U.S. and many other countries.\n\nSo how can AI companies prepare?\n- First, I continue to hear from teams that are surprised to find out how cheap LLM usage is when they actually work through cost calculations. For many applications, it isnâ€™t worth too much effort to optimize the cost. So first and foremost, I advise teams to focus on building a useful application rather than on optimizing LLM costs.\n- Second, even if an application is marginally too expensive to run today, it may be worth deploying in anticipation of lower prices.\n- Finally, as new models get released, it might be worthwhile to periodically examine an application to decide whether to switch to a new model either from the same provider (such as switching from GPT-4 to the latest GPT-4o-2024-08-06) or a different provider, to take advantage of falling prices and/or increased capabilities.\n\nBecause multiple providers now host Llama 3.1 and other open-weight models, if you use one of these models, it might be possible to switch between providers without too much testing (though implementation details â€” specifically quantization, does mean that different offerings of the model do differ in performance). When switching between models, unfortunately, a major barrier is still the difficulty of implementing evals, so carrying out regression testing to make sure your application will still perform after you swap in a new model can be challenging. However, as the science of carrying out evals improves, Iâ€™m optimistic that this will become easier.\n\n[Original text (with links): https://t.co/txk7q32EXn ]",
    "createdAt": "Thu Aug 29 16:13:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 627,
    "replyCount": 114,
    "likeCount": 3583,
    "quoteCount": 114,
    "viewCount": 740702,
    "bookmarkCount": 2048,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨ OpenAI æœ€è¿‘é™ä»·åï¼ŒGPT-4o çš„ token (Token) æˆæœ¬ç°å·²é™è‡³æ¯ç™¾ä¸‡ token 4 ç¾å…ƒï¼ˆæ­¤æ··åˆè´¹ç‡å‡è®¾ 80% ä¸ºè¾“å…¥ tokenï¼Œ20% ä¸ºè¾“å‡º tokenï¼‰ã€‚è€Œ GPT-4 åœ¨ 2023 å¹´ 3 æœˆé¦–æ¬¡å‘å¸ƒæ—¶ï¼Œæ¯ç™¾ä¸‡ token çš„æˆæœ¬é«˜è¾¾ 36 ç¾å…ƒã€‚è¿™æ„å‘³ç€åœ¨çŸ­çŸ­ 17 ä¸ªæœˆå†…ï¼Œtoken ä»·æ ¼ä¸‹é™äº†çº¦ 79%ï¼Œç›¸å½“äºæ¯å¹´çº¦ 79% çš„ä»·æ ¼è·Œå¹…ã€‚(4/36 = (1 - p)^{17/12})\n\næ­£å¦‚ä½ æ‰€è§ï¼Œtoken ä»·æ ¼æ­£åœ¨è¿…é€Ÿä¸‹æ»‘ï¼æ¨åŠ¨ä»·æ ¼ä¸‹è·Œçš„ä¸€ä¸ªé‡è¦åŠ›é‡æ˜¯ Llama 3.1 ç­‰å¼€æ”¾æƒé‡æ¨¡å‹çš„å‘å¸ƒã€‚å¦‚æœ Anyscaleã€Fireworksã€Together AI ç­‰åˆåˆ›å…¬å¸ä»¥åŠä¸€äº›å¤§å‹äº‘å…¬å¸ç­‰ API æä¾›å•†æ— éœ€æ‹…å¿§æ”¶å›æ¨¡å‹å¼€å‘æˆæœ¬ï¼Œä»–ä»¬å°±èƒ½ç›´æ¥åœ¨ä»·æ ¼ã€é€Ÿåº¦ç­‰å› ç´ ä¸Šå±•å¼€ç«äº‰ã€‚\n\næ­¤å¤–ï¼ŒGroqï¼ˆåœ¨å¿«é€Ÿ token ç”Ÿæˆæ–¹é¢å¤„äºé¢†å…ˆåœ°ä½ï¼‰ã€Samba Novaï¼ˆèƒ½ä»¥æ¯ç§’ 114 token çš„æƒŠäººé€Ÿåº¦æä¾› Llama 3.1 405B tokenï¼‰å’Œæ™¶åœ†çº§è®¡ç®—åˆåˆ›å…¬å¸ Cerebrasï¼ˆæœ¬å‘¨åˆšå®£å¸ƒäº†æ–°äº§å“ï¼‰ç­‰å…¬å¸çš„ç¡¬ä»¶åˆ›æ–°ï¼Œä»¥åŠ NVIDIAã€AMDã€Intel å’Œ Qualcomm ç­‰åŠå¯¼ä½“å·¨å¤´çš„å‘å±•ï¼Œéƒ½å°†è¿›ä¸€æ­¥æ¨åŠ¨ä»·æ ¼ä¸‹è°ƒã€‚\n\nåœ¨å¼€å‘åº”ç”¨ç¨‹åºæ—¶ï¼Œæˆ‘å‘ç°æ ¹æ®æŠ€æœ¯æœªæ¥å‘å±•æ–¹å‘è¿›è¡Œè®¾è®¡ï¼Œè€Œéä»…ä»…å±€é™äºç°æœ‰æŠ€æœ¯ï¼Œä¼šæ›´å…·ä»·å€¼ã€‚åŸºäºå¤šå®¶è½¯ä»¶å’Œç¡¬ä»¶å…¬å¸çš„æŠ€æœ¯è·¯çº¿å›¾â€”â€”å…¶ä¸­åŒ…æ‹¬æ”¹è¿›çš„åŠå¯¼ä½“ã€æ›´ç²¾ç®€çš„æ¨¡å‹å’Œæ¨ç†æ¶æ„ä¸­çš„ç®—æ³•åˆ›æ–°â€”â€”æˆ‘åšä¿¡ token ä»·æ ¼å°†ç»§ç»­å¿«é€Ÿä¸‹è·Œã€‚\n\nè¿™æ„å‘³ç€ï¼Œå³ä½¿ä½ æ„å»ºçš„ä»£ç†å¼å·¥ä½œè´Ÿè½½ (agentic workload) ç›®å‰ç»æµæ•ˆç›Šä¸ä½³ï¼Œä¸æ–­ä¸‹é™çš„ token ä»·æ ¼ä¹Ÿå¯èƒ½ä½¿å…¶åœ¨æœªæ¥æŸä¸ªæ—¶é—´ç‚¹å˜å¾—åˆ’ç®—ã€‚æ­£å¦‚æˆ‘ä¹‹å‰æ‰€å†™ï¼Œå¯¹äºä»£ç†å¼å·¥ä½œè´Ÿè½½è€Œè¨€ï¼Œèƒ½å¤Ÿå¤„ç†å¤§é‡ token å°¤å…¶é‡è¦ï¼Œå› ä¸ºå®ƒä»¬åœ¨ç”Ÿæˆæœ€ç»ˆç»“æœä¹‹å‰éœ€è¦å¤šæ¬¡è°ƒç”¨æ¨¡å‹ã€‚è€Œä¸”ï¼Œå³ä¾¿ä»£ç†å¼å·¥ä½œè´Ÿè½½ï¼Œå¯¹äºè®¸å¤šåº”ç”¨æ¥è¯´ä¹Ÿå·²ç»ç›¸å½“ç»æµå®æƒ ã€‚å‡è®¾ä½ å¼€å‘äº†ä¸€ä¸ªåº”ç”¨ç¨‹åºæ¥è¾…åŠ©äººç±»å·¥ä½œè€…ï¼Œå®ƒæ¯ç§’æŒç»­ä½¿ç”¨ 100 tokenï¼šæŒ‰ç…§æ¯ç™¾ä¸‡ token 4 ç¾å…ƒè®¡ç®—ï¼Œä½ æ¯å°æ—¶çš„å¼€é”€ä»…ä¸º 1.44 ç¾å…ƒâ€”â€”è¿™è¿œä½äºç¾å›½åŠè®¸å¤šå…¶ä»–å›½å®¶çš„æœ€ä½å·¥èµ„æ°´å¹³ã€‚\n\né‚£ä¹ˆï¼ŒAI å…¬å¸è¯¥å¦‚ä½•åº”å¯¹å‘¢ï¼Ÿ\n- é¦–å…ˆï¼Œæˆ‘ä¸æ–­å¬åˆ°æœ‰å›¢é˜Ÿåœ¨å®é™…è¿›è¡Œæˆæœ¬ä¼°ç®—æ—¶ï¼ŒæƒŠè®¶åœ°å‘ç°å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„ä½¿ç”¨æˆæœ¬ç«Ÿç„¶å¦‚æ­¤ä¹‹ä½ã€‚å¯¹äºè®¸å¤šåº”ç”¨æ¥è¯´ï¼ŒæŠ•å…¥è¿‡å¤šç²¾åŠ›å»ä¼˜åŒ–æˆæœ¬å¹¶ä¸ååˆ†å€¼å¾—ã€‚å› æ­¤ï¼Œæˆ‘é¦–è¦å»ºè®®å›¢é˜Ÿåº”ä¸“æ³¨äºæ„å»ºæœ‰ç”¨çš„åº”ç”¨ç¨‹åºï¼Œè€Œéè¿‡åº¦å…³æ³¨ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æˆæœ¬ã€‚\n- å…¶æ¬¡ï¼Œå³ä½¿æŸä¸ªåº”ç”¨ç¨‹åºä»Šå¤©è¿è¡Œæˆæœ¬ç•¥é«˜ï¼Œä½†è€ƒè™‘åˆ°æœªæ¥ä»·æ ¼ä¼šæ›´ä½ï¼Œå®ƒå¯èƒ½ä¹Ÿå€¼å¾—æå‰éƒ¨ç½²ã€‚\n- æœ€åï¼Œéšç€æ–°æ¨¡å‹çš„ä¸æ–­å‘å¸ƒï¼Œå®šæœŸæ£€æŸ¥åº”ç”¨ç¨‹åºä»¥å†³å®šæ˜¯å¦åˆ‡æ¢åˆ°æ–°æ¨¡å‹å¯èƒ½å¾ˆæœ‰ä»·å€¼ï¼Œæ— è®ºæ˜¯æ¥è‡ªåŒä¸€æä¾›å•† (ä¾‹å¦‚ä» GPT-4 åˆ‡æ¢åˆ°æœ€æ–°çš„ GPT-4o-2024-08-06)ï¼Œè¿˜æ˜¯ä¸åŒæä¾›å•†ï¼Œä»¥ä¾¿å……åˆ†åˆ©ç”¨ä¸æ–­ä¸‹é™çš„ä»·æ ¼å’Œ/æˆ–å¢å¼ºçš„åŠŸèƒ½ã€‚\n\nç”±äºç°åœ¨æœ‰å¤šä¸ªæä¾›å•†æ‰˜ç®¡ Llama 3.1 å’Œå…¶ä»–å¼€æ”¾æƒé‡æ¨¡å‹ï¼Œå¦‚æœä½ ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªæ¨¡å‹ï¼Œå¯èƒ½æ— éœ€è¿›è¡Œå¤ªå¤šæµ‹è¯•å³å¯åœ¨ä¸åŒæä¾›å•†ä¹‹é—´åˆ‡æ¢ï¼ˆä¸è¿‡ï¼Œå®ç°ç»†èŠ‚ï¼Œå°¤å…¶æ˜¯é‡åŒ– (quantization) æŠ€æœ¯ï¼Œç¡®å®ä¼šå¯¼è‡´åŒä¸€æ¨¡å‹çš„ä¸åŒäº§å“åœ¨æ€§èƒ½ä¸Šæœ‰æ‰€å·®å¼‚ï¼‰ã€‚ç„¶è€Œï¼Œåœ¨æ¨¡å‹ä¹‹é—´åˆ‡æ¢æ—¶ï¼Œä¸€ä¸ªä¸»è¦éšœç¢ä»ç„¶æ˜¯å®æ–½è¯„ä¼° (evals) çš„éš¾åº¦ã€‚å› æ­¤ï¼Œè¿›è¡Œå›å½’æµ‹è¯•ä»¥ç¡®ä¿ä½ çš„åº”ç”¨ç¨‹åºåœ¨æ›´æ¢æ–°æ¨¡å‹åä»èƒ½æ­£å¸¸è¿è¡Œï¼Œå¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸è¿‡ï¼Œéšç€è¯„ä¼° (evals) ç§‘å­¦æ–¹æ³•çš„ä¸æ–­æ”¹è¿›ï¼Œæˆ‘ä¹è§‚åœ°è®¤ä¸ºè¿™å°†ä¼šå˜å¾—æ›´å®¹æ˜“ã€‚\n\n[åŸæ–‡ (å¸¦é“¾æ¥): https://t.co/txk7q32EXn ]"
  },
  {
    "id": "1828844538712224137",
    "url": "https://x.com/AndrewYNg/status/1828844538712224137",
    "text": "Explore state-of-the-art multimodal prompting in our new short course Large Multimodal Model Prompting with Gemini, taught by Erwin Huizenga in collaboration with @googlecloud.\n\nOne interesting insight from this course: with multimodal models, prompt structure matters significantly. Placing text inputs, such as a patient's medical history, before image inputs, like an X-ray, can enhance the model's ability to contextualize and interpret visual data effectively. In other contexts, such as image captioning, you may get better results by putting the image first. Multimodal models behave differently than text-only LLMs, and effective prompting for models varies depending on the model youâ€™re using. In this course youâ€™ll learn how to effectively prompt Gemini models.\n\nGemini's multimodal capabilities also enable new approaches in AI application development, for example:\n- The Gemini library handles various video formats (MP4, MOV, MPEG), streamlining applications using these formats.\n- Large context window (up to 1 million tokens) enables processing of extensive content, like analyzing multiple 50-minute videos simultaneously. \n- Function calling feature integrates real-time data (e.g., current exchange rates) into model responses.\n\nThe course demonstrates building multimodal applications with real-world examples including document analyzers that reason across text and graphs simultaneously, video content extractors that find and timestamp specific information from multiple hours of footage, and automated expense report systems processing receipt images while cross-referencing company policies.\n\nSign up here: https://t.co/4yI4DXcFpK",
    "createdAt": "Wed Aug 28 17:18:10 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 158,
    "replyCount": 36,
    "likeCount": 838,
    "quoteCount": 7,
    "viewCount": 73454,
    "bookmarkCount": 450,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¸ Erwin Huizenga å’Œ @googlecloud åˆä½œï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€é—¨æ–°çŸ­æœŸè¯¾ç¨‹ã€ŠGemini å¤§å‹å¤šæ¨¡æ€æ¨¡å‹æç¤ºã€‹ï¼Œå¸¦æ‚¨æ·±å…¥äº†è§£ç›®å‰æœ€å…ˆè¿›çš„å¤šæ¨¡æ€æç¤ºï¼ˆmultimodal promptingï¼‰æŠ€æœ¯ã€‚\n\næœ¬è¯¾ç¨‹åˆ†äº«äº†ä¸€ä¸ªæœ‰è¶£çš„è§‚ç‚¹ï¼šå¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼ˆmultimodal modelsï¼‰è€Œè¨€ï¼Œæç¤ºï¼ˆpromptï¼‰çš„ç»“æ„è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ï¼Œå°†æ–‡æœ¬è¾“å…¥ï¼ˆå¦‚æ‚£è€…ç—…å²ï¼‰æ”¾åœ¨å›¾åƒè¾“å…¥ï¼ˆå¦‚ X å°„çº¿ï¼‰ä¹‹å‰ï¼Œå¯ä»¥æ˜¾è‘—å¢å¼ºæ¨¡å‹æœ‰æ•ˆç»“åˆä¸Šä¸‹æ–‡ç†è§£å’Œè§£é‡Šè§†è§‰æ•°æ®çš„èƒ½åŠ›ã€‚è€Œåœ¨å…¶ä»–åº”ç”¨åœºæ™¯ï¼Œæ¯”å¦‚å›¾åƒå­—å¹•ç”Ÿæˆä¸­ï¼Œæ‚¨å¯èƒ½ä¼šå‘ç°å…ˆæ”¾ç½®å›¾åƒèƒ½è·å¾—æ›´å¥½çš„æ•ˆæœã€‚å¤šæ¨¡æ€æ¨¡å‹çš„è¡Œä¸ºä¸çº¯æ–‡æœ¬å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ‰æ‰€ä¸åŒï¼Œå› æ­¤é’ˆå¯¹ä¸åŒæ¨¡å‹çš„æœ‰æ•ˆæç¤ºç­–ç•¥ä¹Ÿä¼šå› æ¨¡å‹è€Œå¼‚ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•æœ‰æ•ˆåœ°å‘ Gemini æ¨¡å‹å‘å‡ºæç¤ºã€‚\n\nGemini çš„å¤šæ¨¡æ€èƒ½åŠ›ä¹Ÿä¸º AI åº”ç”¨ç¨‹åºå¼€å‘å¼€å¯äº†æ–°æ€è·¯ï¼Œä¾‹å¦‚ï¼š\n- Gemini åº“èƒ½å¤Ÿå¤„ç†å¤šç§è§†é¢‘æ ¼å¼ï¼ˆMP4ã€MOVã€MPEGï¼‰ï¼Œä»è€Œç®€åŒ–äº†ä½¿ç”¨è¿™äº›æ ¼å¼çš„åº”ç”¨ç¨‹åºå¼€å‘ã€‚\n- å·¨å¤§çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆé«˜è¾¾ 100 ä¸‡ tokenï¼‰è®©å¤„ç†æµ·é‡å†…å®¹æˆä¸ºå¯èƒ½ï¼Œæ¯”å¦‚åŒæ—¶åˆ†æå¤šæ®µ 50 åˆ†é’Ÿçš„è§†é¢‘ã€‚\n- å‡½æ•°è°ƒç”¨ï¼ˆFunction callingï¼‰åŠŸèƒ½å¯ä»¥å°†å®æ—¶æ•°æ®ï¼ˆä¾‹å¦‚å½“å‰æ±‡ç‡ï¼‰æ•´åˆåˆ°æ¨¡å‹å“åº”ä¸­ã€‚\n\næœ¬è¯¾ç¨‹é€šè¿‡çœŸå®ä¸–ç•Œæ¡ˆä¾‹æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºå¤šæ¨¡æ€åº”ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬èƒ½åŒæ—¶åˆ†æç†è§£æ–‡æœ¬å’Œå›¾è¡¨çš„æ–‡æ¡£åˆ†æå™¨ã€èƒ½ä»æ•°å°æ—¶è§†é¢‘ç‰‡æ®µä¸­æŸ¥æ‰¾å¹¶æ ‡è®°ç‰¹å®šä¿¡æ¯çš„è§†é¢‘å†…å®¹æå–å™¨ï¼Œä»¥åŠåœ¨å¤„ç†æ”¶æ®å›¾åƒæ—¶èƒ½å¯¹ç…§å…¬å¸æ”¿ç­–è¿›è¡Œæ ¸æŸ¥çš„è‡ªåŠ¨åŒ–è´¹ç”¨æŠ¥å‘Šç³»ç»Ÿã€‚\n\nç‚¹å‡»æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/4yI4DXcFpK"
  },
  {
    "id": "1828552114123288835",
    "url": "https://x.com/AndrewYNg/status/1828552114123288835",
    "text": "Really fun hackathon, and it was great to see 30 creative Agentic AI projects, all built in a day. Well done to all the hackathon participants, and thank you @HenryYin_ , @AlexReibman and @agihouse_org for having me! \nÂ·",
    "createdAt": "Tue Aug 27 21:56:11 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 44,
    "replyCount": 26,
    "likeCount": 405,
    "quoteCount": 5,
    "viewCount": 64941,
    "bookmarkCount": 36,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "Â· è¿™æ˜¯ä¸€åœºéå¸¸æœ‰è¶£çš„é»‘å®¢é©¬æ‹‰æ¾ï¼Œå¾ˆé«˜å…´çœ‹åˆ° 30 ä¸ªå¯Œæœ‰åˆ›æ„çš„ Agentic AI (Agentic AI) é¡¹ç›®ï¼Œæ‰€æœ‰é¡¹ç›®éƒ½åœ¨ä¸€å¤©ä¹‹å†…å°±æ„å»ºå®Œæˆäº†ã€‚å‘æ‰€æœ‰é»‘å®¢é©¬æ‹‰æ¾çš„å‚ä¸è€…è¡¨ç¤ºç¥è´ºï¼Œå¹¶æ„Ÿè°¢ @HenryYin_ ã€ @AlexReibman å’Œ @agihouse_org é‚€è¯·æˆ‘å‚åŠ ï¼"
  },
  {
    "id": "1828504913158316075",
    "url": "https://x.com/AndrewYNg/status/1828504913158316075",
    "text": "I've been playing with @SambaNovaAI's API serving fast Llama 3.1 405B tokens. Really cool to see leading model running at speed. Congrats to Samba Nova for hitting a 114 tokens/sec speed record (and also thanks @KunleOlukotun for getting me an API key!) https://t.co/GuBfYsfizJ",
    "createdAt": "Tue Aug 27 18:48:37 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 65,
    "replyCount": 20,
    "likeCount": 346,
    "quoteCount": 20,
    "viewCount": 51087,
    "bookmarkCount": 73,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä¸€ç›´åœ¨è¯•ç”¨ @SambaNovaAI çš„ APIï¼Œå®ƒèƒ½é«˜é€Ÿå¤„ç† Llama 3.1 405B æ¨¡å‹çš„ tokenã€‚çœ‹åˆ°é¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹ (Large Language Model) å¦‚æ­¤è¿…é€Ÿåœ°è¿è¡Œï¼ŒçœŸæ˜¯ä»¤äººå°è±¡æ·±åˆ»ã€‚ç¥è´º Samba Nova è¾¾åˆ°äº† 114 token/ç§’çš„é€Ÿåº¦è®°å½•ï¼ˆä¹Ÿè¦æ„Ÿè°¢ @KunleOlukotun å¸®æˆ‘ç”³è¯·åˆ°äº† API å¯†é’¥ï¼ï¼‰https://t.co/GuBfYsfizJ"
  },
  {
    "id": "1827047221013180611",
    "url": "https://x.com/AndrewYNg/status/1827047221013180611",
    "text": "I am thrilled to announce that Dan Maloney is becoming the Chief Executive Officer (CEO) of LandingAI, and I will step into the companyâ€™s Executive Chairman role, where I will continue to focus on Visual AI deep tech with our team, including agentic vision.\n\nSince Dan joined two years ago as the companyâ€™s Chief Operating Officer (COO), his leadership across the company has been instrumental to LandingAI serving more customers and better than ever. Dan played an integral role in all of our key initiatives, including the launch of our self-service offering with LandingLens available for any vision application builder to use, establishing dozens of strategic and channel partnerships, increasing our focus on serving developers, and improving our operational excellence; even as we continue to innovate on Visual AI technology.\n\nI look forward to continuing LandingAIâ€™s journey with Dan, with our fantastic team, and with all our wonderful partners and users!\n\nText of full announcement below. https://t.co/At9k1JhvBV",
    "createdAt": "Fri Aug 23 18:16:17 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 26,
    "replyCount": 27,
    "likeCount": 311,
    "quoteCount": 4,
    "viewCount": 42753,
    "bookmarkCount": 31,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘å¾ˆé«˜å…´åœ°å®£å¸ƒï¼ŒDan Maloney å°†å‡ºä»» LandingAI çš„é¦–å¸­æ‰§è¡Œå®˜ (CEO)ï¼Œè€Œæˆ‘æœ¬äººå°†è½¬ä»»å…¬å¸çš„æ‰§è¡Œä¸»å¸­ï¼Œç»§ç»­ä¸å›¢é˜Ÿæ·±è€•è§†è§‰ AI (Visual AI) æ·±åº¦æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯æ™ºèƒ½ä½“è§†è§‰ (agentic vision) é¢†åŸŸã€‚\n\nè‡ªä» Dan ä¸¤å¹´å‰åŠ å…¥å…¬å¸æ‹…ä»»é¦–å¸­è¿è¥å®˜ (COO) ä»¥æ¥ï¼Œä»–çš„å“è¶Šé¢†å¯¼åŠ›å¯¹äº LandingAI æ›´å¥½åœ°æœåŠ¡æ›´å¤šå®¢æˆ·èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚Dan åœ¨æˆ‘ä»¬å„é¡¹æ ¸å¿ƒä¸¾æªä¸­éƒ½å‘æŒ¥äº†ä¸å¯æˆ–ç¼ºçš„ä½œç”¨ï¼Œå…¶ä¸­åŒ…æ‹¬ï¼šæ¨å‡ºæˆ‘ä»¬çš„è‡ªåŠ©æœåŠ¡äº§å“ LandingLensï¼Œä¾›ä»»ä½•è§†è§‰åº”ç”¨æ„å»ºè€…ä½¿ç”¨ï¼›å»ºç«‹äº†æ•°åä¸ªæˆ˜ç•¥å’Œæ¸ é“åˆä½œä¼™ä¼´å…³ç³»ï¼›å¢åŠ äº†å¯¹æœåŠ¡å¼€å‘è€…çš„å…³æ³¨ï¼›ä»¥åŠæå‡äº†æˆ‘ä»¬çš„è¿è¥å“è¶Šæ€§ã€‚æ‰€æœ‰è¿™äº›éƒ½åœ¨æˆ‘ä»¬æŒç»­åˆ›æ–°è§†è§‰ AI æŠ€æœ¯çš„åŒæ—¶ç¨³æ­¥æ¨è¿›ã€‚\n\næˆ‘æœŸå¾…ç€ä¸ Danã€æˆ‘ä»¬ä¼˜ç§€çš„å›¢é˜Ÿä»¥åŠæ‰€æœ‰å‡ºè‰²çš„åˆä½œä¼™ä¼´å’Œç”¨æˆ·ä¸€èµ·ï¼Œç»§ç»­ LandingAI çš„å‘å±•æ—…ç¨‹ï¼\n\nå®Œæ•´å…¬å‘Šæ–‡æœ¬è¯·è§ä¸‹æ–¹é“¾æ¥ã€‚https://t.co/At9k1JhvBV"
  },
  {
    "id": "1826635358848909737",
    "url": "https://x.com/AndrewYNg/status/1826635358848909737",
    "text": "Iâ€™m encouraged at the progress of the U.S. government at moving to stem harmful AI applications. Two examples are the new Federal Trade Commission (FTC) ban on fake product reviews and the DEFIANCE Act, which imposes punishments for creating and disseminating non-consensual deepfake porn. Both rules take a sensible approach to regulating AI insofar as they target harmful applications rather than general-purpose AI technology.\n\nThe best way to ensure AI safety is to regulate it at the application level rather than the technology level. This is important because the technology is general-purpose and its builders (such as a developer who releases an open-weights foundation model) cannot control how someone else might use it. If, however, someone applies AI in a nefarious way, we should stop that application.\n\nEven before generative AI, fake reviews were a problem on many websites, and many tech companies dedicate considerable resources to combating them. A telltale sign of old-school fake reviews is the use of similar wording in different reviews. AIâ€™s ability to automatically paraphrase or rewrite is making fake reviews harder to detect.\n\nImportantly, the FTC is not going after the makers of foundation models for fake reviews. The provider of an open weights AI model, after all, canâ€™t control what someone else uses it for. Even if one were to try to train a model to put up guardrails against writing reviews, I donâ€™t know how it could distinguish between a real user of a product asking for help writing a legitimate review and a spammer who wanted a fake review. The FTC appropriately aims to ban the application of fake reviews along with other deceptive practices such as buying positive reviews.\n\nThe DEFIANCE Act, which passed unanimously in the Senate (and still requires passage in the House of Representatives before the President can sign it into law) imposes civil penalties for the creating and distributing non-consensual, deepfake porn. This disgusting application is harming many people including underage girls. While many image generation models do have guardrails against generating porn, these guardrails often can be circumvented via jailbreak prompts or fine-tuning (for models with open weights).\n\nAgain, DEFIANCE regulates an application, not the underlying technology. It aims to punish people who engage in the application of creating and distributing non-consensual intimate images, regardless of how they are generated â€” whether the perpetrator uses a diffusion model, a generative adversarial network, or Microsoft Paint to create an image pixel by pixel.\n\nI hope DEFIANCE passes in the House and gets signed into law. Both rules guard against harmful AI applications without stifling AI technology itself (unlike Californiaâ€™s poorly designed SB-1047), and they offer a good model for how the U.S. and other nations can protect citizens against other potentially harmful applications.\n\n[Original text (with links): https://t.co/AA2x2KxCqW ]",
    "createdAt": "Thu Aug 22 14:59:41 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 63,
    "replyCount": 44,
    "likeCount": 320,
    "quoteCount": 14,
    "viewCount": 46353,
    "bookmarkCount": 47,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ç¾å›½æ”¿åºœåœ¨éåˆ¶æœ‰å®³ AI åº”ç”¨æ–¹é¢å–å¾—çš„è¿›å±•è®©æˆ‘å¤‡å—é¼“èˆã€‚æœ‰ä»¥ä¸‹ä¸¤ä¸ªä¾‹å­ï¼šè”é‚¦è´¸æ˜“å§”å‘˜ä¼š (FTC) æ–°é¢å¸ƒçš„è™šå‡äº§å“è¯„è®ºç¦ä»¤ï¼Œä»¥åŠ DEFIANCE æ³•æ¡ˆã€‚åè€…æ—¨åœ¨å¯¹åˆ›å»ºå’Œä¼ æ’­æœªç»åŒæ„çš„æ·±åº¦ä¼ªé€  (deepfake) è‰²æƒ…å†…å®¹æ–½åŠ æƒ©ç½šã€‚è¿™ä¸¤é¡¹è§„å®šåœ¨ AI ç›‘ç®¡ä¸Šéƒ½é‡‡å–äº†æ˜æ™ºçš„ç­–ç•¥ï¼Œå³å®ƒä»¬ä¸»è¦é’ˆå¯¹æœ‰å®³çš„åº”ç”¨ï¼Œè€Œéç¬¼ç»Ÿåœ°é™åˆ¶é€šç”¨äººå·¥æ™ºèƒ½ (AI) æŠ€æœ¯æœ¬èº«ã€‚\n\nç¡®ä¿ AI å®‰å…¨çš„æœ€ä½³é€”å¾„æ˜¯åœ¨åº”ç”¨å±‚é¢è€ŒéæŠ€æœ¯å±‚é¢è¿›è¡Œç›‘ç®¡ã€‚è¿™ä¸€ç‚¹è‡³å…³é‡è¦ï¼Œå› ä¸º AI æŠ€æœ¯å…·æœ‰é€šç”¨æ€§ï¼Œå…¶å¼€å‘è€… (ä¾‹å¦‚å‘å¸ƒå¼€æºæƒé‡åŸºç¡€æ¨¡å‹ (open-weights foundation model) çš„äºº) æ— æ³•æ§åˆ¶ä»–äººå¦‚ä½•ä½¿ç”¨å®ƒã€‚ç„¶è€Œï¼Œå¦‚æœæœ‰äººä»¥æ¶æ„æ–¹å¼åº”ç”¨ AIï¼Œæˆ‘ä»¬ç†åº”é˜»æ­¢è¿™ç§åº”ç”¨ã€‚\n\nç”šè‡³åœ¨ç”Ÿæˆå¼ AI (Generative AI) å‡ºç°ä¹‹å‰ï¼Œè™šå‡è¯„è®ºåœ¨è®¸å¤šç½‘ç«™ä¸Šå°±å·²æ˜¯ä¸ªè€å¤§éš¾é—®é¢˜ï¼Œè®¸å¤šç§‘æŠ€å…¬å¸æŠ•å…¥äº†å¤§é‡èµ„æºæ¥æ‰“å‡»å®ƒä»¬ã€‚ä¼ ç»Ÿè™šå‡è¯„è®ºçš„ä¸€ä¸ªæ˜æ˜¾ç‰¹å¾æ˜¯ä¸åŒè¯„è®ºä¸­å¸¸ä½¿ç”¨ç›¸ä¼¼çš„æªè¾ã€‚è€Œ AI è‡ªåŠ¨æ”¹å†™æˆ–è½¬è¿° (paraphrase) çš„èƒ½åŠ›ï¼Œä½¿å¾—è™šå‡è¯„è®ºå˜å¾—æ›´éš¾è¢«æ£€æµ‹ã€‚\n\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒFTC å¹¶æ²¡æœ‰å› ä¸ºè™šå‡è¯„è®ºè€Œè¿½ç©¶åŸºç¡€æ¨¡å‹å¼€å‘è€…çš„è´£ä»»ã€‚æ¯•ç«Ÿï¼Œä¸€ä¸ªå¼€æºæƒé‡ AI æ¨¡å‹çš„æä¾›è€…æ— æ³•æ§åˆ¶å…¶ä»–äººå°†å®ƒç”¨äºä½•ç§ç›®çš„ã€‚å³ä½¿æœ‰äººå°è¯•è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæ—¨åœ¨è®¾ç½®é˜²æŠ¤æ æ¥é˜»æ­¢æ’°å†™è™šå‡è¯„è®ºï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“å®ƒè¯¥å¦‚ä½•åŒºåˆ†ä¸€ä¸ªäº§å“çš„çœŸå®ç”¨æˆ·å¯»æ±‚å¸®åŠ©æ’°å†™åˆæ³•è¯„è®ºï¼Œå’Œä¸€ä¸ªæƒ³è¦å‘å¸ƒè™šå‡è¯„è®ºçš„åƒåœ¾é‚®ä»¶å‘é€è€…ã€‚å› æ­¤ï¼ŒFTC æ°å½“åœ°é€‰æ‹©ç¦æ­¢è™šå‡è¯„è®ºçš„åº”ç”¨ï¼Œä»¥åŠå…¶ä»–æ¬ºéª—æ€§è¡Œä¸ºï¼Œä¾‹å¦‚è´­ä¹°å¥½è¯„ã€‚\n\nDEFIANCE æ³•æ¡ˆå·²åœ¨å‚è®®é™¢è·å¾—ä¸€è‡´é€šè¿‡ (åœ¨æ€»ç»Ÿç­¾ç½²æˆä¸ºæ³•å¾‹å‰ï¼Œä»éœ€ä¼—è®®é™¢é€šè¿‡)ï¼Œå®ƒå¯¹åˆ›å»ºå’Œåˆ†å‘æœªç»åŒæ„çš„æ·±åº¦ä¼ªé€ è‰²æƒ…å†…å®¹æ–½åŠ æ°‘äº‹å¤„ç½šã€‚è¿™ç§ä»¤äººå‘æŒ‡çš„åº”ç”¨æ­£åœ¨ä¼¤å®³è®¸å¤šäººï¼ŒåŒ…æ‹¬æœªæˆå¹´å¥³å­©ã€‚å°½ç®¡è®¸å¤šå›¾åƒç”Ÿæˆæ¨¡å‹ç¡®å®è®¾æœ‰é˜²æ­¢ç”Ÿæˆè‰²æƒ…å†…å®¹çš„é˜²æŠ¤æªæ–½ï¼Œä½†è¿™äº›é˜²æŠ¤æªæ–½å¾€å¾€å¯ä»¥é€šè¿‡â€œè¶Šç‹±æç¤º (jailbreak prompts)â€æˆ–â€œå¾®è°ƒ (fine-tuning)â€ (å¯¹äºå¼€æºæƒé‡æ¨¡å‹è€Œè¨€) æ¥è§„é¿ã€‚\n\nå†æ¬¡å¼ºè°ƒï¼ŒDEFIANCE ç›‘ç®¡çš„æ˜¯å…·ä½“çš„åº”ç”¨ï¼Œè€Œä¸æ˜¯åº•å±‚çš„æŠ€æœ¯ã€‚å®ƒçš„ç›®æ ‡æ˜¯æƒ©ç½šé‚£äº›ä»äº‹åˆ›å»ºå’Œåˆ†å‘æœªç»åŒæ„çš„ç§å¯†å›¾åƒåº”ç”¨çš„äººï¼Œæ— è®ºè¿™äº›å›¾åƒæ˜¯å¦‚ä½•ç”Ÿæˆçš„â€”â€”æ— è®ºæ˜¯çŠ¯ç½ªè€…ä½¿ç”¨äº†æ‰©æ•£æ¨¡å‹ (diffusion model)ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (generative adversarial network)ï¼Œè¿˜æ˜¯ä»…ä»…ç”¨ Microsoft Paint é€åƒç´ åœ°ç»˜åˆ¶å‡ºæ¥çš„ã€‚\n\næˆ‘è¡·å¿ƒå¸Œæœ› DEFIANCE æ³•æ¡ˆèƒ½åœ¨ä¼—è®®é™¢é€šè¿‡å¹¶æœ€ç»ˆç­¾ç½²æˆä¸ºæ³•å¾‹ã€‚è¿™ä¸¤é¡¹è§„å®šéƒ½åœ¨é˜²èŒƒæœ‰å®³ AI åº”ç”¨çš„åŒæ—¶ï¼Œæ²¡æœ‰æ‰¼æ€ AI æŠ€æœ¯æœ¬èº« (è¿™ä¸åŠ åˆ©ç¦å°¼äºšå·è®¾è®¡æ¬ ä½³çš„ SB-1047 æ³•æ¡ˆå½¢æˆé²œæ˜å¯¹æ¯”)ï¼Œå®ƒä»¬ä¸ºç¾å›½åŠå…¶ä»–å›½å®¶å¦‚ä½•ä¿æŠ¤å…¬æ°‘å…å—å…¶ä»–æ½œåœ¨æœ‰å®³åº”ç”¨æä¾›äº†ä¸€ä¸ªè‰¯å¥½çš„èŒƒä¾‹ã€‚\n\n[Original text (with links): https://t.co/AA2x2KxCqW ]"
  },
  {
    "id": "1826273022149587383",
    "url": "https://x.com/AndrewYNg/status/1826273022149587383",
    "text": "Build and customize complex AI applications with a flexible framework in this new short course, Building AI Applications with Haystack. Created in collaboration with @deepset_ai, and taught by @tuanacelik, who is the developer relations lead for Haystack at deepset.\n\nGenerative AI technology is changing rapidly and it can be challenging to integrate APIs from different LLMs, vector databases, and various tools such as web search. In this course, you will learn how to use the Haystack framework to make your development process more modular, allowing you to manage complexity and focus more on building your application.\n\nIn detail, youâ€™ll:\n- Build a RAG pipeline using Haystackâ€™s main building blocks â€“ components, pipelines, and document stores.\n- Create custom components in your pipeline by building a Hacker News summarizer that extends your appâ€™s ability to access APIs.\n- Use conditional routing to create a branching pipeline with a fallback to web search mechanism when the LLM does not have the necessary context to respond to the user's query.\n- Build a self-reflecting agent for named entity recognition that loops using an output validator custom component.\n- Create a chat agent using OpenAI's function-calling capabilities which allow you to provide Haystack pipelines as tools to the LLM, enhancing that agent's capabilities.\n\nBy the end of this course, you will learn a high-level orchestration framework that can help make your applications flexible, extendible, and maintainable, even as the technology stack changes, new user needs arise, and you add new features to your application.\n\nPlease sign up here: https://t.co/wCvf549cM0",
    "createdAt": "Wed Aug 21 14:59:53 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 101,
    "replyCount": 26,
    "likeCount": 526,
    "quoteCount": 7,
    "viewCount": 53542,
    "bookmarkCount": 232,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ¬¢è¿å‚åŠ ç”± @deepset_ai åˆä½œæ¨å‡ºã€deepset å…¬å¸ Haystack å¼€å‘è€…å…³ç³»è´Ÿè´£äºº @tuanacelik äº²æˆçš„å…¨æ–°çŸ­æœŸè¯¾ç¨‹â€”â€”â€œä½¿ç”¨ Haystack æ„å»º AI åº”ç”¨ç¨‹åºâ€ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨çµæ´»çš„æ¡†æ¶ï¼Œæ„å»ºå¹¶å®šåˆ¶å¤æ‚çš„ AI åº”ç”¨ç¨‹åºã€‚\n\nç”Ÿæˆå¼ AI (Generative AI) æŠ€æœ¯æ—¥æ–°æœˆå¼‚ï¼Œå°†ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ã€å‘é‡æ•°æ®åº“ä»¥åŠè¯¸å¦‚ç½‘ç»œæœç´¢ç­‰å„ç§å·¥å…·çš„ API (åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£) æ•´åˆèµ·æ¥ï¼Œå¯èƒ½é¢‡å…·æŒ‘æˆ˜ã€‚æœ¬è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•ä½¿ç”¨ Haystack æ¡†æ¶ï¼Œè®©ä½ çš„å¼€å‘è¿‡ç¨‹æ›´å…·æ¨¡å—åŒ–ï¼Œä»è€Œå¸®ä½ ç®¡ç†å¤æ‚æ€§ï¼Œå°†æ›´å¤šç²¾åŠ›æ”¾åœ¨åº”ç”¨ç¨‹åºçš„æ„å»ºä¸Šã€‚\n\nå…·ä½“æ¥è¯´ï¼Œä½ å°†ï¼š\n- ä½¿ç”¨ Haystack çš„æ ¸å¿ƒæ„å»ºæ¨¡å—â€”â€”ç»„ä»¶ã€ç®¡é“å’Œæ–‡æ¡£å­˜å‚¨â€”â€”æ„å»ºä¸€ä¸ª RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) ç®¡é“ã€‚\n- æ„å»ºä¸€ä¸ª Hacker News æ‘˜è¦å™¨ï¼Œä»¥æ­¤åˆ›å»ºç®¡é“ä¸­çš„è‡ªå®šä¹‰ç»„ä»¶ï¼Œæ‰©å±•ä½ çš„åº”ç”¨ç¨‹åºè®¿é—®å¤–éƒ¨ API çš„èƒ½åŠ›ã€‚\n- åˆ©ç”¨æ¡ä»¶è·¯ç”± (conditional routing) åˆ›å»ºä¸€ä¸ªåˆ†æ”¯ç®¡é“ï¼Œå½“å¤§è¯­è¨€æ¨¡å‹ç¼ºä¹å“åº”ç”¨æˆ·æŸ¥è¯¢æ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ—¶ï¼Œèƒ½è‡ªåŠ¨å›é€€ (fallback) åˆ°ç½‘ç»œæœç´¢æœºåˆ¶ã€‚\n- æ„å»ºä¸€ä¸ªç”¨äºå‘½åå®ä½“è¯†åˆ« (named entity recognition) çš„è‡ªåæ€ AI æ™ºèƒ½ä½“ (agent)ï¼Œå®ƒé€šè¿‡ä½¿ç”¨è¾“å‡ºéªŒè¯å™¨è‡ªå®šä¹‰ç»„ä»¶å®ç°å¾ªç¯ã€‚\n- åˆ©ç”¨ OpenAI çš„å‡½æ•°è°ƒç”¨ (function-calling) èƒ½åŠ›ï¼Œåˆ›å»ºä¸€ä¸ªèŠå¤© AI æ™ºèƒ½ä½“ï¼Œä½ å¯ä»¥å°† Haystack ç®¡é“ä½œä¸ºå·¥å…·æä¾›ç»™å¤§è¯­è¨€æ¨¡å‹ï¼Œä»è€Œæå‡è¯¥ AI æ™ºèƒ½ä½“çš„åŠŸèƒ½ã€‚\n\nå®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†æŒæ¡ä¸€ä¸ªé«˜çº§ç¼–æ’æ¡†æ¶ï¼Œå®ƒèƒ½å¸®åŠ©ä½ çš„åº”ç”¨ç¨‹åºåœ¨æŠ€æœ¯æ ˆä¸æ–­å˜åŒ–ã€æ–°çš„ç”¨æˆ·éœ€æ±‚ä¸æ–­æ¶Œç°ä»¥åŠä½ æŒç»­æ·»åŠ æ–°åŠŸèƒ½çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶ä¿æŒçµæ´»ã€å¯æ‰©å±•å’Œæ˜“äºç»´æŠ¤ã€‚\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/wCvf549cM0"
  },
  {
    "id": "1825577904287395984",
    "url": "https://x.com/AndrewYNg/status/1825577904287395984",
    "text": "Thank you @RepZoeLofgren for speaking out against the anti-open source, anti-innovation bill SB-1047. \n\nShe is the ranking member of the House Science, Space and Technology Committee. Her staff concludes: \"the problematic core concerns remain: there is little evidentiary basis for the bill; the bill would negatively affect open-source development by applying liability to downstream use; it uses arbitrary thresholds not backed in science.\" [my boldface] \n\nLets all keep fighting to protect open source AI.\n\nhttps://t.co/ln7uOEzmgh",
    "createdAt": "Mon Aug 19 16:57:44 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 79,
    "replyCount": 19,
    "likeCount": 444,
    "quoteCount": 8,
    "viewCount": 116780,
    "bookmarkCount": 36,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ„Ÿè°¢ @RepZoeLofgren å…¬å¼€åå¯¹é˜»ç¢å¼€æºå’Œåˆ›æ–°çš„ SB-1047 æ³•æ¡ˆã€‚\n\nå¥¹æ˜¯ä¼—è®®é™¢ç§‘å­¦ã€ç©ºé—´å’ŒæŠ€æœ¯å§”å‘˜ä¼šçš„é¦–å¸­æˆå‘˜ã€‚å¥¹çš„å·¥ä½œäººå‘˜å¾—å‡ºç»“è®ºï¼šâ€œè¯¥æ³•æ¡ˆçš„æ ¸å¿ƒé—®é¢˜ä¾ç„¶çªå‡ºï¼šå…¶ç¼ºä¹è¶³å¤Ÿçš„è¯æ®æ”¯æŒï¼›å®ƒå°†é€šè¿‡å¯¹ä¸‹æ¸¸ä½¿ç”¨æ–½åŠ è´£ä»»æ¥å¯¹å¼€æºå¼€å‘äº§ç”Ÿè´Ÿé¢å½±å“ï¼›å¹¶ä¸”å®ƒè®¾å®šäº†æ²¡æœ‰ç§‘å­¦ä¾æ®çš„ä»»æ„é—¨æ§›ã€‚â€ [æˆ‘çš„ç²—ä½“]\n\nè®©æˆ‘ä»¬æ‰€æœ‰äººç»§ç»­ä¸ºä¿æŠ¤å¼€æº AI (open source AI) è€ŒåŠªåŠ›ã€‚\n\nhttps://t.co/ln7uOEzmgh"
  },
  {
    "id": "1824106080106123638",
    "url": "https://x.com/AndrewYNg/status/1824106080106123638",
    "text": "When entrepreneurs build a startup, it is often their speed and momentum that gives them a shot at competing with the tech behemoths. This is true of countries as well.\n\nI was recently in Thailand, where I was delighted to see tremendous momentum building in AI (and sip the best Thai ice tea Iâ€™ve ever tasted). Even though Thailand is not as advanced in AI technology or applications as leading tech countries, the enthusiasm for building AI throughout government, corporations, and academia was thrilling. I came away heartened that AIâ€™s benefits will be spread among many countries and convinced that one's level of AI development right now matters less than your momentum toward increasing it.\n\nSeeing the momentum behind AI in Thailand â€” where the per capita GDP is around one fifth that of Japan, and one tenth that of the United States â€” left me feeling that any country, company, or person has a shot at doing meaningful work in the field. While advanced economies such as the U.S. and China are still in the lead, generative AI has made the playing field more level. Foundation models, especially those with open weights, are significantly lowering the barriers to building meaningful AI projects. In Thailand, a lot of people I met werenâ€™t just talking about AI, they were rolling up their sleeves and building. That buys a nation a lot more momentum than just talk.\n\nI met with Prime Minister Srettha Thavisin and his Ministers of Higher Education and Education (primary/secondary) along with many staffers. It was delightful to hear the PM speak of his enthusiasm for AI. The ministers discussed how to (i) provide AI training and (ii) use AI to improve education in a variety of subjects. Happily, the focus was on creating value while thinking through realistic risks like AIâ€™s potential to proliferate misinformation, and not a single person asked me about whether AI will lead to human extinction!\n\nI also met with many business leaders and enjoyed seeing a rapid pace of experimentation with AI. KBTG, an affiliate of the countryâ€™s leading digital bank KBank, is working on a financial chatbot advisor, AI-based identity verification for anti-fraud, AI for auto insurance, and a Thai-language financial large language model. These features are growing mobile banking and increasing financial access. Many business leaders in other sectors, too, have asked their teams to run experiments. There are many AI applications yet to be built in industrial sectors, tourism, trade, and more! (KBTG is an investor in AI Fund, which I lead.)\n\nI often visit universities in both developed and developing economies, and Iâ€™ve been surprised to see that universities in developing economies sometimes adopt AI faster. At Chulalongkorn University (known as Chula), I met with the University President Bundhit Eua-arporn and Director of Chula AI Professor Proadpran Punyabukkana. Chula AI has rolled out campus-wide training in generative AI for faculty, staff, and students. In addition, it supports building AI applications such as AI screening for depression and gastrointestinal cancer. \n\nIt takes years to build up advanced technology. But momentum matters, and there will be many rewards along the journey. Thereâ€™s no time like the present to start building!\n\n[Original text: https://t.co/xqFyYudIZ7 ]",
    "createdAt": "Thu Aug 15 15:29:14 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 72,
    "replyCount": 49,
    "likeCount": 466,
    "quoteCount": 12,
    "viewCount": 72121,
    "bookmarkCount": 97,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åˆ›ä¸šè€…åœ¨åˆ›ç«‹æ–°å…¬å¸æ—¶ï¼Œå¾€å¾€å‡­å€Ÿé€Ÿåº¦å’Œå†²åŠ²æ‰èƒ½æœ‰æœºä¼šä¸ç§‘æŠ€å·¨å¤´ä¸€è¾ƒé«˜ä¸‹ã€‚å¯¹äºå›½å®¶æ¥è¯´ï¼Œè¿™ä¹Ÿæ˜¯åŒæ ·çš„é“ç†ã€‚\n\næˆ‘æœ€è¿‘åœ¨æ³°å›½ï¼Œå¾ˆé«˜å…´çœ‹åˆ°å½“åœ°åœ¨ AI é¢†åŸŸç§¯èšç€å·¨å¤§çš„å‘å±•åŠ¿å¤´ (å½“ç„¶ï¼Œä¹Ÿå“å°åˆ°äº†æˆ‘å–è¿‡æœ€æ£’çš„æ³°å¼å†°èŒ¶)ã€‚å°½ç®¡æ³°å›½åœ¨ AI æŠ€æœ¯æˆ–åº”ç”¨æ–¹é¢å¯èƒ½ä¸å¦‚ä¸€äº›é¢†å…ˆçš„ç§‘æŠ€å¼ºå›½ï¼Œä½†æ”¿åºœã€ä¼ä¸šå’Œå­¦æœ¯ç•Œå¯¹å‘å±• AI çš„çƒ­æƒ…ä»¤äººæŒ¯å¥‹ã€‚æˆ‘æ­¤è¡Œæ„Ÿåˆ°éå¸¸é¼“èˆï¼Œç›¸ä¿¡ AI çš„ç›Šå¤„å°†æ™®æƒ å…¨çƒè¯¸å¤šå›½å®¶ï¼Œå¹¶åšä¿¡ä¸€ä¸ªå›½å®¶å½“å‰ AI çš„å‘å±•æ°´å¹³è¿œä¸å¦‚å…¶æŒç»­æå‡çš„åŠ¿å¤´é‡è¦ã€‚\n\nç›®ç¹æ³°å›½åœ¨ AI é¢†åŸŸå±•ç°å‡ºçš„æ¾æ¹ƒåŠ¨åŠ›â€”â€”é‚£é‡Œçš„äººå‡ GDP å¤§çº¦æ˜¯æ—¥æœ¬çš„äº”åˆ†ä¹‹ä¸€ï¼Œç¾å›½çš„ååˆ†ä¹‹ä¸€â€”â€”è®©æˆ‘ç¡®ä¿¡ï¼Œä»»ä½•å›½å®¶ã€å…¬å¸æˆ–ä¸ªäººéƒ½æœ‰æœºä¼šåœ¨è¿™ä¸ªé¢†åŸŸåšå‡ºæœ‰æ„ä¹‰çš„è´¡çŒ®ã€‚å°½ç®¡ç¾å›½å’Œä¸­å›½ç­‰å‘è¾¾ç»æµä½“ä»å¤„äºé¢†å…ˆåœ°ä½ï¼Œä½†ç”Ÿæˆå¼ AI (generative AI) çš„å‡ºç°å·²ç»è®©ç«äº‰ç¯å¢ƒå˜å¾—æ›´åŠ å…¬å¹³ã€‚åŸºç¡€æ¨¡å‹ (Foundation models)ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å¼€æ”¾æƒé‡çš„æ¨¡å‹ï¼Œæ­£æ˜¾è‘—é™ä½æ„å»ºæœ‰æ„ä¹‰çš„ AI é¡¹ç›®çš„é—¨æ§›ã€‚åœ¨æ³°å›½ï¼Œæˆ‘é‡åˆ°çš„è®¸å¤šäººä¸ä»…ä»…åœç•™åœ¨å£å¤´è®¨è®º AIï¼Œä»–ä»¬æ›´æ˜¯æ’¸èµ·è¢–å­ï¼Œä»˜è¯¸å®è·µã€‚è¿™ç§è¡ŒåŠ¨åŠ›èƒ½ä¸ºä¸€ä¸ªå›½å®¶å¸¦æ¥æ¯”ç©ºè°ˆå¤šå¾—å¤šçš„å‘å±•åŠ¿å¤´ã€‚\n\næˆ‘ä¼šè§äº†æ³°å›½æ€»ç† Srettha Thavisin åŠå…¶é«˜ç­‰æ•™è‚²éƒ¨é•¿å’ŒåŸºç¡€æ•™è‚²éƒ¨é•¿ï¼Œè¿˜æœ‰è®¸å¤šå·¥ä½œäººå‘˜ã€‚å¾ˆé«˜å…´å¬åˆ°æ€»ç†è¡¨è¾¾ä»–å¯¹ AI çš„çƒ­æƒ…ã€‚éƒ¨é•¿ä»¬è®¨è®ºäº†å¦‚ä½• (1) æä¾› AI åŸ¹è®­ï¼Œä»¥åŠ (2) åˆ©ç”¨ AI æ”¹è¿›å„ç§å­¦ç§‘çš„æ•™è‚²ã€‚ä»¤äººæ¬£æ…°çš„æ˜¯ï¼Œä»–ä»¬çš„å…³æ³¨ç‚¹åœ¨äºåˆ›é€ ä»·å€¼ï¼ŒåŒæ—¶å®¡æ…æ€è€ƒ AI ä¼ æ’­é”™è¯¯ä¿¡æ¯ç­‰ç°å®é£é™©ï¼Œè€Œä¸”æ²¡æœ‰ä¸€ä¸ªäººé—®æˆ‘ AI æ˜¯å¦ä¼šå¯¼è‡´äººç±»ç­ç»ï¼\n\næˆ‘è¿˜ä¸è®¸å¤šå•†ä¸šé¢†è¢–è¿›è¡Œäº†äº¤æµï¼Œå¾ˆé«˜å…´çœ‹åˆ° AI å®éªŒæ­£åœ¨å¿«é€Ÿæ¨è¿›ã€‚KBTGï¼Œä½œä¸ºæ³°å›½é¢†å…ˆæ•°å­—é“¶è¡Œ KBank çš„é™„å±å…¬å¸ï¼Œæ­£åœ¨å¼€å‘ä¸€æ¬¾é‡‘èèŠå¤©æœºå™¨äººé¡¾é—®ã€åŸºäº AI çš„åæ¬ºè¯ˆèº«ä»½éªŒè¯ç³»ç»Ÿã€åº”ç”¨äºæ±½è½¦ä¿é™©çš„ AI æŠ€æœ¯ï¼Œä»¥åŠä¸€ä¸ªæ³°è¯­é‡‘èå¤§è¯­è¨€æ¨¡å‹ (large language model)ã€‚è¿™äº›åˆ›æ–°æ­£åœ¨æ¨åŠ¨ç§»åŠ¨é“¶è¡Œçš„å‘å±•ï¼Œå¹¶æé«˜é‡‘èæœåŠ¡çš„å¯åŠæ€§ã€‚å…¶ä»–è¡Œä¸šçš„è®¸å¤šå•†ä¸šé¢†è¢–ä¹Ÿå·²è¦æ±‚ä»–ä»¬çš„å›¢é˜Ÿå¼€å±• AI å®éªŒã€‚åœ¨å·¥ä¸šã€æ—…æ¸¸ã€è´¸æ˜“ç­‰é¢†åŸŸï¼Œè¿˜æœ‰è®¸å¤š AI åº”ç”¨ç­‰å¾…æˆ‘ä»¬å»å¼€å‘ï¼ (KBTG ä¹Ÿæ˜¯æˆ‘æ‰€é¢†å¯¼çš„ AI Fund çš„æŠ•èµ„è€…ã€‚)\n\næˆ‘ç»å¸¸è®¿é—®å‘è¾¾ç»æµä½“å’Œå‘å±•ä¸­ç»æµä½“çš„å¤§å­¦ï¼Œå¹¶æƒŠè®¶åœ°å‘ç°å‘å±•ä¸­ç»æµä½“çš„å¤§å­¦æœ‰æ—¶åœ¨ AI çš„é‡‡çº³é€Ÿåº¦ä¸Šæ›´å¿«ã€‚åœ¨æœ±æ‹‰éš†åŠŸå¤§å­¦ (Chulalongkorn University) (ç®€ç§° Chula)ï¼Œæˆ‘ä¼šè§äº†æ ¡é•¿ Bundhit Eua-arporn å’Œ Chula AI ä¸»ä»» Professor Proadpran Punyabukkanaã€‚Chula AI å·²é¢å‘å…¨ä½“æ•™èŒå‘˜å·¥å’Œå­¦ç”Ÿæ¨å‡ºäº†æ ¡å›­èŒƒå›´çš„ç”Ÿæˆå¼ AI åŸ¹è®­ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ”¯æŒæ„å»º AI åº”ç”¨ï¼Œä¾‹å¦‚ç”¨äºæŠ‘éƒç—‡å’Œèƒƒè‚ ç™Œçš„ AI ç­›æŸ¥å·¥å…·ã€‚\n\nå‘å±•å…ˆè¿›æŠ€æœ¯å¾€å¾€éœ€è¦æ•°å¹´æ—¶é—´ã€‚ä½†åŠ¿å¤´è‡³å…³é‡è¦ï¼Œè€Œä¸”åœ¨è¿™ä¸€å¾ç¨‹ä¸­ä¼šæœ‰ä¸°åšçš„å›æŠ¥ã€‚æ—¶ä¸æˆ‘å¾…ï¼Œç°åœ¨å°±æ˜¯å¼€å§‹è¡ŒåŠ¨çš„æœ€ä½³æ—¶æœºï¼\n\n[åŸæ–‡é“¾æ¥: https://t.co/xqFyYudIZ7 ]"
  },
  {
    "id": "1823759268937650528",
    "url": "https://x.com/AndrewYNg/status/1823759268937650528",
    "text": "Learn a development pattern to systematically improve the accuracy and reliability of LLM applications in our new short course, Improving Accuracy of LLM Applications, built in partnership with @LaminiAI and @Meta, and taught by Laminiâ€™s CEO @realSharonZhou, and Metaâ€™s Senior Director of Partner Engineering,  @asangani7. (Disclosure: I am an investor in Lamini.)\n\nThe path to tuning an LLM application can be complex. In this course, you'll learn a systematic sequence of steps for improving accuracy by reducing hallucinations: \n- Create an evaluation dataset to measure model accuracy\n- Add prompt engineering and self-reflection\n- Fine-tune your model including \"memory-tuning\" which is a new method of embedding facts in an LLM\n\nUsing the Llama 3-8B parameter model, you will:\n- Build a text-to-SQL agent with a custom schema and simulate situations where it hallucinates\n- Understand the difference between instruction fine-tuning, which gives pre-trained LLMs instructions to follow, and memory fine-tuning\n- See how Performance-Efficient Fine-tuning (PEFT) techniques like Low-Rank Adaptation (LoRA) reduce training time by 100x and Mixture of Memory Experts (MoME) reduces it even further\n\nI appreciate Meta releasing the Llama's family of open models -- this course gives an example of the unique type of work that developers can do with such models.\n\nPlease sign up here: https://t.co/FITZFVlzNk",
    "createdAt": "Wed Aug 14 16:31:08 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 126,
    "replyCount": 22,
    "likeCount": 635,
    "quoteCount": 12,
    "viewCount": 65971,
    "bookmarkCount": 312,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æƒ³ç³»ç»Ÿæ€§åœ°æå‡å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨çš„å‡†ç¡®æ€§å’Œå¯é æ€§å—ï¼Ÿå¿«æ¥å‚åŠ æˆ‘ä»¬çš„æ–°çŸ­æœŸè¯¾ç¨‹â€œæé«˜å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨çš„å‡†ç¡®æ€§â€å§ï¼è¿™é—¨è¯¾ç¨‹ç”± @LaminiAI å’Œ @Meta è”æ‰‹æ‰“é€ ï¼Œå°†ç”± Lamini çš„é¦–å¸­æ‰§è¡Œå®˜ @realSharonZhou å’Œ Meta çš„åˆä½œå·¥ç¨‹é«˜çº§æ€»ç›‘ @asangani7 äº²è‡ªæˆè¯¾ã€‚ ï¼ˆå£°æ˜ï¼šæˆ‘æ˜¯ Lamini çš„æŠ•èµ„è€…ã€‚ï¼‰\n\nä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨çš„è¿‡ç¨‹å¯èƒ½é”™ç»¼å¤æ‚ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦åˆ°ä¸€å¥—ç³»ç»ŸåŒ–çš„æ”¹è¿›æ­¥éª¤ï¼Œé€šè¿‡å‡å°‘æ¨¡å‹â€œå¹»è§‰â€ç°è±¡æ¥æå‡å…¶å‡†ç¡®æ€§ï¼š\n- åˆ›å»ºè¯„ä¼°æ•°æ®é›†ï¼Œç”¨äºè¡¡é‡æ¨¡å‹å‡†ç¡®æ€§\n- å¼•å…¥æç¤ºå·¥ç¨‹ (Prompt Engineering) å’Œè‡ªæˆ‘åæ€ (Self-Reflection) æœºåˆ¶\n- å¾®è°ƒæ‚¨çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬ä¸€é¡¹åä¸ºâ€œè®°å¿†å¾®è°ƒâ€çš„æ–°æ–¹æ³•ï¼Œå®ƒèƒ½å°†äº‹å®æœ‰æ•ˆåœ°åµŒå…¥åˆ°å¤§è¯­è¨€æ¨¡å‹ (LLM) ä¸­\n\nä½¿ç”¨ Llama 3-8B å‚æ•°æ¨¡å‹ï¼Œæ‚¨å°†ï¼š\n- æ„å»ºä¸€ä¸ªå¸¦æœ‰è‡ªå®šä¹‰æ¨¡å¼çš„æ–‡æœ¬åˆ° SQL AI æ™ºèƒ½ä½“ (AI Agent)ï¼Œå¹¶æ¨¡æ‹Ÿå…¶å‡ºç°â€œå¹»è§‰â€çš„åœºæ™¯\n- ç†è§£æŒ‡ä»¤å¾®è°ƒï¼ˆå³ä¸ºé¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ (LLM) æä¾›æŒ‡ä»¤ä½¿å…¶éµå¾ªï¼‰ä¸è®°å¿†å¾®è°ƒä¹‹é—´çš„åŒºåˆ«\n- äº†è§£æ€§èƒ½é«˜æ•ˆå¾®è°ƒ (PEFT) æŠ€æœ¯ï¼Œä¾‹å¦‚ä½ç§©é€‚åº” (LoRA)ï¼Œå¦‚ä½•å°†è®­ç»ƒæ—¶é—´ç¼©çŸ­ 100 å€ï¼›ä»¥åŠè®°å¿†ä¸“å®¶æ··åˆ (MoME) å¦‚ä½•åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥åŠ é€Ÿè®­ç»ƒ\n\næˆ‘éå¸¸æ„Ÿè°¢ Meta å‘å¸ƒäº† Llama ç³»åˆ—çš„å¼€æºæ¨¡å‹â€”â€”æœ¬è¯¾ç¨‹æ­£æ˜¯ä¸€ä¸ªç»ä½³èŒƒä¾‹ï¼Œå±•ç¤ºäº†å¼€å‘è€…ä»¬èƒ½å¦‚ä½•åˆ©ç”¨è¿™ç±»æ¨¡å‹å¼€å±•ç‹¬å…·åˆ›æ„çš„å¼€å‘å·¥ä½œã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æŠ¥åï¼šhttps://t.co/FITZFVlzNk"
  },
  {
    "id": "1823429929381585248",
    "url": "https://x.com/AndrewYNg/status/1823429929381585248",
    "text": "It is very rare for the U.S. Federal government to chime in  on state-level legislation. I'm glad that Congressman @RoKhanna is speaking out about why California's proposed SB 1047 is a bad idea. \n\nHe writes that he is \"concerned that the bill as currently written would be ineffective, punishing of individual entrepreneurs and small businesses, and hurt Californiaâ€™s spirit of innovation.\" I agree with him. \n\nhttps://t.co/V1yf7ERyxw",
    "createdAt": "Tue Aug 13 18:42:27 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 29,
    "replyCount": 15,
    "likeCount": 197,
    "quoteCount": 2,
    "viewCount": 38910,
    "bookmarkCount": 14,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ç¾å›½è”é‚¦æ”¿åºœå¾ˆå°‘å¯¹å·çº§ç«‹æ³• (state-level legislation) å‘è¡¨æ„è§ã€‚æˆ‘å¾ˆé«˜å…´ä¼—è®®å‘˜ @RoKhanna å…¬å¼€è¡¨è¾¾äº†ä»–å¯¹åŠ å·æ‹Ÿè®®çš„ SB 1047 æ³•æ¡ˆä¸ºä½•æ˜¯ä¸ªç³Ÿç³•ä¸»æ„çš„çœ‹æ³•ã€‚\n\nä»–å†™é“ï¼Œä»–â€œæ‹…å¿ƒè¯¥æ³•æ¡ˆç›®å‰çš„ç‰ˆæœ¬å°†æ˜¯æ— æ•ˆçš„ï¼Œä¼šå¯¹ä¸ªä½“ä¼ä¸šå®¶å’Œå°å‹ä¼ä¸šé€ æˆæƒ©ç½šæ€§å½±å“ï¼Œå¹¶æŸå®³åŠ å·çš„åˆ›æ–°ç²¾ç¥ã€‚â€æˆ‘åŒæ„ä»–çš„è§‚ç‚¹ã€‚\n\nhttps://t.co/V1yf7ERyxw"
  },
  {
    "id": "1823388325409140946",
    "url": "https://x.com/AndrewYNg/status/1823388325409140946",
    "text": "Iâ€™m speaking on a panel this Thursday (3pm PT) about Stratospheric Aerosol Injection (SAI). SAI is a potential approach to reducing global warming, and AI climate modeling has an important role to play in understanding its impact. I look forward to discussing the atmospheric science and social/political factors of SAI with @chrfield @DKeithClimate @DougMacMartin and Simone Tilmes.\n\nPlease register here to join us! https://t.co/Algxy9Wxqp",
    "createdAt": "Tue Aug 13 15:57:08 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 33,
    "replyCount": 23,
    "likeCount": 169,
    "quoteCount": 6,
    "viewCount": 33538,
    "bookmarkCount": 24,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘å°†åœ¨æœ¬å‘¨å››ï¼ˆå¤ªå¹³æ´‹æ—¶é—´ä¸‹åˆ 3 ç‚¹ï¼‰å‚åŠ ä¸€ä¸ªå°ç»„è®¨è®ºä¼šï¼Œä¸»é¢˜æ˜¯å¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ (Stratospheric Aerosol Injection, SAI)ã€‚SAI æ˜¯ä¸€ç§å¯èƒ½æœ‰åŠ©äºç¼“è§£å…¨çƒå˜æš–çš„æ–¹æ³•ï¼Œè€Œ AI æ°”å€™å»ºæ¨¡åœ¨ç†è§£å…¶æ½œåœ¨å½±å“æ–¹é¢æ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚æˆ‘éå¸¸æœŸå¾…èƒ½ä¸ @chrfield @DKeithClimate @DougMacMartin ä»¥åŠ Simone Tilmes ä¸€èµ·ï¼Œæ·±å…¥æ¢è®¨ SAI æ‰€æ¶‰åŠçš„å¤§æ°”ç§‘å­¦åŸç†åŠå…¶ç¤¾ä¼š/æ”¿æ²»å½±å“ã€‚\n\næ¬¢è¿å¤§å®¶ç‚¹å‡»æ­¤é“¾æ¥æ³¨å†Œï¼ŒåŠ å…¥æˆ‘ä»¬çš„è®¨è®ºï¼https://t.co/Algxy9Wxqp"
  },
  {
    "id": "1821950054439252385",
    "url": "https://x.com/AndrewYNg/status/1821950054439252385",
    "text": "There is an chorus of voices across academia, business and even government concerned about California's proposed anti-open source, anti-innovation bill SB 1047. \n\n@martin_casado has a nice thread summarizing some of these. Thank you @russellwald, @vishalmisra, Ion Stoica, many people from the University of California community, @AnimaAnandkumar, @drfeifei, @garrytan, @AnjneyMidha, Zoe Lofgren and many many others for speaking out to explain why this bill will hurt AI innovation without actually increasing safety. \n\nIf anything, by hurting open source and thus hampering researchers' ability to study cutting-edge models to identify problems, I believe SB1047 is more likely to make AI less safe.",
    "createdAt": "Fri Aug 09 16:41:57 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 69,
    "replyCount": 11,
    "likeCount": 292,
    "quoteCount": 8,
    "viewCount": 72687,
    "bookmarkCount": 38,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "å­¦æœ¯ç•Œã€å•†ç•Œç”šè‡³æ”¿åºœå„æ–¹ï¼Œéƒ½å¯¹åŠ å·æè®®çš„åå¼€æºã€ååˆ›æ–°æ³•æ¡ˆ SB 1047 è¡¨è¾¾äº†æ‹…å¿§ã€‚\n\n@martin_casado å‘äº†ä¸€ä¸ªå¸–å­ï¼Œå¾ˆå¥½åœ°æ€»ç»“äº†å…¶ä¸­çš„ä¸€äº›æ‹…å¿§ã€‚æ„Ÿè°¢ @russellwaldã€@vishalmisraã€Ion Stoicaã€æ¥è‡ªåŠ å·å¤§å­¦ç¤¾åŒºçš„è®¸å¤šäººã€@AnimaAnandkumarã€@drfeifeiã€@garrytanã€@AnjneyMidhaã€Zoe Lofgren ä»¥åŠå…¶ä»–è®¸å¤šäººå…¬å¼€æŒ‡å‡ºï¼Œä¸ºä»€ä¹ˆè¿™é¡¹æ³•æ¡ˆä¼šæŸå®³ AI åˆ›æ–°ï¼Œè€Œå®é™…ä¸Šå¹¶ä¸ä¼šæé«˜å®‰å…¨æ€§ã€‚\n\né€€ä¸€æ­¥è®²ï¼Œæˆ‘ç›¸ä¿¡ SB 1047 é€šè¿‡æŸå®³å¼€æºï¼Œä»è€Œé˜»ç¢ç ”ç©¶äººå‘˜ç ”ç©¶å‰æ²¿æ¨¡å‹ä»¥è¯†åˆ«é—®é¢˜çš„èƒ½åŠ›ï¼Œåè€Œæ›´æœ‰å¯èƒ½è®© AI å˜å¾—æ›´ä¸å®‰å…¨ã€‚"
  },
  {
    "id": "1821206887913943110",
    "url": "https://x.com/AndrewYNg/status/1821206887913943110",
    "text": "I'm teaching a new course! AI Python for Beginners is a series of four short courses that teach anyone to code, regardless of current technical skill. We are offering these courses free for a limited time.\n\nGenerative AI is transforming coding. This course teaches coding in a way thatâ€™s aligned with where the field is going, rather than where it has been:\n\n(1) AI as a Coding Companion. Experienced coders are using AI to help write snippets of code, debug code, and the like. We embrace this approach and describe best-practices for coding with a chatbot. Throughout the course, you'll have access to an AI chatbot that will be your own coding companion that can assist you every step of the way as you code.\n\n(2) Learning by Building AI Applications. You'll write code that interacts with large language models to quickly create fun applications to customize poems, write recipes, and manage a to-do list. This hands-on approach helps you see how writing code that calls on powerful AI models will make you more effective in your work and personal projects.\n\nWith this approach, beginning programmers can learn to do useful things with code far faster than they could have even a year ago.\n\nKnowing a little bit of coding is increasingly helping people in job roles other than software engineers. For example, I've seen a marketing professional write code to download web pages and use generative AI to derive insights; a reporter write code to flag important stories; and an investor automate the initial drafts of contracts.\n\nWith this course youâ€™ll be equipped to automate repetitive tasks, analyze data more efficiently, and leverage AI to enhance your productivity.\n\nIf you are already an experienced developer, please help me spread the word and encourage your non-developer friends to learn a little bit of coding.\n\nI hope you'll check out the first two short courses here! https://t.co/lTupltSZkT",
    "createdAt": "Wed Aug 07 15:28:53 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 1779,
    "replyCount": 487,
    "likeCount": 8575,
    "quoteCount": 173,
    "viewCount": 1214911,
    "bookmarkCount": 7991,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘æ­£åœ¨æ•™æˆä¸€é—¨æ–°è¯¾ç¨‹ï¼â€œé¢å‘åˆå­¦è€…çš„ AI Pythonâ€ æ˜¯ä¸€ä¸ªç”±å››ä¸ªçŸ­æœŸè¯¾ç¨‹ç»„æˆçš„ç³»åˆ—ï¼Œæ—¨åœ¨æ•™æˆä»»ä½•äººç¼–ç ï¼Œæ— è®ºå½“å‰çš„ æŠ€æœ¯æŠ€èƒ½å¦‚ä½•ã€‚æˆ‘ä»¬é™æ—¶å…è´¹æä¾›è¿™äº›è¯¾ç¨‹ã€‚\n\nç”Ÿæˆå¼ AI (Generative AI) æ­£åœ¨æ”¹å˜ç¼–ç æ–¹å¼ã€‚æœ¬è¯¾ç¨‹çš„ç¼–ç æ•™å­¦æ–¹å¼ä¸è¯¥é¢†åŸŸæœªæ¥çš„å‘å±•è¶‹åŠ¿ä¿æŒä¸€è‡´ï¼Œè€Œéå¢¨å®ˆæˆè§„ï¼š\n\n(1) AI ä½œä¸ºç¼–ç ä¼™ä¼´ã€‚ç»éªŒä¸°å¯Œçš„ç¨‹åºå‘˜æ­£åœ¨åˆ©ç”¨ AI ç¼–å†™ä»£ç ç‰‡æ®µã€è°ƒè¯•ä»£ç ç­‰ã€‚æˆ‘ä»¬æ¨å´‡è¿™ç§æ–¹æ³•ï¼Œå¹¶ä¼šä»‹ç»ä½¿ç”¨èŠå¤©æœºå™¨äººè¿›è¡Œç¼–ç çš„æœ€ä½³å®è·µã€‚åœ¨æ•´ä¸ªè¯¾ç¨‹ä¸­ï¼Œä½ éƒ½å°†å¯ä»¥ä½¿ç”¨ä¸€ä¸ª AI èŠå¤©æœºå™¨äººï¼Œå®ƒä¼šæˆä¸ºä½ ä¸“å±çš„ç¼–ç ä¼™ä¼´ï¼Œåœ¨ä½ ç¼–å†™ä»£ç çš„æ¯ä¸€æ­¥éƒ½èƒ½æä¾›ååŠ©ã€‚\n\n(2) é€šè¿‡æ„å»º AI åº”ç”¨ç¨‹åºè¿›è¡Œå­¦ä¹ ã€‚ä½ å°†ç¼–å†™ä¸ å¤§è¯­è¨€æ¨¡å‹ (Large Language Model) äº¤äº’çš„ä»£ç ï¼Œä»è€Œå¿«é€Ÿåˆ›å»ºæœ‰è¶£çš„åº”ç”¨ç¨‹åºï¼Œä¾‹å¦‚è‡ªå®šä¹‰è¯—æ­Œã€æ’°å†™é£Ÿè°±å’Œç®¡ç†å¾…åŠäº‹é¡¹åˆ—è¡¨ã€‚è¿™ç§åŠ¨æ‰‹å®è·µçš„æ–¹æ³•å°†å¸®åŠ©ä½ ç†è§£ï¼Œå¦‚ä½•é€šè¿‡ç¼–å†™è°ƒç”¨å¼ºå¤§ AI æ¨¡å‹çš„ä»£ç ï¼Œæ¥æé«˜ä½ åœ¨å·¥ä½œå’Œä¸ªäººé¡¹ç›®ä¸­çš„æ•ˆç‡ã€‚\n\né€šè¿‡è¿™ç§æ•™å­¦æ–¹æ³•ï¼Œç¼–ç¨‹åˆå­¦è€…èƒ½å¤Ÿæ¯”ä¸€å¹´å‰æ›´å¿«åœ°å­¦ä¼šç”¨ä»£ç å®Œæˆæœ‰ç”¨çš„äº‹æƒ…ã€‚\n\næŒæ¡ä¸€ç‚¹ç‚¹ç¼–ç æŠ€èƒ½æ­£æ—¥ç›Šå¸®åŠ©è½¯ä»¶å·¥ç¨‹å¸ˆä»¥å¤–çš„èŒä¸šäººç¾¤ã€‚ä¾‹å¦‚ï¼Œæˆ‘æ›¾çœ‹åˆ°ä¸€ä½è¥é”€ä¸“ä¸šäººå£«ç¼–å†™ä»£ç ä¸‹è½½ç½‘é¡µï¼Œå¹¶åˆ©ç”¨ç”Ÿæˆå¼ AI æå–æœ‰ä»·å€¼çš„æ´å¯Ÿï¼›ä¸€ä½è®°è€…ç¼–å†™ä»£ç ç­›é€‰é‡è¦æ–°é—»ï¼›ä»¥åŠä¸€ä½æŠ•èµ„è€…è‡ªåŠ¨ç”ŸæˆåˆåŒçš„åˆç¨¿ã€‚\n\né€šè¿‡æœ¬è¯¾ç¨‹ï¼Œä½ å°†èƒ½å¤Ÿè‡ªåŠ¨åŒ–é‡å¤æ€§ä»»åŠ¡ï¼Œæ›´é«˜æ•ˆåœ°åˆ†ææ•°æ®ï¼Œå¹¶åˆ©ç”¨ AI æå‡ä½ çš„ç”Ÿäº§åŠ›ã€‚\n\nå¦‚æœä½ å·²ç»æ˜¯ç»éªŒä¸°å¯Œçš„å¼€å‘äººå‘˜ï¼Œè¯·å¸®åŠ©æˆ‘ä¼ æ’­è¿™ä¸ªæ¶ˆæ¯ï¼Œå¹¶é¼“åŠ±ä½ çš„éå¼€å‘äººå‘˜æœ‹å‹å­¦ä¹ ä¸€ç‚¹ç‚¹ç¼–ç ã€‚\n\nå¸Œæœ›ä½ åœ¨è¿™é‡ŒæŸ¥çœ‹å‰ä¸¤ä¸ªçŸ­æœŸè¯¾ç¨‹ï¼ https://t.co/lTupltSZkT"
  },
  {
    "id": "1820863062993490137",
    "url": "https://x.com/AndrewYNg/status/1820863062993490137",
    "text": "I wrote last week about why working on a concrete startup or project idea â€” meaning a specific product envisioned in enough detail that we can build it for a specific target user â€” lets you go faster. In this letter, Iâ€™d like to share some best practices for identifying promising ideas. \n\nAI Fund, which I lead, works with many corporate partners to identify ideas, often involving applications of AI to the companyâ€™s domain. Because AI is applicable to numerous sectors such as retail, energy, logistics and finance, Iâ€™ve found working with domain experts who know these areas well immensely helpful for identifying what applications are worth building in these areas.\n\nOur brainstorming process starts with recommending that a large number of key contributors at our partner corporation (at least 10 but sometimes well over 100) gain a non-technical, business-level understanding of AI and what it can and canâ€™t do. Taking https://t.co/zpIxRSuky4â€™s â€œGenerative AI for Everyoneâ€ course is a popular option, after which a company is well positioned to assign a small team to coordinate a brainstorming process, followed by a prioritization exercise to pick what to work on. The brainstorming process can be supported by a task-based analysis of jobs in which we decompose employeesâ€™ jobs into tasks to identify which ones might be automated or augmented using AI.\n\nHere are some best practices for these activities:\n\n(i) Trust the domain expertâ€™s gut. A domain expert who has worked for years in a particular sector will have well honed instincts that let them make leaps that would take a non-expert weeks of research.\n\nLetâ€™s say weâ€™re working with a financial services expert and have developed a vague idea (â€œbuild a chatbot for financial adviceâ€). To turn this into a concrete idea, we might need to answer questions such as what areas of finance to target (should we focus on budgeting, investing, or insurance?) and what types of user to serve (fresh graduates, mortgage applicants, new parents, or retirees?) Even a domain expert who has spent years giving financial advice might not know the best answer, but a choice made via their gut gives a quick way to get to one plausible concrete idea. Of course, if market-research data can be obtained quickly to support this decision, we should take advantage of it. But to avoid slowing down too much, weâ€™ve found that expertsâ€™ gut reactions work well and are a quick way to make decisions.\n\nSo, if Iâ€™m handed a non-concrete idea, I often ask a domain expert to use their gut â€” and nothing else â€” to quickly make decisions as needed to make the idea concrete. The resulting idea is only a starting point to be tweaked over time. If, in the discussion, the domain expert picks one option but seems very hesitant to disregard a different option, then we can also keep the second option as a back-up that we can quickly pivot to if the initial one no longer looks promising.\n\n(ii) Generate many ideas. I usually suggest coming up with at least 10 ideas; some will come up with over 100, which is even better. The usual brainstorming advice to go for volume rather than quality applies here. Having many ideas is particularly important when it comes to prioritization. If only one idea is seriously considered â€” sometimes this happens if a senior executive has an idea they really like and puts this forward as the â€œmainâ€ idea to be worked on â€” thereâ€™s a lot of pressure to make this idea work. Even if further investigation discovers problems with it â€” for example, market demand turns out to be weak or the technology is very expensive to build â€” the team will want to keep trying to make it work so we donâ€™t end up with nothing.\n\nIn contrast, when a company has many ideas to choose from, if one starts to look less interesting, itâ€™s easy to shift attention to a different one. When many ideas are considered, itâ€™s easier to compare them to pick the superior ones. As explained in the book Ideaflow, teams that generate more ideas for evaluation and prioritization end up with better solutions.\n\nBecause of this, Iâ€™ve found it helpful to run a broad brainstorming process that involves many employees. Specifically, large companies have many people who collectively have a lot of wisdom regarding the business. Having a small core team coordinate the gathering of ideas from a large number of people lets us tap into this collective fountain of invention. Many times Iâ€™ve seen a broad effort (involving, say, ~100 people who are knowledgeable about the domain and have a basic understanding of AI) end up with better ideas than a narrow one (involving, say, a handful of top executives).\n\n(iii) Make the evaluation criteria explicit. When evaluating and prioritizing, clear criteria for scoring and ranking ideas helps the team to judge ideas more consistently. Business value and technical feasibility are almost always included. Additionally, many companies will prioritize projects that can be a quick win (to build momentum for their overall AI efforts) or support certain strategic priorities such as growth in a particular part of the business. Making such criteria explicit can help during the idea-generation phase, and itâ€™s critical when you evaluate and prioritize.\n\nIn large companies, it can take a few weeks to go through a process to gather and prioritize ideas, but this pays off well in identifying valuable, concrete ideas to pursue. AI isnâ€™t useful unless we find appropriate ways to apply it, and I hope these best practices will help you to generate great AI application ideas to work on.\n\n[Original text: https://t.co/7pwXMGEbpI ]",
    "createdAt": "Tue Aug 06 16:42:38 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 194,
    "replyCount": 24,
    "likeCount": 947,
    "quoteCount": 11,
    "viewCount": 118669,
    "bookmarkCount": 1011,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä¸Šå‘¨çš„æ–‡ç« è®¨è®ºäº†ä¸ºä»€ä¹ˆèšç„¦äºä¸€ä¸ªå…·ä½“çš„åˆ›ä¸šé¡¹ç›®æˆ–äº§å“æ„æƒ³â€”â€”å³ä¸€ä¸ªè¶³å¤Ÿç»†è‡´ã€èƒ½é’ˆå¯¹ç‰¹å®šç”¨æˆ·æ‰“é€ çš„äº§å“â€”â€”å¯ä»¥å¸®åŠ©ä½ æ›´å¿«åœ°å–å¾—è¿›å±•ã€‚åœ¨ä»Šå¤©çš„è¿™å°ä¿¡ä¸­ï¼Œæˆ‘æƒ³åˆ†äº«ä¸€äº›è¯†åˆ«æœ‰å‰æ™¯æƒ³æ³•çš„æœ€ä½³å®è·µã€‚\n\næˆ‘é¢†å¯¼çš„ AI Fund ä¸è®¸å¤šä¼ä¸šä¼™ä¼´åˆä½œï¼Œå…±åŒå‘æ˜æ–°çš„æƒ³æ³•ï¼Œè¿™äº›æƒ³æ³•é€šå¸¸æ¶‰åŠå°† AI åº”ç”¨åˆ°å…¬å¸ç‰¹æœ‰çš„ä¸šåŠ¡é¢†åŸŸã€‚ç”±äº AI (äººå·¥æ™ºèƒ½) é€‚ç”¨äºé›¶å”®ã€èƒ½æºã€ç‰©æµå’Œé‡‘èç­‰ä¼—å¤šè¡Œä¸šï¼Œæˆ‘å‘ç°ä¸ç†Ÿæ‚‰è¿™äº›é¢†åŸŸçš„ä¸“å®¶åˆä½œï¼Œå¯¹äºè¯†åˆ«å“ªäº›åº”ç”¨å€¼å¾—å¼€å‘ï¼Œéå¸¸æœ‰å¸®åŠ©ã€‚\n\næˆ‘ä»¬çš„å¤´è„‘é£æš´è¿‡ç¨‹å§‹äºå»ºè®®æˆ‘ä»¬çš„åˆä½œå…¬å¸ä¸­å¤§é‡çš„æ ¸å¿ƒè´¡çŒ®è€… (è‡³å°‘ 10 äººï¼Œæœ‰æ—¶ç”šè‡³è¶…è¿‡ 100 äºº) å¯¹ AI åŠå…¶èƒ½åŠ›è¾¹ç•Œæœ‰ä¸€ä¸ªéæŠ€æœ¯æ€§ã€ä¸šåŠ¡å±‚é¢çš„ç†è§£ã€‚å‚åŠ  https://t.co/zpIxRSuky4 ä¸Šçš„â€œGenerative AI for Everyoneâ€è¯¾ç¨‹æ˜¯ä¸€ä¸ªå—æ¬¢è¿çš„é€‰æ‹©ã€‚ä¹‹åï¼Œå…¬å¸å°±èƒ½æ›´å¥½åœ°ç»„å»ºä¸€ä¸ªå°å‹å›¢é˜Ÿæ¥åè°ƒå¤´è„‘é£æš´è¿‡ç¨‹ï¼Œæ¥ç€è¿›è¡Œä¼˜å…ˆçº§æ’åºï¼Œä»¥ç¡®å®šä¼˜å…ˆå¼€å±•å“ªäº›å·¥ä½œã€‚å¤´è„‘é£æš´è¿‡ç¨‹è¿˜å¯ä»¥é€šè¿‡ä¸€é¡¹ä»»åŠ¡åˆ†ææ¥æ”¯æŒï¼Œå³æˆ‘ä»¬å°†å‘˜å·¥çš„å·¥ä½œç»†åˆ†ä¸ºå…·ä½“çš„ä»»åŠ¡ï¼Œä»¥è¯†åˆ«å“ªäº›ä»»åŠ¡å¯èƒ½é€šè¿‡ AI å®ç°è‡ªåŠ¨åŒ–æˆ–å¢å¼ºã€‚\n\nä»¥ä¸‹æ˜¯è¿›è¡Œè¿™äº›æ´»åŠ¨çš„ä¸€äº›æœ€ä½³å®è·µï¼š\n\n(i) ä¿¡ä»»é¢†åŸŸä¸“å®¶çš„ç›´è§‰ã€‚ä¸€ä½åœ¨ç‰¹å®šè¡Œä¸šæ·±è€•å¤šå¹´çš„é¢†åŸŸä¸“å®¶ï¼Œä¼šæ‹¥æœ‰æ•é”çš„ç›´è§‰ï¼Œèƒ½å¤Ÿå¿«é€Ÿåšå‡ºéä¸“ä¸šäººå£«éœ€è¦æ•°å‘¨ç ”ç©¶æ‰èƒ½å¾—å‡ºçš„åˆ¤æ–­ã€‚\n\nå‡è®¾æˆ‘ä»¬æ­£ä¸ä¸€ä½é‡‘èæœåŠ¡ä¸“å®¶åˆä½œï¼Œå¹¶æœ‰äº†ä¸€ä¸ªæ¨¡ç³Šçš„æƒ³æ³• (â€œå¼€å‘ä¸€ä¸ªæä¾›é‡‘èå»ºè®®çš„èŠå¤©æœºå™¨äººâ€)ã€‚ä¸ºäº†å°†è¿™ä¸ªæƒ³æ³•å…·ä½“åŒ–ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦å›ç­”ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚ï¼šè¦ç„å‡†é‡‘èé¢†åŸŸçš„å“ªä¸ªå…·ä½“æ–¹å‘ (æˆ‘ä»¬åº”è¯¥å…³æ³¨é¢„ç®—è§„åˆ’ã€æŠ•èµ„ç­–ç•¥ï¼Œè¿˜æ˜¯ä¿é™©æœåŠ¡ï¼Ÿ) ä»¥åŠè¦æœåŠ¡å“ªç±»ç”¨æˆ· (åº”å±Šæ¯•ä¸šç”Ÿã€æŠµæŠ¼è´·æ¬¾ç”³è¯·äººã€æ–°æ‰‹çˆ¶æ¯ï¼Œè¿˜æ˜¯é€€ä¼‘äººå‘˜ï¼Ÿ) å³ä½¿æ˜¯å¤šå¹´æä¾›é‡‘èå»ºè®®çš„ä¸“å®¶ï¼Œä¹Ÿå¯èƒ½æ— æ³•ç«‹åˆ»çŸ¥é“æœ€ä½³ç­”æ¡ˆï¼Œä½†é€šè¿‡ä»–ä»¬çš„ç›´è§‰åšå‡ºçš„é€‰æ‹©ï¼Œèƒ½æä¾›ä¸€ä¸ªå¿«é€Ÿè·å¾—åˆç†å…·ä½“æƒ³æ³•çš„é€”å¾„ã€‚å½“ç„¶ï¼Œå¦‚æœèƒ½å¿«é€Ÿè·å¾—å¸‚åœºè°ƒç ”æ•°æ®æ¥æ”¯æŒè¿™ä¸ªå†³ç­–ï¼Œæˆ‘ä»¬åº”è¯¥åŠ ä»¥åˆ©ç”¨ã€‚ä½†ä¸ºäº†é¿å…è¿›å±•ç¼“æ…¢ï¼Œæˆ‘ä»¬å‘ç°ä¸“å®¶çš„ç›´è§‰ååº”éå¸¸æœ‰æ•ˆï¼Œæ˜¯å¿«é€Ÿåšå‡ºå†³ç­–çš„å¥½æ–¹æ³•ã€‚\n\næ‰€ä»¥ï¼Œå¦‚æœæˆ‘å¾—åˆ°ä¸€ä¸ªä¸å¤Ÿå…·ä½“çš„æƒ³æ³•ï¼Œæˆ‘é€šå¸¸ä¼šè¯·é¢†åŸŸä¸“å®¶ä»…ä»…ä¾é ç›´è§‰ï¼Œå¿«é€Ÿåšå‡ºå¿…è¦çš„å†³ç­–ï¼Œä»¥ä½¿æƒ³æ³•å…·ä½“åŒ–ã€‚ç”±æ­¤äº§ç”Ÿçš„æƒ³æ³•åªæ˜¯ä¸€ä¸ªèµ·ç‚¹ï¼Œä¼šéšç€æ—¶é—´çš„æ¨ç§»ä¸æ–­è°ƒæ•´ã€‚å¦‚æœåœ¨è®¨è®ºä¸­ï¼Œé¢†åŸŸä¸“å®¶é€‰æ‹©äº†ä¸€ä¸ªé€‰é¡¹ä½†ä¼¼ä¹éå¸¸çŠ¹è±«æ˜¯å¦æ”¾å¼ƒå¦ä¸€ä¸ªé€‰é¡¹ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¹Ÿå¯ä»¥å°†ç¬¬äºŒä¸ªé€‰é¡¹ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼Œå¦‚æœæœ€åˆçš„é€‰é¡¹ä¸å†æœ‰å‰æ™¯ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿…é€Ÿè½¬å‘å®ƒã€‚\n\n(ii) äº§ç”Ÿå¤§é‡æƒ³æ³•ã€‚æˆ‘é€šå¸¸å»ºè®®è‡³å°‘æå‡º 10 ä¸ªæƒ³æ³•ï¼›æœ‰äº›äººä¼šæå‡ºè¶…è¿‡ 100 ä¸ªï¼Œè¿™å½“ç„¶æ›´å¥½ã€‚å¤´è„‘é£æš´ä¸­â€œè¿½æ±‚æ•°é‡è€Œéè´¨é‡â€çš„å¸¸è§å»ºè®®åœ¨è¿™é‡ŒåŒæ ·é€‚ç”¨ã€‚åœ¨ä¼˜å…ˆçº§æ’åºæ—¶ï¼Œæ‹¥æœ‰å¤§é‡æƒ³æ³•å°¤å…¶é‡è¦ã€‚å¦‚æœåªæœ‰ä¸€ä¸ªæƒ³æ³•è¢«è®¤çœŸè€ƒè™‘â€”â€”æ¯”å¦‚ï¼ŒæŸä½é«˜çº§ä¸»ç®¡æå‡ºäº†ä¸€ä¸ªä»–éå¸¸å–œæ¬¢å¹¶æŒ‡å®šä¸ºâ€œä¸»è¦â€å·¥ä½œæ–¹å‘çš„æƒ³æ³•â€”â€”é‚£ä¹ˆè¿™ä¸ªæƒ³æ³•æˆåŠŸçš„å‹åŠ›å°±ä¼šéå¸¸å¤§ã€‚å³ä½¿åç»­è°ƒæŸ¥å‘ç°å®ƒå­˜åœ¨é—®é¢˜ (ä¾‹å¦‚ï¼Œå¸‚åœºéœ€æ±‚ç–²è½¯æˆ–æŠ€æœ¯å¼€å‘æˆæœ¬æé«˜)ï¼Œå›¢é˜Ÿä¹Ÿå¾€å¾€ä¼šåŠªåŠ›ä½¿å…¶å¥æ•ˆï¼Œä»¥å…æœ€ç»ˆä¸€æ— æ‰€è·ã€‚\n\nç›¸åï¼Œå½“å…¬å¸æœ‰è®¸å¤šæƒ³æ³•å¯ä¾›é€‰æ‹©æ—¶ï¼Œå¦‚æœå…¶ä¸­ä¸€ä¸ªçœ‹èµ·æ¥ä¸å†é‚£ä¹ˆå¸å¼•äººï¼Œå°±å¯ä»¥è½»æ¾åœ°å°†æ³¨æ„åŠ›è½¬ç§»åˆ°å¦ä¸€ä¸ªä¸Šã€‚å½“åŒæ—¶è€ƒè™‘å¤šä¸ªæƒ³æ³•æ—¶ï¼Œä¹Ÿæ›´å®¹æ˜“è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œé€‰å‡ºæ›´ä¼˜ç§€çš„æ–¹æ¡ˆã€‚æ­£å¦‚ã€ŠIdeaflowã€‹ä¸€ä¹¦æ‰€è§£é‡Šçš„ï¼Œç”Ÿæˆæ›´å¤šæƒ³æ³•è¿›è¡Œè¯„ä¼°å’Œä¼˜å…ˆçº§æ’åºçš„å›¢é˜Ÿï¼Œæœ€ç»ˆä¼šæ‰¾åˆ°æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚\n\næ­£å› ä¸ºå¦‚æ­¤ï¼Œæˆ‘å‘ç°å¼€å±•ä¸€ä¸ªå¹¿æ³›ã€å¤šå‘˜å·¥å‚ä¸çš„å¤´è„‘é£æš´è¿‡ç¨‹éå¸¸æœ‰ç›Šã€‚å…·ä½“æ¥è¯´ï¼Œå¤§å…¬å¸æ‹¥æœ‰ä¼—å¤šå‘˜å·¥ï¼Œä»–ä»¬ collectively (å…±åŒåœ°) ç§¯ç´¯äº†å…³äºä¸šåŠ¡çš„ä¸°å¯Œæ™ºæ…§ã€‚è®©ä¸€ä¸ªå°å‹æ ¸å¿ƒå›¢é˜Ÿåè°ƒä»å¤§é‡å‘˜å·¥é‚£é‡Œæ”¶é›†æƒ³æ³•ï¼Œèƒ½è®©æˆ‘ä»¬å……åˆ†åˆ©ç”¨è¿™ç§é›†ä½“çš„åˆ›æ–°æºæ³‰ã€‚æˆ‘å¤šæ¬¡çœ‹åˆ°ï¼Œä¸€é¡¹å¹¿æ³›çš„åŠªåŠ› (ä¾‹å¦‚ï¼Œæ¶‰åŠçº¦ 100 åå¯¹é¢†åŸŸäº†è§£å¹¶å¯¹ AI æœ‰åŸºæœ¬ç†è§£çš„äºº) æœ€ç»ˆäº§ç”Ÿçš„æƒ³æ³•ï¼Œè¦ä¼˜äºä¸€é¡¹ç‹­éš˜çš„åŠªåŠ› (ä¾‹å¦‚ï¼Œä»…æ¶‰åŠå°‘æ•°å‡ ä½é«˜ç®¡) ã€‚\n\n(iii) æ˜ç¡®è¯„ä¼°æ ‡å‡†ã€‚åœ¨è¯„ä¼°å’Œä¼˜å…ˆçº§æ’åºæ—¶ï¼Œæ¸…æ™°çš„è¯„åˆ†å’Œæ’åæ ‡å‡†æœ‰åŠ©äºå›¢é˜Ÿæ›´ä¸€è‡´åœ°åˆ¤æ–­æƒ³æ³•ã€‚ä¸šåŠ¡ä»·å€¼å’ŒæŠ€æœ¯å¯è¡Œæ€§å‡ ä¹æ€»æ˜¯è¯„ä¼°æ ‡å‡†ä¸­ä¸å¯æˆ–ç¼ºçš„ã€‚æ­¤å¤–ï¼Œè®¸å¤šå…¬å¸è¿˜ä¼šä¼˜å…ˆè€ƒè™‘é‚£äº›èƒ½å¿«é€Ÿå–å¾—æˆåŠŸ (ä¸ºæ•´ä½“ AI éƒ¨ç½²å·¥ä½œå»ºç«‹åŠ¿å¤´) æˆ–æ”¯æŒç‰¹å®šæˆ˜ç•¥é‡ç‚¹ (ä¾‹å¦‚åœ¨ä¸šåŠ¡çš„æŸä¸ªç‰¹å®šéƒ¨åˆ†å®ç°å¢é•¿) çš„é¡¹ç›®ã€‚æ˜ç¡®è¿™äº›æ ‡å‡†åœ¨æƒ³æ³•ç”Ÿæˆé˜¶æ®µä¼šæœ‰æ‰€å¸®åŠ©ï¼Œå¹¶ä¸”åœ¨è¯„ä¼°å’Œä¼˜å…ˆçº§æ’åºæ—¶è‡³å…³é‡è¦ã€‚\n\nåœ¨å¤§å‹å…¬å¸ä¸­ï¼Œå®Œæˆæ”¶é›†å’Œä¼˜å…ˆçº§æ’åºæƒ³æ³•çš„è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ å‘¨æ—¶é—´ï¼Œä½†è¿™å¯¹äºè¯†åˆ«æœ‰ä»·å€¼ã€å¯è¡Œçš„å…·ä½“æƒ³æ³•æ¥è¯´ï¼Œæ˜¯ç‰©æœ‰æ‰€å€¼çš„ã€‚é™¤éæˆ‘ä»¬æ‰¾åˆ°åˆé€‚çš„æ–¹æ³•æ¥åº”ç”¨ AIï¼Œå¦åˆ™ AI çš„æ½œåŠ›å°†æ— æ³•å‘æŒ¥ã€‚æˆ‘å¸Œæœ›è¿™äº›æœ€ä½³å®è·µèƒ½å¸®åŠ©ä½ ç”Ÿæˆå‡ºè‰²çš„ AI åº”ç”¨æƒ³æ³•å¹¶ä»˜è¯¸å®æ–½ã€‚\n\n[Original text: https://t.co/7pwXMGEbpI ]"
  },
  {
    "id": "1818666105340330260",
    "url": "https://x.com/AndrewYNg/status/1818666105340330260",
    "text": "Learn how embedding models are built, trained, and used in semantic search systems in this new short course, Embedding Models: From Architecture to Implementation, created with @vectara and taught by @ofermend.\n\nMany LLM apps use a single embedding model for both questions and answers. This can lead to issues such as retrieving results that are similar to the question itself rather than relevant answers. With a dual encoder architecture, you can use separate embedding models for questions and answers to better match questions with appropriate answers.\n\nIn this course, you will use, build, and train a dual encoder model.\n\nYouâ€™ll also learn:\n- What are word embeddings, and how they are used\n- The evolution of embeddings to BERT, where embeddings take into account each word's surrounding context  \n- How a contrastive loss is used to train a dual encoder model with one encoder trained to embed questions and the other responses.\n- How to analyze a dual encoderâ€™s effect on search relevance and compare it to a retrieval process with a single encoder.\n\nPlease sign up here! https://t.co/4wuz0vAw6X",
    "createdAt": "Wed Jul 31 15:12:43 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 147,
    "replyCount": 23,
    "likeCount": 716,
    "quoteCount": 8,
    "viewCount": 71347,
    "bookmarkCount": 389,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨è¿™é—¨ç”± @vectara åˆ›å»ºã€@ofermend è®²æˆçš„æ–°çŸ­è¯¾ç¨‹ã€ŠåµŒå…¥æ¨¡å‹ï¼šä»æ¶æ„åˆ°å®ç°ã€‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åœ¨è¯­ä¹‰æœç´¢ç³»ç»Ÿä¸­æ„å»ºã€è®­ç»ƒå’Œä½¿ç”¨åµŒå…¥æ¨¡å‹ã€‚\n\nè®¸å¤šå¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºåœ¨å¤„ç†é—®é¢˜å’Œç­”æ¡ˆæ—¶ï¼Œéƒ½åªä½¿ç”¨ä¸€ä¸ªåµŒå…¥æ¨¡å‹ã€‚è¿™å¯èƒ½å¯¼è‡´æ£€ç´¢åˆ°çš„ç»“æœä¸é—®é¢˜æœ¬èº«è¿‡äºç›¸ä¼¼ï¼Œè€ŒéçœŸæ­£ç›¸å…³çš„ç­”æ¡ˆï¼Œä»è€Œäº§ç”Ÿé—®é¢˜ã€‚è€Œé€šè¿‡åŒç¼–ç å™¨ (dual encoder) æ¶æ„ï¼Œä½ å¯ä»¥ä¸ºé—®é¢˜å’Œç­”æ¡ˆåˆ†åˆ«ä½¿ç”¨ç‹¬ç«‹çš„åµŒå…¥æ¨¡å‹ï¼Œä»è€Œæ›´å¥½åœ°å°†é—®é¢˜ä¸æ°å½“çš„ç­”æ¡ˆåŒ¹é…èµ·æ¥ã€‚\n\nåœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†äº²è‡ªåŠ¨æ‰‹ä½¿ç”¨ã€æ„å»ºå’Œè®­ç»ƒä¸€ä¸ªåŒç¼–ç å™¨æ¨¡å‹ã€‚\n\nä½ è¿˜å°†å­¦ä¹ ï¼š\n- ä»€ä¹ˆæ˜¯è¯åµŒå…¥ (word embeddings)ï¼Œä»¥åŠå®ƒä»¬æ˜¯å¦‚ä½•è¢«ä½¿ç”¨çš„ã€‚\n- åµŒå…¥æŠ€æœ¯å¦‚ä½•æ¼”å˜åˆ° BERT æ¨¡å‹ï¼Œå…¶ä¸­åµŒå…¥ä¼šè€ƒè™‘æ¯ä¸ªè¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\n- å¦‚ä½•ä½¿ç”¨å¯¹æ¯”æŸå¤± (contrastive loss) æ¥è®­ç»ƒä¸€ä¸ªåŒç¼–ç å™¨æ¨¡å‹ï¼Œå…¶ä¸­ä¸€ä¸ªç¼–ç å™¨è´Ÿè´£å¤„ç†é—®é¢˜ï¼Œå¦ä¸€ä¸ªåˆ™è´Ÿè´£å¤„ç†å“åº”ã€‚\n- å¦‚ä½•åˆ†æåŒç¼–ç å™¨å¯¹æœç´¢ç›¸å…³æ€§çš„å½±å“ï¼Œå¹¶å°†å…¶ä¸ä½¿ç”¨å•ç¼–ç å™¨çš„æ£€ç´¢è¿‡ç¨‹è¿›è¡Œæ¯”è¾ƒã€‚\n\nè¯·åœ¨æ­¤æ³¨å†Œï¼ https://t.co/4wuz0vAw6X"
  },
  {
    "id": "1818320842654371918",
    "url": "https://x.com/AndrewYNg/status/1818320842654371918",
    "text": "AIâ€™s usefulness in a wide variety of applications creates many opportunities for entrepreneurship. Here, Iâ€™d like to share what might be a counter-intuitive best practice that Iâ€™ve learned from leading AI Fund, a venture studio that has built dozens of startups with extraordinary entrepreneurs. When it comes to building AI applications, we strongly prefer to work on a concrete idea, meaning a specific product envisioned in enough detail that we can build it for a specific target user.\n\nSome design philosophies say you shouldnâ€™t envision a specific product from the start. Instead, they recommend starting with a problem to be solved and then carefully studying the market before you devise a concrete solution. Thereâ€™s a reason for this: The more concrete or precise your product specification, the more likely it is to be off-target. However, I find that having something specific to execute toward lets you go much faster and discover and fix problems more rapidly along the way. If the idea turns out to be flawed, rapid execution will let you discover the flaws sooner, and this knowledge and experience will help you switch to a different concrete idea.\n\nOne test of concreteness is whether youâ€™ve specified the idea in enough detail that a product/engineering team could build an initial prototype. For example, â€œAI for livestock farmingâ€ is not concrete; itâ€™s vague. If you were to ask an engineer to build this, they would have a hard time knowing what to build.  Similarly, â€œAI for livestock tracking in farmingâ€ is still vague. There are so many approaches to this that most reasonable engineers wouldnâ€™t know what to build. But â€œApply face recognition to cows so as to recognize individual cows and monitor their movement on a farmâ€ is specific enough that a good engineer could quickly choose from the available options (for example, what algorithm to try first, what camera resolution to use, and so on) to let us relatively efficiently assess:\n- Technical feasibility: For example, do face recognition algorithms developed for human faces work for cows? (It turns out that they do!)\n- Business feasibility: Does the idea add enough value to be worth building? (Talking to farmers might quickly reveal that solutions like RFID are easier and cheaper.)\n\nArticulating a concrete idea â€” which is more likely than a vague idea to be wrong â€” takes more courage. The more specific an idea, the more likely it is to be a bit off, especially in the details. The general area of AI for livestock farming seems promising, and surely there will be good ways to apply AI for livestock. In contrast, specifying a concrete idea, which is much easier to invalidate, is scary.\n\nThe benefit is that the clarity of a specific product vision lets a team execute much faster. One strong predictor of how likely a startup is to succeed is the speed with which it can get stuff done. This is why founders with clarity of vision tend to be desired; clarity helps drive a team in a specific direction. Of course, the vision has to be a good one, and thereâ€™s always a risk of efficiently building something that no one wants to buy! But a startup is unlikely to succeed if it meanders for too long without forming a clear, concrete vision.\n\nBuilding toward something concrete â€” if you can do so in a responsible way that doesnâ€™t harm others â€” lets you get critical feedback more efficiently and, if necessary, switch directions sooner. (An earlier letter in The Batch also discussed when itâ€™s better to go with a â€œReady, Fire, Aimâ€ approach to projects.) One factor that favors this approach is the low cost of experimenting and iterating. This is increasingly the case for many AI applications, but perhaps less so for deep-tech AI projects.\n\nI realize that this advice runs counter to common practice in design thinking, which warns against leaping to a solution too quickly, and instead advocates spending time understanding end-users, deeply understanding their problems, and brainstorming a wide range of solutions. If youâ€™re starting without any ideas, then such an extended process can be a good way to develop good ideas. Further, keeping ideas open-ended can be good for curiosity-driven research, where investing to pursue deep tech with only a vague direction in mind can pay huge dividends over the long term.\n\nIf you are thinking about starting a new AI project, consider whether you can come up with a concrete vision to execute toward. Even if the initial vision turns out not to be quite right, rapid iteration will let you discover this sooner, and the learnings will let you switch to a different concrete idea.\n\n[Original text: https://t.co/8CkePKyBJ4 ]",
    "createdAt": "Tue Jul 30 16:20:46 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 114,
    "replyCount": 90,
    "likeCount": 581,
    "quoteCount": 14,
    "viewCount": 58787,
    "bookmarkCount": 327,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "äººå·¥æ™ºèƒ½ (AI) åœ¨å„ç§åº”ç”¨ä¸­çš„å¹¿æ³›å‰æ™¯ï¼Œä¸ºåˆ›ä¸šå¸¦æ¥äº†è®¸å¤šæœºä¼šã€‚åœ¨è¿™é‡Œï¼Œæˆ‘æƒ³åˆ†äº«ä¸€ä¸ªæˆ‘ä»é¢†å¯¼ AI Fund å­¦åˆ°çš„ã€å¯èƒ½æœ‰ç‚¹åç›´è§‰ (counter-intuitive) çš„æœ€ä½³å®è·µã€‚AI Fund æ˜¯ä¸€å®¶é£é™©æŠ•èµ„å·¥ä½œå®¤ (venture studio)ï¼Œå·²ç»ä¸ä¼—å¤šæ°å‡ºçš„ä¼ä¸šå®¶åˆä½œå»ºç«‹äº†æ•°åå®¶åˆåˆ›å…¬å¸ã€‚åœ¨å¼€å‘äººå·¥æ™ºèƒ½åº”ç”¨æ—¶ï¼Œæˆ‘ä»¬å¼ºçƒˆå€¾å‘äºä¸“æ³¨äºä¸€ä¸ªå…·ä½“çš„æƒ³æ³•â€”â€”è¿™æ„å‘³ç€è¿™ä¸ªç‰¹å®šäº§å“åœ¨æ„æƒ³æ—¶å¿…é¡»è¶³å¤Ÿè¯¦ç»†ï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½å¤Ÿä¸ºç‰¹å®šçš„ç›®æ ‡ç”¨æˆ·å°†å…¶ä»˜è¯¸å®ç°ã€‚\n\næœ‰äº›è®¾è®¡ç†å¿µè®¤ä¸ºï¼Œä½ ä¸åº”è¯¥ä»ä¸€å¼€å§‹å°±è®¾æƒ³ä¸€ä¸ªå…·ä½“çš„äº§å“ã€‚ç›¸åï¼Œä»–ä»¬å»ºè®®å…ˆä»ä¸€ä¸ªæœ‰å¾…è§£å†³çš„é—®é¢˜å…¥æ‰‹ï¼Œç„¶åä»”ç»†ç ”ç©¶å¸‚åœºï¼Œä¹‹åå†è®¾è®¡å‡ºå…·ä½“çš„è§£å†³æ–¹æ¡ˆã€‚è¿™æ ·åšçš„ç†ç”±æ˜¯ï¼šä½ çš„äº§å“è§„èŒƒè¶Šå…·ä½“æˆ–è¶Šç²¾ç¡®ï¼Œå°±è¶Šæœ‰å¯èƒ½åç¦»ç›®æ ‡ã€‚ç„¶è€Œï¼Œæˆ‘å‘ç°ï¼Œæ‹¥æœ‰ä¸€ä¸ªå…·ä½“çš„æ‰§è¡Œç›®æ ‡èƒ½è®©ä½ å‰è¿›å¾—æ›´å¿«ï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­æ›´è¿…é€Ÿåœ°å‘ç°å’Œè§£å†³é—®é¢˜ã€‚å¦‚æœæŸä¸ªæƒ³æ³•è¢«è¯å®æœ‰ç¼ºé™·ï¼Œå¿«é€Ÿæ‰§è¡Œå°†è®©ä½ æ›´å¿«åœ°å‘ç°è¿™äº›ç¼ºé™·ï¼Œè€Œè¿™äº›çŸ¥è¯†å’Œç»éªŒå°†å¸®åŠ©ä½ è½¬å‘ä¸€ä¸ªä¸åŒçš„å…·ä½“æƒ³æ³•ã€‚\n\nå¦‚ä½•è¡¡é‡ä¸€ä¸ªæƒ³æ³•æ˜¯å¦å…·ä½“å‘¢ï¼Ÿä¸€ä¸ªæ£€éªŒæ ‡å‡†æ˜¯ï¼Œä½ æ˜¯å¦å·²ç»è¶³å¤Ÿè¯¦ç»†åœ°é˜è¿°äº†è¿™ä¸ªæƒ³æ³•ï¼Œä»¥ä¾¿äº§å“/å·¥ç¨‹å›¢é˜Ÿå¯ä»¥æ„å»ºä¸€ä¸ªåˆå§‹åŸå‹ã€‚ä¾‹å¦‚ï¼Œâ€œç”¨äºç•œç‰§ä¸šçš„äººå·¥æ™ºèƒ½â€å°±ä¸å…·ä½“ï¼›å®ƒå¾ˆæ¨¡ç³Šã€‚å¦‚æœä½ è®©ä¸€ä½å·¥ç¨‹å¸ˆåŸºäºè¿™ä¸ªæ¨¡ç³Šæƒ³æ³•è¿›è¡Œå¼€å‘ï¼Œä»–ä»¬å°†å¾ˆéš¾çŸ¥é“å…·ä½“è¦åšä»€ä¹ˆã€‚åŒæ ·ï¼Œâ€œç”¨äºç•œç‰§ä¸šç‰²ç•œè¿½è¸ªçš„äººå·¥æ™ºèƒ½â€ä»ç„¶æ¨¡ç³Šã€‚å®ç°è¿™ä¸€ç›®æ ‡çš„æ–¹æ³•å¤ªå¤šäº†ï¼Œå¤§å¤šæ•°æœ‰ç»éªŒçš„å·¥ç¨‹å¸ˆéƒ½ä¸çŸ¥é“è¯¥é€‰æ‹©å“ªç§æ–¹æ¡ˆæ¥æ„å»ºã€‚ä½†æ˜¯ï¼Œâ€œå°†é¢éƒ¨è¯†åˆ«åº”ç”¨äºå¥¶ç‰›ï¼Œä»¥è¯†åˆ«ä¸ªä½“å¥¶ç‰›å¹¶ç›‘æµ‹å®ƒä»¬åœ¨å†œåœºä¸Šçš„æ´»åŠ¨â€å°±è¶³å¤Ÿå…·ä½“äº†ã€‚ä¸€ä½ä¼˜ç§€çš„å·¥ç¨‹å¸ˆå¯ä»¥å¿«é€Ÿä»ç°æœ‰é€‰é¡¹ä¸­è¿›è¡Œé€‰æ‹©ï¼ˆä¾‹å¦‚ï¼Œé¦–å…ˆå°è¯•å“ªç§ç®—æ³•ï¼Œä½¿ç”¨ä»€ä¹ˆæ‘„åƒå¤´åˆ†è¾¨ç‡ç­‰ï¼‰ï¼Œä»è€Œè®©æˆ‘ä»¬ç›¸å¯¹é«˜æ•ˆåœ°è¯„ä¼°ï¼š\n- æŠ€æœ¯å¯è¡Œæ€§ï¼šä¾‹å¦‚ï¼Œä¸ºäººç±»é¢éƒ¨å¼€å‘çš„é¢éƒ¨è¯†åˆ«ç®—æ³•æ˜¯å¦é€‚ç”¨äºå¥¶ç‰›ï¼Ÿï¼ˆäº‹å®è¯æ˜ï¼Œå®ƒä»¬ç¡®å®é€‚ç”¨ï¼ï¼‰\n- å•†ä¸šå¯è¡Œæ€§ï¼šè¿™ä¸ªæƒ³æ³•æ˜¯å¦èƒ½åˆ›é€ è¶³å¤Ÿçš„ä»·å€¼ï¼Œå€¼å¾—æˆ‘ä»¬æŠ•å…¥å¼€å‘ï¼Ÿï¼ˆä¸å†œæ°‘äº¤æµå¯èƒ½ä¼šå¾ˆå¿«å‘ç°ï¼ŒRFID ç­‰è§£å†³æ–¹æ¡ˆå¯èƒ½æ›´ç®€å•ã€æ›´ä¾¿å®œã€‚ï¼‰\n\næå‡ºä¸€ä¸ªå…·ä½“çš„æƒ³æ³•â€”â€”è¿™æ¯”æ¨¡ç³Šçš„æƒ³æ³•æ›´æœ‰å¯èƒ½å‡ºé”™â€”â€”éœ€è¦æ›´å¤§çš„å‹‡æ°”ã€‚ä¸€ä¸ªæƒ³æ³•è¶Šå…·ä½“ï¼Œå®ƒå°±è¶Šæœ‰å¯èƒ½åœ¨ç»†èŠ‚ä¸Šå‡ºç°åå·®ã€‚è™½ç„¶â€œç”¨äºç•œç‰§ä¸šçš„äººå·¥æ™ºèƒ½â€è¿™ä¸ªå¤§æ–¹å‘çœ‹èµ·æ¥å¾ˆæœ‰å‰æ™¯ï¼Œè€Œä¸”è‚¯å®šä¼šæœ‰å¥½æ–¹æ³•å°†äººå·¥æ™ºèƒ½åº”ç”¨äºç•œç‰§ä¸šï¼Œä½†ç›¸æ¯”ä¹‹ä¸‹ï¼Œæå‡ºä¸€ä¸ªå…·ä½“çš„ã€æ›´å®¹æ˜“è¢«è¯ä¼ªçš„æƒ³æ³•ï¼Œç¡®å®ä»¤äººæœ›è€Œç”Ÿç•ã€‚\n\nè¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œæ¸…æ™°çš„äº§å“æ„¿æ™¯èƒ½è®©å›¢é˜Ÿæ‰§è¡Œå¾—æ›´å¿«ã€‚è¡¡é‡ä¸€å®¶åˆåˆ›å…¬å¸æˆåŠŸå¯èƒ½æ€§çš„ä¸€ä¸ªé‡è¦é¢„æµ‹å› ç´ ï¼Œå°±æ˜¯å®ƒå®Œæˆå·¥ä½œ (get stuff done) çš„é€Ÿåº¦ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé‚£äº›å…·æœ‰æ¸…æ™°æ„¿æ™¯çš„åˆ›å§‹äººå¤‡å—è¿½æ§çš„åŸå› ï¼›æ¸…æ™°åº¦æœ‰åŠ©äºæ¨åŠ¨å›¢é˜Ÿæœç€ä¸€ä¸ªç‰¹å®šæ–¹å‘å‰è¿›ã€‚å½“ç„¶ï¼Œè¿™ä¸ªæ„¿æ™¯å¿…é¡»æ˜¯å¥½çš„ï¼Œè€Œä¸”æ€»æœ‰é«˜æ•ˆåœ°æ„å»ºå‡ºæ— äººæƒ³è´­ä¹°çš„ä¸œè¥¿çš„é£é™©ï¼ä½†å¦‚æœä¸€å®¶åˆåˆ›å…¬å¸é•¿æ—¶é—´æ¼«æ— ç›®çš„åœ°å¾˜å¾Šï¼Œæ²¡æœ‰å½¢æˆä¸€ä¸ªæ¸…æ™°ã€å…·ä½“çš„æ„¿æ™¯ï¼Œå®ƒå°±ä¸å¤ªå¯èƒ½æˆåŠŸã€‚\n\næœç€å…·ä½“çš„ç›®æ ‡åŠªåŠ›â€”â€”å¦‚æœä½ èƒ½ä»¥è´Ÿè´£ä»»çš„æ–¹å¼åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”ä¸ä¼¤å®³ä»–äººâ€”â€”èƒ½è®©ä½ æ›´æœ‰æ•ˆåœ°è·å¾—å…³é”®åé¦ˆï¼Œå¹¶åœ¨å¿…è¦æ—¶æ›´å¿«åœ°æ”¹å˜æ–¹å‘ã€‚ï¼ˆã€ŠThe Batchã€‹ä¸Šæ›´æ—©çš„ä¸€å°ä¿¡ä¹Ÿè®¨è®ºäº†ä½•æ—¶æœ€å¥½é‡‡ç”¨â€œReady, Fire, Aimâ€çš„æ–¹æ³•æ¥å¤„ç†é¡¹ç›®ã€‚ï¼‰æ”¯æŒè¿™ç§æ–¹æ³•çš„ä¸€ä¸ªå› ç´ æ˜¯å®éªŒå’Œè¿­ä»£çš„ä½æˆæœ¬ã€‚å¯¹äºè®¸å¤šäººå·¥æ™ºèƒ½åº”ç”¨æ¥è¯´ï¼Œè¿™ç§æƒ…å†µè¶Šæ¥è¶Šæ™®éï¼Œä½†å¯¹äºç¡¬ç§‘æŠ€ (deep-tech) äººå·¥æ™ºèƒ½é¡¹ç›®å¯èƒ½å¹¶éå¦‚æ­¤ã€‚\n\næˆ‘æ„è¯†åˆ°ï¼Œè¿™ä¸ªå»ºè®®ä¸è®¾è®¡æ€ç»´ (design thinking) ä¸­çš„å¸¸è§åšæ³•æœ‰æ‰€ä¸åŒï¼Œè®¾è®¡æ€ç»´è­¦å‘Šä¸è¦è¿‡å¿«åœ°è·³åˆ°è§£å†³æ–¹æ¡ˆï¼Œè€Œæ˜¯ä¸»å¼ èŠ±æ—¶é—´äº†è§£æœ€ç»ˆç”¨æˆ·ï¼Œæ·±å…¥ç†è§£ä»–ä»¬çš„é—®é¢˜ï¼Œå¹¶é›†æ€å¹¿ç›Šæå‡ºå¹¿æ³›çš„è§£å†³æ–¹æ¡ˆã€‚å¦‚æœä½ åœ¨æ²¡æœ‰ä»»ä½•æƒ³æ³•çš„æƒ…å†µä¸‹å¼€å§‹ï¼Œé‚£ä¹ˆè¿™æ ·ä¸€ä¸ªæ‰©å±•çš„è¿‡ç¨‹å¯èƒ½æ˜¯ä¸€ä¸ªäº§ç”Ÿå¥½æƒ³æ³•çš„å¥½æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä¿æŒæƒ³æ³•å¼€æ”¾å¼å¯¹äºå¥½å¥‡å¿ƒé©±åŠ¨çš„ç ”ç©¶å¯èƒ½æ˜¯æœ‰ç›Šçš„ï¼Œåœ¨è¿™ç§ç ”ç©¶ä¸­ï¼Œå³ä½¿å¿ƒä¸­åªæœ‰æ¨¡ç³Šçš„æ–¹å‘ï¼ŒæŠ•èµ„äºè¿½æ±‚ç¡¬ç§‘æŠ€ï¼Œä»é•¿è¿œæ¥çœ‹ä¹Ÿå¯èƒ½å¸¦æ¥å·¨å¤§çš„å›æŠ¥ã€‚\n\nå¦‚æœä½ æ­£åœ¨è€ƒè™‘å¯åŠ¨ä¸€ä¸ªæ–°çš„ AI é¡¹ç›®ï¼Œè¯·æ€è€ƒä½ æ˜¯å¦èƒ½æå‡ºä¸€ä¸ªå…·ä½“çš„æ„¿æ™¯ä½œä¸ºæ‰§è¡Œæ–¹å‘ã€‚å³ä½¿æœ€åˆçš„æ„¿æ™¯è¢«è¯å®ä¸å®Œå…¨æ­£ç¡®ï¼Œå¿«é€Ÿè¿­ä»£ä¹Ÿå°†è®©ä½ æ›´å¿«åœ°å‘ç°è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”æ‰€å­¦åˆ°çš„ç»éªŒå°†å¸®åŠ©ä½ è½¬å‘ä¸€ä¸ªä¸åŒçš„å…·ä½“æƒ³æ³•ã€‚\n\n[Original text: https://t.co/8CkePKyBJ4 ]"
  },
  {
    "id": "1816171538275787145",
    "url": "https://x.com/AndrewYNg/status/1816171538275787145",
    "text": "Learn to train an LLM with distributed data while ensuring privacy using federated learning in a new two-part short course, Intro to Federated Learning and Federated Fine-tuning of LLMs with Private Data, created with @flwrlabs and taught by @daniel_janes and @niclane7.\n\nFederated learning allows a single model to be trained across multiple devices, such as phones, or multiple organizations, such as hospitals, without the need to share data to a central server.\n\nThis two-part course gives you an introduction to federated learning, and then teaches you how to fine-tune your large language model with distributed data using Flower Labâ€™s open source federated learning framework.\n\nYouâ€™ll learn:\n- How to use federated learning to train a variety of models, ranging from speech and vision models to LLMs, across distributed data while offering data privacy options to users and organizations.\n- Privacy Enhancing Technologies like differential privacy (DP), which obscures individual data by adding calibrated noise to query results.\n- Two variants of differential privacy - Central and Local - and how to choose depending on your use case.\n- How to measure and decrease bandwidth usage to make federated learning more practical and efficient with techniques like using pre-trained models and Parameter-Efficient Fine-Tuning\n- How federated LLM fine-tuning reduces the risk of leaking training data.\n\nSign up here! https://t.co/cuN1n0ylee",
    "createdAt": "Wed Jul 24 18:00:12 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 128,
    "replyCount": 20,
    "likeCount": 656,
    "quoteCount": 11,
    "viewCount": 63905,
    "bookmarkCount": 323,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨æ–°çš„ä¸¤éƒ¨åˆ†çŸ­æœŸè¯¾ç¨‹ä¸­ï¼Œå­¦ä¹ å¦‚ä½•åˆ©ç”¨è”é‚¦å­¦ä¹  (Federated Learning)ï¼Œåœ¨ç¡®ä¿æ•°æ®éšç§çš„å‰æä¸‹ï¼Œä½¿ç”¨åˆ†å¸ƒå¼æ•°æ®è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ (LLM)ã€‚è¿™é—¨è¯¾ç¨‹åä¸ºâ€œè”é‚¦å­¦ä¹ ç®€ä»‹ä¸åŸºäºç§æœ‰æ•°æ®çš„è”é‚¦å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒâ€ï¼Œç”± @flwrlabs åˆ›å»ºï¼Œå¹¶ç”± @daniel_janes å’Œ @niclane7 æˆè¯¾ã€‚\n\nè”é‚¦å­¦ä¹ å…è®¸åœ¨å¤šä¸ªè®¾å¤‡ï¼ˆä¾‹å¦‚æ‰‹æœºï¼‰æˆ–å¤šä¸ªç»„ç»‡ï¼ˆä¾‹å¦‚åŒ»é™¢ï¼‰ä¸Šè®­ç»ƒå•ä¸ªæ¨¡å‹ï¼Œè€Œæ— éœ€å°†æ•°æ®å…±äº«åˆ°ä¸­å¤®æœåŠ¡å™¨ã€‚\n\nè¿™ä¸ªä¸¤éƒ¨åˆ†çš„è¯¾ç¨‹å°†å‘ä½ ä»‹ç»è”é‚¦å­¦ä¹ ï¼Œç„¶åæ•™ä½ å¦‚ä½•ä½¿ç”¨ Flower Lab çš„å¼€æºè”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼æ•°æ®å¾®è°ƒä½ çš„å¤§è¯­è¨€æ¨¡å‹ã€‚\n\nä½ å°†å­¦åˆ°ï¼š\n- å¦‚ä½•ä½¿ç”¨è”é‚¦å­¦ä¹ ï¼Œåœ¨åˆ†å¸ƒå¼æ•°æ®ä¸Šè®­ç»ƒå„ç§æ¨¡å‹ï¼ŒåŒ…æ‹¬ä»è¯­éŸ³æ¨¡å‹ã€è§†è§‰æ¨¡å‹åˆ°å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼ŒåŒæ—¶ä¸ºç”¨æˆ·å’Œç»„ç»‡æä¾›æ•°æ®éšç§é€‰é¡¹ã€‚\n- éšç§å¢å¼ºæŠ€æœ¯ (Privacy Enhancing Technologies)ï¼Œä¾‹å¦‚å·®åˆ†éšç§ (DP)ï¼Œå®ƒé€šè¿‡å‘æŸ¥è¯¢ç»“æœæ·»åŠ ç»è¿‡æ ¡å‡†çš„å™ªå£°æ¥æ¨¡ç³Šä¸ªäººæ•°æ®ã€‚\n- å·®åˆ†éšç§çš„ä¸¤ç§å˜ä½“â€”â€”ä¸­å¤®å¼å’Œå±€éƒ¨å¼â€”â€”ä»¥åŠå¦‚ä½•æ ¹æ®ä½ çš„å…·ä½“ç”¨ä¾‹è¿›è¡Œé€‰æ‹©ã€‚\n- å¦‚ä½•é€šè¿‡ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒ (Parameter-Efficient Fine-Tuning) ç­‰æŠ€æœ¯ï¼Œè¡¡é‡å¹¶å‡å°‘å¸¦å®½ä½¿ç”¨ï¼Œä½¿è”é‚¦å­¦ä¹ æ›´å®ç”¨ã€æ›´é«˜æ•ˆã€‚\n- è”é‚¦å¤§è¯­è¨€æ¨¡å‹ (LLM) å¾®è°ƒå¦‚ä½•é™ä½è®­ç»ƒæ•°æ®æ³„éœ²çš„é£é™©ã€‚\n\nåœ¨æ­¤æ³¨å†Œï¼ https://t.co/cuN1n0ylee"
  },
  {
    "id": "1815792223411429741",
    "url": "https://x.com/AndrewYNg/status/1815792223411429741",
    "text": "Thank you Meta and the Llama team for your huge contributions to open-source! Llama 3.1 with increased context length and improved capabilities is a wonderful gift to everyone. \n\nI hope foolish regulations don't like California's proposed SB1047 don't stop such innovations.",
    "createdAt": "Tue Jul 23 16:52:56 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 215,
    "replyCount": 36,
    "likeCount": 1717,
    "quoteCount": 12,
    "viewCount": 104425,
    "bookmarkCount": 85,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ„Ÿè°¢ Meta å’Œ Llama å›¢é˜Ÿä¸ºå¼€æºç¤¾åŒºåšå‡ºçš„å·¨å¤§è´¡çŒ®ï¼Llama 3.1 ç‰ˆæœ¬ï¼Œå‡­å€Ÿå…¶æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦å’Œæ›´å¼ºçš„èƒ½åŠ›ï¼Œæ— ç–‘æ˜¯é€ç»™å¤§å®¶çš„ä¸€ä»½åšç¤¼ã€‚\n\næˆ‘çœŸå¿ƒå¸Œæœ›ï¼Œä¸è¦è®©åƒåŠ åˆ©ç¦å°¼äºšå·æè®®çš„ SB1047 è¿™æ ·çš„æ„šè ¢æ³•è§„ï¼Œé˜»ç¢äº†æ­¤ç±»åˆ›æ–°ã€‚"
  },
  {
    "id": "1813591557511295234",
    "url": "https://x.com/AndrewYNg/status/1813591557511295234",
    "text": "New short course on Pretraining LLMs! Developed with @UpstageAI and taught by their CEO @hunkims and CSO @echojuliett.\n\nWhile prompting or fine-tuning existing models works well for many general language tasks, pretraining is  valuable for specialized domains or languages with limited representation in current models.\n\nThis course walks you through the LLM pretraining pipeline:\n1. Data preparation: Learn to source, clean, and prepare training data using HuggingFace.\n2. Model architecture: Configure transformer networks, including modifying existing models.\n3. Training: Set up and run training using open-source libraries.\n4. Evaluation: Benchmark performance using popular evaluation strategies.\n\nAs an example use case, you'll also compare the output of a base model with its fine-tuned and further pretrained variants, to see the impact of pretraining on a model's ability to write Python. \n\nThe course also explores an innovative technique called depth up-scaling, which Upstage used to train their Solar model family, reducing pretraining compute costs by up to 70%. This technique works by first duplicating layers of a smaller pretrained model to form a larger model, and then further pretraining the result.\n\nSign up here! https://t.co/IjYmNPR7sd",
    "createdAt": "Wed Jul 17 15:08:16 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 206,
    "replyCount": 30,
    "likeCount": 986,
    "quoteCount": 14,
    "viewCount": 85009,
    "bookmarkCount": 488,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹çš„æ–°çŸ­æœŸè¯¾ç¨‹æ¥å•¦ï¼æœ¬è¯¾ç¨‹ä¸ @UpstageAI è”åˆå¼€å‘ï¼Œç”±å…¶ CEO @hunkims å’Œ CSO @echojuliett äº²è‡ªè®²è§£ã€‚\n\nå°½ç®¡å¯¹ç°æœ‰æ¨¡å‹è¿›è¡Œæç¤º (prompting) æˆ–å¾®è°ƒ (fine-tuning) åœ¨è®¸å¤šé€šç”¨è¯­è¨€ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†é¢„è®­ç»ƒ (pretraining) å¯¹äºä¸“ä¸šé¢†åŸŸæˆ–æ•°æ®ä»£è¡¨æ€§ä¸è¶³çš„è¯­è¨€æ¥è¯´ï¼Œä»ç„¶å…·æœ‰ä¸å¯æ›¿ä»£çš„ä»·å€¼ã€‚\n\næœ¬è¯¾ç¨‹å°†å¸¦ä½ æ·±å…¥æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒæµç¨‹ï¼š\n1.  **æ•°æ®å‡†å¤‡**ï¼šå­¦ä¹ å¦‚ä½•ä½¿ç”¨ HuggingFace è·å–ã€æ¸…æ´—å’Œå‡†å¤‡è®­ç»ƒæ•°æ®ã€‚\n2.  **æ¨¡å‹æ¶æ„**ï¼šé…ç½® Transformer (Transformer) ç½‘ç»œï¼ŒåŒ…æ‹¬å¦‚ä½•ä¿®æ”¹ç°æœ‰æ¨¡å‹ã€‚\n3.  **è®­ç»ƒ**ï¼šä½¿ç”¨å¼€æºåº“è®¾ç½®å¹¶è¿è¡Œæ¨¡å‹è®­ç»ƒã€‚\n4.  **è¯„ä¼°**ï¼šè¿ç”¨æµè¡Œçš„è¯„ä¼°ç­–ç•¥å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚\n\nä½œä¸ºå®è·µæ¡ˆä¾‹ï¼Œä½ è¿˜ä¼šæ¯”è¾ƒä¸€ä¸ªåŸºç¡€æ¨¡å‹ä¸ç»è¿‡å¾®è°ƒå’Œè¿›ä¸€æ­¥é¢„è®­ç»ƒçš„å˜ä½“æ¨¡å‹ï¼Œäº²çœ¼è§è¯é¢„è®­ç»ƒå¦‚ä½•æå‡æ¨¡å‹ç”Ÿæˆ Python ä»£ç çš„èƒ½åŠ›ã€‚\n\næ­¤å¤–ï¼Œæœ¬è¯¾ç¨‹è¿˜ä¼šä»‹ç»ä¸€é¡¹åä¸ºæ·±åº¦æ‰©å±• (depth up-scaling) çš„åˆ›æ–°æŠ€æœ¯ã€‚Upstage å…¬å¸æ­£æ˜¯åˆ©ç”¨è¿™é¡¹æŠ€æœ¯è®­ç»ƒäº†ä»–ä»¬çš„ Solar æ¨¡å‹å®¶æ—ï¼Œä»è€Œå°†é¢„è®­ç»ƒçš„è®¡ç®—æˆæœ¬é™ä½äº†é«˜è¾¾ 70%ï¼è¿™é¡¹æŠ€æœ¯çš„æ ¸å¿ƒåŸç†æ˜¯ï¼šé¦–å…ˆå¤åˆ¶ä¸€ä¸ªè¾ƒå°é¢„è®­ç»ƒæ¨¡å‹çš„å±‚ï¼Œä»¥æ„å»ºä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹ï¼Œç„¶åå†å¯¹è¿™ä¸ªæ–°å½¢æˆçš„æ›´å¤§æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥çš„é¢„è®­ç»ƒã€‚\n\nç‚¹å‡»è¿™é‡ŒæŠ¥åï¼https://t.co/IjYmNPR7sd"
  },
  {
    "id": "1811425437048070328",
    "url": "https://x.com/AndrewYNg/status/1811425437048070328",
    "text": "I continue to be alarmed at the progress of proposed California regulation SB 1047 and the attack it represents on open source and more broadly on AI innovation. As I wrote previously, this proposed law makes a fundamental mistake of regulating AI technology instead of AI applications, and thus would fail to make AI meaningfully safer. Iâ€™d like to explain why the specific mechanisms of SB 1047 are so pernicious to open source.\n\nTo be clear, there are routes that regulators should pursue to improve safety. For example, I would welcome outlawing nonconsensual deepfake pornography, standardizing watermarking and fingerprinting to identify generated content, and investing more in red teaming and other safety research. Unfortunately, the proposed bill pursues a less beneficial and more harmful path.\n\nSB 1047â€™s purported goal is to ensure safety of AI models. It puts in place complex reporting requirements for developers who fine-tune models or develop models that cost more than $100 million to train. It is a vague, ambiguous law that imposes significant penalties for violations, creating a huge gray zone in which developers canâ€™t be sure how to avoid breaking the law. This will paralyze many teams.\n\nYou can read the latest draft of the law online. Iâ€™ve read through it carefully, and I find it ambiguous and very hard to follow.\n\nDevelopers who try to navigate the lawâ€™s complex requirements face what feels like a huge personal risk. It requires that developers submit, under penalty of perjury, a certification of compliance with the requirements of the law. But when the requirements are complex, hard to understand, and can even shift according to the whims of an unelected body (more on this below), how do we ensure we are in compliance?\n\nFor example, the certification must include many different sections. One is an analysis of â€œthe nature and magnitude of critical harms â€¦ the model might reasonably cause or enable.â€ But given that even leading AI researchers arenâ€™t sure what harms models might cause or enable, how is a team of developers supposed to figure this out and declare â€” under penalty of perjury â€” that they meet this requirement?\n\nFurther, some developers will be required to implement â€œprotections to prevent â€¦ misuse of, or unsafe post-training modifications of, the covered model and all covered model derivatives â€¦ that are appropriate in light of the risks associated with the covered model, including from advanced persistent threats or other sophisticated actors.â€ Even leading AI researchers donâ€™t agree on how best to â€œprotectâ€ AI models against these supposed risks, or what would be â€œappropriate.â€ So how are developers supposed to figure out how to comply with this requirement?\n\nThis creates a scary situation for developers. Committing perjury could lead to fines and even jail time. Some developers will have to hire expensive lawyers or consultants to advise them on how to comply with these requirements. (I am not a lawyer and am not giving legal advice, but one way to try to avoid perjury is to show that you are relying on expert advice, to demonstrate that you had no intent to lie.) Others will simply refrain from releasing cutting-edge AI products.\n\nIf this law passes, the fear of a trial by a jury â€” leading to a verdict that can be very unpredictable and with significant penalties in the event of a conviction â€” will be very real. What if someone releases a model today after taking what they genuinely felt were reasonable safeguards, but a few years later, when views on AI technology might have shifted, some aggressive prosecutor manages to convince a jury that whatever they did was not, in hindsight, â€œreasonableâ€? \n\nReasonableness is ambiguous and its legal interpretation can depend on case law, jury instructions, and common facts, among other things. This makes it very hard to ensure that what a developer does today will be deemed reasonable by a future jury. (For more on this, see Context Fundâ€™s analysis of SB 1047. [URLs in article linked to below.])\n\nOne highly placed lawyer in the California government who studied this law carefully told me they found it hard to understand. I invite you to read it and judge for yourself â€” if you find the requirements clear, you might have a brilliant future as a lawyer!\n\nAdding to the ambiguity, the bill would create a Frontier Model Division (FMD) with a five-person board that has the power to dictate standards to developers. This small board would be a great target for lobbying and regulatory capture. (Bill Gurley has a great video on regulatory capture.) The unelected FMD can levy fees on developers to cover its costs. It can arbitrarily change the computation threshold at which fine-tuning a model becomes subject to its oversight. This can lead to even small teams being required to hire an auditor to check for compliance with an ambiguous safety standard.\n\nThese provisions donâ€™t ensure that AI is safe. They create regulatory uncertainty, and more opportunities for vested interests wishing to stifle open-source to lobby for shifts in the requirements that raise the cost of compliance. This would lock out many teams that donâ€™t have a revenue stream â€” specifically, many open-source contributors â€” that would let them pay for lobbyists, auditors, and lawyers to help ensure they comply with these ambiguous and unreasonable requirements.\n\nOpen source is a wonderful force that is bringing knowledge and tools to many people, and is a key pillar of AI innovation. I am dismayed at the concerted attacks on it. Make no mistake, there is a fight in California right now for the future health of open source. I am committed to doing what I can to preserve open source, but I donâ€™t assume that the pro-open source side will prevail. I hope you will join me in speaking out against SB 1047 and other laws that threaten to stifle open source.\n\n[Original text (with links): https://t.co/whAndl5C2g ]",
    "createdAt": "Thu Jul 11 15:40:53 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 502,
    "replyCount": 132,
    "likeCount": 2175,
    "quoteCount": 84,
    "viewCount": 455274,
    "bookmarkCount": 465,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åŠ å·æ‹Ÿè®®çš„ SB 1047 æ³•è§„æ­£åœ¨ä¸æ–­æ¨è¡Œï¼Œè¿™è®©æˆ‘æŒç»­æ„Ÿåˆ°è­¦æƒ•ï¼Œå®ƒä»£è¡¨ç€å¯¹å¼€æºä¹ƒè‡³æ›´å¹¿æ³›çš„ AI åˆ›æ–°å‘èµ·äº†ä¸€åœºæ”»å‡»ã€‚æ­£å¦‚æˆ‘æ­¤å‰æ‰€å†™ï¼Œè¿™é¡¹æ‹Ÿè®®æ³•å¾‹çŠ¯äº†ä¸€ä¸ªæ ¹æœ¬æ€§é”™è¯¯ï¼Œå³å®ƒç›‘ç®¡çš„æ˜¯ AI æŠ€æœ¯æœ¬èº«ï¼Œè€Œé AI çš„å…·ä½“åº”ç”¨ï¼Œå› æ­¤æ— æ³•çœŸæ­£è®© AI å˜å¾—æ›´å®‰å…¨ã€‚æˆ‘æƒ³å€Ÿæ­¤æœºä¼šï¼Œè§£é‡Š SB 1047 çš„å…·ä½“æœºåˆ¶ä¸ºä½•å¯¹å¼€æºé¢†åŸŸå¦‚æ­¤æœ‰å®³ã€‚\n\nè¯šç„¶ï¼Œç›‘ç®¡æœºæ„ç¡®å®åº”è¯¥æ¢ç´¢ä¸€äº›é€”å¾„æ¥æé«˜ AI å®‰å…¨æ€§ã€‚ä¾‹å¦‚ï¼Œæˆ‘éå¸¸æ”¯æŒå–ç¼”æœªç»åŒæ„çš„æ·±åº¦ä¼ªé€ è‰²æƒ…å†…å®¹ã€æ¨å¹¿æ°´å°å’ŒæŒ‡çº¹æŠ€æœ¯ä»¥è¯†åˆ«ç”Ÿæˆå†…å®¹ï¼Œä»¥åŠåŠ å¤§å¯¹çº¢é˜Ÿæµ‹è¯• (red teaming) å’Œå…¶ä»–å®‰å…¨ç ”ç©¶çš„æŠ•å…¥ã€‚ç„¶è€Œï¼Œä»¤äººé—æ†¾çš„æ˜¯ï¼Œè¿™é¡¹æ‹Ÿè®®æ³•æ¡ˆå´é€‰æ‹©äº†ä¸€æ¡æ”¶æ•ˆç”šå¾®ä¸”å±å®³æ›´å¤§çš„é“è·¯ã€‚\n\nSB 1047 çš„ç›®æ ‡å£°ç§°æ˜¯ä¸ºäº†ç¡®ä¿ AI æ¨¡å‹çš„å®‰å…¨ã€‚å®ƒå¯¹é‚£äº›å¾®è°ƒæ¨¡å‹æˆ–å¼€å‘è®­ç»ƒæˆæœ¬è¶…è¿‡ 1 äº¿ç¾å…ƒæ¨¡å‹çš„å¼€å‘è€…æ–½åŠ äº†å¤æ‚çš„æŠ¥å‘Šè¦æ±‚ã€‚è¿™é¡¹æ³•å¾‹æ¡æ–‡å«ç³Šä¸æ¸…ã€æ¨¡æ£±ä¸¤å¯ï¼Œå¯¹è¿è§„è¡Œä¸ºè§„å®šäº†ä¸¥å‰çš„æƒ©ç½šï¼Œä»è€Œåˆ¶é€ äº†ä¸€ä¸ªå·¨å¤§çš„ç°è‰²åœ°å¸¦ï¼Œè®©å¼€å‘è€…éš¾ä»¥ç¡®å®šå¦‚ä½•æ‰èƒ½åˆæ³•åˆè§„ã€‚è¿™æ— ç–‘å°†ä½¿è®¸å¤šå›¢é˜Ÿçš„å·¥ä½œä¸¾æ­¥ç»´è‰°ã€‚\n\næ‚¨å¯ä»¥åœ¨çº¿é˜…è¯»è¯¥æ³•å¾‹çš„æœ€æ–°è‰æ¡ˆã€‚æˆ‘ä»”ç»†ç ”è¯»åå‘ç°ï¼Œå®ƒç¡®å®æ™¦æ¶©éš¾æ‡‚ï¼Œè®©äººéš¾ä»¥ç†è§£ã€‚\n\nè¯•å›¾ç†è§£å¹¶éµå¾ªè¯¥æ³•å¾‹å¤æ‚è¦æ±‚çš„å¼€å‘è€…ï¼Œä»¿ä½›é¢ä¸´ç€å·¨å¤§çš„ä¸ªäººé£é™©ã€‚æ³•å¾‹è¦æ±‚å¼€å‘è€…åœ¨æ‰¿æ‹…ä¼ªè¯ç½ªé£é™©çš„å‰æä¸‹ï¼Œæäº¤ä¸€ä»½å£°æ˜å…¶ç¬¦åˆæ³•å¾‹è¦æ±‚çš„è®¤è¯ã€‚ä½†å½“è¿™äº›è¦æ±‚æ—¢å¤æ‚åˆéš¾ä»¥ç†è§£ï¼Œç”šè‡³å¯èƒ½æ ¹æ®ä¸€ä¸ªæœªç»é€‰ä¸¾çš„æœºæ„çš„æ„æ„¿è€Œéšæ„æ”¹å˜æ—¶ (ä¸‹æ–‡å°†è¯¦ç»†è¯´æ˜)ï¼Œæˆ‘ä»¬åˆå¦‚ä½•èƒ½ç¡®ä¿è‡ªå·±å®Œå…¨åˆè§„å‘¢ï¼Ÿ\n\nä¸¾ä¾‹æ¥è¯´ï¼Œè¯¥è®¤è¯å¿…é¡»åŒ…å«è®¸å¤šä¸åŒçš„éƒ¨åˆ†ã€‚å…¶ä¸­ä¸€é¡¹æ˜¯å¯¹â€œæ¨¡å‹å¯èƒ½åˆç†å¯¼è‡´æˆ–åŠ©é•¿çš„å…³é”®å±å®³çš„æ€§è´¨å’Œä¸¥é‡ç¨‹åº¦â€è¿›è¡Œåˆ†æã€‚ç„¶è€Œï¼Œé‰´äºå³ä½¿æ˜¯é¡¶å°–çš„ AI ç ”ç©¶äººå‘˜ä¹Ÿæ— æ³•å®Œå…¨ç¡®å®šæ¨¡å‹å¯èƒ½é€ æˆæˆ–åŠ©é•¿å“ªäº›å±å®³ï¼Œä¸€ä¸ªå¼€å‘å›¢é˜Ÿåˆè¯¥å¦‚ä½•å¼„æ¸…è¿™äº›ï¼Œå¹¶æ‰¿è¯º â€”â€” åœ¨æ‰¿æ‹…ä¼ªè¯ç½ªé£é™©çš„å‰æä¸‹ â€”â€” ä»–ä»¬ç¬¦åˆè¿™é¡¹è¦æ±‚å‘¢ï¼Ÿ\n\næ­¤å¤–ï¼Œä¸€äº›å¼€å‘è€…è¿˜å°†è¢«è¦æ±‚å®æ–½â€œä¿æŠ¤æªæ–½ï¼Œä»¥é˜²æ­¢...è¢«æ¶µç›–æ¨¡å‹åŠå…¶æ‰€æœ‰è¡ç”Ÿæ¨¡å‹è¢«è¯¯ç”¨æˆ–è¿›è¡Œä¸å®‰å…¨çš„æ¨¡å‹åè®­ç»ƒä¿®æ”¹...è¿™äº›æªæ–½åº”æ ¹æ®è¢«æ¶µç›–æ¨¡å‹æ‰€é¢ä¸´çš„é£é™©ï¼ŒåŒ…æ‹¬æ¥è‡ªé«˜çº§æŒç»­æ€§å¨èƒ (advanced persistent threats) æˆ–å…¶ä»–å¤æ‚æ”»å‡»è€…çš„é£é™©ï¼Œè¿›è¡Œé€‚å½“è°ƒæ•´ã€‚â€ å³ä½¿æ˜¯é¢†å…ˆçš„ AI ç ”ç©¶äººå‘˜ä¹Ÿæœªèƒ½å°±å¦‚ä½•æœ€å¥½åœ°â€œä¿æŠ¤â€AI æ¨¡å‹å…å—è¿™äº›æ½œåœ¨é£é™©ï¼Œæˆ–è€…ä½•ç§æªæ–½æ‰ç®—â€œé€‚å½“â€è¾¾æˆä¸€è‡´ã€‚é‚£ä¹ˆï¼Œå¼€å‘è€…åˆè¯¥å¦‚ä½•æ‘¸ç´¢å‡ºä¸€æ¡åˆè§„ä¹‹è·¯å‘¢ï¼Ÿ\n\nè¿™ä¸ºå¼€å‘è€…åˆ›é€ äº†ä¸€ä¸ªä»¤äººæ‹…å¿§çš„å±€é¢ã€‚ä¸€æ—¦è¢«åˆ¤ä¼ªè¯ç½ªï¼Œå¯èƒ½é¢ä¸´ç½šæ¬¾ç”šè‡³ç‰¢ç‹±ä¹‹ç¾ã€‚ä¸€äº›å¼€å‘è€…å°†ä¸å¾—ä¸è˜è¯·æ˜‚è´µçš„å¾‹å¸ˆæˆ–é¡¾é—®æ¥æŒ‡å¯¼ä»–ä»¬å¦‚ä½•éµå®ˆè¿™äº›è¦æ±‚ã€‚ (æˆ‘å¹¶éå¾‹å¸ˆï¼Œä¹Ÿæ— æ„æä¾›æ³•å¾‹å»ºè®®ï¼Œä½†é¿å…ä¼ªè¯ç½ªçš„ä¸€ç§æ–¹æ³•æ˜¯è¡¨æ˜æ‚¨ä¾èµ–äº†ä¸“å®¶å»ºè®®ï¼Œä»¥æ­¤è¯æ˜æ‚¨æ²¡æœ‰æ’’è°çš„æ„å›¾ã€‚) è€Œå¦ä¸€äº›äººåˆ™ä¼šå¹²è„†æ”¾å¼ƒå‘å¸ƒå‰æ²¿çš„ AI äº§å“ã€‚\n\nå¦‚æœè¿™é¡¹æ³•å¾‹å¾—ä»¥é€šè¿‡ï¼Œé‚£ä¹ˆè¢«é™ªå®¡å›¢å®¡åˆ¤çš„ææƒ§å°†å˜å¾—çœŸçœŸåˆ‡åˆ‡ â€”â€” è¿™ç§å®¡åˆ¤ç»“æœå¾€å¾€éš¾ä»¥é¢„æµ‹ï¼Œä¸€æ—¦å®šç½ªï¼Œå°†é¢ä¸´ä¸¥å‰çš„æƒ©ç½šã€‚è¯•æƒ³ï¼Œå¦‚æœæœ‰äººåœ¨ä»Šå¤©å‘å¸ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œå½“æ—¶ä»–ä»¬çœŸè¯šåœ°è®¤ä¸ºå·²ç»é‡‡å–äº†åˆç†çš„å®‰å…¨æªæ–½ï¼Œä½†å‡ å¹´åï¼Œå½“äººä»¬å¯¹ AI æŠ€æœ¯çš„çœ‹æ³•å¯èƒ½å‘ç”Ÿå˜åŒ–æ—¶ï¼ŒæŸä¸ªç§¯æçš„æ£€å¯Ÿå®˜å´è®¾æ³•è¯´æœé™ªå®¡å›¢ï¼Œè®¤ä¸ºä»–ä»¬å½“æ—¶æ‰€åšçš„ä¸€åˆ‡ï¼Œäº‹åçœ‹æ¥å¹¶ä¸â€œåˆç†â€ï¼Œé‚£è¯¥æ€ä¹ˆåŠï¼Ÿ\n\nâ€œåˆç†æ€§â€æœ¬èº«å°±æ˜¯ä¸€ä¸ªæ¨¡ç³Šçš„æ¦‚å¿µï¼Œå…¶æ³•å¾‹è§£é‡Šå¯èƒ½å–å†³äºåˆ¤ä¾‹æ³•ã€é™ªå®¡å›¢æŒ‡ç¤ºä»¥åŠå…·ä½“æ¡ˆæƒ…ç­‰å¤šç§å› ç´ ã€‚è¿™ä½¿å¾—å¼€å‘è€…å¾ˆéš¾ç¡®ä¿ä»–ä»¬ä»Šå¤©æ‰€åšçš„äº‹æƒ…ï¼Œåœ¨æœªæ¥ä¼šè¢«é™ªå®¡å›¢è®¤å®šä¸ºåˆç†ã€‚ (å…³äºè¿™ä¸€ç‚¹ï¼Œè¯·å‚é˜… Context Fund å¯¹ SB 1047 çš„åˆ†æã€‚)\n\nåŠ å·æ”¿åºœä¸­ä¸€ä½å¯¹è¿™é¡¹æ³•å¾‹è¿›è¡Œè¿‡æ·±å…¥ç ”ç©¶çš„é«˜çº§å¾‹å¸ˆå‘Šè¯‰æˆ‘ï¼Œä»–ä»¬ä¹Ÿè§‰å¾—è¿™é¡¹æ³•å¾‹éš¾ä»¥ç†è§£ã€‚æˆ‘é‚€è¯·æ‚¨äº²è‡ªé˜…è¯»å¹¶åˆ¤æ–­ â€”â€” å¦‚æœæ‚¨è®¤ä¸ºè¿™äº›è¦æ±‚æ¸…æ™°æ˜äº†ï¼Œé‚£ä¹ˆæ‚¨æˆ–è®¸æ‹¥æœ‰æˆä¸ºä¸€åæ°å‡ºå¾‹å¸ˆçš„æ½œåŠ›ï¼\n\né™¤äº†æ¨¡ç³Šæ€§ä¹‹å¤–ï¼Œè¯¥æ³•æ¡ˆè¿˜å°†è®¾ç«‹ä¸€ä¸ªåä¸ºå‰æ²¿æ¨¡å‹éƒ¨é—¨ (Frontier Model Divisionï¼ŒFMD) çš„æœºæ„ï¼Œç”±ä¸€ä¸ªäº”äººå§”å‘˜ä¼šç»„æˆï¼Œè¯¥å§”å‘˜ä¼šæœ‰æƒå‘å¼€å‘è€…åˆ¶å®šæ ‡å‡†ã€‚è¿™ä¸ªå°å‹å§”å‘˜ä¼šå°†ææ˜“æˆä¸ºæ¸¸è¯´å’Œç›‘ç®¡ä¿˜è· (regulatory capture) çš„ç›®æ ‡ã€‚ (Bill Gurley æœ‰ä¸€ä¸ªå…³äºç›‘ç®¡ä¿˜è·çš„ç²¾å½©è§†é¢‘ã€‚) è¿™ä¸ªæœªç»é€‰ä¸¾äº§ç”Ÿçš„ FMD å¯ä»¥å‘å¼€å‘è€…å¾æ”¶è´¹ç”¨æ¥å¼¥è¡¥å…¶è¿è¥æˆæœ¬ã€‚å®ƒè¿˜å¯ä»¥éšæ„è°ƒæ•´å¾®è°ƒæ¨¡å‹ä½•æ—¶éœ€è¦æ¥å—å…¶ç›‘ç®¡çš„è®¡ç®—é˜ˆå€¼ã€‚è¿™å¯èƒ½å¯¼è‡´å³ä½¿æ˜¯å°å‹å›¢é˜Ÿï¼Œä¹Ÿéœ€è¦è˜è¯·å®¡è®¡å¸ˆæ¥æ£€æŸ¥æ˜¯å¦ç¬¦åˆé‚£äº›æ¨¡ç³Šçš„å®‰å…¨æ ‡å‡†ã€‚\n\nè¿™äº›æ¡æ¬¾å¹¶ä¸èƒ½çœŸæ­£ç¡®ä¿ AI çš„å®‰å…¨æ€§ã€‚å®ƒä»¬åªä¼šåˆ¶é€ ç›‘ç®¡ä¸ç¡®å®šæ€§ï¼Œå¹¶ä¸ºé‚£äº›å¸Œæœ›æ‰¼æ€å¼€æºçš„æ—¢å¾—åˆ©ç›Šè€…æä¾›æ›´å¤šæœºä¼šï¼Œè®©ä»–ä»¬æ¸¸è¯´ä¿®æ”¹è¦æ±‚ï¼Œä»è€ŒæŠ¬é«˜åˆè§„æˆæœ¬ã€‚è¿™æ— ç–‘ä¼šå°†è®¸å¤šæ²¡æœ‰æ”¶å…¥æ¥æºçš„å›¢é˜Ÿ â€”â€” ç‰¹åˆ«æ˜¯ä¼—å¤šçš„å¼€æºè´¡çŒ®è€… â€”â€” æ’é™¤åœ¨å¤–ï¼Œå› ä¸ºä»–ä»¬å°†æ— æ³•æ”¯ä»˜æ¸¸è¯´è€…ã€å®¡è®¡å¸ˆå’Œå¾‹å¸ˆçš„è´¹ç”¨ï¼Œä»¥ç¡®ä¿ä»–ä»¬èƒ½å¤Ÿéµå®ˆè¿™äº›æ¨¡ç³Šä¸”ä¸åˆç†çš„è¦æ±‚ã€‚\n\nå¼€æºæ˜¯ä¸€è‚¡ä»¤äººèµå¹çš„åŠ›é‡ï¼Œå®ƒå°†çŸ¥è¯†å’Œå·¥å…·å¸¦ç»™æ— æ•°äººï¼Œä¹Ÿæ˜¯ AI åˆ›æ–°çš„å…³é”®æ”¯æŸ±ã€‚æˆ‘å¯¹å…¶é­å—çš„æœ‰ç»„ç»‡æ”»å‡»æ„Ÿåˆ°æ²®ä¸§ã€‚æ¯‹åº¸ç½®ç–‘ï¼ŒåŠ å·ç›®å‰æ­£åœ¨è¿›è¡Œä¸€åœºäº‹å…³å¼€æºæœªæ¥å‘å±•çš„æ¿€çƒˆæ–—äº‰ã€‚æˆ‘è‡´åŠ›äºå°½æˆ‘æ‰€èƒ½åœ°ç»´æŠ¤å¼€æºï¼Œä½†æˆ‘ä¹Ÿä¸ä¼šæƒ³å½“ç„¶åœ°è®¤ä¸ºæ”¯æŒå¼€æºçš„ä¸€æ–¹ä¸€å®šä¼šè·èƒœã€‚æˆ‘å¸Œæœ›æ‚¨èƒ½ä¸æˆ‘ä¸€é“ï¼Œå¤§å£°ç–¾å‘¼åå¯¹ SB 1047 ä»¥åŠå…¶ä»–å¯èƒ½æ‰¼æ€å¼€æºçš„æ³•å¾‹ã€‚"
  },
  {
    "id": "1811065347841348052",
    "url": "https://x.com/AndrewYNg/status/1811065347841348052",
    "text": "Learn to optimize RAG for cost and performance in our new short course, Prompt Compression and Query Optimization, created with @MongoDB and taught by @richmondalake. \n\nThis course teaches you to combine traditional database capabilities with vector search using MongoDB for RAG. You'll learn these techniques:\n- Vector search: For semantic matching of user queries\n- Filtering using metadata: Pre- and post-filtering to narrow search results\n- Projections: Selecting only necessary fields to minimize data returned\n- Boosting: Reranking results to improve relevance\n- Prompt compression: Using a small LLM to compress context, significantly reducing token count and processing costs\n\nThese methods address scaling, performance, and security challenges in large-scale RAG applications. \n\nYou can sign up here: https://t.co/Z7KwOXlx7i",
    "createdAt": "Wed Jul 10 15:50:01 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 156,
    "replyCount": 18,
    "likeCount": 782,
    "quoteCount": 8,
    "viewCount": 71249,
    "bookmarkCount": 394,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨æˆ‘ä»¬çš„æ–°çŸ­è¯¾ç¨‹ã€Šæç¤ºå‹ç¼©å’ŒæŸ¥è¯¢ä¼˜åŒ–ã€‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä¼˜åŒ–æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) çš„æˆæœ¬å’Œæ€§èƒ½ã€‚è¿™é—¨è¯¾ç¨‹ç”± MongoDB åˆä½œå¼€å‘ï¼Œå¹¶ç”± Richmond Alake æ•™æˆã€‚\n\næœ¬è¯¾ç¨‹å°†æ•™æ‚¨å¦‚ä½•åˆ©ç”¨ MongoDB å°†ä¼ ç»Ÿæ•°æ®åº“åŠŸèƒ½ä¸å‘é‡æœç´¢ç»“åˆèµ·æ¥ï¼Œåº”ç”¨äº RAGã€‚æ‚¨å°†å­¦ä¹ ä»¥ä¸‹å®ç”¨æŠ€å·§ï¼š\n- å‘é‡æœç´¢ï¼šå®ç°ç”¨æˆ·æŸ¥è¯¢çš„è¯­ä¹‰åŒ¹é…ã€‚\n- ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤ï¼šé€šè¿‡é¢„è¿‡æ»¤å’Œåè¿‡æ»¤ï¼Œæœ‰æ•ˆç¼©å°æœç´¢ç»“æœèŒƒå›´ã€‚\n- æŠ•å½±ï¼šåªé€‰æ‹©å¿…è¦çš„å­—æ®µï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘è¿”å›çš„æ•°æ®é‡ã€‚\n- æå‡ï¼šé‡æ–°æ’åºæœç´¢ç»“æœï¼Œä»è€Œæé«˜å…¶ç›¸å…³æ€§ã€‚\n- æç¤ºå‹ç¼©ï¼šåˆ©ç”¨å°å‹å¤§è¯­è¨€æ¨¡å‹ (LLM) å‹ç¼©ä¸Šä¸‹æ–‡ï¼Œæ˜¾è‘—å‡å°‘ Token æ•°é‡å’Œå¤„ç†æˆæœ¬ã€‚\n\nè¿™äº›æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè§£å†³å¤§è§„æ¨¡ RAG åº”ç”¨ç¨‹åºåœ¨æ‰©å±•æ€§ã€æ€§èƒ½å’Œå®‰å…¨æ€§æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ã€‚\n\næ‚¨å¯ä»¥åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/Z7KwOXlx7i"
  },
  {
    "id": "1810338684270768464",
    "url": "https://x.com/AndrewYNg/status/1810338684270768464",
    "text": "As we reach the milestone of the 256th issue of The Batch, Iâ€™m reflecting on how AI has changed over the years and how society continues to change with it. As AI becomes more widely available, itâ€™s clear that many people â€” developers and non-developers â€” will benefit from high-quality training to keep up with the changes and gain useful AI skills.\n\nIn my years of working in education, Iâ€™ve felt that the world has enough low-quality courses, newsletters, social media posts, and other forms of content.  Itâ€™s possible to build a business churning out mediocre content in sufficient volume to attract a meaningful amount of attention, but I have no interest in doing that.\n\nAt https://t.co/zpIxRSuky4, our core philosophy is to put learners first. Our team obsesses about how to create quality training or other programs that benefit people who want to learn about AI. We have intense debates about what tools to teach, which examples to include, even which partners to work with, based on what we think is best for learners.\n\nFor example, I recall vividly how, when working on the Machine Learning Specialization, our team spent ages debating whether to use row or column matrices. Both sides showed up with deep analysis of the pros and cons, made Powerpoint presentations to argue their case, and we spent hours debating over what was better for learners in terms of both ease of picking up the concepts as well as subsequently being able to use these skills with third-party machine learning libraries.\n\nWe donâ€™t release a course unless we think itâ€™s a good use of a learnerâ€™s time and weâ€™d be proud to recommend it to our own friends and family members. Quality, of course, can mean a lot of things. I expect what we do to be technically accurate, useful, up to date, clear, and time-efficient for learners. And, if possible, fun!\n\nWe donâ€™t always get it right, but we scrutinize learner feedback (one of my most important weekly routines is to study a dashboard that summarizes learner ratings of our courses) and work to make sure our courses serve learners well. And yes, we have a large-language model powered application that reads learner reviews to flag important issues quickly.\n\nEarlier this year, we realized that some of the paid content we had launched was below our quality standard, and that I wouldnâ€™t in good conscience recommend it to my friends or family members. Despite this content being profitable, we did what we felt was the right thing for learners. So we decided to retire that content and forgo the revenues, but we feel much better now for having done the right thing for learners.\n\nWhen we teach courses with partners, we tell them our priorities are â€œlearners first, partners second, ourselves last.â€ Iâ€™m grateful to the many wonderful companies and individuals that work with us to teach cutting-edge techniques, and given an opportunity we try to support our partnersâ€™ goals as well. But we never prioritize the interest of our educational partners over that of learners. Fortunately, our partners are onboard with this as well. We have a common goal to serve learners. Without their help, it would be difficult to teach many of the topics we do with high-quality content.\n\nQuite a few companies have tried to offer to pay us to teach a course with them, but weâ€™ve always said no. We work only with the companies that we think help us serve learners best, and are not interested in being paid to teach lower quality courses.\n\nOne reason I obsess about building quality training materials is that I think learning must be a habit. Learning a little every week is important to get through the volume of learning we all need, and additionally to keep up with changing technology. High-quality training thatâ€™s also fun supports a healthy learning habit!\n\nFun fact: In addition to taking online courses, I also read a lot. Recently I noticed that my digital reading app says Iâ€™ve been on a reading streak for 170 weeks. Iâ€™ve used the app for many years, but apparently I had broken and restarted my streak 170 weeks ago. What happened then? That was the week that my son was born, Coursera became a public company, and my grandfather died. While my life has had disruptions since then, I was happy to find that it takes a disruption of this magnitude to make me pause my learning habit for a week.\n\n[Original text: https://t.co/OXdmYHgrR1 ]",
    "createdAt": "Mon Jul 08 15:42:31 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 64,
    "replyCount": 59,
    "likeCount": 427,
    "quoteCount": 11,
    "viewCount": 64056,
    "bookmarkCount": 90,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å½“ The Batch åˆŠå‘ç¬¬ 256 æœŸä¹‹é™…ï¼Œæˆ‘ä¸ç¦å›é¡¾ AI (äººå·¥æ™ºèƒ½) è¿™äº›å¹´çš„å‘å±•å†ç¨‹ï¼Œä»¥åŠç¤¾ä¼šå¦‚ä½•éšä¹‹ä¸æ–­æ¼”å˜ã€‚éšç€ AI çš„æ—¥ç›Šæ™®åŠï¼Œä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„äº‹å®æ˜¯ï¼Œæ— è®ºæ˜¯å¼€å‘è€…è¿˜æ˜¯éå¼€å‘è€…ï¼Œè®¸å¤šäººéƒ½å°†ä»é«˜è´¨é‡çš„åŸ¹è®­ä¸­å—ç›Šï¼Œä»è€Œè·Ÿä¸ŠæŠ€æœ¯å˜é©çš„æ­¥ä¼ï¼ŒæŒæ¡å®ç”¨çš„ AI æŠ€èƒ½ã€‚\n\nåœ¨æˆ‘å¤šå¹´ä»äº‹æ•™è‚²å·¥ä½œçš„ç”Ÿæ¶¯ä¸­ï¼Œæˆ‘æ·±æ„Ÿå¸‚é¢ä¸Šå……æ–¥ç€å¤§é‡ä½è´¨é‡çš„è¯¾ç¨‹ã€æ–°é—»é‚®ä»¶ã€ç¤¾äº¤åª’ä½“å¸–å­ä»¥åŠå…¶ä»–å½¢å¼çš„å†…å®¹ã€‚è™½ç„¶ä»¥é‡å–èƒœã€å¤§é‡ç‚®åˆ¶å¹³åº¸å†…å®¹æˆ–è®¸èƒ½å¸å¼•è¶³å¤Ÿçš„å…³æ³¨å¹¶å»ºç«‹èµ·ä¸€ç•ªäº‹ä¸šï¼Œä½†æˆ‘å¯¹æ­¤æ¯«æ— å…´è¶£ã€‚\n\nåœ¨ https://t.co/zpIxRSuky4ï¼Œæˆ‘ä»¬çš„æ ¸å¿ƒç†å¿µæ˜¯å§‹ç»ˆæŠŠå­¦ä¹ è€…æ”¾åœ¨é¦–ä½ã€‚æˆ‘ä»¬çš„å›¢é˜Ÿè‡´åŠ›äºæ·±å…¥æ€è€ƒå¦‚ä½•åˆ›å»ºé«˜è´¨é‡çš„åŸ¹è®­æˆ–å…¶ä»–é¡¹ç›®ï¼Œä»è€ŒçœŸæ­£é€ ç¦é‚£äº›æ¸´æœ›å­¦ä¹  AI çš„äººã€‚æˆ‘ä»¬å›´ç»•æ•™æˆå“ªäº›å·¥å…·ã€é€‰æ‹©å“ªäº›æ¡ˆä¾‹ï¼Œç”šè‡³ä¸å“ªäº›åˆä½œä¼™ä¼´åˆä½œç­‰é—®é¢˜å±•å¼€è¿‡æ¿€çƒˆçš„è®¨è®ºï¼Œæ‰€æœ‰è¿™äº›è€ƒé‡éƒ½åŸºäºæˆ‘ä»¬è®¤ä¸ºä»€ä¹ˆå¯¹å­¦ä¹ è€…æœ€æœ‰åˆ©ã€‚\n\nä¾‹å¦‚ï¼Œæˆ‘æ¸…æ¥šåœ°è®°å¾—ï¼Œåœ¨å¼€å‘æœºå™¨å­¦ä¹ ä¸“ä¸šè¯¾ç¨‹æ—¶ï¼Œæˆ‘ä»¬çš„å›¢é˜Ÿæ›¾èŠ±äº†å¤§é‡æ—¶é—´äº‰è®ºç©¶ç«Ÿæ˜¯åº”è¯¥ä½¿ç”¨è¡ŒçŸ©é˜µè¿˜æ˜¯åˆ—çŸ©é˜µã€‚åŒæ–¹éƒ½å¸¦ç€å¯¹å„è‡ªä¼˜ç¼ºç‚¹çš„æ·±å…¥åˆ†æï¼Œåˆ¶ä½œäº† Powerpoint æ¼”ç¤ºæ–‡ç¨¿æ¥é˜è¿°è§‚ç‚¹ã€‚æˆ‘ä»¬èŠ±è´¹äº†æ•°å°æ—¶è®¨è®ºï¼Œå“ªç§æ–¹å¼å¯¹å­¦ä¹ è€…è€Œè¨€æ›´å¥½ï¼Œè¿™æ—¢åŒ…æ‹¬ä»–ä»¬æŒæ¡æ¦‚å¿µçš„å®¹æ˜“ç¨‹åº¦ï¼Œä¹ŸåŒ…æ‹¬ä»–ä»¬éšåå°†è¿™äº›æŠ€èƒ½åº”ç”¨äºç¬¬ä¸‰æ–¹æœºå™¨å­¦ä¹ åº“çš„èƒ½åŠ›ã€‚\n\né™¤éæˆ‘ä»¬è®¤ä¸ºä¸€é—¨è¯¾ç¨‹çœŸæ­£å€¼å¾—å­¦ä¹ è€…æŠ•å…¥æ—¶é—´ï¼Œå¹¶ä¸”æˆ‘ä»¬éå¸¸ä¹æ„å°†å…¶æ¨èç»™æˆ‘ä»¬çš„æœ‹å‹å’Œå®¶äººï¼Œå¦åˆ™æˆ‘ä»¬ç»ä¸ä¼šå‘å¸ƒã€‚å½“ç„¶ï¼Œâ€œè´¨é‡â€çš„å†…æ¶µååˆ†ä¸°å¯Œã€‚æˆ‘æœŸæœ›æˆ‘ä»¬æ‰€åšçš„æ¯ä¸€ä»¶äº‹éƒ½èƒ½åšåˆ°æŠ€æœ¯å‡†ç¡®ã€å®ç”¨ã€åŠæ—¶æ›´æ–°ã€æ¸…æ™°æ˜“æ‡‚ï¼Œå¹¶ä¸”å¯¹å­¦ä¹ è€…æ¥è¯´æ˜¯é«˜æ•ˆçœæ—¶çš„ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œè¿˜è¦å……æ»¡ä¹è¶£ï¼\n\næˆ‘ä»¬å¹¶éæ€»èƒ½åšåˆ°å®Œç¾ï¼Œä½†æˆ‘ä»¬ä¼šè®¤çœŸå®¡è§†å­¦ä¹ è€…çš„åé¦ˆ (æˆ‘æœ€é‡è¦çš„æ¯å‘¨ä¾‹è¡Œå·¥ä½œä¹‹ä¸€ï¼Œå°±æ˜¯ç ”ç©¶ä¸€ä¸ªæ±‡æ€»å­¦å‘˜å¯¹æˆ‘ä»¬è¯¾ç¨‹è¯„ä»·çš„ä»ªè¡¨ç›˜)ï¼Œå¹¶åŠªåŠ›ç¡®ä¿æˆ‘ä»¬çš„è¯¾ç¨‹èƒ½æ›´å¥½åœ°æœåŠ¡äºå­¦ä¹ è€…ã€‚æ˜¯çš„ï¼Œæˆ‘ä»¬è¿˜æ‹¥æœ‰ä¸€æ¬¾ç”±å¤§è¯­è¨€æ¨¡å‹ (Large Language Model) é©±åŠ¨çš„åº”ç”¨ç¨‹åºï¼Œå®ƒèƒ½å¤Ÿé˜…è¯»å­¦ä¹ è€…è¯„è®ºï¼Œå¹¶è¿…é€Ÿæ ‡è®°å‡ºé‡è¦é—®é¢˜ã€‚\n\nä»Šå¹´æ—©äº›æ—¶å€™ï¼Œæˆ‘ä»¬æ„è¯†åˆ°ä¹‹å‰æ¨å‡ºçš„ä¸€äº›ä»˜è´¹å†…å®¹æœªèƒ½è¾¾åˆ°æˆ‘ä»¬çš„è´¨é‡æ ‡å‡†ï¼Œæˆ‘æ— æ³•é—®å¿ƒæœ‰æ„§åœ°å°†å®ƒä»¬æ¨èç»™æˆ‘çš„æœ‹å‹æˆ–å®¶äººã€‚å°½ç®¡è¿™äº›å†…å®¹èƒ½å¤Ÿç›ˆåˆ©ï¼Œä½†æˆ‘ä»¬è¿˜æ˜¯åšäº†æˆ‘ä»¬è®¤ä¸ºå¯¹å­¦ä¹ è€…æ­£ç¡®çš„äº‹æƒ…ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å†³å®šåœç”¨è¿™äº›å†…å®¹å¹¶æ”¾å¼ƒç”±æ­¤å¸¦æ¥çš„æ”¶ç›Šï¼Œä½†ç°åœ¨æˆ‘ä»¬ä¸ºå¯¹å­¦ä¹ è€…åšäº†æ­£ç¡®çš„äº‹æƒ…è€Œæ„Ÿåˆ°å¿ƒå®‰ç†å¾—ã€‚\n\nå½“æˆ‘ä»¬ä¸åˆä½œä¼™ä¼´å…±åŒæˆè¯¾æ—¶ï¼Œæˆ‘ä»¬ä¼šæ˜ç¡®å‘Šè¯‰ä»–ä»¬ï¼Œæˆ‘ä»¬çš„ä¼˜å…ˆé¡ºåºæ˜¯â€œå­¦ä¹ è€…ç¬¬ä¸€ï¼Œåˆä½œä¼™ä¼´ç¬¬äºŒï¼Œæˆ‘ä»¬è‡ªå·±æœ€åâ€ã€‚æˆ‘éå¸¸æ„Ÿè°¢ä¼—å¤šä¼˜ç§€çš„æœºæ„å’Œä¸ªäººä¸æˆ‘ä»¬æºæ‰‹æ•™æˆå‰æ²¿æŠ€æœ¯ã€‚åœ¨æœ‰æœºä¼šçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿä¼šåŠªåŠ›æ”¯æŒåˆä½œä¼™ä¼´çš„ç›®æ ‡ã€‚ä½†æˆ‘ä»¬ç»ä¸ä¼šå°†æ•™è‚²åˆä½œä¼™ä¼´çš„åˆ©ç›Šç½®äºå­¦ä¹ è€…çš„åˆ©ç›Šä¹‹ä¸Šã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬çš„åˆä½œä¼™ä¼´ä¹Ÿå¯¹æ­¤æ·±è¡¨è®¤åŒã€‚æˆ‘ä»¬å…±åŒçš„ç›®æ ‡æ˜¯æœåŠ¡å¥½å­¦ä¹ è€…ã€‚æ²¡æœ‰ä»–ä»¬çš„å¸®åŠ©ï¼Œæˆ‘ä»¬å¾ˆéš¾ä»¥é«˜è´¨é‡çš„å†…å®¹æ•™æˆæˆ‘ä»¬æ‰€æ¶‰åŠçš„è¯¸å¤šä¸»é¢˜ã€‚\n\nä¸å°‘å…¬å¸æ›¾ä¸»åŠ¨æå‡ºä»˜è´¹ï¼Œå¸Œæœ›ä¸æˆ‘ä»¬åˆä½œå¼€è®¾è¯¾ç¨‹ï¼Œä½†æˆ‘ä»¬å§‹ç»ˆæ‹’ç»ã€‚æˆ‘ä»¬åªä¸é‚£äº›æˆ‘ä»¬è®¤ä¸ºèƒ½å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°æœåŠ¡å­¦ä¹ è€…çš„å…¬å¸åˆä½œï¼Œå¹¶ä¸”ä¸æ„¿ä¸ºäº†æŠ¥é…¬å»æ•™æˆä½è´¨é‡çš„è¯¾ç¨‹ã€‚\n\næˆ‘ä¹‹æ‰€ä»¥æ‰§ç€äºæ‰“é€ é«˜è´¨é‡çš„åŸ¹è®­ææ–™ï¼Œå…¶ä¸­ä¸€ä¸ªåŸå› æ˜¯ï¼Œæˆ‘è®¤ä¸ºå­¦ä¹ å¿…é¡»æˆä¸ºä¸€ç§ä¹ æƒ¯ã€‚æ¯å‘¨æŒç»­å­¦ä¹ ä¸€ç‚¹ç‚¹ï¼Œå¯¹äºæ¶ˆåŒ–æˆ‘ä»¬æ‰€éœ€çš„å¤§é‡çŸ¥è¯†è‡³å…³é‡è¦ï¼ŒåŒæ—¶ä¹Ÿèƒ½å¸®åŠ©æˆ‘ä»¬è·Ÿä¸Šä¸æ–­å˜åŒ–çš„æŠ€æœ¯ã€‚é«˜è´¨é‡ä¸”æœ‰è¶£çš„åŸ¹è®­ï¼Œæ­£æ˜¯åŸ¹å…»å¥åº·å­¦ä¹ ä¹ æƒ¯çš„æœ‰åŠ›ä¿éšœï¼\n\nè¶£é—»ï¼šé™¤äº†å‚åŠ åœ¨çº¿è¯¾ç¨‹ï¼Œæˆ‘ä¹Ÿé˜…è¯»äº†å¤§é‡ä¹¦ç±ã€‚æœ€è¿‘æˆ‘æ³¨æ„åˆ°æˆ‘çš„æ•°å­—é˜…è¯»åº”ç”¨ç¨‹åºæ˜¾ç¤ºï¼Œæˆ‘å·²ç»è¿ç»­é˜…è¯»äº† 170 å‘¨ã€‚æˆ‘ä½¿ç”¨è¿™æ¬¾åº”ç”¨å·²ç»å¾ˆå¤šå¹´äº†ï¼Œä½†æ˜¾ç„¶æˆ‘çš„é˜…è¯»è¿è´¯æ€§æ˜¯åœ¨ 170 å‘¨å‰ä¸­æ–­å¹¶é‡æ–°å¼€å§‹çš„ã€‚é‚£æ—¶å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿé‚£æ˜¯æˆ‘çš„å„¿å­å‡ºç”Ÿã€Coursera æˆä¸ºä¸Šå¸‚å…¬å¸ã€ä»¥åŠæˆ‘ç¥–çˆ¶å»ä¸–çš„é‚£ä¸€å‘¨ã€‚å°½ç®¡æ­¤åæˆ‘çš„ç”Ÿæ´»ä¹Ÿä¸ä¹æ‰“æ‰°ï¼Œä½†æˆ‘å¾ˆé«˜å…´åœ°å‘ç°ï¼Œåªæœ‰å¦‚æ­¤é‡å¤§çš„å˜æ•…ï¼Œæ‰èƒ½è®©æˆ‘æš‚åœä¸€å‘¨çš„å­¦ä¹ ä¹ æƒ¯ã€‚\n\n[åŸæ–‡ï¼šhttps://t.co/OXdmYHgrR1 ]"
  },
  {
    "id": "1809658174724796583",
    "url": "https://x.com/AndrewYNg/status/1809658174724796583",
    "text": "Shoutout to the team that built https://t.co/sJnTRDfHGF . Really neat site that benchmarks the speed of different LLM API providers to help developers pick which models to use. This nicely complements the LMSYS Chatbot Arena, Hugging Face open LLM leaderboards and Stanford's HELM that focus more on the quality of the outputs. \n\nI hope benchmarks like this encourage more providers to work on fast token generation, which is critical for agentic workflows!",
    "createdAt": "Sat Jul 06 18:38:25 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 482,
    "replyCount": 80,
    "likeCount": 2063,
    "quoteCount": 47,
    "viewCount": 546962,
    "bookmarkCount": 1389,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢å¼€å‘äº† https://t.co/sJnTRDfHGF ç½‘ç«™çš„å›¢é˜Ÿã€‚è¿™ä¸ªç½‘ç«™éå¸¸å‡ºè‰²ï¼Œå®ƒå¯¹ä¸åŒå¤§è¯­è¨€æ¨¡å‹ (LLM) API æä¾›å•†çš„é€Ÿåº¦è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚è¿™ä¸ LMSYS Chatbot Arenaã€Hugging Face å¼€æ”¾ LLM æ’è¡Œæ¦œä»¥åŠ Stanford çš„ HELM å½¢æˆäº†è‰¯å¥½çš„äº’è¡¥ï¼Œå› ä¸ºåè€…æ›´å¤šå…³æ³¨æ¨¡å‹è¾“å‡ºçš„è´¨é‡ã€‚\n\næˆ‘å¸Œæœ›è¿™æ ·çš„åŸºå‡†æµ‹è¯•èƒ½é¼“åŠ±æ›´å¤šæä¾›å•†ä¸“æ³¨äºæå‡ Token çš„ç”Ÿæˆé€Ÿåº¦ï¼Œè¿™å¯¹äº AI æ™ºèƒ½ä½“ (AI Agent) çš„å·¥ä½œæµè‡³å…³é‡è¦ï¼"
  },
  {
    "id": "1806383866472730749",
    "url": "https://x.com/AndrewYNg/status/1806383866472730749",
    "text": "An often overlooked part of the AI supply chain is electricity to power our data centers. \n\n@TheAESCorp is the leading provider of renewable energy to data centers, and is a also global leader in building technology to efficiently scale renewal energy projects. At AI Fund, we're thrilled to work with the visionary @AndresGluski and the AES team to co-build new AI companies that will help with the energy transition!",
    "createdAt": "Thu Jun 27 17:47:29 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 24,
    "replyCount": 15,
    "likeCount": 158,
    "quoteCount": 3,
    "viewCount": 48625,
    "bookmarkCount": 22,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "åœ¨äººå·¥æ™ºèƒ½çš„ä¾›åº”é“¾ä¸­ï¼Œæœ‰ä¸€ä¸ªå¸¸å¸¸è¢«äººä»¬å¿½ç•¥çš„å…³é”®ç¯èŠ‚ï¼Œé‚£å°±æ˜¯ä¸ºæ•°æ®ä¸­å¿ƒæä¾›åŠ¨åŠ›çš„ç”µåŠ›ã€‚\n\nAESå…¬å¸ (@TheAESCorp) ä¸ä»…æ˜¯æ•°æ®ä¸­å¿ƒå¯å†ç”Ÿèƒ½æºçš„ä¸»è¦ä¾›åº”å•†ï¼ŒåŒæ—¶ä¹Ÿæ˜¯åœ¨é«˜æ•ˆæ‰©å¤§å¯å†ç”Ÿèƒ½æºé¡¹ç›®æŠ€æœ¯æ–¹é¢çš„å…¨çƒé¢†å†›è€…ã€‚åœ¨ AI Fundï¼Œæˆ‘ä»¬éå¸¸é«˜å…´èƒ½ä¸å¯Œæœ‰è¿œè§çš„ Andres Gluski å…ˆç”Ÿå’Œ AES å›¢é˜Ÿæºæ‰‹åˆä½œï¼Œå…±åŒå­µåŒ–æ–°çš„ AI å…¬å¸ï¼ŒåŠ©åŠ›å…¨çƒèƒ½æºè½¬å‹ï¼"
  },
  {
    "id": "1806008133862805840",
    "url": "https://x.com/AndrewYNg/status/1806008133862805840",
    "text": "As machine learning models grow in size, so too does their carbon footprint. As AI scales, it's important that we quantify and mitigate these emissions. \nIn our new short course Carbon Aware Computing for GenAI Developers you'll learn from @googlecloud  Developer Advocate Nikita Namjoshi how to:\n- Query the ElectricityMaps API for real-time data on regional electricity grid carbon intensity\n- Route your model training jobs to data centers in regions primarily powered by low-carbon sources like wind, solar, hydro and nuclear\n- Measure the carbon footprint of your ML training, inference, storage and API usage with the Google Cloud's Carbon Footprint tool\n- Optimize training job scheduling to run when clean energy is most abundant in a given region.\n\nYou can sign up here: https://t.co/CW3dBUJYfe",
    "createdAt": "Wed Jun 26 16:54:27 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 158,
    "replyCount": 30,
    "likeCount": 787,
    "quoteCount": 10,
    "viewCount": 102839,
    "bookmarkCount": 205,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "éšç€æœºå™¨å­¦ä¹ æ¨¡å‹è§„æ¨¡ä¸æ–­æ‰©å¤§ï¼Œå…¶ç¢³è¶³è¿¹ä¹Ÿéšä¹‹å¢å¤§ã€‚åœ¨ AI (äººå·¥æ™ºèƒ½) è§„æ¨¡åŒ–å‘å±•çš„åŒæ—¶ï¼Œé‡åŒ–å¹¶å‡å°‘è¿™äº›æ’æ”¾è‡³å…³é‡è¦ã€‚\nåœ¨æˆ‘ä»¬çš„æ–°çŸ­è¯¾ç¨‹â€œé¢å‘ç”Ÿæˆå¼ AI (Generative AI) å¼€å‘è€…çš„ç¢³æ„ŸçŸ¥è®¡ç®—â€ä¸­ï¼Œä½ å°†è·Ÿéš @googlecloud å¼€å‘è€…å€¡å¯¼è€… Nikita Namjoshi å­¦ä¹ å¦‚ä½•ï¼š\n- æŸ¥è¯¢ ElectricityMaps APIï¼Œè·å–åŒºåŸŸç”µç½‘ç¢³å¼ºåº¦çš„å®æ—¶æ•°æ®\n- å°†ä½ çš„æ¨¡å‹è®­ç»ƒä»»åŠ¡éƒ¨ç½²åˆ°ä¸»è¦ä¾é é£èƒ½ã€å¤ªé˜³èƒ½ã€æ°´åŠ›å‘ç”µå’Œæ ¸èƒ½ç­‰ä½ç¢³èƒ½æºä¾›ç”µçš„æ•°æ®ä¸­å¿ƒæ‰€åœ¨çš„åŒºåŸŸ\n- ä½¿ç”¨ Google Cloud çš„ç¢³è¶³è¿¹å·¥å…·ï¼Œæµ‹é‡ä½ çš„æ¨¡å‹è®­ç»ƒã€æ¨ç†ã€å­˜å‚¨å’Œ API ä½¿ç”¨æ‰€äº§ç”Ÿçš„ç¢³è¶³è¿¹\n- ä¼˜åŒ–è®­ç»ƒä»»åŠ¡çš„è°ƒåº¦ï¼Œä»¥ä¾¿åœ¨ç‰¹å®šåŒºåŸŸæ¸…æ´èƒ½æºæœ€å……è¶³æ—¶è¿è¡Œã€‚\n\nä½ å¯ä»¥åœ¨è¿™é‡Œæ³¨å†Œï¼šhttps://t.co/CW3dBUJYfe"
  },
  {
    "id": "1803835964604977663",
    "url": "https://x.com/AndrewYNg/status/1803835964604977663",
    "text": "On Fatherâ€™s Day last weekend, I sat with my daughter to help her practice solving arithmetic problems. To give her practice problems, I used OpenDevin, an open-source agentic coding framework, to write a Python script that generated questions that she enjoyed answering at her own pace. OpenDevin wrote the code much faster than I could have and genuinely improved my and my daughterâ€™s day.\n\nSix months ago, coding agents were a novelty. They still frequently fail to deliver, but I find that theyâ€™re now working well enough that they might be genuinely useful to more and more people!\n\nGiven a coding problem thatâ€™s specified in a prompt, the workflow for a coding agent typically goes something like this: Use a large language model (LLM) to analyze the problem and potentially break it into steps to write code for, generate the code, test it, and iteratively use any errors discovered to ask the coding agent to refine its answer. But within this broad framework, a huge design space and numerous innovations are available to experiment with. Iâ€™d like to highlight a few papers that I find notable:\n- â€œAgentCoder: Multiagent-Code Generation with Iterative Testing and Optimisation,â€ Huang et al. (2024).\n- â€œLDB: A Large Language Model Debugger via Verifying Runtime Execution Step by Step,â€ Zhong et al., (2024).\n- â€œSWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering,â€ Yang et al. (2024).\n\nHow can we test the code without requiring the user to write test cases? In a multi-agent system, each â€œagentâ€ is an LLM prompted to play a particular role. An interesting result from AgentCoder shows that having separate agents for writing code and generating tests results in better performance than letting a single agent do both tasks. This is presumably because, if the agent writing the code is also responsible for writing the tests, the tests might be influenced by the code and fail to consider corner cases that the code does not cover.\n\nWhen people think of testing code, many initially think of output testing, in which we see if the code generates the correct outputs to a specific set of test inputs. If the code fails a test, an LLM can be prompted to reflect on why the code failed and then to try to fix it. In addition to testing the output, the LDB method is helpful. LDB steps through the code and presents to the LLM values of the variables during intermediate steps of execution, to see if the LLM can spot exactly where the error is. This mimics how a human developer might step through the code to see where one of the computational steps went wrong, and so pinpoint and fix the problem.\n\nA lot of agentic workflows mimic human workflows. Similar to other work in machine learning, if humans can do a task, then trying to mimic humans makes development much easier compared to inventing a new process. However, the authors of SWE-agent noticed that many tools that humans use for coding are very inefficient for agents. For example, giving an agent access to a bash shell and having it find a piece of code by executing numerous cd, ls, and cat commands is inefficient, even though humans can do this rapidly. Similarly, visual coding editors like VSCode, emacs, and vim are easy for humans to use, but hard for LLMs (or LMMs) to navigate. Because agents interact with computers differently than humans do, the authors found that building special-purpose tools (functions) to let an agent search, view, and edit codebases resulted in better performance.\n\nOne reason research into coding agents is making rapid progress is that their performance can be evaluated automatically and reliably. With benchmarks like HumanEval, MBPP, and SWE-bench, researchers can try out an idea and automatically test how often it generates correct code. In contrast, even though thereâ€™s considerable activity on AI research agents that search the web and synthesize an article (Iâ€™ve enjoyed using the open-source STORM system by Stanford's Yijia Shao et al.), they are hard to evaluate and this makes progress harder.\n\nGithub Copilot was released in 2021, and many developers have been getting coding help by prompting LLMs. The rapid evolution from that to more sophisticated coding agents is expanding how computers can help us with coding tasks, and the pace of progress is rapid. With these tools, I expect programming to become even more fun and more productive.\n\n[Original text (with links): https://t.co/QP1JRomjrZ ]",
    "createdAt": "Thu Jun 20 17:03:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 314,
    "replyCount": 56,
    "likeCount": 1604,
    "quoteCount": 18,
    "viewCount": 217527,
    "bookmarkCount": 1341,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¸Šå‘¨æœ«çš„çˆ¶äº²èŠ‚ï¼Œæˆ‘é™ªå¥³å„¿ç»ƒä¹ ç®—æœ¯é¢˜ã€‚ä¸ºäº†ç»™å¥¹å‡ºé¢˜ï¼Œæˆ‘ç”¨ OpenDevin è¿™ä¸ªå¼€æºçš„ AI æ™ºèƒ½ä½“ (AI Agent) ç¼–ç æ¡†æ¶ï¼Œç¼–å†™äº†ä¸€ä¸ª Python è„šæœ¬ï¼Œç”Ÿæˆå¥¹å–œæ¬¢æŒ‰ç…§è‡ªå·±çš„èŠ‚å¥å›ç­”çš„é—®é¢˜ã€‚OpenDevin ç¼–å†™ä»£ç çš„é€Ÿåº¦è¿œè¶…æˆ‘çš„é¢„æœŸï¼Œç¡®å®è®©æˆ‘å’Œå¥³å„¿çš„ä¸€å¤©æ›´åŠ æ„‰å¿«ã€‚\n\nä»…ä»…å…­ä¸ªæœˆå‰ï¼Œç¼–ç  AI æ™ºèƒ½ä½“ (coding agents) è¿˜æ˜¯ä¸ªæ–°é²œäº‹ç‰©ã€‚è™½ç„¶å®ƒä»¬ç°åœ¨ä»æ—¶å¸¸æ— æ³•å®Œå…¨è¾¾åˆ°é¢„æœŸï¼Œä½†æˆ‘å‘ç°å®ƒä»¬å·²ç»å˜å¾—è¶³å¤Ÿå¥½ç”¨ï¼Œæœ‰æœ›å¯¹è¶Šæ¥è¶Šå¤šçš„äººçœŸæ­£æœ‰æ‰€åŠ©ç›Šï¼\n\nå¯¹äºä¸€ä¸ªåœ¨æç¤ºè¯ (prompt) ä¸­æŒ‡å®šçš„ç¼–ç é—®é¢˜ï¼Œç¼–ç  AI æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹é€šå¸¸æ˜¯è¿™æ ·çš„ï¼šå®ƒä¼šåˆ©ç”¨ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLM) æ¥åˆ†æé—®é¢˜ï¼Œå¹¶å¯èƒ½å°†å…¶åˆ†è§£æˆè‹¥å¹²ä¸ªç¼–å†™ä»£ç çš„æ­¥éª¤ï¼Œç„¶åç”Ÿæˆä»£ç ï¼Œè¿›è¡Œæµ‹è¯•ï¼Œå¹¶æ ¹æ®å‘ç°çš„é”™è¯¯è¿­ä»£åœ°è¦æ±‚ç¼–ç  AI æ™ºèƒ½ä½“ä¼˜åŒ–å…¶è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œåœ¨è¿™ä¸ªå®½æ³›çš„æ¡†æ¶å†…ï¼Œå­˜åœ¨å·¨å¤§çš„è®¾è®¡ç©ºé—´ï¼Œæœ‰æ— æ•°åˆ›æ–°å¯ä¾›æˆ‘ä»¬æ¢ç´¢å’Œå®éªŒã€‚æˆ‘æƒ³é‡ç‚¹ä»‹ç»å‡ ç¯‡æˆ‘å‘ç°å€¼å¾—å…³æ³¨çš„è®ºæ–‡ï¼š\n- â€œAgentCoder: Multiagent-Code Generation with Iterative Testing and Optimisation,â€ Huang et al. (2024).\n- â€œLDB: A Large Language Model Debugger via Verifying Runtime Execution Step by Step,â€ Zhong et al., (2024).\n- â€œSWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering,â€ Yang et al. (2024).\n\næˆ‘ä»¬å¦‚ä½•åœ¨ä¸è¦æ±‚ç”¨æˆ·ç¼–å†™æµ‹è¯•ç”¨ä¾‹çš„æƒ…å†µä¸‹æµ‹è¯•ä»£ç å‘¢ï¼Ÿåœ¨ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ (multi-agent) ç³»ç»Ÿä¸­ï¼Œæ¯ä¸ªâ€œæ™ºèƒ½ä½“â€éƒ½æ˜¯ä¸€ä¸ªè¢«æŒ‡ç¤ºæ‰®æ¼”ç‰¹å®šè§’è‰²çš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ã€‚AgentCoder çš„ä¸€é¡¹æœ‰è¶£ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œå¦‚æœè®©ä¸åŒçš„æ™ºèƒ½ä½“åˆ†åˆ«è´Ÿè´£ç¼–å†™ä»£ç å’Œç”Ÿæˆæµ‹è¯•ï¼Œå…¶æ€§èƒ½è¦ä¼˜äºè®©å•ä¸ªæ™ºèƒ½ä½“å®Œæˆè¿™ä¸¤é¡¹ä»»åŠ¡ã€‚è¿™å¤§æ¦‚æ˜¯å› ä¸ºï¼Œå¦‚æœè´Ÿè´£ç¼–å†™ä»£ç çš„æ™ºèƒ½ä½“åŒæ—¶ä¹Ÿè¦è´Ÿè´£ç¼–å†™æµ‹è¯•ï¼Œé‚£ä¹ˆæµ‹è¯•å¯èƒ½ä¼šå—åˆ°ä»£ç æœ¬èº«çš„å½±å“ï¼Œä»è€Œå¿½ç•¥ä»£ç å¯èƒ½å­˜åœ¨çš„è¾¹ç¼˜æƒ…å†µã€‚\n\nå½“äººä»¬æƒ³åˆ°æµ‹è¯•ä»£ç æ—¶ï¼Œè®¸å¤šäººé¦–å…ˆæƒ³åˆ°çš„æ˜¯è¾“å‡ºæµ‹è¯•ï¼Œå³æ£€æŸ¥ä»£ç æ˜¯å¦ä¸ºä¸€ç»„ç‰¹å®šçš„æµ‹è¯•è¾“å…¥ç”Ÿæˆäº†æ­£ç¡®çš„è¾“å‡ºã€‚å¦‚æœä»£ç æœªé€šè¿‡æµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥æç¤ºå¤§è¯­è¨€æ¨¡å‹ (LLM) åˆ†æä»£ç å¤±è´¥çš„åŸå› ï¼Œç„¶åå°è¯•ä¿®å¤å®ƒã€‚é™¤äº†è¾“å‡ºæµ‹è¯•ï¼ŒLDB æ–¹æ³•ä¹Ÿå¾ˆæœ‰ç”¨ã€‚LDB ä¼šé€æ­¥æ‰§è¡Œä»£ç ï¼Œå¹¶å‘å¤§è¯­è¨€æ¨¡å‹ (LLM) å±•ç¤ºä»£ç æ‰§è¡Œä¸­é—´æ­¥éª¤ä¸­å˜é‡çš„å€¼ï¼Œä»¥å¸®åŠ© LLM å‡†ç¡®æ‰¾å‡ºé”™è¯¯æ‰€åœ¨ã€‚è¿™æ¨¡ä»¿äº†äººç±»å¼€å‘äººå‘˜é€æ­¥è°ƒè¯•ä»£ç ï¼ŒæŸ¥æ‰¾è®¡ç®—æ­¥éª¤ä¸­å“ªä¸ªç¯èŠ‚å‡ºäº†é—®é¢˜ï¼Œä»è€Œç²¾ç¡®å®šä½å¹¶ä¿®å¤é—®é¢˜çš„è¿‡ç¨‹ã€‚\n\nè®¸å¤š AI æ™ºèƒ½ä½“ (agentic) å·¥ä½œæµéƒ½æ¨¡ä»¿äº†äººç±»çš„å·¥ä½œæ–¹å¼ã€‚ä¸æœºå™¨å­¦ä¹ é¢†åŸŸçš„å…¶ä»–ç ”ç©¶ç±»ä¼¼ï¼Œå¦‚æœä¸€é¡¹ä»»åŠ¡äººç±»å¯ä»¥å®Œæˆï¼Œé‚£ä¹ˆå°è¯•æ¨¡ä»¿äººç±»çš„å·¥ä½œæ–¹å¼å¾€å¾€æ¯”å‘æ˜å…¨æ–°çš„æµç¨‹èƒ½è®©å¼€å‘å·¥ä½œå®¹æ˜“å¾—å¤šã€‚ç„¶è€Œï¼ŒSWE-agent çš„ä½œè€…æ³¨æ„åˆ°ï¼Œè®¸å¤šäººç±»åœ¨ç¼–ç ä¸­ä½¿ç”¨çš„å·¥å…·å¯¹äº AI æ™ºèƒ½ä½“æ¥è¯´æ•ˆç‡éå¸¸ä½ã€‚ä¾‹å¦‚ï¼Œè®©ä¸€ä¸ª AI æ™ºèƒ½ä½“è®¿é—® bash shell å¹¶é€šè¿‡æ‰§è¡Œå¤§é‡çš„ cdã€ls å’Œ cat å‘½ä»¤æ¥æŸ¥æ‰¾ä¸€æ®µä»£ç ï¼Œæ•ˆç‡éå¸¸ä½ä¸‹ï¼Œå°½ç®¡äººç±»å¯ä»¥è¿…é€Ÿå®Œæˆè¿™äº›æ“ä½œã€‚åŒæ ·ï¼Œåƒ VSCodeã€emacs å’Œ vim è¿™æ ·çš„å¯è§†åŒ–ä»£ç ç¼–è¾‘å™¨å¯¹äººç±»æ¥è¯´æ˜“äºä½¿ç”¨ï¼Œä½†å¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs)ï¼ˆæˆ–å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ (LMMs)ï¼‰æ¥è¯´å´éš¾ä»¥æ“ä½œã€‚ç”±äº AI æ™ºèƒ½ä½“ä¸è®¡ç®—æœºçš„äº¤äº’æ–¹å¼ä¸äººç±»ä¸åŒï¼Œä½œè€…å‘ç°ï¼Œæ„å»ºä¸“é—¨çš„å·¥å…·ï¼ˆå‡½æ•°ï¼‰è®©æ™ºèƒ½ä½“èƒ½å¤Ÿæœç´¢ã€æŸ¥çœ‹å’Œç¼–è¾‘ä»£ç åº“ï¼Œèƒ½å¤Ÿå¸¦æ¥æ›´å¥½çš„æ€§èƒ½ã€‚\n\nç¼–ç  AI æ™ºèƒ½ä½“ç ”ç©¶ä¹‹æ‰€ä»¥èƒ½å–å¾—å¿«é€Ÿè¿›å±•ï¼Œä¸€ä¸ªåŸå› åœ¨äºå®ƒä»¬çš„æ€§èƒ½å¯ä»¥è¢«è‡ªåŠ¨ä¸”å¯é åœ°è¯„ä¼°ã€‚å€ŸåŠ© HumanEvalã€MBPP å’Œ SWE-bench ç­‰åŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶äººå‘˜å¯ä»¥å°è¯•æ–°çš„æƒ³æ³•ï¼Œå¹¶è‡ªåŠ¨æµ‹è¯•å…¶ç”Ÿæˆæ­£ç¡®ä»£ç çš„é¢‘ç‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå°½ç®¡ä¸“æ³¨äºæœç´¢ç½‘é¡µå’Œåˆæˆæ–‡ç« çš„ AI ç ”ç©¶æ™ºèƒ½ä½“ (AI research agents) é¢†åŸŸéå¸¸æ´»è·ƒï¼ˆæˆ‘ä¸ªäººå¾ˆå–œæ¬¢ä½¿ç”¨ Stanford å¤§å­¦ Yijia Shao ç­‰äººå¼€å‘çš„å¼€æº STORM ç³»ç»Ÿï¼‰ï¼Œä½†å®ƒä»¬å¾ˆéš¾è¯„ä¼°ï¼Œè¿™ä½¿å¾—è¯¥é¢†åŸŸçš„è¿›å±•æ›´åŠ å›°éš¾ã€‚\n\nGitHub Copilot äº 2021 å¹´å‘å¸ƒï¼Œè®¸å¤šå¼€å‘äººå‘˜å·²ç»å¼€å§‹é€šè¿‡æç¤ºå¤§è¯­è¨€æ¨¡å‹ (LLMs) æ¥è·å¾—ç¼–ç å¸®åŠ©ã€‚ä»é‚£æ—¶åˆ°ç°åœ¨ï¼Œæ›´å¤æ‚çš„ç¼–ç  AI æ™ºèƒ½ä½“çš„å¿«é€Ÿæ¼”å˜ï¼Œæ­£åœ¨æå¤§åœ°æ‰©å±•è®¡ç®—æœºåœ¨ç¼–ç ä»»åŠ¡ä¸Šå¸®åŠ©æˆ‘ä»¬çš„æ–¹å¼ï¼Œè€Œä¸”è¿›å±•é€Ÿåº¦éå¸¸å¿«ã€‚æœ‰äº†è¿™äº›å·¥å…·ï¼Œæˆ‘é¢„è®¡ç¼–ç¨‹å°†å˜å¾—æ›´åŠ æœ‰è¶£å’Œé«˜æ•ˆã€‚\n\n[åŸæ–‡é“¾æ¥ï¼š https://t.co/QP1JRomjrZ ]"
  },
  {
    "id": "1803812309460189479",
    "url": "https://x.com/AndrewYNg/status/1803812309460189479",
    "text": "Function calling is a powerful way to extend the capabilities of LLMs and AI agents by letting them use external tools. Our new short course Function calling and Data Extraction with LLMs, created with @NexusflowX and taught by @JiantaoJ  and @VenkatKSrini, demonstrates how to prompt LLMs to form calls to external functions. \n\nYou'll work with NexusRavenV2-13B, a 13B parameter open-source model that excels in function calling tasks while still being small enough to host locally. Learn to use function calling to extract structured data from unstructured text and access web APIs, and build an end-to-end application that processes customer service transcripts. You'll learn how to build LLM-powered applications that can analyze feedback, automate data entry, and enhance search. \n\nPlease get started here: https://t.co/FxSp3jv36w",
    "createdAt": "Thu Jun 20 15:29:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 200,
    "replyCount": 98,
    "likeCount": 846,
    "quoteCount": 14,
    "viewCount": 110186,
    "bookmarkCount": 513,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å‡½æ•°è°ƒç”¨ (Function calling) æ˜¯ä¸€ç§å¼ºå¤§çš„æ–¹æ³•ï¼Œå®ƒèƒ½è®©å¤§è¯­è¨€æ¨¡å‹ (LLM) å’Œ AI æ™ºèƒ½ä½“ (AI Agent) å€ŸåŠ©å¤–éƒ¨å·¥å…·ï¼Œä»è€Œæ‰©å±•å®ƒä»¬çš„èƒ½åŠ›ã€‚æˆ‘ä»¬ä¸ @NexusflowX åˆä½œå¼€å‘ï¼Œå¹¶ç”± @JiantaoJ å’Œ @VenkatKSrini æ•™æˆçš„æ–°çŸ­è¯¾ç¨‹â€œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå‡½æ•°è°ƒç”¨å’Œæ•°æ®æå–â€ï¼Œå°†æ¼”ç¤ºå¦‚ä½•æç¤ºå¤§è¯­è¨€æ¨¡å‹æ¥ç”Ÿæˆå¯¹å¤–éƒ¨å‡½æ•°çš„è°ƒç”¨ã€‚\n\nä½ å°†ä¼šåœ¨è¯¾ç¨‹ä¸­æ¥è§¦åˆ° NexusRavenV2-13Bâ€”â€”ä¸€ä¸ªæ‹¥æœ‰ 130 äº¿å‚æ•°çš„å¼€æºæ¨¡å‹ã€‚å®ƒåœ¨å‡½æ•°è°ƒç”¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”ä½“ç§¯è¶³å¤Ÿå°ï¼Œå¯ä»¥åœ¨æœ¬åœ°è®¾å¤‡ä¸Šè¿è¡Œã€‚ä½ å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨å‡½æ•°è°ƒç”¨ï¼Œä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®ï¼Œè®¿é—®ç½‘ç»œ APIï¼Œå¹¶æ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„åº”ç”¨ç¨‹åºæ¥å¤„ç†å®¢æˆ·æœåŠ¡æ–‡æœ¬è®°å½•ã€‚ä½ è¿˜ä¼šæŒæ¡å¦‚ä½•å¼€å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºï¼Œè¿™äº›åº”ç”¨èƒ½å¤Ÿåˆ†æç”¨æˆ·åé¦ˆã€è‡ªåŠ¨åŒ–æ•°æ®è¾“å…¥ä»¥åŠå¢å¼ºæœç´¢åŠŸèƒ½ã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„å¼€å§‹å­¦ä¹ ï¼šhttps://t.co/FxSp3jv36w"
  },
  {
    "id": "1801295202788983136",
    "url": "https://x.com/AndrewYNg/status/1801295202788983136",
    "text": "One reason for machine learningâ€™s success is that our field welcomes a wide range of work. I canâ€™t think of even one example where someone developed what they called a machine learning algorithm and senior members of our community criticized it saying, â€œthatâ€™s not machine learning!â€ Indeed, linear regression using a least-squares cost function was used by mathematicians Legendre and Gauss in the early 1800s â€” long before the invention of computers â€” yet machine learning has embraced these algorithms, and we routinely call them â€œmachine learningâ€ in introductory courses!\n\nIn contrast, about 20 years ago, I saw statistics departments at a number of universities look at developments in machine learning and say, â€œthatâ€™s not really statistics.â€ This is one reason why machine learning grew much more in computer science than statistics departments. (Fortunately, since then, most statistics departments have become much more open to machine learning.)\n\nThis contrast came to mind a few months ago, as I thought about how to talk about agentic systems that use design patterns such as reflection, tool use, planning, and multi-agent collaboration to produce better results than zero-shot prompting. I had been involved in conversations about whether certain systems should count as â€œagents.â€ Rather than having to choose whether or not something is an agent in a binary way, I thought, it would be more useful to think of systems as being agent-like to different degrees. Unlike the noun â€œagent,â€ the adjective â€œagenticâ€ allows us to contemplate such systems and include all of them in this growing movement.\n\nMore and more people are building systems that prompt a large language model multiple times using agent-like design patterns. But thereâ€™s a gray zone between what clearly is not an agent (prompting a model once) and what clearly is (say, an autonomous agent that, given high-level instructions, plans, uses tools, and carries out multiple, iterative steps of processing).\n\nRather than arguing over which work to include or exclude as being a true agent, we can acknowledge that there are different degrees to which systems can be agentic. Then we can more easily include everyone who wants to work on agentic systems. We can also encourage newcomers to start by building simple agentic workflows and iteratively make their systems more sophisticated.\n\nIn the past few weeks, Iâ€™ve noticed that, while technical people and non-technical people alike sometimes use the word â€œagent,â€ mainly only technical people use the word â€œagenticâ€ (for now!). So when I see an article that talks about â€œagenticâ€ workflows, Iâ€™m more likely to read it, since itâ€™s less likely to be marketing fluff and more likely to have been written by someone who understands the technology.\n\nLetâ€™s keep working on agentic systems and keep welcoming anyone who wants to join our field!\n\n[Original text: https://t.co/4izf1hsv9P ]",
    "createdAt": "Thu Jun 13 16:46:57 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 204,
    "replyCount": 59,
    "likeCount": 1130,
    "quoteCount": 23,
    "viewCount": 178391,
    "bookmarkCount": 430,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æœºå™¨å­¦ä¹  (Machine Learning) ä¹‹æ‰€ä»¥èƒ½å–å¾—æˆåŠŸï¼Œå…¶ä¸­ä¸€ä¸ªåŸå› æ˜¯æˆ‘ä»¬çš„é¢†åŸŸå¯¹å„ç§ç ”ç©¶æ–¹å‘éƒ½æŒå¼€æ”¾æ€åº¦ã€‚æˆ‘ç”šè‡³æƒ³ä¸å‡ºæœ‰å“ªä¸ªä¾‹å­ï¼Œæ˜¯æœ‰äººå¼€å‘äº†ä»–ä»¬æ‰€è°“çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå´é­åˆ°ç¤¾åŒºèµ„æ·±æˆå‘˜çš„æ‰¹è¯„ï¼Œè¯´â€œé‚£æ ¹æœ¬ä¸æ˜¯æœºå™¨å­¦ä¹ ï¼â€ äº‹å®ä¸Šï¼Œä½¿ç”¨æœ€å°äºŒä¹˜æˆæœ¬å‡½æ•° (least-squares cost function) çš„çº¿æ€§å›å½’ (linear regression)ï¼Œæ—©åœ¨ 19 ä¸–çºªåˆï¼Œä¹Ÿå°±æ˜¯è®¡ç®—æœºå‘æ˜ä¹‹å‰ï¼Œå°±è¢«æ•°å­¦å®¶ Legendre å’Œ Gauss ä½¿ç”¨äº†ã€‚ç„¶è€Œï¼Œæœºå™¨å­¦ä¹ å´æ¬£ç„¶æ¥çº³äº†è¿™äº›ç®—æ³•ï¼Œæˆ‘ä»¬ç”šè‡³åœ¨å…¥é—¨è¯¾ç¨‹ä¸­ä¹Ÿä¹ æƒ¯æ€§åœ°ç§°å®ƒä»¬ä¸ºâ€œæœºå™¨å­¦ä¹ â€ï¼\n\nä¸æ­¤å½¢æˆé²œæ˜å¯¹æ¯”çš„æ˜¯ï¼Œå¤§çº¦ 20 å¹´å‰ï¼Œæˆ‘çœ‹åˆ°è®¸å¤šå¤§å­¦çš„ç»Ÿè®¡å­¦ç³»åœ¨çœ‹å¾…æœºå™¨å­¦ä¹ çš„å‘å±•æ—¶ï¼Œä¼šè¯´â€œé‚£ä¸æ˜¯çœŸæ­£çš„ç»Ÿè®¡å­¦ã€‚â€ è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæœºå™¨å­¦ä¹ åœ¨è®¡ç®—æœºç§‘å­¦ç³»çš„å‘å±•ï¼Œè¦æ¯”åœ¨ç»Ÿè®¡å­¦ç³»å¿«å¾—å¤šçš„ä¸€ä¸ªåŸå› ã€‚ï¼ˆå¹¸è¿çš„æ˜¯ï¼Œè‡ªé‚£ä»¥åï¼Œå¤§å¤šæ•°ç»Ÿè®¡å­¦ç³»å¯¹æœºå™¨å­¦ä¹ çš„æ€åº¦å˜å¾—å¼€æ”¾äº†è®¸å¤šã€‚ï¼‰\n\nå‡ ä¸ªæœˆå‰ï¼Œå½“æˆ‘æ€è€ƒå¦‚ä½•è°ˆè®ºé‚£äº›ä½¿ç”¨åå°„ (reflection)ã€å·¥å…·ä½¿ç”¨ (tool use)ã€è§„åˆ’ (planning) å’Œå¤š AI æ™ºèƒ½ä½“ (multi-agent) åä½œç­‰è®¾è®¡æ¨¡å¼ (design patterns)ï¼Œä»è€Œäº§å‡ºæ¯”é›¶æ ·æœ¬ (Zero-shot) æç¤º (prompting) æ›´å¥½ç»“æœçš„æ™ºèƒ½ä½“ç³»ç»Ÿ (agentic systems) æ—¶ï¼Œæˆ‘æƒ³åˆ°äº†è¿™ç§å¯¹æ¯”ã€‚æˆ‘æ›¾å‚ä¸è¿‡ä¸€äº›è®¨è®ºï¼Œäº‰è®ºæŸäº›ç³»ç»Ÿæ˜¯å¦åº”è¯¥è¢«ç®—ä½œâ€œAI æ™ºèƒ½ä½“ (AI Agent)â€ã€‚æˆ‘å½“æ—¶æƒ³ï¼Œä¸å…¶å¿…é¡»ä»¥éæ­¤å³å½¼çš„æ–¹å¼å»åˆ¤æ–­ä¸€ä¸ªç³»ç»Ÿæ˜¯ä¸æ˜¯ AI æ™ºèƒ½ä½“ï¼Œä¸å¦‚å°†ç³»ç»Ÿçœ‹ä½œæ˜¯å…·å¤‡ä¸åŒç¨‹åº¦â€œæ™ºèƒ½ä½“åŒ– (agentic)â€ç‰¹æ€§çš„ï¼Œè¿™ä¼šæ›´æœ‰æ„ä¹‰ã€‚ä¸åè¯â€œAI æ™ºèƒ½ä½“â€ä¸åŒï¼Œå½¢å®¹è¯â€œæ™ºèƒ½ä½“åŒ–â€å…è®¸æˆ‘ä»¬å®¡è§†å¹¶æ¥çº³æ‰€æœ‰è¿™ç±»ç³»ç»Ÿï¼Œå°†å®ƒä»¬éƒ½çº³å…¥åˆ°è¿™ä¸€æ—¥ç›Šå£®å¤§çš„è¿åŠ¨ä¸­ã€‚\n\nè¶Šæ¥è¶Šå¤šçš„äººæ­£åœ¨æ„å»ºç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿä¼šåˆ©ç”¨æ™ºèƒ½ä½“åŒ–çš„è®¾è®¡æ¨¡å¼ï¼Œå¤šæ¬¡å‘å¤§è¯­è¨€æ¨¡å‹ (LLM/Large Language Model) å‘å‡ºæç¤ºã€‚ç„¶è€Œï¼Œåœ¨é‚£äº›æ˜ç¡®ä¸æ˜¯ AI æ™ºèƒ½ä½“çš„ç³»ç»Ÿï¼ˆä¾‹å¦‚ï¼Œåªå‘æ¨¡å‹å‘å‡ºä¸€æ¬¡æç¤ºï¼‰å’Œé‚£äº›æ˜ç¡®æ˜¯ AI æ™ºèƒ½ä½“çš„ç³»ç»Ÿï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªè‡ªä¸» AI æ™ºèƒ½ä½“ï¼Œåœ¨æ¥æ”¶åˆ°é«˜çº§æŒ‡ä»¤åï¼Œèƒ½å¤Ÿè¿›è¡Œè§„åˆ’ã€ä½¿ç”¨å·¥å…·å¹¶æ‰§è¡Œå¤šä¸ªè¿­ä»£å¤„ç†æ­¥éª¤ï¼‰ä¹‹é—´ï¼Œå­˜åœ¨ä¸€ä¸ªç°è‰²åœ°å¸¦ã€‚\n\nä¸å…¶äº‰è®ºå“ªäº›å·¥ä½œåº”è¯¥è¢«çº³å…¥æˆ–æ’é™¤åœ¨â€œçœŸæ­£ AI æ™ºèƒ½ä½“â€çš„èŒƒç•´ä¹‹å¤–ï¼Œæˆ‘ä»¬ä¸å¦‚æ‰¿è®¤ç³»ç»Ÿåœ¨ä¸åŒç¨‹åº¦ä¸Šå¯ä»¥æ˜¯æ™ºèƒ½ä½“åŒ–çš„ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±èƒ½æ›´å®¹æ˜“åœ°æ¬¢è¿æ‰€æœ‰å¸Œæœ›ä»äº‹æ™ºèƒ½ä½“åŒ–ç³»ç»Ÿç ”ç©¶çš„äººã€‚æˆ‘ä»¬è¿˜å¯ä»¥é¼“åŠ±æ–°æ‰‹ä»æ„å»ºç®€å•çš„æ™ºèƒ½ä½“åŒ–å·¥ä½œæµ (workflow) å¼€å§‹ï¼Œç„¶åé€šè¿‡è¿­ä»£çš„æ–¹å¼é€æ­¥æå‡å…¶ç³»ç»Ÿçš„å¤æ‚æ€§ã€‚\n\nåœ¨è¿‡å»çš„å‡ å‘¨é‡Œï¼Œæˆ‘æ³¨æ„åˆ°ï¼Œå°½ç®¡æŠ€æœ¯äººå‘˜å’ŒéæŠ€æœ¯äººå‘˜æœ‰æ—¶éƒ½ä¼šä½¿ç”¨â€œAI æ™ºèƒ½ä½“â€è¿™ä¸ªè¯ï¼Œä½†ï¼ˆç›®å‰ï¼ï¼‰ä¸»è¦åªæœ‰æŠ€æœ¯äººå‘˜ä¼šä½¿ç”¨â€œæ™ºèƒ½ä½“åŒ–â€è¿™ä¸ªè¯ã€‚æ‰€ä»¥ï¼Œå½“æˆ‘çœ‹åˆ°ä¸€ç¯‡è°ˆè®ºâ€œæ™ºèƒ½ä½“åŒ–â€å·¥ä½œæµçš„æ–‡ç« æ—¶ï¼Œæˆ‘æ›´æœ‰å¯èƒ½å»é˜…è¯»å®ƒï¼Œå› ä¸ºå®ƒä¸å¤ªå¯èƒ½æ˜¯è¥é”€æ€§è´¨çš„ç©ºè¯ï¼Œè€Œæ›´å¯èƒ½æ˜¯ç”±çœŸæ­£ç†è§£æŠ€æœ¯çš„äººæ’°å†™çš„ã€‚\n\nè®©æˆ‘ä»¬ç»§ç»­è‡´åŠ›äºæ™ºèƒ½ä½“åŒ–ç³»ç»Ÿï¼Œå¹¶æ¬¢è¿æ‰€æœ‰æ„¿æ„åŠ å…¥æˆ‘ä»¬é¢†åŸŸçš„äººï¼\n\n[åŸæ–‡é“¾æ¥: https://t.co/4izf1hsv9P ]"
  },
  {
    "id": "1801277928740970619",
    "url": "https://x.com/AndrewYNg/status/1801277928740970619",
    "text": "New short course: Building Your Own Database Agent, created with Microsoft @Azure's @adriangs86. You'll learn to build an AI assistant that translates natural language questions into SQL queries. Querying with natural language empowers everyone in your organization, from business leaders to developers, to access data insights directly, using plain English.\n\nYouâ€™ll use the Azure OpenAI Service and LangChain to implement retrieval augmented generation and function calling, and leverage the Assistants API. You'll gain hands-on experience building an agent that can reason over both CSV files and SQL databases.\n\nPlease sign up here! https://t.co/9NxN8pJYKC",
    "createdAt": "Thu Jun 13 15:38:18 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 216,
    "replyCount": 20,
    "likeCount": 1052,
    "quoteCount": 21,
    "viewCount": 109282,
    "bookmarkCount": 781,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°çš„çŸ­æœŸè¯¾ç¨‹ï¼šæ„å»ºä½ è‡ªå·±çš„æ•°æ®åº“æ™ºèƒ½ä½“ (AI Agent)ï¼Œç”± Microsoft @Azure ä¸ @adriangs86 åˆä½œæ¨å‡ºã€‚ä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºä¸€ä¸ª AI åŠ©æ‰‹ (AI assistant)ï¼Œå®ƒèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬åŒ–ä¸º SQL æŸ¥è¯¢ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œç»„ç»‡é‡Œçš„æ¯ä¸ªäººâ€”â€”ä»ä¸šåŠ¡é¢†å¯¼è€…åˆ°å¼€å‘è€…â€”â€”éƒ½èƒ½ç›´æ¥ä½¿ç”¨æ—¥å¸¸è‹±è¯­è·å–æ•°æ®æ´å¯Ÿã€‚\n\næœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†ä½¿ç”¨ Azure OpenAI Service å’Œ LangChain æ¥å®ç°æ£€ç´¢å¢å¼ºç”Ÿæˆ (retrieval augmented generation) å’Œå‡½æ•°è°ƒç”¨ (function calling)ï¼Œå¹¶åˆ©ç”¨ Assistants APIã€‚ä½ å°†è·å¾—å®é™…ç»éªŒï¼Œæ„å»ºä¸€ä¸ªèƒ½ç†è§£ CSV æ–‡ä»¶å’Œ SQL æ•°æ®åº“å¹¶æ®æ­¤è¿›è¡Œæ¨ç†çš„æ™ºèƒ½ä½“ã€‚\n\nè¯·åœ¨è¿™é‡ŒæŠ¥åï¼https://t.co/9NxN8pJYKC"
  },
  {
    "id": "1800582171259982289",
    "url": "https://x.com/AndrewYNg/status/1800582171259982289",
    "text": "I think AI agentic machine translation has huge potential for improving over traditional neural machine translation, and am releasing as open-source a demonstration I'd been playing with as a fun weekend project.\n\nUsing an agentic workflow, this demonstration (i) Prompts an LLM to translate from one language to another, (ii) Reflects on the translation to come up with constructive suggestions, (iii) Uses the suggestions to refine the translation. In our limited testing, this is sometimes competitive with, and sometimes worse than, leading commercial providers.\n\nBut it gives a highly steerable translation system where by simply changing the prompt, you can specify the tone (formal/informal), regional variation (do you want Spanish as spoken in Spain or as spoken in Latin America?), and ensure consistent translation of terms (by providing a glossary).\n\nThis is not mature software. But I hope the open-source community can make agentic translation work much better. Given how a simple reflection workflow already gives decent results, I think there's significant headroom to make agentic translation much better.\n\nReleasing an early software prototype like this is something new I decided to try to see if it is helpful to the developer community. I'd love any feedback on this.\n\nThanks to Joaquin Dominguez, @nedteneva, @JohnSanterre for help with this.\n\nhttps://t.co/nghC3wN3Id",
    "createdAt": "Tue Jun 11 17:33:37 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 348,
    "replyCount": 87,
    "likeCount": 1736,
    "quoteCount": 52,
    "viewCount": 544536,
    "bookmarkCount": 1363,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘è®¤ä¸º AI æ™ºèƒ½ä½“æœºå™¨ç¿»è¯‘ (AI agentic machine translation) åœ¨è¶…è¶Šä¼ ç»Ÿç¥ç»ç½‘ç»œæœºå™¨ç¿»è¯‘æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå› æ­¤æˆ‘å†³å®šå°†æˆ‘ä½œä¸ºå‘¨æœ«å…´è¶£é¡¹ç›®å¼€å‘çš„ä¸€ä¸ªæ¼”ç¤ºç¨‹åºå¼€æºå‘å¸ƒã€‚\n\nè¿™ä¸ªæ¼”ç¤ºç¨‹åºé‡‡ç”¨äº†ä¸€ç§æ™ºèƒ½ä½“å·¥ä½œæµ (agentic workflow)ï¼Œå®ƒä¼šæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š(i) æç¤ºä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLM) è¿›è¡Œè·¨è¯­è¨€ç¿»è¯‘ï¼›(ii) å¯¹ç¿»è¯‘ç»“æœè¿›è¡Œåæ€ï¼Œä»è€Œæå‡ºå»ºè®¾æ€§å»ºè®®ï¼›(iii) åˆ©ç”¨è¿™äº›å»ºè®®æ¥ä¼˜åŒ–æœ€ç»ˆè¯‘æ–‡ã€‚åœ¨æˆ‘ä»¬æœ‰é™çš„æµ‹è¯•ä¸­ï¼Œå®ƒçš„è¡¨ç°æœ‰æ—¶èƒ½ä¸é¡¶å°–çš„å•†ä¸šç¿»è¯‘æœåŠ¡åª²ç¾ï¼Œæœ‰æ—¶åˆ™ç•¥é€Šä¸€ç­¹ã€‚\n\nä¸è¿‡ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªé«˜åº¦å¯æ§çš„ç¿»è¯‘ç³»ç»Ÿã€‚é€šè¿‡ç®€å•åœ°ä¿®æ”¹æç¤ºè¯ï¼Œä½ å°±èƒ½æŒ‡å®šè¯‘æ–‡çš„è¯­è°ƒ (ä¾‹å¦‚ï¼Œæ­£å¼æˆ–éæ­£å¼)ã€åŒºåŸŸå·®å¼‚ (æ¯”å¦‚ï¼Œä½ æƒ³è¦åœ¨è¥¿ç­ç‰™ä½¿ç”¨çš„è¥¿ç­ç‰™è¯­ï¼Œè¿˜æ˜¯æ‹‰ä¸ç¾æ´²çš„è¥¿ç­ç‰™è¯­ï¼Ÿ)ï¼Œç”šè‡³å¯ä»¥é€šè¿‡æä¾›æœ¯è¯­è¡¨æ¥ç¡®ä¿ä¸“ä¸šæœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§ã€‚\n\nè¿™è™½ç„¶è¿˜ä¸æ˜¯ä¸€æ¬¾æˆç†Ÿçš„è½¯ä»¶ï¼Œä½†æˆ‘å¸Œæœ›å¼€æºç¤¾åŒºèƒ½å…±åŒåŠªåŠ›ï¼Œè®©æ™ºèƒ½ä½“ç¿»è¯‘å‘æŒ¥å‡ºæ›´å¤§çš„ä½œç”¨ã€‚é‰´äºä¸€ä¸ªç®€å•çš„åæ€å·¥ä½œæµå°±å·²ç»èƒ½å¸¦æ¥ä¸é”™çš„æ•ˆæœï¼Œæˆ‘è®¤ä¸ºæ™ºèƒ½ä½“ç¿»è¯‘æœªæ¥è¿˜æœ‰å·¨å¤§çš„æå‡ç©ºé—´ã€‚\n\nå‘å¸ƒè¿™æ ·ä¸€ä¸ªæ—©æœŸçš„è½¯ä»¶åŸå‹ï¼Œæ˜¯æˆ‘é¦–æ¬¡å°è¯•çš„æ–¹å¼ï¼Œå¸Œæœ›èƒ½å¯¹å¼€å‘è€…ç¤¾åŒºæœ‰æ‰€å¸®åŠ©ã€‚æˆ‘éå¸¸æœŸå¾…èƒ½æ”¶åˆ°å¤§å®¶å¯¹æ­¤çš„ä»»ä½•åé¦ˆã€‚\n\næ„Ÿè°¢ Joaquin Dominguezã€@nedtenevaã€@JohnSanterre åœ¨æ­¤é¡¹ç›®ä¸­çš„å¸®åŠ©ã€‚\n\nhttps://t.co/nghC3wN3Id"
  },
  {
    "id": "1798753608974139779",
    "url": "https://x.com/AndrewYNg/status/1798753608974139779",
    "text": "The effort to protect innovation and open source continues. I believe weâ€™re all better off if anyone can carry out basic AI research and share their innovations. Right now, Iâ€™m deeply concerned about California's proposed law SB-1047. Itâ€™s a long, complex bill with many parts that require safety assessments, shutdown capability for models, and so on.\n\nThere are many things wrong with this bill, but Iâ€™d like to focus here on just one: It defines an unreasonable â€œhazardous capabilityâ€ designation that may make builders of large AI models liable if someone uses their models to do something that exceeds the billâ€™s definition of harm (such as causing $500 million in damage). That is practically impossible for any AI builder to ensure. If the bill is passed in its present form, it will stifle AI model builders, especially open source developers.\n\nSome AI applications, for example in healthcare, are risky. But as I wrote previously, regulators should regulate applications rather than technology.\n- Technology refers to tools that can be applied in many ways to solve various problems.\n- Applications are specific implementations of technologies designed to meet particular customer needs.\n\nFor example, an electric motor is a technology. When we put it in a blender, an electric vehicle, dialysis machine, or guided bomb, it becomes an application. Imagine if we passed laws saying, if anyone uses a motor in a harmful way, the motor manufacturer is liable. Motor makers would either shut down or make motors so tiny as to be useless for most applications. If we pass such a law, sure, we might stop people from building guided bombs, but weâ€™d also lose blenders, electric vehicles, and dialysis machines. In contrast, if we look at specific applications, like blenders, we can more rationally assess risks and figure out how to make sure theyâ€™re safe, and even ban classes of applications, like certain types of munitions.\n\nSafety is a property of the application, not a property of the technology (or model), as @random_walker and @sayashk have pointed out. Whether a blender is a safe one canâ€™t be determined by examining the electric motor. A similar argument holds for AI.\n\nSB-1047 doesnâ€™t account for this distinction. It ignores the reality that the number of beneficial uses of AI models is, like electric motors, vastly greater than the number of harmful ones. But, just as no one knows how to build a motor that canâ€™t be used to cause harm, no one has figured out how to make sure an AI model canâ€™t be adapted to harmful uses. In the case of open source models, thereâ€™s no known defense to fine-tuning to remove RLHF alignment. And jailbreaking work has shown that even closed-source, proprietary models that have been properly aligned can be attacked in ways that make them give harmful responses. Indeed, the sharp-witted @elder_plinius regularly tweets about jailbreaks for closed models. Kudos also to Anthropicâ€™s @cem__anil and collaborators for publishing their work on many-shot jailbreaking, an attack that can get leading large language models to give inappropriate responses and is hard to defend against.\n\nCalifornia has been home to a lot of innovation in AI. Iâ€™m worried that this anti-competitive, anti-innovation proposal has gotten so much traction in the legislature. Worse, other jurisdictions often follow California, and it would be awful if they were to do so in this instance.\n\nSB-1047 passed in a key vote in the State Senate in May, but it still has additional steps before it becomes law. I hope you will speak out against it if you get a chance to do so.\n\n[Original text (with links): https://t.co/MOQqFF6cID ]",
    "createdAt": "Thu Jun 06 16:27:34 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 782,
    "replyCount": 163,
    "likeCount": 3331,
    "quoteCount": 136,
    "viewCount": 1119357,
    "bookmarkCount": 881,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¿æŠ¤åˆ›æ–°å’Œå¼€æº (open source) çš„åŠªåŠ›ä»åœ¨ç»§ç»­ã€‚æˆ‘ç›¸ä¿¡ï¼Œå¦‚æœæ¯ä¸ªäººéƒ½èƒ½è¿›è¡ŒåŸºç¡€çš„ AI ç ”ç©¶å¹¶åˆ†äº«ä»–ä»¬çš„åˆ›æ–°ï¼Œæˆ‘ä»¬æ‰€æœ‰äººéƒ½ä¼šä»ä¸­å—ç›Šã€‚ç›®å‰ï¼Œæˆ‘æ·±åˆ‡å…³æ³¨åŠ åˆ©ç¦å°¼äºšå·æ‹Ÿè®®çš„æ³•å¾‹ SB-1047ã€‚è¿™æ˜¯ä¸€é¡¹æ¼«é•¿è€Œå¤æ‚çš„æ³•æ¡ˆï¼Œå…¶ä¸­è®¸å¤šæ¡æ¬¾è¦æ±‚å¯¹æ¨¡å‹è¿›è¡Œå®‰å…¨è¯„ä¼°ã€å…·å¤‡æ¨¡å‹å…³é—­èƒ½åŠ›ç­‰ã€‚\n\nè¿™é¡¹æ³•æ¡ˆå­˜åœ¨è¯¸å¤šé—®é¢˜ï¼Œä½†æˆ‘åœ¨æ­¤åªèšç„¦äºå…¶ä¸­ä¸€ä¸ªï¼šå®ƒå®šä¹‰äº†ä¸€ç§ä¸åˆç†çš„â€œå±é™©èƒ½åŠ›â€è®¤å®šï¼Œè¿™å¯èƒ½å¯¼è‡´å¤§å‹ AI æ¨¡å‹å¼€å‘è€…æ‰¿æ‹…è´£ä»»ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚æœæœ‰äººä½¿ç”¨ä»–ä»¬çš„æ¨¡å‹åšå‡ºäº†è¶…å‡ºè¯¥æ³•æ¡ˆæ‰€å®šä¹‰æŸå®³èŒƒå›´çš„è¡Œä¸ºï¼ˆä¾‹å¦‚é€ æˆ 5 äº¿ç¾å…ƒçš„æŸå¤±ï¼‰ï¼Œå¼€å‘è€…å°±å¯èƒ½è¢«è¿½è´£ã€‚å¯¹äºä»»ä½• AI å¼€å‘è€…æ¥è¯´ï¼Œå‡ ä¹ä¸å¯èƒ½ç¡®ä¿æ¨¡å‹ä¸è¢«å¦‚æ­¤æ»¥ç”¨ã€‚å¦‚æœè¯¥æ³•æ¡ˆä»¥ç›®å‰çš„å½¢å¼é€šè¿‡ï¼Œå®ƒå°†æ‰¼æ€ AI æ¨¡å‹å¼€å‘è€…ï¼Œå°¤å…¶æ˜¯å¼€æºå¼€å‘è€…ã€‚\n\nä¸€äº› AI åº”ç”¨ï¼Œä¾‹å¦‚åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸï¼Œç¡®å®å­˜åœ¨é£é™©ã€‚ä½†æ­£å¦‚æˆ‘ä¹‹å‰æ‰€å†™ï¼Œç›‘ç®¡æœºæ„åº”è¯¥ç›‘ç®¡åº”ç”¨ï¼Œè€Œä¸æ˜¯æŠ€æœ¯ã€‚\n- æŠ€æœ¯æŒ‡çš„æ˜¯å¯ä»¥å¤šç§æ–¹å¼åº”ç”¨ä»¥è§£å†³å„ç§é—®é¢˜çš„å·¥å…·ã€‚\n- åº”ç”¨æ˜¯æŠ€æœ¯çš„ç‰¹å®šå®ç°ï¼Œæ—¨åœ¨æ»¡è¶³ç‰¹å®šçš„å®¢æˆ·éœ€æ±‚ã€‚\n\nä¸¾ä¸ªä¾‹å­ï¼Œç”µåŠ¨æœºå°±æ˜¯ä¸€ç§æŠ€æœ¯ã€‚å½“æˆ‘ä»¬å°†å…¶å®‰è£…åœ¨æ…æ‹Œæœºã€ç”µåŠ¨æ±½è½¦ã€é€ææœºæˆ–åˆ¶å¯¼ç‚¸å¼¹ä¸­æ—¶ï¼Œå®ƒå°±å˜æˆäº†ä¸€ç§åº”ç”¨ã€‚è¯•æƒ³ä¸€ä¸‹ï¼Œå¦‚æœæˆ‘ä»¬é€šè¿‡æ³•å¾‹è§„å®šï¼Œå¦‚æœæœ‰äººä»¥æœ‰å®³æ–¹å¼ä½¿ç”¨ç”µæœºï¼Œç”µæœºåˆ¶é€ å•†å°†æ‰¿æ‹…è´£ä»»ï¼Œé‚£ä¼šæ€æ ·ï¼Ÿç”µæœºåˆ¶é€ å•†è¦ä¹ˆå€’é—­ï¼Œè¦ä¹ˆåˆ¶é€ å‡ºéå¸¸å¾®å°çš„ç”µæœºï¼Œä»¥è‡³äºæ— æ³•ç”¨äºå¤§å¤šæ•°åº”ç”¨ã€‚å¦‚æœé€šè¿‡è¿™æ ·çš„æ³•å¾‹ï¼Œæˆ‘ä»¬å›ºç„¶å¯èƒ½é˜»æ­¢äººä»¬åˆ¶é€ åˆ¶å¯¼ç‚¸å¼¹ï¼Œä½†åŒæ—¶æˆ‘ä»¬ä¹Ÿå°†å¤±å»æ…æ‹Œæœºã€ç”µåŠ¨æ±½è½¦å’Œé€ææœºã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¦‚æœæˆ‘ä»¬å®¡è§†å…·ä½“çš„åº”ç”¨ï¼Œæ¯”å¦‚æ…æ‹Œæœºï¼Œæˆ‘ä»¬å°±å¯ä»¥æ›´åˆç†åœ°è¯„ä¼°é£é™©ï¼Œå¹¶æ‰¾å‡ºå¦‚ä½•ç¡®ä¿å…¶å®‰å…¨çš„æ–¹æ³•ï¼Œç”šè‡³å¯ä»¥ç¦æ­¢æŸäº›ç±»åˆ«çš„åº”ç”¨ï¼Œæ¯”å¦‚ç‰¹å®šç±»å‹çš„å¼¹è¯ã€‚\n\nå®‰å…¨æ€§æ˜¯åº”ç”¨çš„å±æ€§ï¼Œè€ŒéæŠ€æœ¯ï¼ˆæˆ–æ¨¡å‹ï¼‰å›ºæœ‰çš„å±æ€§ï¼Œæ­£å¦‚ @random_walker å’Œ @sayashk æ‰€æŒ‡å‡ºçš„ã€‚æ…æ‹Œæœºæ˜¯å¦å®‰å…¨ï¼Œæ— æ³•é€šè¿‡æ£€æŸ¥å…¶ç”µåŠ¨æœºæ¥åˆ¤æ–­ã€‚ç±»ä¼¼çš„è®ºç‚¹ä¹Ÿé€‚ç”¨äº AIã€‚\n\nSB-1047 æ²¡æœ‰è€ƒè™‘åˆ°è¿™ç§åŒºåˆ«ã€‚å®ƒå¿½ç•¥äº†è¿™æ ·ä¸€ä¸ªç°å®ï¼šAI æ¨¡å‹çš„æœ‰ç›Šç”¨é€”æ•°é‡ï¼Œå°±åƒç”µåŠ¨æœºä¸€æ ·ï¼Œè¿œè¿œè¶…è¿‡äº†æœ‰å®³ç”¨é€”çš„æ•°é‡ã€‚ä½†æ˜¯ï¼Œæ­£å¦‚æ²¡æœ‰äººçŸ¥é“å¦‚ä½•åˆ¶é€ ä¸€ä¸ªä¸èƒ½é€ æˆä¼¤å®³çš„ç”µæœºä¸€æ ·ï¼Œä¹Ÿæ²¡æœ‰äººçŸ¥é“å¦‚ä½•ç¡®ä¿ AI æ¨¡å‹ä¸ä¼šè¢«æ»¥ç”¨äºæœ‰å®³ç›®çš„ã€‚å¯¹äºå¼€æºæ¨¡å‹ï¼Œç›®å‰æ²¡æœ‰å·²çŸ¥çš„é˜²å¾¡æªæ–½å¯ä»¥æœ‰æ•ˆé˜»æ­¢é€šè¿‡å¾®è°ƒ (fine-tuning) æ¥ç§»é™¤å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆ (RLHF) å¯¹é½ã€‚æ­¤å¤–ï¼Œè¶Šç‹± (jailbreaking) ç ”ç©¶è¡¨æ˜ï¼Œå³ä½¿æ˜¯ç»è¿‡é€‚å½“å¯¹é½çš„é—­æºä¸“æœ‰æ¨¡å‹ï¼Œä¹Ÿå¯èƒ½è¢«æ”»å‡»ï¼Œä½¿å…¶äº§ç”Ÿæœ‰å®³å›åº”ã€‚äº‹å®ä¸Šï¼Œ@elder_plinius ç»å¸¸åœ¨æ¨ç‰¹ä¸Šå‘å¸ƒå…³äºé—­æºæ¨¡å‹è¶Šç‹±çš„æ¶ˆæ¯ã€‚æˆ‘ä»¬ä¹Ÿè¦èµæ‰¬ Anthropic çš„ @cem__anil åŠå…¶åˆä½œè€…ï¼Œä»–ä»¬å‘è¡¨äº†å…³äºå¤šæ ·æœ¬è¶Šç‹± (many-shot jailbreaking) çš„ç ”ç©¶ï¼Œè¿™ç§æ”»å‡»èƒ½å¤Ÿä½¿é¢†å…ˆçš„ **å¤§è¯­è¨€æ¨¡å‹ (Large Language Model)** ç»™å‡ºä¸å½“å›åº”ï¼Œå¹¶ä¸”éš¾ä»¥é˜²å¾¡ã€‚\n\nåŠ åˆ©ç¦å°¼äºšå·ä¸€ç›´æ˜¯ AI é¢†åŸŸè®¸å¤šåˆ›æ–°çš„å‘æºåœ°ã€‚æˆ‘æ‹…å¿ƒè¿™é¡¹åç«äº‰ã€ååˆ›æ–°çš„ææ¡ˆåœ¨ç«‹æ³•æœºæ„ä¸­è·å¾—äº†å¦‚æ­¤å¤§çš„å…³æ³¨ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œå…¶ä»–å¸æ³•ç®¡è¾–åŒºé€šå¸¸ä¼šæ•ˆä»¿åŠ åˆ©ç¦å°¼äºšå·ï¼Œå¦‚æœä»–ä»¬åœ¨è¿™ç§æƒ…å†µä¸‹ä¹Ÿè¿™æ ·åšï¼Œé‚£å°†æ˜¯ä»¤äººæ‹…å¿§çš„ã€‚\n\nSB-1047 å·²äºäº”æœˆä»½åœ¨å·å‚è®®é™¢çš„ä¸€æ¬¡å…³é”®æ€§æŠ•ç¥¨ä¸­é€šè¿‡ï¼Œä½†åœ¨æˆä¸ºæ³•å¾‹ä¹‹å‰ä»éœ€ç»å†è¿›ä¸€æ­¥çš„ç«‹æ³•ç¨‹åºã€‚æˆ‘å¸Œæœ›å¦‚æœæœ‰æœºä¼šï¼Œå¤§å®¶èƒ½ç«™å‡ºæ¥åå¯¹å®ƒã€‚\n\n[åŸæ–‡é“¾æ¥ï¼šhttps://t.co/MOQqFF6cID ]"
  },
  {
    "id": "1798378861337723039",
    "url": "https://x.com/AndrewYNg/status/1798378861337723039",
    "text": "New AI Agentic course! Learn to use LangGraph to build single and multi-agent LLM applications in AI Agents in LangGraph. This short course, taught by LangChain @LangChainAI  founder Harrison Chase @hwchase17 and @tavilyai founder @weiss_rotem, shows how to integrate agentic search to enhance an agent's knowledge with query-focused answers in predictable formats. Also learn to implement agentic memory to save state for reasoning and debugging, and see how human-in-the-loop input can guide agents at key junctures. \n\nYou'll build an agent from scratch, then reconstruct it with LangGraph to thoroughly understand the framework. Finally, you'll build a sophisticated essay-writing agent that incorporates all the learnings from the course.\n\nSign up here! https://t.co/ZDpjLmdyDL",
    "createdAt": "Wed Jun 05 15:38:27 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 215,
    "replyCount": 57,
    "likeCount": 1134,
    "quoteCount": 16,
    "viewCount": 151103,
    "bookmarkCount": 826,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°çš„ AI æ™ºèƒ½ä½“ (AI Agent) è¯¾ç¨‹ï¼å­¦ä¹ å¦‚ä½•ä½¿ç”¨ LangGraph åœ¨ LangGraph æ¡†æ¶ä¸‹æ„å»ºå•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“ å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºã€‚è¿™ä¸ªçŸ­è¯¾ç¨‹ç”± LangChain @LangChainAI åˆ›å§‹äºº Harrison Chase @hwchase17 å’Œ @tavilyai åˆ›å§‹äºº @weiss_rotem äº²è‡ªæˆè¯¾ï¼Œå°†å‘ä½ å±•ç¤ºå¦‚ä½•é›†æˆæ™ºèƒ½ä½“æœç´¢ (Agentic Search)ï¼Œé€šè¿‡å¯é¢„æµ‹æ ¼å¼çš„ã€ä»¥æŸ¥è¯¢ä¸ºä¸­å¿ƒçš„ç­”æ¡ˆæ¥å¢å¼ºæ™ºèƒ½ä½“çš„çŸ¥è¯†ã€‚ä½ è¿˜å°†å­¦ä¹ å¦‚ä½•å®ç°æ™ºèƒ½ä½“è®°å¿† (Agentic Memory) æ¥ä¿å­˜æ¨ç†å’Œè°ƒè¯•çš„çŠ¶æ€ï¼Œå¹¶äº†è§£äººå·¥å¾ªç¯è¾“å…¥ (Human-in-the-loop Input) å¦‚ä½•åœ¨å…³é”®æ—¶åˆ»å¼•å¯¼æ™ºèƒ½ä½“ã€‚\n\nä½ å°†ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œç„¶åä½¿ç”¨ LangGraph å¯¹å…¶è¿›è¡Œé‡æ„ï¼Œä»¥ä¾¿å½»åº•ç†è§£è¯¥æ¡†æ¶ã€‚æœ€åï¼Œä½ å°†æ„å»ºä¸€ä¸ªå¤æ‚çš„æ–‡ç« å†™ä½œæ™ºèƒ½ä½“ï¼Œå®ƒå°†èåˆè¯¾ç¨‹ä¸­çš„æ‰€æœ‰å­¦ä¹ å†…å®¹ã€‚\n\nåœ¨æ­¤æ³¨å†Œï¼https://t.co/ZDpjLmdyDL"
  },
  {
    "id": "1798063159787577843",
    "url": "https://x.com/AndrewYNg/status/1798063159787577843",
    "text": "We just released a new climate emulator to explore the application of Stratospheric Aerosol Injection (SAI) to mitigate global warming!\n\nSAI uses reflective particles in the atmosphere to reflect sunlight and thereby cool Earthâ€™s surface. Our emulator lets you explore how different ways to apply SAI might affect average global temperature.\n\nPlease check out the emulator at https://t.co/OxtaQMyDuL.\n\nSAI is a promising direction, but we still need more research to better understand its impact and potential implementation.\n\nBig thanks to collaborators @jeremy_irvin16 @DanVisioni Ben Kravitz @dakotagruener @chrisroadmap and @DWatsonParris",
    "createdAt": "Tue Jun 04 18:43:58 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 163,
    "replyCount": 95,
    "likeCount": 987,
    "quoteCount": 37,
    "viewCount": 140885,
    "bookmarkCount": 268,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä»¬åˆšåˆšå‘å¸ƒäº†ä¸€æ¬¾å…¨æ–°çš„æ°”å€™æ¨¡æ‹Ÿå™¨ï¼Œæ—¨åœ¨æ¢ç´¢å¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ (SAI) åœ¨ç¼“è§£å…¨çƒå˜æš–æ–¹é¢çš„åº”ç”¨ï¼\n\nå¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ (SAI) çš„åŸç†æ˜¯åˆ©ç”¨å¤§æ°”ä¸­çš„åå°„ç²’å­æ¥åå°„å¤ªé˜³å…‰ï¼Œä»è€Œè¾¾åˆ°å†·å´åœ°çƒè¡¨é¢çš„ç›®çš„ã€‚æˆ‘ä»¬çš„æ¨¡æ‹Ÿå™¨èƒ½å¸®åŠ©ä½ æ¢ç´¢ï¼Œä»¥ä¸åŒæ–¹å¼å®æ–½ SAI å¯èƒ½å¯¹å…¨çƒå¹³å‡æ¸©åº¦äº§ç”Ÿæ€æ ·çš„å½±å“ã€‚\n\næ¬¢è¿è®¿é—® https://t.co/OxtaQMyDuL ä½“éªŒè¿™æ¬¾æ¨¡æ‹Ÿå™¨ã€‚\n\nSAI æ˜¯ä¸€ä¸ªå¾ˆæœ‰å‰æ™¯çš„æ–¹å‘ï¼Œä½†æˆ‘ä»¬ä»éœ€æ›´å¤šç ”ç©¶ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å…¶å½±å“ä»¥åŠå¦‚ä½•æ½œåœ¨åœ°å®æ–½ã€‚\n\nè¡·å¿ƒæ„Ÿè°¢æ‰€æœ‰åˆä½œè€…ï¼š@jeremy_irvin16ã€@DanVisioniã€Ben Kravitzã€@dakotagruenerã€@chrisroadmap å’Œ @DWatsonParrisã€‚"
  },
  {
    "id": "1796206876805489105",
    "url": "https://x.com/AndrewYNg/status/1796206876805489105",
    "text": "A barrier to faster progress in generative AI is evaluations (evals), particularly of custom AI  applications that generate free-form text. Letâ€™s say you have a multi-agent research system that includes a researcher agent and a writer agent. Would adding a fact-checking agent improve the results? If we canâ€™t efficiently evaluate the impact of such changes, itâ€™s hard to know which changes to keep.\n\nFor evaluating general-purpose foundation models such as large language models (LLMs) â€” which are trained to respond to a large variety of prompts â€” we have standardized tests like MMLU (multiple-choice questions that cover 57 disciplines like math, philosophy, and medicine) and HumanEval (testing code generation); the LMSYS Chatbot arena, which pits two LLMsâ€™ responses against each other and asks a human to judge which response is superior; and large-scale benchmarking like HELM. These evaluation tools took considerable effort to build, and they are invaluable for giving LLM users a sense of different models' relative performance. Nonetheless, they have limitations: For example, leakage of benchmarks datasetsâ€™ questions and answers into training data is a constant worry, and human preference for certain answers does not mean those answers are more accurate.\n\nIn contrast, our current options for evaluating specific applications built using LLMs are far more limited. Here, I see two major types of applications.\n- For applications designed to deliver unambiguous, right-or-wrong responses, we have reasonable options. Letâ€™s say we want an LLM to read a resume and extract the candidate's most recent job title, or read a customer email and route it to the right department. We can create a test set that comprises ground-truth labeled examples with the right responses, and measure the percentage of times the LLM generates the right output. The main bottleneck is creating the labeled test set, which is expensive but surmountable.\n- But many LLM-based applications generate free-text output with no single right response. For example, if we ask an LLM to summarize customer emails, thereâ€™s a multitude of possible good (and bad) responses. The same holds for an agentic system to do web research and write an article about a topic, or a RAG system for answering questions. Itâ€™s impractical to hire an army of human experts to read the LLMâ€™s outputs every time we tweak the algorithm and evaluate if the answers have improved â€” we need an automated way to test the outputs. Thus, many teams use an advanced language model to evaluate outputs. In the customer email summarization example, we might design an evaluation rubric (scoring criteria) for what makes a good summary. Given an email summary generated by our system, we might prompt an advanced LLM to read it and score it according to our rubric. Iâ€™ve found that the results of such a procedure, while better than nothing, can also be noisy â€” sometimes too noisy to reliably tell me if the way Iâ€™ve tweaked an algorithm is good or bad.\n\nThe cost of running evals poses an additional challenge. Letâ€™s say youâ€™re using an LLM that costs $10 per million input tokens, and a typical query has 1000 tokens. Each user query therefore costs only $0.01. However, if you iteratively work to improve your algorithm based on 1000 test examples, and if in a single day you evaluate 20 ideas, then your cost will be 20*1000*0.01 = $200. For many projects Iâ€™ve worked on, the development costs were fairly negligible until we started doing evals, whereupon the costs suddenly increased. (If the product turned out to be successful, then costs increased even more at deployment, but that was something we were happy to see!)\n\nIn addition to the dollar cost, evals also have a significant time cost. Running evals on 1000 examples might take tens of minutes or even hours. Time spent waiting for eval jobs to finish also slows down the speed with which we can experiment and iterate over new ideas. Previously I wrote that fast, inexpensive token generation is critical for agentic workflows. This will also be useful for evals, which involve nested for-loops that iterate over a test set and different model/hyperparameter/prompt choices and therefore consume large numbers of tokens.\n\nDespite the limitations of today's eval methodologies, Iâ€™m optimistic that our community will invent better techniques (maybe involving agentic workflows like reflection?) for getting LLMs to evaluate such output.\n\nIf youâ€™re a developer or researcher and have ideas along these lines, I hope youâ€™ll keep working on them and consider open sourcing or publishing your findings!\n\n[Original text: https://t.co/HXtzJH7eP8 ]",
    "createdAt": "Thu May 30 15:47:45 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 162,
    "replyCount": 60,
    "likeCount": 881,
    "quoteCount": 26,
    "viewCount": 186788,
    "bookmarkCount": 597,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ç”Ÿæˆå¼ AI (Generative AI) æƒ³è¦å–å¾—æ›´å¿«è¿›å±•ï¼Œä¸€å¤§é˜»ç¢å°±æ˜¯è¯„ä¼° (evals)ï¼Œå°¤å…¶æ˜¯å¯¹é‚£äº›èƒ½ç”Ÿæˆè‡ªç”±æ ¼å¼æ–‡æœ¬çš„å®šåˆ¶åŒ– AI åº”ç”¨ç¨‹åºçš„è¯„ä¼°ã€‚æ¯”æ–¹è¯´ï¼Œä½ æœ‰ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿï¼Œé‡Œé¢åŒ…å«ä¸€ä¸ªç ”ç©¶å‘˜æ™ºèƒ½ä½“å’Œä¸€ä¸ªå†™ä½œè€…æ™ºèƒ½ä½“ã€‚é‚£ä¹ˆï¼Œå¦‚æœå†åŠ ä¸€ä¸ªäº‹å®æ ¸æŸ¥æ™ºèƒ½ä½“ï¼Œæ•ˆæœä¼šæ›´å¥½å—ï¼Ÿå¦‚æœæˆ‘ä»¬æ— æ³•é«˜æ•ˆåœ°è¯„ä¼°è¿™äº›æ”¹åŠ¨å¸¦æ¥çš„å½±å“ï¼Œå°±å¾ˆéš¾çŸ¥é“ç©¶ç«Ÿå“ªäº›æ”¹åŠ¨å€¼å¾—ä¿ç•™ã€‚\n\nå¯¹äºè¯„ä¼°åƒå¤§è¯­è¨€æ¨¡å‹ (LLMs) è¿™æ ·çš„é€šç”¨åŸºç¡€æ¨¡å‹â€”â€”è¿™äº›æ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œèƒ½å¤Ÿå“åº”å„ç§å„æ ·çš„æç¤ºâ€”â€”æˆ‘ä»¬æœ‰ä¸€å¥—æ ‡å‡†åŒ–çš„æµ‹è¯•æ–¹æ³•ã€‚ä¾‹å¦‚ï¼ŒMMLU (åŒ…å«æ•°å­¦ã€å“²å­¦ã€åŒ»å­¦ç­‰ 57 ä¸ªå­¦ç§‘çš„å¤šé¡¹é€‰æ‹©é¢˜) å’Œ HumanEval (æµ‹è¯•ä»£ç ç”Ÿæˆèƒ½åŠ›)ï¼›LMSYS Chatbot Arenaï¼Œå®ƒé€šè¿‡è®©ä¸¤ä¸ª LLM çš„å›ç­”è¿›è¡Œæ¯”æ‹¼ï¼Œå¹¶ç”±äººç±»åˆ¤æ–­å“ªä¸ªå›ç­”æ›´ä¼˜ï¼›ä»¥åŠåƒ HELM è¿™æ ·çš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ã€‚è¿™äº›è¯„ä¼°å·¥å…·çš„æ„å»ºè€—è´¹äº†å·¨å¤§çš„ç²¾åŠ›ï¼Œå®ƒä»¬å¯¹äº LLM ç”¨æˆ·äº†è§£ä¸åŒæ¨¡å‹çš„ç›¸å¯¹æ€§èƒ½æ¥è¯´æ˜¯æ— ä»·ä¹‹å®ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä¹Ÿå¹¶éæ²¡æœ‰å±€é™æ€§ï¼šä¾‹å¦‚ï¼ŒåŸºå‡†æµ‹è¯•æ•°æ®é›†çš„é—®é¢˜å’Œç­”æ¡ˆå¯èƒ½ä¼šæ³„éœ²åˆ°è®­ç»ƒæ•°æ®ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ªæŒç»­çš„æ‹…å¿§ï¼›è€Œä¸”äººç±»åå¥½çš„ç­”æ¡ˆä¸ä¸€å®šå°±æ„å‘³ç€å®ƒä»¬æ›´å‡†ç¡®ã€‚\n\nç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬ç›®å‰ç”¨äºè¯„ä¼°åŸºäº LLM æ„å»ºçš„ç‰¹å®šåº”ç”¨ç¨‹åºçš„é€‰é¡¹åˆ™è¦æœ‰é™å¾—å¤šã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œè¿™ç±»åº”ç”¨ç¨‹åºä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š\n- å¯¹äºé‚£äº›æ—¨åœ¨æä¾›æ˜ç¡®çš„ã€éå¯¹å³é”™å“åº”çš„åº”ç”¨ï¼Œæˆ‘ä»¬æœ‰ç›¸å¯¹æˆç†Ÿçš„è¯„ä¼°æ–¹æ¡ˆã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¸Œæœ› LLM é˜…è¯»ä¸€ä»½ç®€å†ï¼Œæå–å€™é€‰äººæœ€è¿‘çš„èŒä½åç§°ï¼Œæˆ–è€…é˜…è¯»ä¸€å°å®¢æˆ·é‚®ä»¶ï¼Œå°†å…¶è·¯ç”±åˆ°æ­£ç¡®çš„éƒ¨é—¨ã€‚è¿™æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæµ‹è¯•é›†ï¼Œå…¶ä¸­åŒ…å«å¸¦æœ‰æ­£ç¡®å“åº”çš„çœŸå®æ ‡ç­¾ç¤ºä¾‹ï¼Œç„¶åæµ‹é‡ LLM ç”Ÿæˆæ­£ç¡®è¾“å‡ºçš„ç™¾åˆ†æ¯”ã€‚ä¸»è¦çš„æŒ‘æˆ˜åœ¨äºåˆ›å»ºè¿™æ ·çš„æ ‡ç­¾æµ‹è¯•é›†ï¼Œè¿™è™½ç„¶æˆæœ¬ä¸è²ï¼Œä½†å¹¶éæ— æ³•å…‹æœã€‚\n- ç„¶è€Œï¼Œè®¸å¤šåŸºäº LLM çš„åº”ç”¨ä¼šç”Ÿæˆå¼€æ”¾å¼æ–‡æœ¬è¾“å‡ºï¼Œå¾€å¾€æ²¡æœ‰å”¯ä¸€æ­£ç¡®çš„ç­”æ¡ˆã€‚æ¯”å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¦æ±‚ LLM æ€»ç»“å®¢æˆ·é‚®ä»¶ï¼Œå¯èƒ½ä¼šæœ‰æ— æ•°ç§å¥½çš„ (å½“ç„¶ä¹Ÿæœ‰åçš„) æ€»ç»“æ–¹å¼ã€‚å¯¹äºä¸€ä¸ªè´Ÿè´£ç½‘ç»œç ”ç©¶å¹¶æ’°å†™æ–‡ç« çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæˆ–è€…ä¸€ä¸ªç”¨äºå›ç­”é—®é¢˜çš„ RAG ç³»ç»Ÿæ¥è¯´ï¼Œä¹Ÿé¢ä¸´åŒæ ·çš„é—®é¢˜ã€‚æ¯æ¬¡æˆ‘ä»¬è°ƒæ•´ç®—æ³•ï¼Œå¹¶æƒ³è¯„ä¼°ç­”æ¡ˆæ˜¯å¦æœ‰æ‰€æ”¹è¿›æ—¶ï¼Œéƒ½é›‡ä½£ä¸€æ”¯åºå¤§çš„äººç±»ä¸“å®¶å›¢é˜Ÿæ¥é˜…è¯» LLM çš„è¾“å‡ºï¼Œè¿™æ˜¯ä¸ç°å®çš„ã€‚æˆ‘ä»¬éœ€è¦ä¸€ç§è‡ªåŠ¨åŒ–çš„æ–¹æ³•æ¥æµ‹è¯•è¿™äº›è¾“å‡ºã€‚å› æ­¤ï¼Œè®¸å¤šå›¢é˜Ÿé€‰æ‹©ä½¿ç”¨å…ˆè¿›çš„è¯­è¨€æ¨¡å‹æ¥è¯„ä¼°è¾“å‡ºã€‚åœ¨å®¢æˆ·é‚®ä»¶æ€»ç»“çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè®¾è®¡ä¸€å¥—è¯„ä¼°å‡†åˆ™ (è¯„åˆ†æ ‡å‡†) æ¥å®šä¹‰ä»€ä¹ˆæ‰ç®—ä¸€ä»½å¥½çš„æ€»ç»“ã€‚ç„¶åï¼Œå¯¹äºç³»ç»Ÿç”Ÿæˆçš„ä¸€ä»½é‚®ä»¶æ€»ç»“ï¼Œæˆ‘ä»¬å°±å¯ä»¥æç¤ºä¸€ä¸ªå…ˆè¿›çš„ LLM æ¥é˜…è¯»å®ƒï¼Œå¹¶æ ¹æ®æˆ‘ä»¬çš„å‡†åˆ™è¿›è¡Œè¯„åˆ†ã€‚æˆ‘å‘ç°ï¼Œè¿™ç§æ–¹æ³•çš„è¯„ä¼°ç»“æœè™½ç„¶èŠèƒœäºæ— ï¼Œä½†ä¹Ÿå¯èƒ½å……æ»¡å™ªå£°â€”â€”æœ‰æ—¶è¿™ç§å™ªå£°å¤§åˆ°æ— æ³•å¯é åœ°å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯¹ç®—æ³•çš„è°ƒæ•´ç©¶ç«Ÿæ˜¯å¥½æ˜¯åã€‚\n\nè¿è¡Œè¯„ä¼°çš„æˆæœ¬ä¹Ÿå¸¦æ¥äº†é¢å¤–çš„æŒ‘æˆ˜ã€‚å‡è®¾ä½ æ­£åœ¨ä½¿ç”¨ä¸€ä¸ª LLMï¼Œæ¯ç™¾ä¸‡è¾“å…¥ Token æˆæœ¬ä¸º 10 ç¾å…ƒï¼Œè€Œä¸€æ¬¡å…¸å‹æŸ¥è¯¢åŒ…å« 1000 ä¸ª Tokenã€‚è¿™æ ·ç®—ä¸‹æ¥ï¼Œæ¯ä¸ªç”¨æˆ·æŸ¥è¯¢çš„æˆæœ¬ä»…ä¸º 0.01 ç¾å…ƒã€‚ç„¶è€Œï¼Œå¦‚æœä½ åŸºäº 1000 ä¸ªæµ‹è¯•ç¤ºä¾‹æ¥è¿­ä»£æ”¹è¿›ç®—æ³•ï¼Œå¹¶ä¸”å¦‚æœä½ åœ¨ä¸€å¤©ä¹‹å†…è¯„ä¼°äº† 20 ä¸ªä¸åŒçš„æƒ³æ³•ï¼Œé‚£ä¹ˆä½ çš„æˆæœ¬å°†æ˜¯ 20 * 1000 * 0.01 = 200 ç¾å…ƒã€‚åœ¨æˆ‘å‚ä¸è¿‡çš„è®¸å¤šé¡¹ç›®ä¸­ï¼Œåœ¨å¼€å§‹è¿›è¡Œè¯„ä¼°ä¹‹å‰ï¼Œå¼€å‘æˆæœ¬éƒ½ç›¸å½“å¾®ä¸è¶³é“ï¼Œè€Œä¸€æ—¦å¯åŠ¨è¯„ä¼°ï¼Œæˆæœ¬å°±ä¼šçªç„¶é£™å‡ã€‚(å¦‚æœäº§å“æœ€ç»ˆè·å¾—æˆåŠŸï¼Œé‚£ä¹ˆéƒ¨ç½²æ—¶çš„æˆæœ¬è¿˜ä¼šæ›´é«˜ï¼Œä½†è¿™é€šå¸¸æ˜¯æˆ‘ä»¬ä¹è§å…¶æˆçš„äº‹ï¼)\n\né™¤äº†é‡‘é’±æˆæœ¬ï¼Œè¯„ä¼°è¿˜éœ€è¦è€—è´¹å¤§é‡æ—¶é—´ã€‚å¯¹ 1000 ä¸ªç¤ºä¾‹è¿›è¡Œè¯„ä¼°å¯èƒ½éœ€è¦æ•°ååˆ†é’Ÿç”šè‡³æ•°å°æ—¶ã€‚ç­‰å¾…è¯„ä¼°ä»»åŠ¡å®Œæˆçš„æ—¶é—´ï¼Œä¹Ÿä¼šæ‹–æ…¢æˆ‘ä»¬å®éªŒå’Œè¿­ä»£æ–°æƒ³æ³•çš„é€Ÿåº¦ã€‚æˆ‘ä¹‹å‰æ›¾æåˆ°ï¼Œå¿«é€Ÿã€å»‰ä»·çš„ Token ç”Ÿæˆå¯¹äºæ™ºèƒ½ä½“å·¥ä½œæµè‡³å…³é‡è¦ã€‚è¿™å¯¹äºè¯„ä¼°åŒæ ·å¤§æœ‰è£¨ç›Šï¼Œå› ä¸ºè¯„ä¼°æ¶‰åŠåµŒå¥—çš„ for å¾ªç¯ï¼Œéœ€è¦éå†æµ‹è¯•é›†ä»¥åŠä¸åŒçš„æ¨¡å‹ã€è¶…å‚æ•°å’Œæç¤ºé€‰æ‹©ï¼Œå› æ­¤ä¼šæ¶ˆè€—å¤§é‡çš„ Tokenã€‚\n\nå°½ç®¡ç›®å‰çš„è¯„ä¼°æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œæˆ‘ä»ç„¶ä¹è§‚åœ°è®¤ä¸ºï¼Œæˆ‘ä»¬çš„ç¤¾åŒºå°†å‘æ˜å‡ºæ›´å¥½çš„æŠ€æœ¯ (ä¹Ÿè®¸ä¼šæ¶‰åŠåƒåæ€è¿™æ ·çš„æ™ºèƒ½ä½“å·¥ä½œæµï¼Ÿ) æ¥è®© LLM æ›´å¥½åœ°è¯„ä¼°æ­¤ç±»è¾“å‡ºã€‚\n\nå¦‚æœä½ æ˜¯å¼€å‘äººå‘˜æˆ–ç ”ç©¶äººå‘˜ï¼Œå¹¶ä¸”åœ¨è¿™äº›æ–¹é¢æœ‰ä»»ä½•æƒ³æ³•ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½ç»§ç»­åŠªåŠ›ï¼Œå¹¶è€ƒè™‘å¼€æºæˆ–å…¬å¸ƒä½ çš„ç ”ç©¶æˆæœï¼\n\n[åŸæ–‡é“¾æ¥: https://t.co/HXtzJH7eP8 ]"
  },
  {
    "id": "1795845101979406490",
    "url": "https://x.com/AndrewYNg/status/1795845101979406490",
    "text": "New Agentic AI short course! AI Agentic Design Patterns with AutoGen, taught by @MSFTResearch's @Chi_Wang_ and @penn_state's @qingyun_wu, shows you how to use AutoGen to implement agentic design patterns like multi-agent collaboration, sequential and nested chat, reflection, tool use, and planning. Learn how to build and combine multiple specialized agents â€“ such as researchers, planners, coders, writers, and critics â€“ that interact to execute complex workflows, like generating detailed financial reports, that would otherwise have taken extensive manual effort.\n\nThis course illustrates key agentic design principles with many fun demonstrations. For example, you'll build a conversational chess game using two player agents, each of which can use a tool to validate moves and update the board state, while engaging in lively banter about the game!\n\nI've enjoyed using AutoGen, and think you will too. Sign up to get started here:  https://t.co/C0tsLuilMf",
    "createdAt": "Wed May 29 15:50:12 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 294,
    "replyCount": 60,
    "likeCount": 1496,
    "quoteCount": 26,
    "viewCount": 215378,
    "bookmarkCount": 1143,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…¨æ–°çš„ AI æ™ºèƒ½ä½“ (Agentic AI) çŸ­æœŸè¯¾ç¨‹æ¥äº†ï¼ç”± @MSFTResearch çš„ @Chi_Wang_ å’Œ @penn_state çš„ @qingyun_wu æ•™æˆçš„â€œåŸºäº AutoGen çš„ AI æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼â€è¯¾ç¨‹ï¼Œå°†å‘ä½ å±•ç¤ºå¦‚ä½•åˆ©ç”¨ AutoGen å®ç°å„ç§æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼ï¼Œä¾‹å¦‚å¤šæ™ºèƒ½ä½“åä½œã€é¡ºåºå’ŒåµŒå¥—èŠå¤©ã€è‡ªæˆ‘åæ€ã€å·¥å…·ä½¿ç”¨ä»¥åŠè§„åˆ’ç­‰ã€‚ä½ å°†å­¦ä¹ å¦‚ä½•æ„å»ºå’Œç»„åˆå¤šä¸ªä¸“ä¸šçš„æ™ºèƒ½ä½“â€”â€”æ¯”å¦‚ç ”ç©¶å‘˜ã€è§„åˆ’è€…ã€ç¨‹åºå‘˜ã€ä½œå®¶å’Œè¯„è®ºå‘˜â€”â€”è®©å®ƒä»¬ååŒå·¥ä½œï¼Œä»¥å®Œæˆå¤æ‚çš„ä»»åŠ¡æµç¨‹ï¼Œä¾‹å¦‚ç”Ÿæˆè¯¦ç»†çš„è´¢åŠ¡æŠ¥å‘Šï¼Œè€Œè¿™äº›ä»»åŠ¡è‹¥éå¦‚æ­¤ï¼Œå°†éœ€è¦å¤§é‡çš„äººå·¥æ“ä½œã€‚\n\næœ¬è¯¾ç¨‹é€šè¿‡è®¸å¤šæœ‰è¶£çš„æ¼”ç¤ºï¼Œé˜é‡Šäº†å…³é”®çš„ AI æ™ºèƒ½ä½“è®¾è®¡åŸåˆ™ã€‚ä¾‹å¦‚ï¼Œä½ å°†æ„å»ºä¸€ä¸ªå¯¹è¯å¼å›½é™…è±¡æ£‹æ¸¸æˆï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªç©å®¶æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½èƒ½ä½¿ç”¨å·¥å…·æ¥éªŒè¯æ£‹æ­¥å¹¶æ›´æ–°æ£‹ç›˜çŠ¶æ€ï¼ŒåŒæ—¶å®ƒä»¬è¿˜èƒ½å°±æ£‹å±€å±•å¼€å¦™è¶£æ¨ªç”Ÿçš„å¯¹è¯ï¼\n\næˆ‘ä¸ªäººéå¸¸å–œæ¬¢ä½¿ç”¨ AutoGenï¼Œç›¸ä¿¡ä½ ä¹Ÿä¼šå¦‚æ­¤ã€‚ç‚¹å‡»è¿™é‡Œæ³¨å†Œï¼Œå³åˆ»å¼€å¯ä½ çš„å­¦ä¹ ä¹‹æ—…ï¼š https://t.co/C0tsLuilMf"
  },
  {
    "id": "1793760961343701045",
    "url": "https://x.com/AndrewYNg/status/1793760961343701045",
    "text": "@greg_karsten Thank you for sharing this -- I think a lot of people feel similarly as you. Please keep tinkering, and from your description it sounds to me like you're making good progress! ğŸ‰",
    "createdAt": "Thu May 23 21:48:34 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 0,
    "likeCount": 12,
    "quoteCount": 0,
    "viewCount": 2132,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@greg_karsten æ„Ÿè°¢ä½ åˆ†äº«è¿™äº›æƒ³æ³•â€”â€”æˆ‘æƒ³å¾ˆå¤šäººéƒ½å’Œä½ æœ‰ç€ç›¸ä¼¼çš„æ„Ÿå—ã€‚è¯·ç»§ç»­ä½ çš„æ¢ç´¢å’Œå°è¯•ï¼Œå¬ä½ æè¿°çš„æƒ…å†µï¼Œçœ‹æ¥ä½ æ­£åœ¨å–å¾—ä¸é”™çš„è¿›å±•ï¼ğŸ‰"
  },
  {
    "id": "1793673520863715396",
    "url": "https://x.com/AndrewYNg/status/1793673520863715396",
    "text": "A good way to get started in AI is to start with coursework, which gives a systematic way to gain knowledge, and then to work on projects. For many who hear this advice, â€œprojectsâ€ may evoke a significant undertaking that delivers value to users. But I encourage you to set a lower bar and relish small, weekend tinkering projects that let you learn, even if they donâ€™t result in a meaningful deliverable.\n\nRecently, my son and daughter (ages 3 and 5) were building Lego vehicles. They built a beautiful ice-cream truck as well as a . . . umm . . . colorful and asymmetric dinosaur car, shown in the picture below. While most observers would judge the ice-cream truck as the superior creation, my kids built it by following Legoâ€™s instructions, and it is likely identical to thousands of ice-cream trucks built by others. In contrast, building the dinosaur car required creativity and novel thinking. The exercise helped them hone their ability to pick and assemble Lego building blocks.\n\nThere is, of course, room for both mimicking othersâ€™ designs (with permission) and coming up with your own. As a parent, I try to celebrate both. (To be honest, I celebrated the dinosaur car more.) When learning to build Lego, itâ€™s helpful to start by following a template. But eventually, building your own unique projects enriches your skills.\n\nAs a developer, too, I try to celebrate unique creations. Yes, it is nice to have beautiful software, and the impact of the output does matter. But good software is often written by people who spend many hours tinkering and building things. By building unique projects, you master key software building blocks. Then, using those blocks, you can go on to build bigger projects\n\nI routinely tinker with building AI applications, and a lot of my tinkering doesnâ€™t result in anything useful. My latest example: I built a Streamlit app that would authenticate to Google docs, read the text in a doc, use a large language model to edit my text, and write the result back into the doc. I didnâ€™t find it useful in the end because of friction in the user interface, and Iâ€™m sure a commercial provider will soon, if they havenâ€™t already, build a better product than I was able to throw together in a couple of hours on a weekend. But such tinkering helps me hone my intuition and master software components (I now know how to programmatically interface with Google docs) that might be useful in future projects.\n\nIf you have an idea for a project, I encourage you to build it! Often, working on a project will also help you decide what additional skills to learn, perhaps through coursework. To sustain momentum, it helps to find friends with whom to talk about ideas and celebrate projects â€” large or small.\n\n[Original text: https://t.co/i21oCaQpDc ]",
    "createdAt": "Thu May 23 16:01:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 141,
    "replyCount": 38,
    "likeCount": 897,
    "quoteCount": 12,
    "viewCount": 91383,
    "bookmarkCount": 281,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æƒ³è¦è¿ˆå…¥ AI é¢†åŸŸï¼Œä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹æ–¹å¼æ˜¯å­¦ä¹ ç›¸å…³è¯¾ç¨‹ï¼Œè¿™èƒ½å¸®ä½ ç³»ç»Ÿåœ°ç§¯ç´¯çŸ¥è¯†ï¼Œéšåä¾¿æ˜¯ç€æ‰‹å®è·µé¡¹ç›®ã€‚å¾ˆå¤šäººå¬åˆ°â€œé¡¹ç›®â€è¿™ä¸ªè¯ï¼Œè„‘æµ·ä¸­å¯èƒ½ä¼šæµ®ç°å‡ºé‚£äº›èƒ½ä¸ºç”¨æˆ·åˆ›é€ ä»·å€¼çš„ã€æ„ä¹‰é‡å¤§çš„å·¥ä½œã€‚ä½†æˆ‘é¼“åŠ±ä½ æ”¾ä½æ ‡å‡†ï¼Œå°½æƒ…æŠ•å…¥é‚£äº›å°å‹çš„ã€åˆ©ç”¨å‘¨æœ«æ—¶é—´ä¿®ä¿®è¡¥è¡¥çš„é¡¹ç›®ï¼Œå®ƒä»¬èƒ½è®©ä½ ä»ä¸­å­¦ä¹ ï¼Œå³ä½¿æœ€ç»ˆæ²¡æœ‰äº§ç”Ÿä»€ä¹ˆâ€œæ‹¿å¾—å‡ºæ‰‹â€çš„æˆæœã€‚\n\næœ€è¿‘ï¼Œæˆ‘çš„å„¿å­å’Œå¥³å„¿ï¼ˆåˆ†åˆ«ä¸º3å²å’Œ5å²ï¼‰æ­£åœ¨æ­å»ºä¹é«˜ç©å…·ã€‚ä»–ä»¬æ‹¼å‡ºäº†ä¸€è¾†æ¼‚äº®çš„å†°æ·‡æ·‹è½¦ï¼Œè¿˜æœ‰ä¸€è¾†â€¦â€¦å—¯â€¦â€¦é€ å‹ç‹¬ç‰¹ã€è‰²å½©é²œè‰³ä¸”ä¸å¯¹ç§°çš„æé¾™è½¦ï¼Œæ­£å¦‚ä½ ä»ä¸‹å›¾æ‰€çœ‹åˆ°çš„ã€‚è™½ç„¶å¤§å¤šæ•°æ—è§‚è€…ä¼šè§‰å¾—å†°æ·‡æ·‹è½¦æ›´ç²¾ç¾ï¼Œä½†é‚£æ˜¯æˆ‘çš„å­©å­ä»¬ç…§ç€ä¹é«˜è¯´æ˜ä¹¦æ‹¼å‡ºæ¥çš„ï¼Œå¯èƒ½å’Œæˆåƒä¸Šä¸‡å…¶ä»–äººæ‹¼å‡ºçš„å†°æ·‡æ·‹è½¦ä¸€æ¨¡ä¸€æ ·ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ­å»ºé‚£è¾†æé¾™è½¦åˆ™éœ€è¦æ›´å¤šçš„åˆ›é€ åŠ›å’Œæ–°é¢–æ€ç»´ã€‚è¿™ä¸ªè¿‡ç¨‹å¸®åŠ©ä»–ä»¬é”»ç‚¼äº†æŒ‘é€‰å’Œç»„è£…ä¹é«˜ç§¯æœ¨çš„èƒ½åŠ›ã€‚\n\nå½“ç„¶ï¼Œæ¨¡ä»¿ä»–äººçš„è®¾è®¡ï¼ˆåœ¨è·å¾—è®¸å¯çš„å‰æä¸‹ï¼‰å’Œè‡ªå·±åˆ›é€ è®¾è®¡ï¼Œä¸¤è€…éƒ½æœ‰å…¶ä»·å€¼ã€‚ä½œä¸ºä¸€åå®¶é•¿ï¼Œæˆ‘åŠªåŠ›å¯¹è¿™ä¸¤ç§åˆ›é€ éƒ½è¡¨ç¤ºè®¤å¯ã€‚ï¼ˆè¯´å®è¯ï¼Œæˆ‘å¯¹é‚£è¾†æé¾™è½¦æ›´â€œåçˆ±â€ä¸€äº›ã€‚ï¼‰åœ¨å­¦ä¹ æ­å»ºä¹é«˜æ—¶ï¼Œä»éµå¾ªæ¨¡æ¿å¼€å§‹ç¡®å®æœ‰æ‰€å¸®åŠ©ã€‚ä½†æœ€ç»ˆï¼Œæ­å»ºè‡ªå·±ç‹¬ä¸€æ— äºŒçš„é¡¹ç›®æ‰èƒ½çœŸæ­£ä¸°å¯Œä½ çš„æŠ€èƒ½ã€‚\n\nä½œä¸ºä¸€åå¼€å‘è€…ï¼Œæˆ‘ä¹ŸåŠªåŠ›æ¨å´‡ç‹¬åˆ›æ€§çš„ä½œå“ã€‚æ²¡é”™ï¼Œæ‹¥æœ‰ç²¾ç¾çš„è½¯ä»¶å›ºç„¶æ˜¯å¥½äº‹ï¼Œå…¶äº§å‡ºçš„å½±å“ä¹Ÿç¡®å®é‡è¦ã€‚ä½†ä¼˜ç§€çš„è½¯ä»¶å¾€å¾€æ˜¯ç”±é‚£äº›æŠ•å…¥å¤§é‡æ—¶é—´ä¿®ä¿®è¡¥è¡¥ã€ä¸æ–­æ„å»ºçš„äººå†™å‡ºæ¥çš„ã€‚é€šè¿‡æ„å»ºç‹¬ç‰¹çš„é¡¹ç›®ï¼Œä½ å¯ä»¥æŒæ¡å…³é”®çš„è½¯ä»¶æ„å»ºæ¨¡å—ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™äº›æ¨¡å—ï¼Œä½ å°±èƒ½ç€æ‰‹æ„å»ºæ›´å¤§çš„é¡¹ç›®ã€‚\n\næˆ‘ç»å¸¸ä¼šæ£é¼“ç€å¼€å‘ä¸€äº› AI åº”ç”¨ç¨‹åºï¼Œå…¶ä¸­å¾ˆå¤šå°è¯•æœ€ç»ˆéƒ½æ²¡æœ‰ä»€ä¹ˆå®é™…ç”¨å¤„ã€‚ä¸¾ä¸ªæœ€è¿‘çš„ä¾‹å­ï¼šæˆ‘æ›¾å¼€å‘äº†ä¸€ä¸ª Streamlit åº”ç”¨ï¼Œå®ƒå¯ä»¥è¿æ¥åˆ° Google Docs è¿›è¡Œèº«ä»½éªŒè¯ï¼Œè¯»å–æ–‡æ¡£ä¸­çš„æ–‡æœ¬ï¼Œç„¶åä½¿ç”¨ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ (Large Language Model) æ¥ç¼–è¾‘æˆ‘çš„æ–‡æœ¬ï¼Œå¹¶å°†ç»“æœå†™å›æ–‡æ¡£ã€‚ä½†ç”±äºç”¨æˆ·ç•Œé¢ (UI) çš„ä¸€äº›ä¸ä¾¿ï¼Œæˆ‘æœ€ç»ˆè§‰å¾—å®ƒä¸å¤ªå®ç”¨ã€‚æˆ‘ç›¸ä¿¡ï¼Œå¾ˆå¿«å°±ä¼šæœ‰å•†ä¸šå…¬å¸ï¼ˆå¦‚æœä»–ä»¬è¿˜æ²¡åšï¼‰æ¨å‡ºæ¯”æˆ‘å‘¨æœ«èŠ±å‡ ä¸ªå°æ—¶æ‹¼å‡‘å‡ºæ¥çš„äº§å“æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚ä½†å³ä¾¿å¦‚æ­¤ï¼Œè¿™æ ·çš„ä¿®ä¿®è¡¥è¡¥ä¹Ÿå¸®åŠ©æˆ‘ç£¨ç»ƒäº†ç›´è§‰ï¼Œå¹¶æŒæ¡äº†è®¸å¤šè½¯ä»¶ç»„ä»¶ï¼ˆæ¯”å¦‚æˆ‘ç°åœ¨çŸ¥é“å¦‚ä½•é€šè¿‡ç¼–ç¨‹æ–¹å¼ä¸ Google Docs è¿›è¡Œäº¤äº’ï¼‰ï¼Œè¿™äº›çŸ¥è¯†å¯èƒ½åœ¨æœªæ¥çš„é¡¹ç›®ä¸­å‘æŒ¥ä½œç”¨ã€‚\n\nå¦‚æœä½ æœ‰ä¸€ä¸ªé¡¹ç›®çš„æƒ³æ³•ï¼Œæˆ‘éå¸¸é¼“åŠ±ä½ å»åŠ¨æ‰‹å®ç°å®ƒï¼å¾ˆå¤šæ—¶å€™ï¼Œç€æ‰‹ä¸€ä¸ªé¡¹ç›®ä¹Ÿä¼šå¸®ä½ æ˜ç¡®è¿˜éœ€è¦å­¦ä¹ å“ªäº›é¢å¤–çš„æŠ€èƒ½ï¼Œä¹Ÿè®¸è¿™åˆä¼šä¿ƒä½¿ä½ ç»§ç»­å­¦ä¹ æ–°çš„è¯¾ç¨‹ã€‚ä¸ºäº†ä¿æŒè¿™ä»½çƒ­æƒ…ï¼Œæ‰¾ä¸€äº›å¿—åŒé“åˆçš„æœ‹å‹ï¼Œä¸€èµ·äº¤æµæƒ³æ³•ï¼Œå…±åŒåº†ç¥é¡¹ç›®çš„è¿›å±•â€”â€”æ— è®ºé¡¹ç›®å¤§å°â€”â€”éƒ½å°†å¤§æœ‰è£¨ç›Šã€‚\n\n[Original text: https://t.co/i21oCaQpDc ]"
  },
  {
    "id": "1792986667852374386",
    "url": "https://x.com/AndrewYNg/status/1792986667852374386",
    "text": "Thank you! Itâ€™s been a privilege for Landing AI to work with you @RamaswmySridhar, \n@jeffhollan, and the whole Snowflake team. Many businesses have a lot of image data, and integrating our vision software to run as a native app in Snowpark Container Services makes it easy for users to get insights out of their vision data stored in Snowflake. @danmaloney and I also look forward to seeing you at the Summit!",
    "createdAt": "Tue May 21 18:31:48 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 2,
    "replyCount": 2,
    "likeCount": 11,
    "quoteCount": 0,
    "viewCount": 2076,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "è°¢è°¢ï¼Landing AI å¾ˆè£å¹¸èƒ½ä¸ @RamaswmySridharã€@jeffhollan ä»¥åŠæ•´ä¸ª Snowflake å›¢é˜Ÿåˆä½œã€‚è®¸å¤šä¼ä¸šéƒ½æ‹¥æœ‰æµ·é‡çš„å›¾åƒæ•°æ®ï¼Œè€Œæˆ‘ä»¬å°†è§†è§‰è½¯ä»¶é›†æˆåˆ° Snowpark Container Services ä¸­ï¼Œä½¿å…¶èƒ½ä½œä¸ºåŸç”Ÿåº”ç”¨è¿è¡Œï¼Œè¿™è®©ç”¨æˆ·å¯ä»¥è½»æ¾åœ°ä»å­˜å‚¨åœ¨ Snowflake ä¸­çš„è§†è§‰æ•°æ®é‡Œè·å–æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚@danmaloney å’Œæˆ‘ä¹ŸæœŸå¾…èƒ½åœ¨å³°ä¼š (Summit) ä¸Šä¸æ‚¨è§é¢ï¼"
  },
  {
    "id": "1792919935691214899",
    "url": "https://x.com/AndrewYNg/status/1792919935691214899",
    "text": "Learn to deploy AI models to edge devices in our new short course Introduction to On-Device AI, created with @Qualcomm and taught by Senior Director of Engineering @krishna_srd.\n\nI think on-device (edge) AI is an important technology trend that's enabling new low latency, privacy-preserving applications. In this course, you'll deploy a real-time image segmentation model on-device, and through this learn key steps for on-device deployment: Neural Network graph capture, on-device compilation, hardware acceleration, and validating on-device numerical correctness. You'll also see how quantization can make your model up to 4x faster and 4x smaller, and thereby improve its performance on resource-constrained edge devices.\n\nThe techniques covered are used to deploy models on numerous device types including smartphones, drones, and robots, and are enabling many new, creative applications. \n\nPlease sign up here: https://t.co/V4mS6E7dXx",
    "createdAt": "Tue May 21 14:06:38 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 199,
    "replyCount": 34,
    "likeCount": 981,
    "quoteCount": 14,
    "viewCount": 112667,
    "bookmarkCount": 508,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨æˆ‘ä»¬çš„å…¨æ–°çŸ­æœŸè¯¾ç¨‹ã€ŠOn-Device AI ä»‹ç»ã€‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°† AI æ¨¡å‹éƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ã€‚æœ¬è¯¾ç¨‹ç”± Qualcomm è”åˆæ‰“é€ ï¼Œå¹¶ç”±å·¥ç¨‹é«˜çº§æ€»ç›‘ Krishna Sarda äº²è‡ªæˆè¯¾ã€‚\n\næˆ‘è®¤ä¸ºè®¾å¤‡ç«¯ AI (On-Device AI) æˆ–ç§°ä¸ºè¾¹ç¼˜ AI (Edge AI) æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯è¶‹åŠ¿ï¼Œå®ƒæ­£åœ¨èµ‹èƒ½è®¸å¤šä½å»¶è¿Ÿã€æ³¨é‡éšç§çš„åº”ç”¨ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†äº²æ‰‹éƒ¨ç½²ä¸€ä¸ªå®æ—¶å›¾åƒåˆ†å‰²æ¨¡å‹åˆ°è®¾å¤‡ç«¯ï¼Œå¹¶é€šè¿‡è¿™ä¸ªè¿‡ç¨‹æŒæ¡è®¾å¤‡ç«¯éƒ¨ç½²çš„å…³é”®æ­¥éª¤ï¼šç¥ç»ç½‘ç»œå›¾æ•è· (Neural Network graph capture)ã€è®¾å¤‡ç«¯ç¼–è¯‘ (on-device compilation)ã€ç¡¬ä»¶åŠ é€Ÿ (hardware acceleration)ï¼Œä»¥åŠéªŒè¯è®¾å¤‡ç«¯æ•°å€¼æ­£ç¡®æ€§ (on-device numerical correctness)ã€‚ä½ è¿˜å°†äº†è§£åˆ°é‡åŒ– (quantization) æŠ€æœ¯å¦‚ä½•èƒ½è®©ä½ çš„æ¨¡å‹é€Ÿåº¦æå‡ 4 å€ï¼ŒåŒæ—¶ä½“ç§¯ç¼©å° 4 å€ï¼Œä»è€Œæ˜¾è‘—æå‡æ¨¡å‹åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ€§èƒ½ã€‚\n\nè¯¾ç¨‹ä¸­æ¶µç›–çš„æŠ€æœ¯å¹¿æ³›åº”ç”¨äºåŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€æ— äººæœºå’Œæœºå™¨äººåœ¨å†…çš„å¤šç§è®¾å¤‡ç±»å‹ä¸Šéƒ¨ç½² AI æ¨¡å‹ï¼Œå¹¶æ­£åœ¨å‚¬ç”Ÿè®¸å¤šæ–°é¢–ã€å¯Œæœ‰åˆ›æ„çš„åº”ç”¨ã€‚\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/V4mS6E7dXx"
  },
  {
    "id": "1791134037178020308",
    "url": "https://x.com/AndrewYNg/status/1791134037178020308",
    "text": "This week, Google announced a doubling of Gemini Pro 1.5's input context window from 1 million to 2 million tokens, and OpenAI released GPT-4o, which generates tokens 2x faster and 50% cheaper than GPT-4 Turbo and natively accepts and generates multimodal tokens. I view these developments as the latest in an 18-month trend. Given the improvements we've seen, best practices for developers have changed as well.\n\nSince the launch of ChatGPT in Nov 2022, with key milestones that include the releases of GPT-4, Gemini 1.5 Pro, Claude 3 Opus, and Llama 3-70B, many model providers have improved their capabilities in two important ways: (i) reasoning, which allows LLMs to think through complex concepts and and follow complex instructions; and (ii) longer input context windows. \n\nThe reasoning capability of GPT-4 and other advanced models makes them quite good at interpreting complex prompts with detailed instructions. Many people are used to dashing off a quick, 1- to 2-sentence query to an LLM. In contrast, when building applications, I see sophisticated teams frequently writing prompts that might be 1 to 2 pages long (my teams call them â€œmega-promptsâ€) that provide complex instructions to specify in detail how weâ€™d like an LLM to perform a task. I still see teams not going far enough in terms of writing detailed instructions. For an example of a moderately lengthy prompt, take a look at Claude 3â€™s system prompt. Itâ€™s detailed and gives clear guidance on how Claude should behave. \n\nThis is a very different style of prompting than we typically use with LLMsâ€™ web user interfaces, where we might dash off a quick query and, if the response is unsatisfactory, clarify what we want through repeated conversational turns with the chatbot.\n\nFurther, the increasing length of input context windows has added another technique to the developerâ€™s toolkit. GPT-3 kicked off a lot of research on few-shot in-context learning. For example, if youâ€™re using an LLM for text classification, you might give a handful â€” say 1 to 5 examples â€” of text snippets and their class labels, so that it can use those examples to generalize to additional texts. However, with longer input context windows â€” GPT-4o accepts 128,000 input tokens, Claude 3 Opus 200,000 tokens, and Gemini 1.5 Pro 1 million tokens (2 million just announced in a limited preview) â€” LLMs arenâ€™t limited to a handful of examples. With many-shot learning, developers can give dozens, even hundreds of examples in the prompt, and this works better than few-shot learning. \n\nWhen building complex workflows, I see developers getting good results with this process: \n- Write quick, simple prompts and see how it does.\n- Based on where the output falls short, flesh out the prompt iteratively. This often leads to a longer, more detailed, prompt, perhaps even a mega-prompt.\n- If thatâ€™s still insufficient, consider few-shot or many-shot learning (if applicable) or, less frequently, fine-tuning.\n- If that still doesnâ€™t yield the results you need, break down the task into subtasks and apply an agentic workflow.\n\nI hope a process like this will help you build applications more easily. If youâ€™re interested in taking a deeper dive into prompting strategies, I recommend Microsoft's Medprompt paper (Nori et al., 2023), which lays out a complex set of prompting strategies that can lead to very good results.\n\n[Original text (with links): https://t.co/UOtLDza1Vh ]",
    "createdAt": "Thu May 16 15:50:06 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 553,
    "replyCount": 74,
    "likeCount": 2873,
    "quoteCount": 66,
    "viewCount": 505103,
    "bookmarkCount": 2067,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æœ¬å‘¨ï¼ŒGoogle å®£å¸ƒå°† Gemini Pro 1.5 çš„è¾“å…¥ä¸Šä¸‹æ–‡çª—å£ (input context window) å®¹é‡ç¿»å€ï¼Œä» 100 ä¸‡ä¸ª Token å¢åŠ åˆ° 200 ä¸‡ä¸ª Token ï¼›åŒæ—¶ï¼ŒOpenAI å‘å¸ƒäº† GPT-4oï¼Œå®ƒçš„ Token (Token) ç”Ÿæˆé€Ÿåº¦æ˜¯ GPT-4 Turbo çš„ 2 å€ï¼Œæˆæœ¬é™ä½ 50%ï¼Œå¹¶ä¸”èƒ½å¤ŸåŸç”Ÿæ”¯æŒå¤šæ¨¡æ€ (multimodal) Token çš„è¾“å…¥å’Œç”Ÿæˆã€‚æˆ‘è®¤ä¸ºè¿™äº›å‘å±•æ˜¯è¿‡å» 18 ä¸ªæœˆè¶‹åŠ¿çš„æœ€æ–°ä½“ç°ã€‚é‰´äºæˆ‘ä»¬æ‰€è§çš„è¿™äº›è¿›æ­¥ï¼Œå¼€å‘äººå‘˜çš„æœ€ä½³å®è·µ (best practices) ä¹Ÿéšä¹‹å‘ç”Ÿäº†æ”¹å˜ã€‚\n\nè‡ª 2022 å¹´ 11 æœˆ ChatGPT å‘å¸ƒä»¥æ¥ï¼Œéšç€ GPT-4ã€Gemini 1.5 Proã€Claude 3 Opus å’Œ Llama 3-70B ç­‰é‡è¦é‡Œç¨‹ç¢‘çš„æ¨å‡ºï¼Œè®¸å¤šæ¨¡å‹æä¾›å•†åœ¨ä¸¤ä¸ªå…³é”®æ–¹é¢æå‡äº†å…¶èƒ½åŠ›ï¼š(i) æ¨ç† (reasoning) èƒ½åŠ›ï¼Œè¿™ä½¿å¾—å¤§è¯­è¨€æ¨¡å‹ (LLM) èƒ½å¤Ÿå¤„ç†å¤æ‚æ¦‚å¿µå¹¶éµå¾ªå¤æ‚æŒ‡ä»¤ï¼›(ii) æ›´é•¿çš„è¾“å…¥ä¸Šä¸‹æ–‡çª—å£ã€‚\n\nGPT-4 åŠå…¶ä»–å…ˆè¿›æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶åœ¨ç†è§£å¸¦æœ‰è¯¦ç»†è¯´æ˜çš„å¤æ‚æç¤º (prompt) æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚è®¸å¤šäººä¹ æƒ¯äºå‘å¤§è¯­è¨€æ¨¡å‹ éšæ„å‘å‡º 1 åˆ° 2 å¥è¯çš„ç®€çŸ­æŸ¥è¯¢ã€‚ç„¶è€Œï¼Œåœ¨æ„å»ºåº”ç”¨ç¨‹åºæ—¶ï¼Œæˆ‘å‘ç°ä¸“ä¸šçš„å›¢é˜Ÿç»å¸¸ä¼šç¼–å†™é•¿è¾¾ 1 åˆ° 2 é¡µçš„æç¤º ï¼ˆæˆ‘çš„å›¢é˜Ÿç§°ä¹‹ä¸ºâ€œå·¨å‹æç¤ºâ€ï¼‰ï¼Œè¿™äº›æç¤ºæä¾›äº†å¤æ‚çš„æŒ‡ä»¤ï¼Œè¯¦ç»†åœ°è¯´æ˜äº†æˆ‘ä»¬å¸Œæœ›å¤§è¯­è¨€æ¨¡å‹ å¦‚ä½•æ‰§è¡ŒæŸé¡¹ä»»åŠ¡ã€‚ä½†æˆ‘å‘ç°ä»æœ‰å›¢é˜Ÿåœ¨ç¼–å†™è¯¦ç»†æŒ‡ä»¤æ—¶æœªèƒ½å……åˆ†å‘æŒ¥å…¶æ½œåŠ›ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæƒ³äº†è§£ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„æç¤ºï¼Œå¯ä»¥å‚è€ƒ Claude 3 çš„ç³»ç»Ÿæç¤ºã€‚å®ƒéå¸¸è¯¦ç»†ï¼Œå¹¶å°± Claude åº”å¦‚ä½•è¡¨ç°æä¾›äº†æ¸…æ™°çš„æŒ‡å¯¼ã€‚\n\nè¿™ä¸æˆ‘ä»¬é€šå¸¸åœ¨ å¤§è¯­è¨€æ¨¡å‹ çš„ç½‘é¡µç”¨æˆ·ç•Œé¢ä¸­ä½¿ç”¨çš„æç¤ºé£æ ¼æˆªç„¶ä¸åŒï¼Œåœ¨ç½‘é¡µç•Œé¢ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¿«é€Ÿæå‡ºä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœå›å¤ä¸å°½å¦‚äººæ„ï¼Œå°±ä¼šé€šè¿‡ä¸èŠå¤©æœºå™¨äººåå¤å¯¹è¯æ¥æ¾„æ¸…æˆ‘ä»¬çš„æ„å›¾ã€‚\n\næ­¤å¤–ï¼Œè¾“å…¥ä¸Šä¸‹æ–‡çª—å£é•¿åº¦çš„å¢åŠ ä¸ºå¼€å‘äººå‘˜çš„å·¥å…·ç®±å¢æ·»äº†ä¸€é¡¹æ–°æŠ€æœ¯ã€‚GPT-3 å‚¬ç”Ÿäº†å¤§é‡å…³äºå°‘æ ·æœ¬ (Few-shot) ä¸Šä¸‹æ–‡å­¦ä¹  (in-context learning) çš„ç ”ç©¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æ­£åœ¨ä½¿ç”¨ å¤§è¯­è¨€æ¨¡å‹ è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼Œä½ å¯èƒ½ä¼šæä¾›å°‘é‡â€”â€”æ¯”å¦‚ 1 åˆ° 5 ä¸ªä¾‹å­â€”â€”çš„æ–‡æœ¬ç‰‡æ®µåŠå…¶å¯¹åº”çš„ç±»åˆ«æ ‡ç­¾ï¼Œè¿™æ ·æ¨¡å‹å°±å¯ä»¥åˆ©ç”¨è¿™äº›ä¾‹å­æ¥æ¨æ–­æˆ–åº”ç”¨äºå…¶ä»–æ–‡æœ¬ã€‚ç„¶è€Œï¼Œéšç€è¾“å…¥ä¸Šä¸‹æ–‡çª—å£çš„ä¸æ–­åŠ é•¿â€”â€”GPT-4o æ”¯æŒ 128,000 ä¸ªè¾“å…¥ Token ï¼ŒClaude 3 Opus æ”¯æŒ 200,000 ä¸ª Token ï¼Œè€Œ Gemini 1.5 Pro æ”¯æŒ 100 ä¸‡ä¸ª Token ï¼ˆæœ€è¿‘å®£å¸ƒåœ¨æœ‰é™é¢„è§ˆç‰ˆä¸­è¾¾åˆ° 200 ä¸‡ä¸ªï¼‰â€”â€” å¤§è¯­è¨€æ¨¡å‹ ä¸å†ä»…é™äºæä¾›å°‘é‡ä¾‹å­ã€‚é€šè¿‡å¤šæ ·æœ¬ (many-shot) å­¦ä¹ ï¼Œå¼€å‘äººå‘˜å¯ä»¥åœ¨æç¤ºä¸­ç»™å‡ºå‡ åç”šè‡³æ•°ç™¾ä¸ªä¾‹å­ï¼Œå¹¶ä¸”è¿™ç§æ–¹æ³•é€šå¸¸æ¯”å°‘æ ·æœ¬ å­¦ä¹ æ•ˆæœæ›´å¥½ã€‚\n\nåœ¨æ„å»ºå¤æ‚å·¥ä½œæµæ—¶ï¼Œæˆ‘å‘ç°å¼€å‘äººå‘˜é€šè¿‡ä»¥ä¸‹æµç¨‹èƒ½è·å¾—è‰¯å¥½æ•ˆæœï¼š\n- å…ˆç¼–å†™å¿«é€Ÿã€ç®€å•çš„æç¤ºï¼Œè§‚å¯Ÿå…¶è¡¨ç°ã€‚\n- æ ¹æ®è¾“å‡ºçš„ä¸è¶³ä¹‹å¤„ï¼Œè¿­ä»£åœ°å……å®å’Œå®Œå–„æç¤ºã€‚è¿™é€šå¸¸ä¼šå½¢æˆä¸€ä¸ªæ›´é•¿ã€æ›´è¯¦ç»†çš„æç¤ºï¼Œç”šè‡³å¯èƒ½æ˜¯ä¸€ä¸ªå·¨å‹æç¤ºã€‚\n- å¦‚æœè¿™ä»ç„¶ä¸å¤Ÿï¼Œå¯ä»¥è€ƒè™‘é‡‡ç”¨å°‘æ ·æœ¬ æˆ–å¤šæ ·æœ¬ å­¦ä¹  ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ï¼Œæˆ–è€…ï¼Œä¸é‚£ä¹ˆé¢‘ç¹åœ°ï¼Œè¿›è¡Œå¾®è°ƒ (fine-tuning)ã€‚\n- å¦‚æœä¾ç„¶æœªèƒ½è·å¾—æ‰€éœ€ç»“æœï¼Œåˆ™å°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œå¹¶é‡‡ç”¨ AI æ™ºèƒ½ä½“ (AI Agent) å·¥ä½œæµã€‚\n\næˆ‘å¸Œæœ›è¿™æ ·çš„æµç¨‹èƒ½å¸®åŠ©ä½ æ›´è½»æ¾åœ°æ„å»ºåº”ç”¨ç¨‹åºã€‚å¦‚æœä½ æœ‰å…´è¶£æ·±å…¥æ¢ç´¢æç¤ºç­–ç•¥ï¼Œæˆ‘æ¨èé˜…è¯» Microsoft çš„ Medprompt è®ºæ–‡ (Nori et al., 2023)ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€å¥—å¤æ‚çš„æç¤ºç­–ç•¥ï¼Œèƒ½å¤Ÿå¸¦æ¥éå¸¸å¥½çš„ç»“æœã€‚\n\n[åŸæ–‡é“¾æ¥ (åŒ…å«é“¾æ¥): https://t.co/UOtLDza1Vh ]"
  },
  {
    "id": "1790769732146307308",
    "url": "https://x.com/AndrewYNg/status/1790769732146307308",
    "text": "New agentic short course! Multi AI Agent Systems with crewAI, built with @crewAIInc's founder and CEO @joaomdmoura. In this course, you'll learn how to break down complex tasks into subtasks for multiple AI agents, each playing a specialized role, to execute. \n\nFor example, to generate a research report, you might have researcher, writer, and quality assurance agents collaborate. You'll define the roles, expectations, and interactions between the agentsâ€”like a manager organizing a team.\n\nYou'll work with key agentic AI techniques like role-playing, tool use, memory, guardrails, and cross-agent collaboration. And you'll build your own multi-agent systems that can tackle complex tasks. I think you'll find it both productive and fun to design agents and watch them collaborate to get things done.\n\nLet me know what you think! I believe multi-agent architectures will drive significant progress in AI systems.\n\nPlease sign up here! https://t.co/0rObe4feBz",
    "createdAt": "Wed May 15 15:42:29 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 278,
    "replyCount": 85,
    "likeCount": 1490,
    "quoteCount": 46,
    "viewCount": 348115,
    "bookmarkCount": 1255,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "é‡ç£…æ¨å‡ºå…¨æ–°åŸºäºæ™ºèƒ½ä½“çš„çŸ­æœŸè¯¾ç¨‹ï¼ä¸ @crewAIInc çš„åˆ›å§‹äººå…¼ CEO @joaomdmoura å…±åŒæ‰“é€ çš„ Multi AI Agent Systems with crewAIã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œå¹¶åˆ†é…ç»™ä¸åŒçš„ AI æ™ºèƒ½ä½“ (AI Agent) æ¥æ‰§è¡Œï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æ‰®æ¼”ç€ä¸“ä¸šçš„è§’è‰²ã€‚\n\nä¾‹å¦‚ï¼Œä¸ºäº†ç”Ÿæˆä¸€ä»½ç ”ç©¶æŠ¥å‘Šï¼Œä½ å¯èƒ½éœ€è¦è®©ç ”ç©¶å‘˜ã€ä½œè€…å’Œè´¨é‡ä¿è¯æ™ºèƒ½ä½“ç›¸äº’åä½œã€‚ä½ å°†å®šä¹‰è¿™äº›æ™ºèƒ½ä½“ä¹‹é—´çš„è§’è‰²ã€é¢„æœŸè¡Œä¸ºä»¥åŠå®ƒä»¬å¦‚ä½•äº’åŠ¨â€”â€”å°±åƒä¸€ä½ç»ç†åœ¨ç»„ç»‡ä¸€ä¸ªå›¢é˜Ÿã€‚\n\nä½ å°†æ¥è§¦å¹¶è¿ç”¨å…³é”®çš„æ™ºèƒ½ä½“ AI æŠ€æœ¯ï¼Œä¾‹å¦‚è§’è‰²æ‰®æ¼” (role-playing)ã€å·¥å…·ä½¿ç”¨ (tool use)ã€è®°å¿† (memory)ã€æŠ¤æ  (guardrails) ä»¥åŠè·¨æ™ºèƒ½ä½“åä½œ (cross-agent collaboration)ã€‚ä½ è¿˜å°†äº²æ‰‹æ„å»ºè‡ªå·±çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿèƒ½å¤Ÿåº”å¯¹å„ç§å¤æ‚ä»»åŠ¡ã€‚æˆ‘ç›¸ä¿¡ä½ ä¼šå‘ç°è®¾è®¡æ™ºèƒ½ä½“å¹¶çœ‹ç€å®ƒä»¬ååŒå·¥ä½œæ¥å®Œæˆä»»åŠ¡ï¼Œæ—¢å¯Œæœ‰æˆæ•ˆåˆå……æ»¡ä¹è¶£ã€‚\n\næœŸå¾…å¬åˆ°ä½ çš„æƒ³æ³•ï¼æˆ‘ç›¸ä¿¡å¤šæ™ºèƒ½ä½“æ¶æ„å°†ä¸º AI ç³»ç»Ÿå¸¦æ¥çªç ´æ€§çš„è¿›å±•ã€‚\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼https://t.co/0rObe4feBz"
  },
  {
    "id": "1790500978279776450",
    "url": "https://x.com/AndrewYNg/status/1790500978279776450",
    "text": "Congratulations to all my Google friends for the cool announcements at I/O! \n\nI'm personally looking forward to Gemini with 2 million token input context window and better support for on-device AI -- should open up new opportunities for application builders!",
    "createdAt": "Tue May 14 21:54:33 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 72,
    "replyCount": 36,
    "likeCount": 1061,
    "quoteCount": 6,
    "viewCount": 112230,
    "bookmarkCount": 68,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ­å–œæˆ‘æ‰€æœ‰çš„è°·æ­Œæœ‹å‹ä»¬åœ¨ I/O å¤§ä¼šä¸Šçš„ç²¾å½©å‘å¸ƒï¼\n\næˆ‘ä¸ªäººéå¸¸æœŸå¾…æ‹¥æœ‰ 200 ä¸‡ token è¾“å…¥ä¸Šä¸‹æ–‡çª—å£çš„ Geminiï¼Œä»¥åŠå¯¹è®¾å¤‡ç«¯ AI (on-device AI) çš„æ›´å¥½æ”¯æŒâ€”â€”è¿™åº”è¯¥ä¼šä¸ºåº”ç”¨å¼€å‘è€…ä»¬å¼€å¯æ–°çš„æœºé‡ï¼"
  },
  {
    "id": "1790088683259048120",
    "url": "https://x.com/AndrewYNg/status/1790088683259048120",
    "text": "Congrats to OpenAI for the release of GPT-4o! 2x faster and 50% cheaper tokens will be great for everyone using agentic AI workflows. \n\nWhen an agentic job that used to take 10min now takes 5min just by switching APIs, that's great progress!",
    "createdAt": "Mon May 13 18:36:14 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 222,
    "replyCount": 46,
    "likeCount": 1934,
    "quoteCount": 7,
    "viewCount": 184926,
    "bookmarkCount": 158,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "æ­å–œ OpenAI å‘å¸ƒ GPT-4oï¼é€Ÿåº¦æå‡ä¸¤å€ã€token ä»·æ ¼é™ä½50%ï¼Œè¿™å¯¹æ‰€æœ‰ä½¿ç”¨ AI æ™ºèƒ½ä½“ (Agentic AI) å·¥ä½œæµçš„ç”¨æˆ·æ¥è¯´éƒ½å°†æ˜¯é‡å¤§åˆ©å¥½ã€‚\n\nå¦‚æœä¸€ä¸ª AI æ™ºèƒ½ä½“ä»»åŠ¡è¿‡å»éœ€è¦10åˆ†é’Ÿï¼Œç°åœ¨ä»…ä»…é€šè¿‡åˆ‡æ¢ API å°±èƒ½åœ¨5åˆ†é’Ÿå†…å®Œæˆï¼Œé‚£æ— ç–‘æ˜¯å·¨å¤§çš„è¿›æ­¥ï¼"
  },
  {
    "id": "1790050852776112439",
    "url": "https://x.com/AndrewYNg/status/1790050852776112439",
    "text": "New short course: Building Multimodal Search and RAG\", by @weaviate_io's  @sebawita.\n\nContrastive learning is used to train models to map vectors into an embedding space by pulling similar concepts closer together and pushing dissimilar concepts away from each other. This technique is also used to train multimodal embedding models that capture semantic similarity across different modalities like text, images, and audio. These multimodal embeddings can be used to build multimodal search and RAG systems.\n\nIn this course, you'll learn how contrastive learning works, and how to add multimodality to RAG â€“ so your models can draw on diverse, relevant context to answer questions. For example, a query about a financial report might synthesize information from text snippets, graphs, tables, and slides. You will also learn how visual instruction tuning lets you integrate image understanding into language models, and build a multi-vector recommender system using Weaviateâ€™s open-source vector database.\n\nPlease sign up here: https://t.co/IVULLqbdOD",
    "createdAt": "Mon May 13 16:05:55 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 179,
    "replyCount": 19,
    "likeCount": 836,
    "quoteCount": 9,
    "viewCount": 103888,
    "bookmarkCount": 531,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°çŸ­æœŸè¯¾ç¨‹ï¼šã€Šæ„å»ºå¤šæ¨¡æ€æœç´¢å’ŒRAGã€‹ï¼Œç”±@weaviate_ioçš„@sebawitaä¸»è®²ã€‚\n\nå¯¹æ¯”å­¦ä¹  (Contrastive learning) æ˜¯ä¸€ç§è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼Œå®ƒé€šè¿‡æ‹‰è¿‘ç›¸ä¼¼æ¦‚å¿µçš„å‘é‡å¹¶æ¨è¿œä¸ç›¸ä¼¼æ¦‚å¿µçš„å‘é‡ï¼Œä»è€Œå°†å®ƒä»¬æ˜ å°„åˆ°ä¸€ä¸ªåµŒå…¥ç©ºé—´ (embedding space) ä¸­ã€‚è¿™é¡¹æŠ€æœ¯ä¹Ÿè¢«ç”¨äºè®­ç»ƒå¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿæ•æ‰æ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘ç­‰ä¸åŒæ¨¡æ€ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚åˆ©ç”¨è¿™äº›å¤šæ¨¡æ€åµŒå…¥ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºå¤šæ¨¡æ€æœç´¢å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿã€‚\n\nåœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¯¹æ¯”å­¦ä¹ çš„å·¥ä½œåŸç†ï¼Œä»¥åŠå¦‚ä½•ä¸º RAG å¼•å…¥å¤šæ¨¡æ€èƒ½åŠ›â€”â€”è¿™æ ·ä½ çš„æ¨¡å‹å°±èƒ½åˆ©ç”¨å¤šæ ·åŒ–ä¸”ç›¸å…³çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå½“æŸ¥è¯¢ä¸€ä»½è´¢åŠ¡æŠ¥å‘Šæ—¶ï¼Œæ¨¡å‹å¯ä»¥ç»¼åˆæ–‡æœ¬ç‰‡æ®µã€å›¾è¡¨ã€è¡¨æ ¼å’Œå¹»ç¯ç‰‡ä¸­çš„ä¿¡æ¯ã€‚ä½ è¿˜å°†å­¦ä¹ è§†è§‰æŒ‡ä»¤å¾®è°ƒ (visual instruction tuning) å¦‚ä½•å°†å›¾åƒç†è§£èƒ½åŠ›æ•´åˆåˆ°å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œå¹¶ä½¿ç”¨ Weaviate çš„å¼€æºå‘é‡æ•°æ®åº“æ„å»ºä¸€ä¸ªå¤šå‘é‡æ¨èç³»ç»Ÿã€‚\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/IVULLqbdOD"
  },
  {
    "id": "1788648531873628607",
    "url": "https://x.com/AndrewYNg/status/1788648531873628607",
    "text": "Last week, I spoke about AI and regulations at an event at the U.S. Capitol attended by legislative and business leaders. Iâ€™m encouraged by the progress the open source community has made fending off regulations that would have stifled innovation. But opponents of open source are continuing to shift their arguments, with the latest worries centering on open source's impact on national security. I hope weâ€™ll all keep protecting open source!\n\nBased on my conversations with legislators, Iâ€™m encouraged by the progress the U.S. federal government has made getting a realistic grasp of AIâ€™s risks. To be clear, guardrails are needed. But they should be applied to AI applications, not to general-purpose AI technology.\n\nNonetheless, some companies are eager to limit open source, possibly to protect the value of massive investments theyâ€™ve made in proprietary models and to deter competitors. It has been fascinating to watch their arguments change over time.\n\nFor instance, about 12 months ago, the Center For AI Safetyâ€™s â€œStatement on AI Riskâ€ warned that AI could cause human extinction and stoked fears of AI taking over. This alarmed leaders in Washington. But many people in AI pointed out that this dystopian science-fiction scenario had little basis in reality. About six months later, when I testified at the U.S. Senateâ€™s AI Insight forum, legislators no longer worried much about an AI takeover.\n\nThen the opponents of open source shifted gears. Their leading argument shifted to the risk of AI helping to create bioweapons. Soon afterward, OpenAI and RAND showed that current AI does not significantly increase the ability of malefactors to build bioweapons. This fear of AI-enabled bioweapons has diminished. To be sure, the possibility that bad actors could use bioweapons â€” with or without AI â€” remains a topic of great international concern.\n\nThe latest argument for blocking open source AI has shifted to national security. AI is useful for both economic competition and warfare, and open source opponents say the U.S. should make sure its adversaries donâ€™t have access to the latest foundation models. While I donâ€™t want authoritarian governments to use AI, particularly to wage unjust wars, the LLM cat is out of the bag, and authoritarian countries will fill the vacuum if democratic nations limit access. When, some day, a child asks an AI system questions about democracy, the role of a free press, or the function of an independent judiciary in preserving the rule of law, I would like the AI to reflect democratic values rather than favor authoritarian leadersâ€™ goals over, say, human rights.\n\nI came away from Washington optimistic about the progress weâ€™ve made. A  year ago, legislators seemed to me to spend 80% of their time talking about guardrails for AI and 20% about investing in innovation. I was delighted that the ratio has flipped, and there was far more talk of investing in innovation.\nLooking beyond the U.S. federal government, there are many jurisdictions globally. Unfortunately, arguments in favor of  regulations that would stifle AI development continue to proliferate. But Iâ€™ve learned from my trips to Washington and other nationsâ€™ capitals that talking to regulators does have an impact. If you have a chance to talk to a regulator at any level, I hope youâ€™ll do what you can to help governments better understand AI.\n\n[Original text (with links): https://t.co/tw2iT0ooLT ]",
    "createdAt": "Thu May 09 19:13:36 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 253,
    "replyCount": 81,
    "likeCount": 1137,
    "quoteCount": 51,
    "viewCount": 290058,
    "bookmarkCount": 244,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¸Šå‘¨ï¼Œæˆ‘åœ¨ç¾å›½å›½ä¼šå¤§å¦å‚åŠ äº†ä¸€åœºç”±ç«‹æ³•å’Œå•†ä¸šé¢†è¢–å‡ºå¸­çš„æ´»åŠ¨ï¼Œå¹¶åœ¨ä¼šä¸Šè®¨è®ºäº†äººå·¥æ™ºèƒ½ (AI) åŠå…¶ç›‘ç®¡é—®é¢˜ã€‚ä»¤æˆ‘æ„Ÿåˆ°é¼“èˆçš„æ˜¯ï¼Œå¼€æºç¤¾åŒºåœ¨æŠµåˆ¶é‚£äº›å¯èƒ½æ‰¼æ€åˆ›æ–°çš„ç›‘ç®¡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¼€æºçš„åå¯¹è€…ä»¬æ­£ä¸æ–­è°ƒæ•´ä»–ä»¬çš„è®ºç‚¹ï¼Œç›®å‰æœ€æ–°çš„æ‹…å¿§ä¸»è¦é›†ä¸­åœ¨å¼€æºå¯¹å›½å®¶å®‰å…¨å¯èƒ½é€ æˆçš„å½±å“ä¸Šã€‚æˆ‘å¸Œæœ›æˆ‘ä»¬æ‰€æœ‰äººéƒ½èƒ½ç»§ç»­ä¿æŠ¤å¼€æºï¼\n\næ ¹æ®æˆ‘ä¸ç«‹æ³•è€…çš„äº¤æµï¼Œç¾å›½è”é‚¦æ”¿åºœåœ¨åˆ‡å®ç†è§£ AI é£é™©æ–¹é¢æ‰€å–å¾—çš„è¿›å±•ä¹Ÿè®©æˆ‘å¤‡å—é¼“èˆã€‚éœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œä¿éšœæªæ–½ç¡®å®æ˜¯å¿…éœ€çš„ã€‚ä½†è¿™äº›æªæ–½åº”è¯¥åº”ç”¨äº AI åº”ç”¨ç¨‹åºæœ¬èº«ï¼Œè€Œä¸æ˜¯é’ˆå¯¹é€šç”¨çš„ AI æŠ€æœ¯ã€‚\n\nå°½ç®¡å¦‚æ­¤ï¼Œä¸€äº›å…¬å¸ä»ç„¶æ€¥äºé™åˆ¶å¼€æºï¼Œè¿™å¯èƒ½æ˜¯ä¸ºäº†ä¿æŠ¤ä»–ä»¬åœ¨ä¸“æœ‰æ¨¡å‹ä¸ŠæŠ•å…¥çš„å·¨é¢èµ„é‡‘ä»·å€¼ï¼Œå¹¶å€Ÿæ­¤é˜»æ­¢ç«äº‰å¯¹æ‰‹ã€‚è§‚å¯Ÿä»–ä»¬çš„è®ºç‚¹å¦‚ä½•éšç€æ—¶é—´æ¨ç§»è€Œå˜åŒ–ï¼Œä¸€ç›´ä»¤äººç€è¿·ã€‚\n\nä¾‹å¦‚ï¼Œå¤§çº¦ 12 ä¸ªæœˆå‰ï¼Œäººå·¥æ™ºèƒ½å®‰å…¨ä¸­å¿ƒ (Center For AI Safety) çš„ã€ŠAI é£é™©å£°æ˜ã€‹(Statement on AI Risk) æ›¾è­¦å‘Š AI å¯èƒ½å¯¼è‡´äººç±»ç­ç»ï¼Œå¹¶åŠ å‰§äº†äººä»¬å¯¹ AI æ¥ç®¡ä¸–ç•Œçš„ææ…Œã€‚è¿™éœ‡æƒŠäº†åç››é¡¿çš„é¢†å¯¼äººã€‚ä½†è®¸å¤š AI é¢†åŸŸçš„ä¸“ä¸šäººå£«æŒ‡å‡ºï¼Œè¿™ç§åä¹Œæ‰˜é‚¦å¼çš„ç§‘å¹»åœºæ™¯ç¼ºä¹ç°å®åŸºç¡€ã€‚å¤§çº¦å…­ä¸ªæœˆåï¼Œå½“æˆ‘å‡ºå¸­ç¾å›½å‚è®®é™¢çš„ AI æ´å¯Ÿè®ºå›ä½œè¯æ—¶ï¼Œç«‹æ³•è€…ä»¬å·²ç»ä¸å†é‚£ä¹ˆæ‹…å¿ƒ AI æ¥ç®¡çš„é—®é¢˜äº†ã€‚\n\néšåï¼Œå¼€æºçš„åå¯¹è€…ä»¬æ”¹å˜äº†è®ºè°ƒã€‚ä»–ä»¬çš„ä¸»è¦è®ºç‚¹è½¬å‘äº† AI å¯èƒ½å¸®åŠ©åˆ¶é€ ç”Ÿç‰©æ­¦å™¨çš„é£é™©ã€‚æ­¤åä¸ä¹…ï¼ŒOpenAI å’Œ RAND çš„ç ”ç©¶è¡¨æ˜ï¼Œå½“å‰çš„ AI å¹¶æœªæ˜¾è‘—å¢åŠ ä¸æ³•åˆ†å­åˆ¶é€ ç”Ÿç‰©æ­¦å™¨çš„èƒ½åŠ›ã€‚è¿™ç§å¯¹ AI é©±åŠ¨çš„ç”Ÿç‰©æ­¦å™¨çš„ææƒ§å·²ç»å‡å¼±ã€‚å½“ç„¶ï¼Œæ¶æ„è¡Œä¸ºè€…å¯èƒ½ä½¿ç”¨ç”Ÿç‰©æ­¦å™¨â€”â€”æ— è®ºæ˜¯å¦æœ‰ AI è¾…åŠ©â€”â€”è¿™ä»ç„¶æ˜¯ä¸€ä¸ªå—åˆ°å›½é™…ç¤¾ä¼šé«˜åº¦å…³æ³¨çš„è¯é¢˜ã€‚\n\nç›®å‰ï¼Œé˜»ç¢å¼€æº AI çš„æœ€æ–°è®ºç‚¹å·²ç»è½¬å‘å›½å®¶å®‰å…¨ã€‚AI å¯¹äºç»æµç«äº‰å’Œå†›äº‹æˆ˜äº‰éƒ½éå¸¸æœ‰ç”¨ï¼Œå¼€æºçš„åå¯¹è€…å£°ç§°ç¾å›½åº”è¯¥ç¡®ä¿å…¶å¯¹æ‰‹æ— æ³•è·å–æœ€æ–°çš„åŸºç¡€æ¨¡å‹ã€‚è™½ç„¶æˆ‘ä¸å¸Œæœ›å¨æƒæ”¿åºœä½¿ç”¨ AIï¼Œå°¤å…¶æ˜¯å‘åŠ¨éæ­£ä¹‰çš„æˆ˜äº‰ï¼Œä½†æ˜¯å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å‘å±•å·²åŠ¿ä¸å¯æŒ¡ã€‚å¦‚æœæ°‘ä¸»å›½å®¶é™åˆ¶è®¿é—®ï¼Œå¨æƒå›½å®¶åè€Œä¼šå¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚æ€»æœ‰ä¸€å¤©ï¼Œå½“ä¸€ä¸ªå­©å­å‘ AI ç³»ç»Ÿæé—®å…³äºæ°‘ä¸»ã€è‡ªç”±åª’ä½“çš„ä½œç”¨ï¼Œæˆ–è€…ç‹¬ç«‹å¸æ³•æœºæ„åœ¨ç»´æŠ¤æ³•æ²»ä¸­çš„åŠŸèƒ½æ—¶ï¼Œæˆ‘å¸Œæœ› AI èƒ½åæ˜ æ°‘ä¸»ä»·å€¼è§‚ï¼Œè€Œä¸æ˜¯åè¢’å¨æƒé¢†å¯¼äººçš„ç›®æ ‡ï¼Œä½¿å…¶å‡Œé©¾äºäººæƒï¼ˆä¾‹å¦‚ï¼‰ä¹‹ä¸Šã€‚\n\næˆ‘ä»åç››é¡¿å›æ¥æ—¶ï¼Œå¯¹æˆ‘ä»¬æ‰€å–å¾—çš„è¿›å±•æ„Ÿåˆ°ä¹è§‚ã€‚ä¸€å¹´å‰ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼Œç«‹æ³•è€…ä¼¼ä¹å°† 80% çš„æ—¶é—´èŠ±åœ¨è®¨è®º AI çš„ä¿éšœæªæ–½ä¸Šï¼Œè€Œåªæœ‰ 20% çš„æ—¶é—´ç”¨äºæŠ•èµ„åˆ›æ–°ã€‚æˆ‘å¾ˆé«˜å…´è¿™ä¸ªæ¯”ä¾‹å·²ç»å‘ç”Ÿäº†è½¬å˜ï¼Œç°åœ¨æ›´å¤šåœ°æ˜¯åœ¨è®¨è®ºæŠ•èµ„åˆ›æ–°ã€‚\næ”¾çœ¼ç¾å›½è”é‚¦æ”¿åºœä¹‹å¤–ï¼Œå…¨çƒè¿˜æœ‰è®¸å¤šå¸æ³•ç®¡è¾–åŒºã€‚ä¸å¹¸çš„æ˜¯ï¼Œæ”¯æŒå‡ºå°æ‰¼æ€ AI å‘å±•çš„ç›‘ç®¡æªæ–½çš„è®ºç‚¹ä»åœ¨æŒç»­å­˜åœ¨ã€‚ä½†æˆ‘ä»åç››é¡¿å’Œå…¶ä»–å›½å®¶é¦–éƒ½çš„è®¿é—®ä¸­äº†è§£åˆ°ï¼Œä¸ç›‘ç®¡æœºæ„å¯¹è¯ç¡®å®èƒ½äº§ç”Ÿå½±å“ã€‚å¦‚æœä½ æœ‰æœºä¼šä¸ä»»ä½•çº§åˆ«çš„ç›‘ç®¡æœºæ„äº¤è°ˆï¼Œæˆ‘å¸Œæœ›ä½ å°½åŠ›å¸®åŠ©æ”¿åºœæ›´å¥½åœ°ç†è§£ AIã€‚\n\n[åŸæ–‡é“¾æ¥ï¼š https://t.co/tw2iT0ooLT ]"
  },
  {
    "id": "1788246239517282795",
    "url": "https://x.com/AndrewYNg/status/1788246239517282795",
    "text": "Iâ€™m excited to kick off the first of our short courses focused on agents, starting with Building Agentic RAG with LlamaIndex, taught by @jerryjliu0, CEO of @llama_index.\n\nThis covers an important shift in RAG (retrieval augmented generation), in which rather than having the developer write explicit routines to retrieve information to feed into the LLM context, we instead build a RAG agent that that has access to tools for retrieving information. This lets the agent decide what information to fetch, and enables it to answer more complex questions using multi-step reasoning.\n\nIn detail, you'll learn about:\n- Routing: Where your agent will use decision-making to route requests to multiple tools.\n- Tool Use: Where you'll create an interface for agents to select what tool (function call) to use as well as generate the right arguments.\n- Multi-step reasoning with tool use: Where you'll use an LLM to carry out multiple steps of reasoning, while retaining memory throughout the process.\n\nYouâ€™ll also learn how to step through what your agent is doing to debug and improve it iteratively.\n\nItâ€™s an exciting time to build agents. Sign up and get started here! https://t.co/sHhzRRJG0l",
    "createdAt": "Wed May 08 16:35:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 227,
    "replyCount": 24,
    "likeCount": 1247,
    "quoteCount": 21,
    "viewCount": 296183,
    "bookmarkCount": 969,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘å¾ˆé«˜å…´åœ°å®£å¸ƒï¼Œæˆ‘ä»¬é¦–ä¸ªä¸“æ³¨äº AI æ™ºèƒ½ä½“ (Agent) çš„çŸ­æœŸè¯¾ç¨‹å³å°†å¼€è¯¾ï¼Œè¯¾ç¨‹ä¸»é¢˜æ˜¯â€œBuilding Agentic RAG with LlamaIndexâ€ï¼Œç”± @llama_index çš„é¦–å¸­æ‰§è¡Œå®˜ @jerryjliu0 äº²è‡ªæˆè¯¾ã€‚\n\næœ¬æ¬¡è¯¾ç¨‹å°†æ·±å…¥æ¢è®¨ RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ŒRetrieval Augmented Generation) é¢†åŸŸçš„ä¸€ä¸ªé‡è¦è½¬å˜ã€‚è¿‡å»ï¼Œå¼€å‘è€…éœ€è¦ç¼–å†™æ˜ç¡®çš„ä¾‹ç¨‹æ¥æ£€ç´¢ä¿¡æ¯ï¼Œå¹¶å°†å…¶æä¾›ç»™ å¤§è¯­è¨€æ¨¡å‹ (Large Language Model) çš„ä¸Šä¸‹æ–‡ã€‚è€Œç°åœ¨ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª RAG AI æ™ºèƒ½ä½“ï¼Œå®ƒèƒ½å¤Ÿè‡ªè¡Œè®¿é—®å„ç§å·¥å…·æ¥æ£€ç´¢ä¿¡æ¯ã€‚è¿™ä½¿å¾— AI æ™ºèƒ½ä½“å¯ä»¥è‡ªä¸»å†³å®šè·å–å“ªäº›ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¤šæ­¥æ¨ç†æ¥å›ç­”æ›´å¤æ‚çš„é—®é¢˜ã€‚\n\nå…·ä½“æ¥è¯´ï¼Œæ‚¨å°†å­¦ä¹ ä»¥ä¸‹å†…å®¹ï¼š\n- è·¯ç”± (Routing): æ‚¨çš„ AI æ™ºèƒ½ä½“å°†è¿ç”¨å…¶å†³ç­–èƒ½åŠ›ï¼Œå°†è¯·æ±‚è·¯ç”±åˆ°ä¸åŒçš„å·¥å…·ã€‚\n- å·¥å…·ä½¿ç”¨ (Tool Use): æ‚¨å°†ä¸º AI æ™ºèƒ½ä½“åˆ›å»ºä¸€ä¸ªæ¥å£ï¼Œä½¿å…¶èƒ½å¤Ÿé€‰æ‹©è¦ä½¿ç”¨çš„å·¥å…· (å‡½æ•°è°ƒç”¨)ï¼Œå¹¶ç”Ÿæˆæ­£ç¡®çš„å‚æ•°ã€‚\n- ç»“åˆå·¥å…·ä½¿ç”¨çš„å¤šæ­¥æ¨ç† (Multi-step reasoning with tool use): æ‚¨å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨ å¤§è¯­è¨€æ¨¡å‹ æ‰§è¡Œå¤šæ­¥æ¨ç†ï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­ä¿æŒè®°å¿†ã€‚\n\næ‚¨è¿˜å°†å­¦ä¹ å¦‚ä½•é€æ­¥è·Ÿè¸ª AI æ™ºèƒ½ä½“çš„è¿è¡Œè¿‡ç¨‹ï¼Œä»¥ä¾¿è¿›è¡Œè¿­ä»£è°ƒè¯•å’ŒæŒç»­æ”¹è¿›ã€‚\n\nè¿™æ˜¯ä¸€ä¸ªæ„å»º AI æ™ºèƒ½ä½“çš„æ¿€åŠ¨äººå¿ƒçš„æ—¶ä»£ã€‚ç«‹å³æ³¨å†Œï¼Œå¼€å§‹æ‚¨çš„å­¦ä¹ ä¹‹æ—…å§ï¼šhttps://t.co/sHhzRRJG0l"
  },
  {
    "id": "1787525611864695148",
    "url": "https://x.com/AndrewYNg/status/1787525611864695148",
    "text": "Have you used quantization with an open source machine learning library, and wondered how quantization works? How can you preserve model accuracy as you compress from 32 bits to 16, 8, or even 2 bits? In our new short course, Quantization in Depth, taught by @huggingface's @_marcsun and @younesbelkada, you'll learn to implement variants of linear quantization, such as asymmetric and symmetric modes, from scratch. You'll also quantize at different granularities (per-tensor, per-channel, per-group) to maintain performance. Youâ€™ll then construct a quantizer to compress any open source deep learning modelâ€™s dense layers to 8-bit precision. Finally, youâ€™ll practice quantizing weights into 2 bits by packing four 2-bit weights into a single 8-bit integer.\n\nIf you've ever run a large open source model on your laptop, you've likely benefited from someone's work in quantization. Come learn how this key technique works under the hood!\n\nPlease sign up here: https://t.co/lPfRY0LdFI",
    "createdAt": "Mon May 06 16:51:31 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 191,
    "replyCount": 22,
    "likeCount": 1174,
    "quoteCount": 15,
    "viewCount": 197942,
    "bookmarkCount": 745,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ‚¨æ˜¯å¦æ›¾åœ¨å¼€æºæœºå™¨å­¦ä¹ åº“ä¸­å°è¯•è¿‡**é‡åŒ–** (quantization)ï¼Œå¹¶å¥½å¥‡å®ƒç©¶ç«Ÿæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿå½“æ‚¨éœ€è¦å°†æ¨¡å‹ä» 32 ä½å‹ç¼©åˆ° 16 ä½ã€8 ä½ç”šè‡³ä½è‡³ 2 ä½æ—¶ï¼Œè¯¥å¦‚ä½•ç¡®ä¿æ¨¡å‹çš„å‡†ç¡®æ€§ä¸æ‰“æŠ˜æ‰£å‘¢ï¼Ÿåœ¨æˆ‘ä»¬çš„æ–°çŸ­æœŸè¯¾ç¨‹ã€Šæ·±åº¦é‡åŒ–ã€‹(Quantization in Depth) ä¸­ï¼Œæ‚¨å°†è·Ÿéš @huggingface çš„ @_marcsun å’Œ @younesbelkada ä¸¤ä½è€å¸ˆï¼Œå­¦ä¹ ä»é›¶å¼€å§‹äº²æ‰‹å®ç°å„ç§çº¿æ€§é‡åŒ–æ–¹å¼ï¼Œä¾‹å¦‚**éå¯¹ç§°æ¨¡å¼** (asymmetric mode) å’Œ**å¯¹ç§°æ¨¡å¼** (symmetric mode)ã€‚æ‚¨è¿˜å°†æŒæ¡å¦‚ä½•åœ¨ä¸åŒçš„**ç²’åº¦** (granularity) ä¸‹è¿›è¡Œé‡åŒ–ï¼ˆä¾‹å¦‚æŒ‰å¼ é‡ per-tensorã€æŒ‰é€šé“ per-channelã€æŒ‰ç»„ per-groupï¼‰ï¼Œä»¥ä¿æŒæ¨¡å‹çš„æ€§èƒ½ã€‚æ¥ç€ï¼Œæ‚¨å°†åŠ¨æ‰‹æ„å»ºä¸€ä¸ªé‡åŒ–å™¨ï¼Œå°†ä»»ä½•å¼€æºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„**å¯†é›†å±‚** (dense layers) å‹ç¼©åˆ° 8 ä½ç²¾åº¦ã€‚æœ€åï¼Œæ‚¨è¿˜å°†å®è·µå¦‚ä½•å°†**æƒé‡** (weights) é‡åŒ–åˆ° 2 ä½ï¼Œå…·ä½“åšæ³•æ˜¯å°†å››ä¸ª 2 ä½æƒé‡â€œæ‰“åŒ…â€åˆ°ä¸€ä¸ª 8 ä½æ•´æ•°ä¸­ã€‚\n\nå¦‚æœæ‚¨æ›¾åœ¨è‡ªå·±çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šè¿è¡Œè¿‡å¤§å‹å¼€æºæ¨¡å‹ï¼Œé‚£ä¹ˆå¾ˆå¯èƒ½å·²ç»å—ç›Šäºä»–äººæ‰€åšçš„é‡åŒ–å·¥ä½œã€‚å¿«æ¥æ·±å…¥äº†è§£è¿™é¡¹å…³é”®æŠ€æœ¯çš„åº•å±‚å·¥ä½œåŸç†å§ï¼\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/lPfRY0LdFI"
  },
  {
    "id": "1787219405916828001",
    "url": "https://x.com/AndrewYNg/status/1787219405916828001",
    "text": "Back then, the idea that scaling deep learning would lead to significant performance gains was controversial. Several senior academic colleagues were advising me not to waste time trying to scale deep learning, but to just focus on inventing new algorithms, which was where they thought the action was! \n\nFortunately, I already had small scale data from my Stanford group (thanks to @adampaulcoates, @honglaklee, and many others) that gave me conviction that scaling was going to work, and we just kept pushing in that direction.",
    "createdAt": "Sun May 05 20:34:45 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 4,
    "quoteCount": 0,
    "viewCount": 798,
    "bookmarkCount": 1,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "å›æº¯åˆ°é‚£æ—¶ï¼Œæ·±åº¦å­¦ä¹  (deep learning) çš„è§„æ¨¡åŒ– (scaling) èƒ½å¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡çš„è§‚ç‚¹å¤‡å—äº‰è®®ã€‚æœ‰å‡ ä½èµ„æ·±çš„å­¦æœ¯åŒäº‹åŠæˆ‘ï¼Œåˆ«æŠŠæ—¶é—´æµªè´¹åœ¨å°è¯•æ‰©å¤§æ·±åº¦å­¦ä¹ çš„è§„æ¨¡ä¸Šï¼Œè€Œåº”è¯¥ä¸“æ³¨äºå‘æ˜æ–°ç®—æ³•ï¼Œä»–ä»¬è®¤ä¸ºé‚£æ‰æ˜¯å…³é”®æ‰€åœ¨ï¼\n\nå¹¸è¿çš„æ˜¯ï¼Œæˆ‘å½“æ—¶å·²ç»ä»æˆ‘çš„æ–¯å¦ç¦å›¢é˜Ÿé‚£é‡Œè·å¾—äº†å°è§„æ¨¡çš„æ•°æ®ï¼ˆæ„Ÿè°¢ @adampaulcoatesã€@honglaklee å’Œè®¸å¤šå…¶ä»–äººï¼‰ï¼Œè¿™è®©æˆ‘åšä¿¡è§„æ¨¡åŒ–æ˜¯è¡Œå¾—é€šçš„ã€‚äºæ˜¯ï¼Œæˆ‘ä»¬ä¾¿æŒç»­æœç€è¿™ä¸ªæ–¹å‘åŠªåŠ›ã€‚"
  },
  {
    "id": "1787216859621958078",
    "url": "https://x.com/AndrewYNg/status/1787216859621958078",
    "text": "@quocleix @ylecun @JeffDean @deliprao @karpathy Yup. By the way @quocleix, I still remember the time we were both in the office, and you waved at me to come over to your desk to look at your new result. And right there on your monitor was the now-famous Google Cat image. That was a defining moment for Google Brain!",
    "createdAt": "Sun May 05 20:24:38 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 3,
    "replyCount": 3,
    "likeCount": 52,
    "quoteCount": 1,
    "viewCount": 14228,
    "bookmarkCount": 6,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@quocleix @ylecun @JeffDean @deliprao @karpathy æ˜¯çš„ï¼Œæ²¡é”™ã€‚é¡ºä¾¿æä¸€ä¸‹ï¼Œ@quocleixï¼Œæˆ‘ä»ç„¶æ¸…æ¥šåœ°è®°å¾—ï¼Œå½“æ—¶æˆ‘ä»¬éƒ½åœ¨åŠå…¬å®¤ï¼Œä½ å‘æˆ‘æ‹›æ‰‹ç¤ºæ„æˆ‘åˆ°ä½ çš„åŠå…¬æ¡Œæ—ï¼Œçœ‹çœ‹ä½ çš„æœ€æ–°ç ”ç©¶æˆæœã€‚å°±åœ¨ä½ çš„æ˜¾ç¤ºå™¨ä¸Šï¼Œèµ«ç„¶æ˜¾ç¤ºç€å¦‚ä»Šå·²å®¶å–»æˆ·æ™“çš„ Google Cat å›¾åƒã€‚é‚£å¯¹äº Google Brain æ¥è¯´ï¼ŒçœŸæ˜¯ä¸€ä¸ªæ ‡å¿—æ€§çš„å†³å®šæ€§æ—¶åˆ»ï¼"
  },
  {
    "id": "1787209990023082105",
    "url": "https://x.com/AndrewYNg/status/1787209990023082105",
    "text": "@unJADded @JeffDean @ylecun @deliprao @karpathy You were a real pioneer @unJADded ! â¤ï¸\n\nLooking back, honestly I feel a bit bad at how hard DistBelief was to use, and the complexity of the C++ interface we built.... Nonetheless, I'm glad it turned out to be a useful product of its time!",
    "createdAt": "Sun May 05 19:57:21 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 1,
    "likeCount": 19,
    "quoteCount": 3,
    "viewCount": 4677,
    "bookmarkCount": 0,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@unJADded @JeffDean @ylecun @deliprao @karpathy @unJADded ä½ çœŸæ˜¯ä¸€ä½çœŸæ­£çš„å…ˆé©±ï¼ â¤ï¸\n\nå›æƒ³èµ·æ¥ï¼Œè¯´å®è¯ï¼Œæˆ‘æœ‰ç‚¹æŠ±æ­‰ DistBelief ç”¨èµ·æ¥é‚£ä¹ˆå›°éš¾ï¼Œè¿˜æœ‰æˆ‘ä»¬å½“å¹´æ„å»ºçš„ C++ æ¥å£æ˜¯å¦‚æ­¤å¤æ‚â€¦â€¦å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘è¿˜æ˜¯å¾ˆæ¬£æ…°å®ƒæœ€ç»ˆæˆä¸ºäº†é‚£ä¸ªæ—¶ä»£çš„ä¸€é¡¹æœ‰ç”¨æˆæœï¼"
  },
  {
    "id": "1787204296590987630",
    "url": "https://x.com/AndrewYNg/status/1787204296590987630",
    "text": "I'm with @JeffDean on this. DistBelief taught us early important lessons about scaling up deep learning, and it was general enough for many algorithms including supervised backprop. \n\nObviously, we got a lot of software and hardware architecture details \"wrong\" back in 2012 -- but who didn't? But DistBelief was used by numerous teams within Google, taught early lessons about scaling deep learning, and became the precursor to TensorFlow. \n\nFun fact: Back then, \"Deep Belief Networks\" (by Geoff Hinton) was a popular algorithm. When we built our Distributed training system, it was Jeff that came up with the name DistBelief, which I thought was a real groaner. I guess we were hoping our results would be so good that people would look at them with disbelief. ğŸ˜€",
    "createdAt": "Sun May 05 19:34:43 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 10,
    "replyCount": 3,
    "likeCount": 230,
    "quoteCount": 0,
    "viewCount": 46321,
    "bookmarkCount": 51,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "å…³äºè¿™ä¸€ç‚¹ï¼Œæˆ‘èµåŒ Jeff Dean çš„çœ‹æ³•ã€‚DistBelief æ•™ä¼šäº†æˆ‘ä»¬æ‰©å±•ï¼ˆscaling upï¼‰æ·±åº¦å­¦ä¹ ï¼ˆdeep learningï¼‰çš„æ—©æœŸé‡è¦ç»éªŒï¼Œè€Œä¸”å®ƒè¶³å¤Ÿé€šç”¨ï¼Œèƒ½æ”¯æŒåŒ…æ‹¬ç›‘ç£åå‘ä¼ æ’­ï¼ˆsupervised backpropï¼‰åœ¨å†…çš„å¤šç§ç®—æ³•ã€‚\n\nå½“ç„¶ï¼Œæˆ‘ä»¬å›æœ› 2012 å¹´ï¼Œå½“æ—¶åœ¨è®¸å¤šè½¯ä»¶å’Œç¡¬ä»¶æ¶æ„ç»†èŠ‚ä¸Šç¡®å®çŠ¯äº†ä¸å°‘â€œé”™è¯¯â€â€”â€”ä½†è°åˆä¸æ˜¯å‘¢ï¼Ÿä¸è¿‡ï¼ŒDistBelief å½“æ—¶è¢« Google å†…éƒ¨çš„è®¸å¤šå›¢é˜Ÿå¹¿æ³›ä½¿ç”¨ï¼Œç§¯ç´¯äº†æ‰©å±•æ·±åº¦å­¦ä¹ çš„æ—©æœŸç»éªŒï¼Œå¹¶æˆä¸ºäº† TensorFlow çš„å‰èº«ã€‚\n\nä¸€ä¸ªè¶£é—»æ˜¯ï¼šé‚£æ—¶ï¼Œâ€œæ·±åº¦ä¿¡å¿µç½‘ç»œâ€ (Deep Belief Networks) ï¼ˆç”± Geoff Hinton æå‡ºï¼‰æ˜¯ä¸€ç§å¾ˆæµè¡Œçš„ç®—æ³•ã€‚å½“æˆ‘ä»¬æ„å»ºåˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿæ—¶ï¼Œæ˜¯ Jeff æå‡ºäº† DistBelief è¿™ä¸ªåå­—ï¼Œæˆ‘å½“æ—¶è§‰å¾—è¿™åå­—å¬èµ·æ¥çœŸæ˜¯ä¸ªâ€œå†·ç¬‘è¯â€ã€‚æˆ‘æƒ³ï¼Œæˆ‘ä»¬å¤§æ¦‚æ˜¯å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶æˆæœèƒ½å¥½åˆ°è®©äººä»¬éš¾ä»¥ç½®ä¿¡å§ã€‚ğŸ˜€"
  },
  {
    "id": "1787199044194070776",
    "url": "https://x.com/AndrewYNg/status/1787199044194070776",
    "text": "Link to original article:  https://t.co/9CEoDsWYgh",
    "createdAt": "Sun May 05 19:13:51 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 5,
    "replyCount": 6,
    "likeCount": 45,
    "quoteCount": 0,
    "viewCount": 26866,
    "bookmarkCount": 5,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "åœ¨ Microsoftã€OpenAI å’Œ Amazon [20] æœ€è¿‘å‘è¡¨çš„ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œç ”ç©¶äººå‘˜å±•ç¤ºäº†å¦‚ä½•è®©å¤§è¯­è¨€æ¨¡å‹ (LLM) é€šè¿‡æ§åˆ¶è‡ªå·±çš„å¼€å…³æ¥â€œä¼‘çœ â€å’Œâ€œå”¤é†’â€ã€‚å…·ä½“æ¥è¯´ï¼Œä»–ä»¬å¼•å…¥äº†ä¸€ç§æœºåˆ¶ï¼Œè®©å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè‡ªè¡Œå†³å®šè¿›å…¥ä½åŠŸè€—çš„â€œä¼‘çœ â€çŠ¶æ€ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬ï¼Œç„¶ååœ¨éœ€è¦æ‰§è¡Œä»»åŠ¡æ—¶å†â€œå”¤é†’â€ã€‚è¿™å¯¹ AI æ¥è¯´ï¼Œå°±å¥½æ¯”äººç±»å†³å®šä½•æ—¶ä¼‘æ¯ã€ä½•æ—¶æ´»åŠ¨ä¸€æ ·ã€‚\n\nå›¾ 1: å…·æœ‰ä¼‘çœ å’Œå”¤é†’åŠŸèƒ½çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ (LLM agent) çš„æ¦‚å¿µå›¾ã€‚"
  },
  {
    "id": "1787198521747308637",
    "url": "https://x.com/AndrewYNg/status/1787198521747308637",
    "text": "I'm glad the Washington Post's editorial board is pushing for governments to engage in exploring climate geoengineering. I believe AI climate modeling has an important role to play. \n\nHere's the situation as I see it:\n- Earth is on track to a catastrophic 2-4 degrees Celsius of warming. The article references the UN Environment Program's estimate of 2.9 degrees on the current trajectory.\n- We have a high degree of confidence that geoengineering via stratospheric aerosol injection (SAI) will significantly lower Earth's average surface temperature. The science here is really solid: Use aerosols in the atmosphere to reflect more sunlight away from earth, and we become cooler.\n- So, why don't we just do it? Multiple reasons, but the biggest is that we still don't have good models for estimating how it will affect local climate and weather patterns, even though we're confident global average surface temperature will go down. \n\nThat's why better AI climate modeling is crucial for reducing uncertainty and better understanding the impacts of various geoengineering strategies.\n\nThere're other issues to consider too, like governance, moral hazard (disincentivizing decarbonization), equity,  pollution from the aerosols, and the challenging implementation engineering. But many of these  problems become easier if we can make progress on the core problem of better understanding what impact SAI will have.",
    "createdAt": "Sun May 05 19:11:46 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 96,
    "replyCount": 63,
    "likeCount": 452,
    "quoteCount": 15,
    "viewCount": 112120,
    "bookmarkCount": 134,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘å¾ˆé«˜å…´çœ‹åˆ°ã€Šåç››é¡¿é‚®æŠ¥ã€‹ç¼–è¾‘å§”å‘˜ä¼šæ­£åœ¨ç§¯æå€¡å¯¼å„å›½æ”¿åºœå‚ä¸æ¢è®¨æ°”å€™åœ°çƒå·¥ç¨‹ (geoengineering)ã€‚æˆ‘ç›¸ä¿¡ï¼Œ AI æ°”å€™å»ºæ¨¡ (AI climate modeling) åœ¨å…¶ä¸­èƒ½å‘æŒ¥ä¸¾è¶³è½»é‡çš„ä½œç”¨ã€‚\n\nåœ¨æˆ‘çœ‹æ¥ï¼Œç›®å‰çš„æƒ…å†µæ˜¯è¿™æ ·çš„ï¼š\n- åœ°çƒæ­£æœç€ç¾éš¾æ€§çš„ 2-4 æ‘„æ°åº¦å‡æ¸©è½¨è¿¹å‘å±•ã€‚æ ¹æ®æ–‡ç« å¼•è¿°çš„è”åˆå›½ç¯å¢ƒè§„åˆ’ç½² (UN Environment Program) ä¼°ç®—ï¼ŒæŒ‰å½“å‰è¶‹åŠ¿ï¼Œå…¨çƒæ°”æ¸©å°†ä¸Šå‡ 2.9 æ‘„æ°åº¦ã€‚\n- æˆ‘ä»¬é«˜åº¦ç¡®ä¿¡ï¼Œé€šè¿‡å¹³æµå±‚æ°”æº¶èƒ¶æ³¨å…¥ (stratospheric aerosol injection, SAI) è¿›è¡Œåœ°çƒå·¥ç¨‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½åœ°çƒçš„å¹³å‡åœ°è¡¨æ¸©åº¦ã€‚è¿™èƒŒåçš„ç§‘å­¦åŸç†éå¸¸åšå®ï¼šåœ¨å¤§æ°”ä¸­å–·æ´’æ°”æº¶èƒ¶ï¼Œå°†æ›´å¤šé˜³å…‰åå°„å›å¤ªç©ºï¼Œä»è€Œä½¿åœ°çƒé™æ¸©ã€‚\n- æ—¢ç„¶å¦‚æ­¤ï¼Œæˆ‘ä»¬ä¸ºä½•ä¸ç›´æ¥ä»˜è¯¸å®è·µå‘¢ï¼ŸåŸå› æœ‰å¾ˆå¤šï¼Œä½†æœ€ä¸»è¦çš„ä¸€ç‚¹æ˜¯ï¼Œå°½ç®¡æˆ‘ä»¬ç¡®ä¿¡å…¨çƒå¹³å‡åœ°è¡¨æ¸©åº¦ä¼šä¸‹é™ï¼Œä½†æˆ‘ä»¬ä»ç„¶ç¼ºä¹å¯é çš„æ¨¡å‹æ¥å‡†ç¡®é¢„æµ‹å®ƒå°†å¦‚ä½•å½±å“å±€éƒ¨æ°”å€™å’Œå¤©æ°”æ¨¡å¼ã€‚\n\nå› æ­¤ï¼Œä¸ºäº†å‡å°‘ä¸ç¡®å®šæ€§ï¼Œæ›´å¥½åœ°ç†è§£å„ç§åœ°çƒå·¥ç¨‹ç­–ç•¥å¯èƒ½å¸¦æ¥çš„å½±å“ï¼Œå¼€å‘æ›´å…ˆè¿›çš„ AI æ°”å€™å»ºæ¨¡æŠ€æœ¯æ˜¾å¾—è‡³å…³é‡è¦ã€‚\n\nå½“ç„¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘å…¶ä»–ä¸€ç³»åˆ—é—®é¢˜ï¼ŒåŒ…æ‹¬æ²»ç†ã€é“å¾·é£é™© (å³å¯èƒ½å‰Šå¼±äººä»¬å¯¹è„±ç¢³ (decarbonization) çš„ç§¯ææ€§)ã€å…¬å¹³æ€§ã€æ°”æº¶èƒ¶æœ¬èº«å¯èƒ½é€ æˆçš„æ±¡æŸ“ï¼Œä»¥åŠå®æ–½å·¥ç¨‹çš„å·¨å¤§æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬èƒ½åœ¨æ›´å¥½åœ°ç†è§£ SAI ä¼šäº§ç”Ÿä½•ç§å½±å“è¿™ä¸€æ ¸å¿ƒé—®é¢˜ä¸Šå–å¾—çªç ´ï¼Œè®¸å¤šä¸Šè¿°é—®é¢˜éƒ½å°†è¿åˆƒè€Œè§£ã€‚"
  },
  {
    "id": "1786057567178834328",
    "url": "https://x.com/AndrewYNg/status/1786057567178834328",
    "text": "Inexpensive token generation and agentic workflows for large language models (LLMs) open up intriguing new possibilities for training LLMs on synthetic data. Pretraining an LLM on its own directly generated responses to prompts doesn't help. But if an agentic workflow implemented with the LLM results in higher quality output than the LLM can generate directly, then training on that output becomes potentially useful.\n\nJust as humans can learn from their own thinking, perhaps LLMs can, too. For example, imagine a math student who is learning to write mathematical proofs. By solving a few problems â€” even without external input â€” they can reflect on what does and doesnâ€™t work and, through practice, learn how to more quickly generate good proofs.\n\nBroadly, LLM training involves (i) pretraining (learning from unlabeled text data to predict the next word) followed by (ii) instruction fine-tuning (learning to follow instructions) and (iii) RLHF/DPO tuning to align the LLMâ€™s output to human values. Step (i) requires many orders of magnitude more data than the other steps. For example, Llama 3 was pretrained on over 15 trillion tokens, and LLM developers are still hungry for more data. Where can we get more text to train on?\n\nMany developers train smaller models directly on the output of larger models, so a smaller model learns to mimic a larger modelâ€™s behavior on a particular task. However, an LLM canâ€™t learn much by training on data it generated directly, just like a supervised learning algorithm canâ€™t learn from trying to predict labels it generated by itself. Indeed, training a model repeatedly on the output of an earlier version of itself can result in model collapse.\n\nHowever, an LLM wrapped in an agentic workflow may produce higher-quality output than it can generate directly. In this case, the LLMâ€™s higher-quality output might be useful as pretraining data for the LLM itself.\nEfforts like these have precedents:\n- When using  reinforcement learning to play a game like chess, a model might learn a function that evaluates board positions. If we apply game tree search along with a low-accuracy evaluation function, the model can come up with more accurate evaluations. Then we can train that evaluation function to mimic these more accurate values.\n- In the alignment step, Anthropicâ€™s constitutional AI method uses RLAIF (RL from AI Feedback) to judge the quality of LLM outputs, substituting feedback generated by an AI model for human feedback.\n\nA significant barrier to using LLMs prompted via agentic workflows to produce their own training data is the cost of generating tokens. Say we want to generate 1 trillion tokens to extend a pre-existing training dataset. Currently, at publicly announced prices, generating 1 trillion tokens using GPT-4-turbo ($30 per million output tokens), Claude 3 Opus ($75), Gemini 1.5 Pro ($21), and Llama-3-70B on Groq ($0.79) would cost, respectively, $30M, $75M, $21M and $790K. Of course, an agentic workflow that uses a design pattern like Reflection would require generating more than one token per token that we would use as training data. But budgets for training cutting-edge LLMs easily surpass $100M, so spending a few million dollars more for data to boost performance is quite feasible.\n\nThatâ€™s why I believe agentic workflows will open up intriguing new opportunities for high-quality synthetic data generation.\n\n[Original text: https://t.co/zOiuUFtmo3 ]",
    "createdAt": "Thu May 02 15:38:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 236,
    "replyCount": 32,
    "likeCount": 1267,
    "quoteCount": 26,
    "viewCount": 203693,
    "bookmarkCount": 706,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å¤§è¯­è¨€æ¨¡å‹ (LLM) å»‰ä»·çš„ Token ç”Ÿæˆèƒ½åŠ›å’Œ AI æ™ºèƒ½ä½“ (agentic) å·¥ä½œæµï¼Œä¸ºåœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒ LLM å¸¦æ¥äº†è®¸å¤šä»¤äººå…´å¥‹çš„æ–°å¯èƒ½ã€‚å¦‚æœåªæ˜¯ç”¨ LLM è‡ªå·±ç›´æ¥ç”Ÿæˆçš„å“åº”æ¥é¢„è®­ç»ƒå®ƒï¼Œæ•ˆæœå¹¶ä¸ç†æƒ³ã€‚ä½†æ˜¯ï¼Œå¦‚æœä¸€ä¸ªç”± LLM é©±åŠ¨çš„ AI æ™ºèƒ½ä½“å·¥ä½œæµèƒ½å¤Ÿäº§ç”Ÿæ¯” LLM ç›´æ¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„è¾“å‡ºï¼Œé‚£ä¹ˆåˆ©ç”¨è¿™äº›é«˜è´¨é‡è¾“å‡ºè¿›è¡Œè®­ç»ƒå°±å¯èƒ½å¤§æœ‰è£¨ç›Šã€‚\n\nå°±åƒäººç±»å¯ä»¥ä»è‡ªèº«çš„æ€è€ƒä¸­å­¦ä¹ ä¸€æ ·ï¼Œæˆ–è®¸ LLM ä¹Ÿèƒ½åšåˆ°ã€‚ä¾‹å¦‚ï¼Œæƒ³è±¡ä¸€ä½æ­£åœ¨å­¦ä¹ ç¼–å†™æ•°å­¦è¯æ˜çš„å­¦ç”Ÿã€‚å³ä½¿æ²¡æœ‰å¤–éƒ¨å¸®åŠ©ï¼Œä»–ä»¬ä¹Ÿå¯ä»¥é€šè¿‡è§£å†³ä¸€äº›é—®é¢˜æ¥åæ€å“ªäº›æ–¹æ³•æœ‰æ•ˆã€å“ªäº›æ— æ•ˆï¼Œå¹¶é€šè¿‡ä¸æ–­ç»ƒä¹ ï¼Œå­¦ä¼šæ›´å¿«åœ°ç»™å‡ºä¼˜ç§€çš„è¯æ˜ã€‚\n\nä»å®è§‚ä¸Šçœ‹ï¼ŒLLM çš„è®­ç»ƒé€šå¸¸åŒ…æ‹¬ï¼š (i) é¢„è®­ç»ƒï¼ˆä»å¤§é‡æœªæ ‡æ³¨æ–‡æœ¬æ•°æ®ä¸­å­¦ä¹ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰ï¼›æ¥ç€æ˜¯ (ii) æŒ‡ä»¤å¾®è°ƒï¼ˆå­¦ä¹ ç†è§£å¹¶éµå¾ªæŒ‡ä»¤ï¼‰ï¼›æœ€åæ˜¯ (iii) é€šè¿‡ RLHF/DPO å¾®è°ƒï¼Œä½¿ LLM çš„è¾“å‡ºä¸äººç±»ä»·å€¼è§‚å¯¹é½ã€‚å…¶ä¸­ï¼Œæ­¥éª¤ (i) æ‰€éœ€çš„æ•°æ®é‡è¦æ¯”å…¶ä»–æ­¥éª¤å¤šå‡ºå‡ ä¸ªæ•°é‡çº§ã€‚ä¾‹å¦‚ï¼ŒLlama 3 å°±æ›¾åœ¨è¶…è¿‡ 15 ä¸‡äº¿ä¸ª Token ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè€Œ LLM å¼€å‘è€…ä»¬ä¾ç„¶å¯¹æ›´å¤šæ•°æ®æ±‚è´¤è‹¥æ¸´ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬èƒ½ä»å“ªé‡Œè·å¾—æ›´å¤šå¯ç”¨äºè®­ç»ƒçš„æ–‡æœ¬æ•°æ®å‘¢ï¼Ÿ\n\nè®¸å¤šå¼€å‘è€…ä¼šç›´æ¥ç”¨è¾ƒå¤§æ¨¡å‹çš„è¾“å‡ºæ¥è®­ç»ƒè¾ƒå°çš„æ¨¡å‹ï¼Œè¿™æ ·å°æ¨¡å‹å°±èƒ½å­¦ä¹ æ¨¡ä»¿å¤§æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡Œä¸ºã€‚ç„¶è€Œï¼ŒLLM æ— æ³•é€šè¿‡è®­ç»ƒè‡ªå·±ç›´æ¥ç”Ÿæˆçš„æ•°æ®å­¦åˆ°å¤šå°‘ä¸œè¥¿ï¼Œè¿™å°±åƒä¸€ä¸ªç›‘ç£å­¦ä¹ ç®—æ³•æ— æ³•é€šè¿‡å°è¯•é¢„æµ‹è‡ªå·±ç”Ÿæˆçš„æ ‡ç­¾æ¥å­¦ä¹ ä¸€æ ·ã€‚äº‹å®ä¸Šï¼Œå¦‚æœåå¤ç”¨ä¸€ä¸ªæ¨¡å‹æ—©æœŸç‰ˆæœ¬ç”Ÿæˆçš„è¾“å‡ºæ¥è®­ç»ƒå®ƒï¼Œç”šè‡³å¯èƒ½å¯¼è‡´æ¨¡å‹å´©æºƒã€‚\n\nç„¶è€Œï¼Œä¸€ä¸ªèå…¥äº† AI æ™ºèƒ½ä½“å·¥ä½œæµçš„ LLMï¼Œå¯èƒ½ä¼šæ¯”å®ƒç›´æ¥ç”Ÿæˆäº§ç”Ÿæ›´é«˜è´¨é‡çš„è¾“å‡ºã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLLM äº§ç”Ÿçš„é«˜è´¨é‡è¾“å‡ºå°±å¯ä»¥ä½œä¸º LLM è‡ªèº«çš„é¢„è®­ç»ƒæ•°æ®æ¥ä½¿ç”¨ã€‚\nè¿™ç±»å°è¯•å¹¶éæ²¡æœ‰å…ˆä¾‹ï¼š\n- åœ¨ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç©å›½é™…è±¡æ£‹è¿™ç±»æ¸¸æˆæ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šå­¦ä¹ ä¸€ä¸ªç”¨äºè¯„ä¼°æ£‹ç›˜ä½ç½®çš„å‡½æ•°ã€‚å¦‚æœæˆ‘ä»¬ç»“åˆåšå¼ˆæ ‘æœç´¢å’Œè¿™ä¸ªç²¾åº¦è¾ƒä½çš„è¯„ä¼°å‡½æ•°ï¼Œæ¨¡å‹å°±èƒ½å¾—å‡ºæ›´å‡†ç¡®çš„è¯„ä¼°ã€‚ç„¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥è®­ç»ƒè¯¥è¯„ä¼°å‡½æ•°æ¥å­¦ä¹ è¿™äº›æ›´å‡†ç¡®çš„è¯„ä¼°å€¼ã€‚\n- åœ¨å¯¹é½é˜¶æ®µï¼ŒAnthropic çš„å®ªæ³• AI æ–¹æ³•å°±ä½¿ç”¨äº† RLAIF (åŸºäº AI åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ) æ¥åˆ¤æ–­ LLM è¾“å‡ºçš„è´¨é‡ï¼Œç”¨ AI æ¨¡å‹ç”Ÿæˆçš„åé¦ˆæ›¿ä»£äº†äººç±»åé¦ˆã€‚\n\nåˆ©ç”¨é€šè¿‡ AI æ™ºèƒ½ä½“å·¥ä½œæµæç¤º LLM æ¥ç”Ÿæˆè‡ªèº«è®­ç»ƒæ•°æ®çš„ä¸€ä¸ªä¸»è¦éšœç¢æ˜¯ç”Ÿæˆ Token çš„æˆæœ¬ã€‚å‡è®¾æˆ‘ä»¬æƒ³ç”Ÿæˆ 1 ä¸‡äº¿ä¸ª Token æ¥æ‰©å±•ç°æœ‰çš„è®­ç»ƒæ•°æ®é›†ã€‚ç›®å‰æ ¹æ®å…¬å¼€æŠ¥ä»·ï¼Œä½¿ç”¨ GPT-4-turbo (æ¯ç™¾ä¸‡è¾“å‡º Token 30 ç¾å…ƒ)ã€Claude 3 Opus (75 ç¾å…ƒ)ã€Gemini 1.5 Pro (21 ç¾å…ƒ) å’Œ Groq ä¸Šçš„ Llama-3-70B (0.79 ç¾å…ƒ) ç”Ÿæˆ 1 ä¸‡äº¿ä¸ª Token çš„è´¹ç”¨å°†åˆ†åˆ«é«˜è¾¾ 3000 ä¸‡ç¾å…ƒã€7500 ä¸‡ç¾å…ƒã€2100 ä¸‡ç¾å…ƒå’Œ 79 ä¸‡ç¾å…ƒã€‚å½“ç„¶ï¼Œä¸€ä¸ªé‡‡ç”¨ Reflection ç­‰è®¾è®¡æ¨¡å¼çš„ AI æ™ºèƒ½ä½“å·¥ä½œæµï¼Œæ¯ç”Ÿæˆä¸€ä¸ªæˆ‘ä»¬ç”¨ä½œè®­ç»ƒæ•°æ®çš„ Tokenï¼Œå¯èƒ½éœ€è¦æ¶ˆè€—æ›´å¤šçš„ Tokenã€‚ä½†æ˜¯ï¼Œè®­ç»ƒæœ€å…ˆè¿› LLM çš„é¢„ç®—é€šå¸¸ä¼šè½»æ˜“è¶…è¿‡ 1 äº¿ç¾å…ƒï¼Œå› æ­¤å¤šèŠ±å‡ ç™¾ä¸‡ç¾å…ƒæ¥è·å–æ•°æ®ä»¥æå‡æ€§èƒ½ï¼Œæ˜¯å®Œå…¨å¯è¡Œçš„ã€‚\n\næ­£å› å¦‚æ­¤ï¼Œæˆ‘ç›¸ä¿¡ AI æ™ºèƒ½ä½“å·¥ä½œæµå°†ä¸ºé«˜è´¨é‡åˆæˆæ•°æ®ç”Ÿæˆå¼€è¾Ÿå‡ºæ¿€åŠ¨äººå¿ƒçš„æ–°æœºé‡ã€‚\n\n[åŸæ–‡é“¾æ¥: https://t.co/zOiuUFtmo3 ]"
  },
  {
    "id": "1785152969304068405",
    "url": "https://x.com/AndrewYNg/status/1785152969304068405",
    "text": "Chatting with @GroqIncâ€™s CEO @JonathanRoss321. Groq has super fast token generation capabilities now. And,  I was excited also to hear about his plans to scale up capacity aggressively and also expand this to other models than just LLMs! This is a good time to be building AI applications.",
    "createdAt": "Tue Apr 30 03:43:29 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 104,
    "replyCount": 52,
    "likeCount": 1205,
    "quoteCount": 12,
    "viewCount": 147202,
    "bookmarkCount": 122,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘æ­£åœ¨ä¸ GroqInc çš„é¦–å¸­æ‰§è¡Œå®˜ Jonathan Ross (@JonathanRoss321) èŠå¤©ã€‚Groq ç°åœ¨å…·å¤‡è¶…å¿«çš„ Token ç”Ÿæˆèƒ½åŠ›ã€‚æ›´è®©æˆ‘æ„Ÿåˆ°å…´å¥‹çš„æ˜¯ï¼Œæˆ‘å¬è¯´ä»–è®¡åˆ’ç§¯ææ‰©å¤§äº§èƒ½ï¼Œå¹¶å°†è¿™é¡¹æŠ€æœ¯ä¸ä»…é™äºå¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œè¿˜è¦æ‰©å±•åˆ°å…¶ä»–æ¨¡å‹ï¼è¿™æ— ç–‘æ˜¯å¼€å‘ AI åº”ç”¨ç¨‹åºçš„ä¸€ä¸ªç»ä½³æ—¶æœºã€‚"
  },
  {
    "id": "1784977075176374704",
    "url": "https://x.com/AndrewYNg/status/1784977075176374704",
    "text": "In Prompt Engineering for Vision Models, taught by @anmorgan2414 @JacquesVerre and @KaiserFrose of @Cometml , youâ€™ll learn how to prompt and fine-tune vision models for personalized image generation, image editing, object detection and segmentation. The prompts you'll use for vision models could be text, point coordinates, or bounding boxes, depending on the model. You'll also learn to tune hyperparameters to shape the output.\n\nModels you'll use include Segment-Anything Model (SAM), OWL-ViT, and Stable Diffusion. You'll also learn to fine-tune Stable Diffusion to generate personalized images (say, an image of a specific person), using a handful of images for training. As an example of a multi-step workflow, you'll use OWL-ViT to detect an object based on a text prompt, then pass the bounding box to SAM to create a segmentation mask, and input that mask into Stable Diffusion to replace the original object with a new one based on a text prompt.\n\nControlling vision models can be tricky; this course will teach prompting and fine-tuning techniques to get precise control over their output. Get started here: https://t.co/7JerpCG9l9",
    "createdAt": "Mon Apr 29 16:04:32 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 124,
    "replyCount": 23,
    "likeCount": 651,
    "quoteCount": 14,
    "viewCount": 151458,
    "bookmarkCount": 382,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨ç”± @Cometml å…¬å¸çš„ @anmorgan2414ã€@JacquesVerre å’Œ @KaiserFrose å…±åŒè®²æˆçš„ã€Šè§†è§‰æ¨¡å‹æç¤ºå·¥ç¨‹ã€‹è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å¯¹è§†è§‰æ¨¡å‹è¿›è¡Œæç¤ºï¼ˆpromptï¼‰å’Œå¾®è°ƒï¼ˆfine-tuneï¼‰ï¼Œä»¥å®ç°ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€ç›®æ ‡æ£€æµ‹ï¼ˆobject detectionï¼‰å’Œåˆ†å‰²ï¼ˆsegmentationï¼‰ç­‰ä»»åŠ¡ã€‚æ ¹æ®ä¸åŒçš„æ¨¡å‹ï¼Œä½ ç”¨äºè§†è§‰æ¨¡å‹çš„æç¤ºå¯ä»¥æ˜¯æ–‡æœ¬ã€ç‚¹åæ ‡æˆ–è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰ã€‚ä½ è¿˜å°†å­¦ä¹ è°ƒæ•´è¶…å‚æ•°ï¼ˆhyperparametersï¼‰æ¥å¡‘é€ æ¨¡å‹çš„è¾“å‡ºã€‚\n\nä½ å°†ä½¿ç”¨çš„æ¨¡å‹åŒ…æ‹¬ Segment-Anything Model (SAM)ã€OWL-ViT å’Œ Stable Diffusionã€‚ä½ è¿˜å°†å­¦ä¹ å¦‚ä½•å¾®è°ƒ Stable Diffusionï¼Œä»…ç”¨å°‘é‡å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œå°±èƒ½ç”Ÿæˆä¸ªæ€§åŒ–å›¾åƒï¼ˆæ¯”å¦‚ï¼Œç‰¹å®šäººç‰©çš„å›¾åƒï¼‰ã€‚ä½œä¸ºå¤šæ­¥å·¥ä½œæµç¨‹çš„ä¸€ä¸ªä¾‹å­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ OWL-ViT æ ¹æ®æ–‡æœ¬æç¤ºæ£€æµ‹ä¸€ä¸ªå¯¹è±¡ï¼Œç„¶åå°†æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ä¼ é€’ç»™ SAM ä»¥åˆ›å»ºåˆ†å‰²æ©è†œï¼ˆsegmentation maskï¼‰ï¼Œæœ€åå°†è¯¥æ©è†œè¾“å…¥ Stable Diffusionï¼Œæ ¹æ®æ–°çš„æ–‡æœ¬æç¤ºæ›¿æ¢æ‰åŸå§‹å¯¹è±¡ã€‚\n\næ§åˆ¶è§†è§‰æ¨¡å‹å¯èƒ½é¢‡å…·æŒ‘æˆ˜æ€§ï¼›æœ¬è¯¾ç¨‹å°†æ•™æˆæç¤ºå’Œå¾®è°ƒæŠ€æœ¯ï¼Œå¸®åŠ©ä½ ç²¾å‡†åœ°æ§åˆ¶å®ƒä»¬çš„è¾“å‡ºã€‚ç«‹å³å¼€å§‹å­¦ä¹ ï¼šhttps://t.co/7JerpCG9l9"
  },
  {
    "id": "1783588055770886652",
    "url": "https://x.com/AndrewYNg/status/1783588055770886652",
    "text": "I've really enjoyed using @crewAIInc 's tools to build multiagent AI systems -- in addition to being productive, it's also fun to use! It was great hanging out with its creator @joaomdmoura to chat about best practices for building agentic workflows. https://t.co/IxVeqTqWWj",
    "createdAt": "Thu Apr 25 20:05:04 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 37,
    "replyCount": 43,
    "likeCount": 637,
    "quoteCount": 7,
    "viewCount": 115255,
    "bookmarkCount": 122,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘éå¸¸å–œæ¬¢ä½¿ç”¨ @crewAIInc çš„å·¥å…·æ¥æ„å»ºå¤šæ™ºèƒ½ä½“ (multiagent) AI ç³»ç»Ÿâ€”â€”è¿™äº›å·¥å…·ä¸ä»…é«˜æ•ˆï¼Œç”¨èµ·æ¥ä¹Ÿå¾ˆæœ‰æ„æ€ï¼èƒ½å’Œå®ƒçš„åˆ›å»ºè€… @joaomdmoura èŠèŠæ„å»º AI æ™ºèƒ½ä½“ (AI Agent) å·¥ä½œæµçš„æœ€ä½³å®è·µï¼ŒçœŸæ˜¯å¤ªæ£’äº†ã€‚https://t.co/IxVeqTqWWj"
  },
  {
    "id": "1783521818093195277",
    "url": "https://x.com/AndrewYNg/status/1783521818093195277",
    "text": "Much has been said about many companiesâ€™ desire for more compute (as well as data) to train larger foundation models. I think itâ€™s under-appreciated that we have nowhere near enough compute available for inference on foundation models as well.\n\nYears ago, when I was leading teams at Google, Baidu, and Stanford that focused on scaling up deep learning algorithms, many semiconductor manufacturers, data center operators, and academic researchers asked me whether I felt that AI technology would continue to make good use of more compute if they kept on delivering it. For many normal desktop processing workloads, like running a web browser or a text editor, having a faster CPU doesnâ€™t help that much beyond a certain point. So do we really need faster and faster AI processors to train larger and larger models? Each time, I confidently replied â€œyes!â€ and encouraged them to keep scaling up compute. (Sometimes, I added half-jokingly that I had never met a machine learning engineer who felt like they had enough compute. ğŸ˜€)\n\nFortunately, this prediction has been right so far. However, beyond training, I believe we are also far from exhausting the benefits of faster and higher volumes of inference.\n\nToday, a lot of LLM output is primarily for human consumption. A human might read around 250 words per minute, which is around 6 tokens per second (250 words/min / (0.75 words/token) / (60 secs/min)). So it might initially seem like thereâ€™s little value to generating tokens much faster than this.\n\nBut in an agentic workflow, an LLM might be prompted repeatedly to reflect on and improve its output, use tools, plan and execute sequences of steps, or implement multiple agents that collaborate with each other. In such settings, we might easily generate hundreds of thousands of tokens or more before showing any output to a user. This makes fast token generation very desirable and makes slower generation a bottleneck to taking better advantage of existing foundation models.\n\nThatâ€™s why Iâ€™m excited about the work of companies like @GroqInc, which can generate hundreds of tokens per second. Recently, @SambaNovaAI also published an impressive demo that hit hundreds of tokens per second.\n\nIncidentally, faster, cheaper token generation will also help make running evaluations (evals), a step that can be slow and expensive today since it typically involves iterating over many examples, more palatable. Having better evals will help many developers with the process of tuning models to improve their performance.\n\nFortunately, it appears that both training and inference are rapidly becoming cheaper. I recently spoke with @CathieDWood and @CCRobertsARK of the investment firm ARK, which is famous for its bullish predictions on tech. They estimate that AI training costs are falling at 75% a year. If they are right, a foundation model that costs $100M to train this year might cost only $25M to train next year. Further, they report that for â€œenterprise scale use cases, inference costs seem to be falling at an annual rate of ~86%, even faster than training costs.â€\n\nI donâ€™t know how accurate these specific predictions will turn out to be, but with improvements in both semiconductors and algorithms, I do see training and inference costs falling rapidly. This will be good for application builders and help AI agentic workflows lift off.\n\n[Original text: https://t.co/BaH6bqZDds ]",
    "createdAt": "Thu Apr 25 15:41:52 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 236,
    "replyCount": 52,
    "likeCount": 1303,
    "quoteCount": 39,
    "viewCount": 251741,
    "bookmarkCount": 499,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…³äºè®¸å¤šå…¬å¸æ¸´æœ›æ›´å¤šç®—åŠ› (ä»¥åŠæ•°æ®) æ¥è®­ç»ƒæ›´å¤§çš„åŸºç¡€æ¨¡å‹ï¼Œäººä»¬å·²ç»è®¨è®ºäº†å¾ˆå¤šã€‚ä½†æˆ‘è®¤ä¸ºï¼Œæˆ‘ä»¬ç”¨äºåŸºç¡€æ¨¡å‹æ¨ç†çš„ç®—åŠ›ä¹Ÿè¿œä¸å¤Ÿç”¨ï¼Œè¿™ä¸€ç‚¹å´å¸¸å¸¸è¢«ä½ä¼°ã€‚\n\nå¤šå¹´å‰ï¼Œæˆ‘åœ¨ Googleã€ç™¾åº¦å’Œæ–¯å¦ç¦é¢†å¯¼å›¢é˜Ÿï¼Œè‡´åŠ›äºæ‰©å±•æ·±åº¦å­¦ä¹ ç®—æ³•ã€‚é‚£æ—¶ï¼Œè®¸å¤šåŠå¯¼ä½“åˆ¶é€ å•†ã€æ•°æ®ä¸­å¿ƒè¿è¥å•†å’Œå­¦æœ¯ç ”ç©¶äººå‘˜éƒ½æ›¾é—®æˆ‘ï¼Œå¦‚æœä»–ä»¬æŒç»­æä¾›æ›´å¤šç®—åŠ›ï¼Œæˆ‘æ˜¯å¦è®¤ä¸º AI æŠ€æœ¯ä¼šç»§ç»­é«˜æ•ˆåœ°åˆ©ç”¨è¿™äº›èµ„æºã€‚è¦çŸ¥é“ï¼Œå¯¹äºè®¸å¤šæ—¥å¸¸æ¡Œé¢å¤„ç†ä»»åŠ¡ï¼Œæ¯”å¦‚è¿è¡Œç½‘é¡µæµè§ˆå™¨æˆ–æ–‡æœ¬ç¼–è¾‘å™¨ï¼ŒCPU é€Ÿåº¦æå‡åˆ°ä¸€å®šç¨‹åº¦åï¼Œå¸®åŠ©å°±ä¸å¤§äº†ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬çœŸçš„éœ€è¦è¶Šæ¥è¶Šå¿«çš„ AI å¤„ç†å™¨æ¥è®­ç»ƒè¶Šæ¥è¶Šå¤§çš„æ¨¡å‹å—ï¼Ÿæ¯æ¬¡æˆ‘éƒ½åšå®šåœ°å›ç­”â€œæ˜¯çš„ï¼â€ï¼Œå¹¶é¼“åŠ±ä»–ä»¬ç»§ç»­æ‰©å±•ç®—åŠ›ã€‚ï¼ˆæœ‰æ—¶ï¼Œæˆ‘è¿˜ä¼šåŠå¼€ç©ç¬‘åœ°è¡¥å……ä¸€å¥ï¼šæˆ‘ä»æœªé‡åˆ°è¿‡è§‰å¾—è‡ªå·±ç®—åŠ›è¶³å¤Ÿçš„æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆã€‚ğŸ˜€ï¼‰\n\nå¹¸è¿çš„æ˜¯ï¼Œè¿™ä¸ªé¢„æµ‹åˆ°ç›®å‰ä¸ºæ­¢éƒ½æ˜¯å‡†ç¡®çš„ã€‚ç„¶è€Œï¼Œé™¤äº†æ¨¡å‹è®­ç»ƒï¼Œæˆ‘ç›¸ä¿¡åœ¨æ›´å¿«ã€æ›´å¤§è§„æ¨¡çš„æ¨ç†æ–¹é¢ï¼Œæˆ‘ä»¬è¿˜æœ‰å·¨å¤§çš„æ½œåŠ›è¿œæœªè¢«å……åˆ†æŒ–æ˜ã€‚\n\nå¦‚ä»Šï¼Œå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å¤§éƒ¨åˆ†è¾“å‡ºä¸»è¦æ˜¯ä¾›äººç±»é˜…è¯»ã€‚ä¸€ä¸ªäººæ¯åˆ†é’Ÿå¤§çº¦èƒ½é˜…è¯» 250 ä¸ªå•è¯ï¼Œè¿™ç›¸å½“äºæ¯ç§’çº¦ 6 ä¸ª Token (250 words/min / (0.75 words/token) / (60 secs/min))ã€‚æ‰€ä»¥ï¼Œä¹ä¸€çœ‹ï¼Œå¦‚æœç”Ÿæˆ Token çš„é€Ÿåº¦è¿œè¶…è¿™ä¸ªå€¼ï¼Œä¼¼ä¹æ²¡æœ‰å¤šå¤§æ„ä¹‰ã€‚\n\nä½†åœ¨ AI æ™ºèƒ½ä½“ (agentic) çš„å·¥ä½œæµç¨‹ä¸­ï¼Œå¤§è¯­è¨€æ¨¡å‹å¯èƒ½ä¼šè¢«åå¤æç¤ºï¼Œç”¨äºåæ€å¹¶æ”¹è¿›è‡ªå·±çš„è¾“å‡ºã€è°ƒç”¨å·¥å…·ã€è§„åˆ’å’Œæ‰§è¡Œä¸€ç³»åˆ—æ­¥éª¤ï¼Œæˆ–è€…ååŒè¿ä½œå¤šä¸ª AI æ™ºèƒ½ä½“ã€‚åœ¨è¿™ç§åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½åœ¨å‘ç”¨æˆ·å±•ç¤ºä»»ä½•ç»“æœä¹‹å‰ï¼Œå°±å·²ç»è½»æ¾ç”Ÿæˆäº†æ•°åä¸‡ç”šè‡³æ›´å¤šçš„ Tokenã€‚å› æ­¤ï¼Œå¿«é€Ÿç”Ÿæˆ Token å˜å¾—æå…¶é‡è¦ï¼Œè€Œç”Ÿæˆé€Ÿåº¦è¿‡æ…¢åˆ™ä¼šæˆä¸ºæˆ‘ä»¬æ›´å¥½åˆ©ç”¨ç°æœ‰åŸºç¡€æ¨¡å‹çš„ç“¶é¢ˆã€‚\n\næ­£å› å¦‚æ­¤ï¼Œæˆ‘å¯¹åƒ @GroqInc è¿™æ ·æ¯ç§’èƒ½ç”Ÿæˆæ•°ç™¾ä¸ª Token çš„å…¬å¸æ‰€åšçš„å·¥ä½œæ„Ÿåˆ°éå¸¸å…´å¥‹ã€‚æœ€è¿‘ï¼Œ@SambaNovaAI ä¹Ÿå±•ç¤ºäº†ä¸€é¡¹ä»¤äººå°è±¡æ·±åˆ»çš„æ¼”ç¤ºï¼Œå…¶ç”Ÿæˆé€Ÿåº¦åŒæ ·è¾¾åˆ°äº†æ¯ç§’æ•°ç™¾ä¸ª Tokenã€‚\n\né¡ºå¸¦ä¸€æï¼Œæ›´å¿«ã€æ›´ä¾¿å®œçš„ Token ç”Ÿæˆä¹Ÿå°†æœ‰åŠ©äºè®©è¿è¡Œè¯„ä¼° (evals) å˜å¾—æ›´å®¹æ˜“ã€‚ç›®å‰ï¼Œè¯„ä¼°è¿‡ç¨‹å¯èƒ½æ—¢ç¼“æ…¢åˆæ˜‚è´µï¼Œå› ä¸ºå®ƒé€šå¸¸éœ€è¦è¿­ä»£å¤§é‡ç¤ºä¾‹ã€‚è€Œæ›´å¥½çš„è¯„ä¼°æ–¹æ³•å°†å¸®åŠ©è®¸å¤šå¼€å‘è€…ä¼˜åŒ–æ¨¡å‹ï¼Œä»è€Œæå‡å…¶æ€§èƒ½ã€‚\n\nä»¤äººæ¬£æ…°çš„æ˜¯ï¼Œæ— è®ºæ˜¯è®­ç»ƒè¿˜æ˜¯æ¨ç†ï¼Œå…¶æˆæœ¬ä¼¼ä¹éƒ½åœ¨è¿…é€Ÿä¸‹é™ã€‚æˆ‘æœ€è¿‘ä¸æŠ•èµ„å…¬å¸ ARK çš„ @CathieDWood å’Œ @CCRobertsARK è¿›è¡Œäº†äº¤æµï¼Œè¯¥å…¬å¸ä»¥å…¶å¯¹ç§‘æŠ€è¡Œä¸šçš„ä¹è§‚é¢„æµ‹è€Œé—»åã€‚ä»–ä»¬ä¼°è®¡ï¼ŒAI è®­ç»ƒæˆæœ¬æ¯å¹´ä¸‹é™ 75%ã€‚å¦‚æœä»–ä»¬çš„é¢„æµ‹å‡†ç¡®ï¼Œé‚£ä¹ˆä»Šå¹´è®­ç»ƒä¸€ä¸ªèŠ±è´¹ 1 äº¿ç¾å…ƒçš„åŸºç¡€æ¨¡å‹ï¼Œæ˜å¹´å¯èƒ½åªéœ€ 2500 ä¸‡ç¾å…ƒã€‚æ­¤å¤–ï¼Œä»–ä»¬æŠ¥å‘Šç§°ï¼Œå¯¹äºâ€œä¼ä¸šè§„æ¨¡çš„ç”¨ä¾‹ï¼Œæ¨ç†æˆæœ¬ä¼¼ä¹æ­£ä»¥æ¯å¹´çº¦ 86% çš„é€Ÿåº¦ä¸‹é™ï¼Œç”šè‡³æ¯”è®­ç»ƒæˆæœ¬ä¸‹é™å¾—æ›´å¿«ã€‚â€\n\næˆ‘æ— æ³•åˆ¤æ–­è¿™äº›å…·ä½“é¢„æµ‹çš„å‡†ç¡®æ€§å¦‚ä½•ï¼Œä½†éšç€åŠå¯¼ä½“å’Œç®—æ³•çš„ä¸æ–­è¿›æ­¥ï¼Œæˆ‘ç¡®å®çœ‹åˆ°è®­ç»ƒå’Œæ¨ç†æˆæœ¬æ­£åœ¨å¿«é€Ÿé™ä½ã€‚è¿™å¯¹åº”ç”¨ç¨‹åºå¼€å‘è€…æ¥è¯´æ˜¯ä¸ªå¥½æ¶ˆæ¯ï¼Œä¹Ÿå°†åŠ©åŠ› AI æ™ºèƒ½ä½“å·¥ä½œæµå®ç°è…¾é£ã€‚\n\n[åŸæ–‡é“¾æ¥: https://t.co/BaH6bqZDds ]"
  },
  {
    "id": "1782442718960230688",
    "url": "https://x.com/AndrewYNg/status/1782442718960230688",
    "text": "New short course with @MistralAI !\n\nMistral's open-source Mixtral 8x7B model uses a \"mixture of experts\" (MoE) architecture. Unlike a standard transformer, an MoE model has multiple expert feed-forward networks (8 in this case), with a gating network selecting two experts at inference time. This enables MoE to match the performance of a large model but faster inference. Mixtral 8x7B has 46.7B parameters but activates only 12.9B at inference to predict the next token.\n\nIn Getting Started with Mistral, youâ€™ll learn from Mistralâ€™s @sophiamyang to:\n- Explore Mistral's open-source models (Mistral 7B, Mixtral 8x7B) and commercial models via API calls and Mistral AI's Le Chat website\n- Implement JSON mode to generate structured outputs to integrate directly into larger software systems.\n- Use function calling for Tool Use, such as calling custom Python code that queries tabular data\n- Ground your LLM's response with external knowledge sources using RAG\n- Build a Mistral-powered chat interface that can reference external documents\n\nThis course will help deepen your prompt engineering skills. Please sign up here: https://t.co/weYwGmPlLA",
    "createdAt": "Mon Apr 22 16:13:55 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 278,
    "replyCount": 40,
    "likeCount": 1630,
    "quoteCount": 17,
    "viewCount": 385624,
    "bookmarkCount": 1030,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "@MistralAI æ¨å‡ºå…¨æ–°çŸ­æœŸè¯¾ç¨‹ï¼\n\nMistral çš„å¼€æº Mixtral 8x7B æ¨¡å‹é‡‡ç”¨äº†ä¸€ç§â€œä¸“å®¶æ··åˆâ€ (Mixture of Experts, MoE) æ¶æ„ã€‚ä¸æ ‡å‡† Transformer ä¸åŒï¼ŒMoE æ¨¡å‹æ‹¥æœ‰å¤šä¸ªä¸“å®¶å‰é¦ˆç½‘ç»œ ï¼ˆæœ¬ä¾‹ä¸­æœ‰ 8 ä¸ªï¼‰ï¼Œå¹¶é…å¤‡ä¸€ä¸ªé—¨æ§ç½‘ç»œï¼Œåœ¨æ¨ç†æ—¶é€‰æ‹©å…¶ä¸­ä¸¤ä¸ªä¸“å®¶ã€‚è¿™ç§è®¾è®¡ä½¿å¾— MoE åœ¨æ€§èƒ½ä¸Šèƒ½å¤Ÿä¸å¤§å‹æ¨¡å‹åª²ç¾ï¼ŒåŒæ—¶å®ç°æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚Mixtral 8x7B æ‹¥æœ‰ 46.7B å‚æ•°ï¼Œä½†åœ¨æ¨ç†æ—¶ä»…æ¿€æ´»å…¶ä¸­çš„ 12.9B å‚æ•°æ¥é¢„æµ‹ä¸‹ä¸€ä¸ª Token (Token)ã€‚\n\nåœ¨ã€Šå¼€å§‹ä½¿ç”¨ Mistralã€‹è¯¾ç¨‹ä¸­ï¼Œä½ å°†è·Ÿéš Mistral çš„ @sophiamyang å­¦ä¹ ï¼š\n- æ¢ç´¢ Mistral çš„å¼€æºæ¨¡å‹ (Mistral 7B, Mixtral 8x7B)ï¼Œä»¥åŠé€šè¿‡ API è°ƒç”¨å’Œ Mistral AI çš„ Le Chat ç½‘ç«™è®¿é—®çš„å•†ä¸šæ¨¡å‹\n- å®ç° JSON æ¨¡å¼ï¼Œä»¥ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼Œä»è€Œç›´æ¥é›†æˆåˆ°æ›´å¤§çš„è½¯ä»¶ç³»ç»Ÿä¸­\n- ä½¿ç”¨å‡½æ•°è°ƒç”¨ (Function Calling) å®ç°å·¥å…·è°ƒç”¨ï¼Œä¾‹å¦‚è°ƒç”¨æŸ¥è¯¢è¡¨æ ¼æ•°æ®çš„è‡ªå®šä¹‰ Python ä»£ç \n- åˆ©ç”¨ RAG (Retrieval Augmented Generation) æŠ€æœ¯ï¼ŒåŸºäºå¤–éƒ¨çŸ¥è¯†æºæ¥å¢å¼ºä½ å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å“åº”\n- æ„å»ºä¸€ä¸ªç”± Mistral æä¾›æ”¯æŒçš„èŠå¤©ç•Œé¢ï¼Œè¯¥ç•Œé¢èƒ½å¤Ÿå‚è€ƒå¤–éƒ¨æ–‡æ¡£\n\næœ¬è¯¾ç¨‹å°†å¸®åŠ©ä½ æå‡æç¤ºå·¥ç¨‹ (Prompt Engineering) æŠ€èƒ½ã€‚è¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/weYwGmPlLA"
  },
  {
    "id": "1781021135339164147",
    "url": "https://x.com/AndrewYNg/status/1781021135339164147",
    "text": "Meta released Llama 3 on my birthday! ğŸ‚ Best present ever, thanks Meta! ğŸ˜€",
    "createdAt": "Thu Apr 18 18:05:03 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 166,
    "replyCount": 288,
    "likeCount": 4171,
    "quoteCount": 27,
    "viewCount": 293078,
    "bookmarkCount": 113,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "Meta åœ¨æˆ‘ç”Ÿæ—¥å½“å¤©å‘å¸ƒäº† Llama 3ï¼ğŸ‚ è¿™çœŸæ˜¯æœ‰å²ä»¥æ¥æœ€æ£’çš„ç¤¼ç‰©ï¼Œæ„Ÿè°¢ Metaï¼ğŸ˜€"
  },
  {
    "id": "1780991671855161506",
    "url": "https://x.com/AndrewYNg/status/1780991671855161506",
    "text": "Multi-agent collaboration has emerged as a key AI agentic design pattern. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles -- such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on -- and have different agents accomplish different subtasks.\n\nDifferent agents might be built by prompting one LLM (or, if you prefer, different LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: \"You are an expert in writing clear, efficient code. Write code to perform the task â€¦\".\n\nIt might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I'd like to offer a few reasons:\n- It works! Many teams are getting good results with this method, and there's nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.\n- Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An  agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that  subtask: For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.\n- Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task -- like implementing a web browser -- into subtasks that are easier to code. I find thinking through multi-agents roles to be a useful abstraction.\n\nIn many companies, managers routinely decide what roles to hire, and then how to split complex projects -- like writing a large piece of software or preparing a research report -- into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technologies -- how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents themselves can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.\n\nWhile managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!\n\nEmerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their github repo and perhaps even clone the repo and run  the system yourself. While it may not always produce what you want, you might be amazed at how well it does!\n\nLike the design pattern of Planning, I find the output quality of multi-agent collaboration hard to predict. The more mature patterns of Reflection and Tool use are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!\n\nIf you're interested in learning more, I recommend:\n- Communicative Agents for Software Development, Qian et al. (2023) (the ChatDev paper)\n- AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation, Wu et al. (2023)\n- MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework, Hong et al. (2023)\n\n[Original text: https://t.co/4gTbcQfikx ]",
    "createdAt": "Thu Apr 18 16:07:58 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 516,
    "replyCount": 89,
    "likeCount": 2402,
    "quoteCount": 87,
    "viewCount": 413335,
    "bookmarkCount": 1894,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å¤šæ™ºèƒ½ä½“åä½œ (Multi-agent collaboration) å·²ç»æˆä¸º AI æ™ºèƒ½ä½“ (AI agent) è®¾è®¡ä¸­çš„ä¸€ä¸ªå…³é”®æ¨¡å¼ã€‚è®¾æƒ³ä¸€ä¸ªåƒç¼–å†™è½¯ä»¶è¿™æ ·çš„å¤æ‚ä»»åŠ¡ï¼Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ä¼šå°†ä»»åŠ¡åˆ†è§£æˆç”±ä¸åŒâ€œè§’è‰²â€è´Ÿè´£çš„å­ä»»åŠ¡â€”â€”æ¯”å¦‚è½¯ä»¶å·¥ç¨‹å¸ˆã€äº§å“ç»ç†ã€è®¾è®¡å¸ˆã€QA (è´¨é‡ä¿è¯) å·¥ç¨‹å¸ˆç­‰ç­‰â€”â€”ç„¶åè®©ä¸åŒçš„æ™ºèƒ½ä½“å»å®Œæˆè¿™äº›ä¸åŒçš„å­ä»»åŠ¡ã€‚\n\næ„å»ºè¿™äº›æ™ºèƒ½ä½“çš„æ–¹æ³•æ˜¯ï¼Œç”¨ç‰¹å®šçš„æç¤ºè¯å¼•å¯¼ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLM) ï¼ˆæˆ–è€…è¯´ï¼Œå¯ä»¥ä¸ºä¸åŒçš„æ™ºèƒ½ä½“è®¾å®šä¸åŒçš„ LLMï¼‰æ¥æ‰§è¡Œä¸åŒçš„ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œè¦åˆ›å»ºä¸€ä¸ªè½¯ä»¶å·¥ç¨‹å¸ˆæ™ºèƒ½ä½“ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè¿™æ ·æç¤º LLMï¼šâ€œä½ æ˜¯ä¸€ä½ç¼–å†™æ¸…æ™°ã€é«˜æ•ˆä»£ç çš„ä¸“å®¶ã€‚è¯·ç¼–å†™ä»£ç æ¥å®Œæˆè¿™é¡¹ä»»åŠ¡â€¦â€¦â€\n\nè¿™æˆ–è®¸å¬èµ·æ¥æœ‰äº›åå¸¸ï¼Œæ¯•ç«Ÿæˆ‘ä»¬å¯èƒ½åªæ˜¯åœ¨å¯¹åŒä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šæ¬¡è°ƒç”¨ï¼Œä½†æˆ‘ä»¬ä»ç„¶é‡‡ç”¨äº†å¤šä¸ªæ™ºèƒ½ä½“çš„ç¼–ç¨‹æŠ½è±¡æ¨¡å¼ã€‚å¯¹æ­¤ï¼Œæˆ‘æƒ³ç»™å‡ºå‡ ä¸ªåŸå› ï¼š\n- è¿™ç§æ–¹æ³•ç¡®å®æœ‰æ•ˆï¼è®¸å¤šå›¢é˜Ÿæ­£é€šè¿‡å®ƒå–å¾—è‰¯å¥½çš„ç»“æœï¼Œå®è·µæ•ˆæœæ˜¯æœ€å¥½çš„è¯æ˜ï¼æ­¤å¤–ï¼Œæ¶ˆèç ”ç©¶ (ablation studies) ï¼ˆä¾‹å¦‚ï¼Œä¸‹é¢å¼•ç”¨çš„ AutoGen è®ºæ–‡ä¸­ï¼‰ä¹Ÿè¡¨æ˜ï¼Œå¤šä¸ªæ™ºèƒ½ä½“æ¯”å•ä¸ªæ™ºèƒ½ä½“èƒ½å¸¦æ¥æ›´å“è¶Šçš„æ€§èƒ½ã€‚\n- å°½ç®¡ç°åœ¨ä¸€äº›å¤§è¯­è¨€æ¨¡å‹å¯ä»¥æ¥å—éå¸¸é•¿çš„è¾“å…¥ä¸Šä¸‹æ–‡ï¼ˆæ¯”å¦‚ Gemini 1.5 Pro èƒ½æ¥å— 100 ä¸‡ä¸ª Tokenï¼‰ï¼Œä½†å®ƒä»¬çœŸæ­£ç†è§£è¿™äº›é•¿è€Œå¤æ‚è¾“å…¥çš„èƒ½åŠ›è¡¨ç°ä¸ä¸€ã€‚é‡‡ç”¨æ™ºèƒ½ä½“å·¥ä½œæµ (agentic workflow) ï¼Œè®©å¤§è¯­è¨€æ¨¡å‹ä¸€æ¬¡åªä¸“æ³¨äºä¸€ä»¶äº‹æƒ…ï¼Œå¯ä»¥å¸¦æ¥æ›´å¥½çš„æ€§èƒ½ã€‚é€šè¿‡æ˜ç¡®å‘Šè¯‰å®ƒä½•æ—¶åº”è¯¥æ‰®æ¼”è½¯ä»¶å·¥ç¨‹å¸ˆçš„è§’è‰²ï¼Œæˆ‘ä»¬ä¹Ÿèƒ½æŒ‡å®šè¯¥å­ä»»åŠ¡ä¸­å“ªäº›è¦ç´ æ˜¯é‡è¦çš„ï¼šä¾‹å¦‚ï¼Œä¸Šé¢æåˆ°çš„æç¤ºè¯å¼ºè°ƒäº†æ¸…æ™°ã€é«˜æ•ˆçš„ä»£ç ï¼Œè€Œéå¯æ‰©å±•æ€§æˆ–é«˜å®‰å…¨æ€§ã€‚é€šè¿‡å°†æ•´ä½“ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œæˆ‘ä»¬å°±èƒ½æ›´å¥½åœ°ä¼˜åŒ–æ¯ä¸€ä¸ªå­ä»»åŠ¡ã€‚\n- ä¹Ÿè®¸æœ€é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œå¤šæ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼ä¸ºæˆ‘ä»¬å¼€å‘è€…æä¾›äº†ä¸€ä¸ªå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡çš„æ¡†æ¶ã€‚å°±åƒæˆ‘ä»¬åœ¨ç¼–å†™è¿è¡Œäºå•ä¸ª CPU ä¸Šçš„ä»£ç æ—¶ï¼Œå¸¸å¸¸ä¼šæŠŠç¨‹åºåˆ†è§£æˆä¸åŒçš„è¿›ç¨‹æˆ–çº¿ç¨‹ã€‚è¿™æ˜¯ä¸€ç§éå¸¸æœ‰ç”¨çš„æŠ½è±¡æ–¹å¼ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿå°†ä¸€ä¸ªå¤§ä»»åŠ¡ï¼ˆæ¯”å¦‚å®ç°ä¸€ä¸ªç½‘é¡µæµè§ˆå™¨ï¼‰åˆ†è§£æˆæ›´å®¹æ˜“ç¼–ç çš„å­ä»»åŠ¡ã€‚æˆ‘å‘ç°å°†å¤šæ™ºèƒ½ä½“è§’è‰²ä½œä¸ºä¸€ç§æŠ½è±¡æ€è€ƒæ–¹å¼ï¼Œèƒ½å¸¦æ¥æå¤§çš„ä¾¿åˆ©ã€‚\n\nåœ¨è®¸å¤šå…¬å¸ä¸­ï¼Œç®¡ç†è€…ä»¬é€šå¸¸ä¼šå†³å®šæ‹›è˜å“ªäº›èŒä½ï¼Œç„¶åå°†å¤æ‚çš„é¡¹ç›®ï¼ˆæ¯”å¦‚å¼€å‘å¤§å‹è½¯ä»¶æˆ–å‡†å¤‡ç ”ç©¶æŠ¥å‘Šï¼‰åˆ†è§£æˆå°ä»»åŠ¡ï¼Œåˆ†é…ç»™å…·æœ‰ä¸åŒä¸“ä¸šæŠ€èƒ½çš„å‘˜å·¥ã€‚ä½¿ç”¨å¤šä¸ªæ™ºèƒ½ä½“çš„é“ç†ä¸æ­¤ç±»ä¼¼ã€‚æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æ‰§è¡Œè‡ªå·±çš„å·¥ä½œæµï¼Œæ‹¥æœ‰è‡ªå·±çš„è®°å¿†ï¼ˆè¿™æœ¬èº«å°±æ˜¯æ™ºèƒ½ä½“æŠ€æœ¯ä¸­ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸâ€”â€”æ™ºèƒ½ä½“å¦‚ä½•è®°ä½è¶³å¤Ÿå¤šçš„è¿‡å»äº¤äº’ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„ä»»åŠ¡ä¸­è¡¨ç°æ›´å‡ºè‰²ï¼Ÿï¼‰ï¼Œå¹¶ä¸”å¯èƒ½ä¼šå‘å…¶ä»–æ™ºèƒ½ä½“å¯»æ±‚å¸®åŠ©ã€‚æ™ºèƒ½ä½“æœ¬èº«è¿˜å¯ä»¥è¿›è¡Œè§„åˆ’ (Planning) å’Œå·¥å…·ä½¿ç”¨ (Tool Use) ã€‚è¿™äº›å› ç´ å…±åŒå¯¼è‡´äº†å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨å’Œæ™ºèƒ½ä½“ä¹‹é—´æ¶ˆæ¯ä¼ é€’çš„é¢‘ç¹å‘ç”Ÿï¼Œä»è€Œå½¢æˆäº†éå¸¸å¤æ‚çš„å·¥ä½œæµã€‚\n\nè™½ç„¶ç®¡ç†äººå‘˜å¾ˆå›°éš¾ï¼Œä½†å®ƒæ˜¯ä¸€ä¸ªæˆ‘ä»¬è¶³å¤Ÿç†Ÿæ‚‰çš„ç†å¿µï¼Œå®ƒä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¦‚ä½•â€œæ‹›è˜â€å’Œåˆ†é…ä»»åŠ¡ç»™æˆ‘ä»¬çš„ AI æ™ºèƒ½ä½“çš„å¿ƒæ™ºæ¨¡å‹ã€‚å¹¸è¿çš„æ˜¯ï¼Œé”™è¯¯ç®¡ç† AI æ™ºèƒ½ä½“æ‰€é€ æˆçš„æŸå¤±ï¼Œè¿œä½äºé”™è¯¯ç®¡ç†äººåŠ›æ‰€é€ æˆçš„æŸå¤±ï¼\n\nAutoGenã€Crew AI å’Œ LangGraph ç­‰æ–°å…´æ¡†æ¶æä¾›äº†ä¸°å¯Œçš„æ–¹å¼æ¥æ„å»ºå¤šæ™ºèƒ½ä½“è§£å†³æ–¹æ¡ˆã€‚å¦‚æœä½ æœ‰å…´è¶£å°è¯•ä¸€ä¸ªæœ‰è¶£çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¹Ÿå¯ä»¥çœ‹çœ‹ ChatDevï¼Œå®ƒæ˜¯ä¸€ä¸ªè¿è¡Œè™šæ‹Ÿè½¯ä»¶å…¬å¸çš„ä¸€ç»„æ™ºèƒ½ä½“çš„å¼€æºå®ç°ã€‚æˆ‘é¼“åŠ±ä½ æŸ¥çœ‹ä»–ä»¬çš„ GitHub ä»“åº“ï¼Œç”šè‡³å¯ä»¥å…‹éš†ä»“åº“å¹¶äº²è‡ªè¿è¡Œè¿™ä¸ªç³»ç»Ÿã€‚è™½ç„¶å®ƒå¯èƒ½ä¸æ€»æ˜¯äº§ç”Ÿä½ æƒ³è¦çš„ç»“æœï¼Œä½†ä½ å¯èƒ½ä¼šå¯¹å…¶è¡¨ç°æ„Ÿåˆ°æƒŠå¹ï¼\n\nä¸è§„åˆ’ (Planning) è¿™ç§è®¾è®¡æ¨¡å¼ç±»ä¼¼ï¼Œæˆ‘å‘ç°å¤šæ™ºèƒ½ä½“åä½œçš„è¾“å‡ºè´¨é‡éš¾ä»¥é¢„æµ‹ã€‚è€Œæ›´ä¸ºæˆç†Ÿçš„åå°„ (Reflection) å’Œå·¥å…·ä½¿ç”¨ (Tool Use) åˆ™ç›¸å¯¹æ›´å¯é ã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢å°è¯•è¿™äº›æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼ï¼Œå¹¶æœŸå¾…å®ƒä»¬èƒ½ä¸ºä½ å¸¦æ¥æƒŠäººçš„æˆæœï¼\n\nå¦‚æœä½ æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œæˆ‘æ¨èï¼š\n- Communicative Agents for Software Development, Qian et al. (2023) (ChatDev è®ºæ–‡)\n- AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation, Wu et al. (2023)\n- MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework, Hong et al. (2023)"
  },
  {
    "id": "1779905922602782752",
    "url": "https://x.com/AndrewYNg/status/1779905922602782752",
    "text": "LLMs can take gigabytes of memory to store, which limits what can be run on consumer hardware. But quantization can dramatically compress models, making a wider selection of models available to developers. You can often reduce model size by 4x or more while maintaining reasonable performance. In our new short course Quantization Fundamentals taught by @huggingface's @younesbelkada and @_marcsun, you'll: \n- Learn how to quantize nearly any open source model\n- Use int8 and bfloat16 (Brain float 16) data types to load and run LLMs using PyTorch and the Hugging Face Transformers library\n- Dive into the technical details of linear quantization to map 32-bit floats to 8-bit integers\n\nAs models get bigger and bigger, quantization becomes more important for making models practical and accessible. Please check out the course here:  https://t.co/i8trQdOIOh",
    "createdAt": "Mon Apr 15 16:13:35 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 451,
    "replyCount": 41,
    "likeCount": 2355,
    "quoteCount": 28,
    "viewCount": 287673,
    "bookmarkCount": 1351,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å­˜å‚¨é€šå¸¸éœ€è¦å ç”¨æ•°åƒå…†å­—èŠ‚çš„å†…å­˜ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šçš„è¿è¡Œèƒ½åŠ›ã€‚ç„¶è€Œï¼Œé‡åŒ– (quantization) æŠ€æœ¯å¯ä»¥æ˜¾è‘—å‹ç¼©æ¨¡å‹ï¼Œä»è€Œè®©å¼€å‘è€…èƒ½å¤Ÿä½¿ç”¨æ›´å¹¿æ³›çš„æ¨¡å‹ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥åœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶ï¼Œå°†æ¨¡å‹å¤§å°å‡å°‘ 4 å€ç”šè‡³æ›´å¤šã€‚åœ¨ç”± @huggingface çš„ @younesbelkada å’Œ @_marcsun è®²æˆçš„æ–°çŸ­è¯¾ç¨‹â€œé‡åŒ–åŸºç¡€ (Quantization Fundamentals)â€ä¸­ï¼Œæ‚¨å°†å­¦ä¹ åˆ°ï¼š\n- å¦‚ä½•é‡åŒ–å‡ ä¹æ‰€æœ‰å¼€æºæ¨¡å‹\n- åˆ©ç”¨ int8 å’Œ bfloat16 (Brain float 16) æ•°æ®ç±»å‹ï¼Œé€šè¿‡ PyTorch å’Œ Hugging Face Transformers åº“åŠ è½½å¹¶è¿è¡Œå¤§è¯­è¨€æ¨¡å‹ (LLM)\n- æ·±å…¥äº†è§£çº¿æ€§é‡åŒ–çš„æŠ€æœ¯ç»†èŠ‚ï¼Œå³å¦‚ä½•å°† 32 ä½æµ®ç‚¹æ•°æ˜ å°„æˆ 8 ä½æ•´æ•°\n\néšç€æ¨¡å‹è§„æ¨¡è¶Šæ¥è¶Šåºå¤§ï¼Œé‡åŒ–å¯¹äºæå‡æ¨¡å‹çš„å®ç”¨æ€§å’Œå¯è®¿é—®æ€§å˜å¾—æ„ˆå‘é‡è¦ã€‚è¯·ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹è¯¾ç¨‹è¯¦æƒ…ï¼šhttps://t.co/i8trQdOIOh"
  },
  {
    "id": "1779606380665803144",
    "url": "https://x.com/AndrewYNg/status/1779606380665803144",
    "text": "Planning is a key agentic AI design pattern in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute to accomplish a larger task. For example, if we ask an agent to do online research on a given topic, we might use an LLM to break down the objective into smaller subtasks, such as researching specific subtopics, synthesizing findings, and compiling a report.\n\nMany people had a â€œChatGPT momentâ€ shortly after ChatGPT was released, when they played with it and were surprised that it significantly exceeded their expectation of what AI can do. If you have not yet had a similar â€œAI Agentic moment,â€ I hope you will soon. I had one several months ago, when I presented a live demo of a research agent I had implemented that had access to various online search tools.\n\nI had tested this agent multiple times privately, during which it consistently used a web search tool to gather information and wrote up a summary. During the live demo, though, the web search API unexpectedly returned with a rate limiting error. I thought my demo was about to fail publicly, and I dreaded what was to come next. To my surprise, the agent pivoted deftly to a Wikipedia search tool â€” which I had forgotten Iâ€™d given it â€” and completed the task using Wikipedia instead of web search.\n\nThis was an AI Agentic moment of surprise for me. I think many people who havenâ€™t experienced such a moment yet will do so in the coming months. Itâ€™s a beautiful thing when you see an agent autonomously decide to do things in ways that you had not anticipated, and succeed as a result!\n\nMany tasks canâ€™t be done in a single step or with a single tool invocation, but an agent can decide what steps to take. For example, to simplify an example from the HuggingGPT paper (cited below), if you want an agent to consider a picture of a boy and draw a picture of a girl in the same pose, the task might be decomposed into two distinct steps: (i) detect the pose in the picture of the boy and (ii) render a picture of a girl in the detected pose. An LLM might be fine-tuned or prompted (with few-shot prompting) to specify a plan by outputting a string like \"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}\".\n\nThis structured output, which specifies two steps to take, then triggers software to invoke a pose detection tool followed by a pose-to-image tool to complete the task. (This example is for illustrative purposes only; HuggingGPT uses a different format.)\n\nAdmittedly, many agentic workflows do not need planning. For example, you might have an agent reflect on, and improve, its output a fixed number of times. In this case, the sequence of steps the agent takes is fixed and deterministic. But for complex tasks in which you arenâ€™t able to specify a decomposition of the task into a set of steps ahead of time, Planning allows the agent to decide dynamically what steps to take.\n\nOn one hand, Planning is a very powerful capability; on the other, it leads to less predictable results. In my experience, while I can get the agentic design patterns of Reflection and Tool use to work reliably and improve my applicationsâ€™ performance, Planning is a less mature technology, and I find it hard to predict in advance what it will do. But the field continues to evolve rapidly, and I'm confident that Planning abilities will improve quickly.\n\nIf youâ€™re interested in learning more about Planning with LLMs, I recommend:\n- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, Wei et al. (2022)\n- HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face, Shen et al. (2023)\n- Understanding the planning of LLM agents: A survey, by Huang et al. (2024)\n\n[Original text: https://t.co/pWmIR9wEki ]",
    "createdAt": "Sun Apr 14 20:23:19 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 457,
    "replyCount": 83,
    "likeCount": 2431,
    "quoteCount": 58,
    "viewCount": 389654,
    "bookmarkCount": 2022,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "è§„åˆ’ (Planning) æ˜¯ä¸€ç§æ ¸å¿ƒçš„ AI æ™ºèƒ½ä½“ (AI agent) è®¾è®¡æ¨¡å¼ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) è‡ªä¸»å†³å®šä¸€ç³»åˆ—è¦æ‰§è¡Œçš„æ­¥éª¤ï¼Œä»¥å®Œæˆä¸€é¡¹æ›´å¤§çš„ä»»åŠ¡ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœæˆ‘ä»¬è¦æ±‚ä¸€ä¸ªæ™ºèƒ½ä½“å°±æŸä¸ªä¸»é¢˜è¿›è¡Œåœ¨çº¿ç ”ç©¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè®© LLM å°†è¿™ä¸ªå¤§ç›®æ ‡æ‹†è§£æˆæ›´å°çš„å­ä»»åŠ¡ï¼Œæ¯”å¦‚ç ”ç©¶å…·ä½“çš„å­ä¸»é¢˜ã€æ•´åˆå„é¡¹å‘ç°ï¼Œæœ€åå†æ’°å†™ä¸€ä»½æŠ¥å‘Šã€‚\n\nè®¸å¤šäººåœ¨ ChatGPT å‘å¸ƒåä¸ä¹…ï¼Œéƒ½ç»å†è¿‡ä¸€ä¸ªâ€œChatGPT æ—¶åˆ»â€â€”â€”å½“ä»–ä»¬è¯•ç”¨ ChatGPT æ—¶ï¼ŒæƒŠå–œåœ°å‘ç°å®ƒçš„è¡¨ç°è¿œè¶…ä»–ä»¬å¯¹ AI èƒ½åŠ›çš„é¢„æœŸã€‚å¦‚æœä½ è¿˜æ²¡ä½“éªŒè¿‡ç±»ä¼¼çš„â€œAI æ™ºèƒ½ä½“æ—¶åˆ»â€ï¼Œæˆ‘å¸Œæœ›ä½ å¾ˆå¿«ä¹Ÿèƒ½ç»å†ã€‚æˆ‘å‡ ä¸ªæœˆå‰å°±æœ‰è¿‡ä¸€æ¬¡è¿™æ ·çš„ä½“éªŒï¼šå½“æ—¶æˆ‘ç°åœºæ¼”ç¤ºäº†ä¸€ä¸ªè‡ªå·±å®ç°çš„ç ”ç©¶æ™ºèƒ½ä½“ï¼Œå®ƒèƒ½è°ƒç”¨å„ç§åœ¨çº¿æœç´¢å·¥å…·ã€‚\n\næˆ‘æ›¾å¤šæ¬¡ç§ä¸‹æµ‹è¯•è¿™ä¸ªæ™ºèƒ½ä½“ï¼Œæ¯æ¬¡å®ƒéƒ½èƒ½ç¨³å®šåœ°ä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·æ”¶é›†ä¿¡æ¯ï¼Œå¹¶æ€»ç»“å‡ºä¸€ä»½æŠ¥å‘Šã€‚ç„¶è€Œï¼Œåœ¨ä¸€æ¬¡ç°åœºæ¼”ç¤ºä¸­ï¼Œç½‘ç»œæœç´¢ API å´æ„å¤–åœ°æŠ¥å‡ºäº†é€Ÿç‡é™åˆ¶é”™è¯¯ã€‚æˆ‘å½“æ—¶ä»¥ä¸ºæˆ‘çš„æ¼”ç¤ºè¦å½“ä¼—å¤±è´¥äº†ï¼Œå¿ƒé‡Œéå¸¸å¿å¿‘ã€‚ä½†å‡ºä¹æˆ‘æ„æ–™çš„æ˜¯ï¼Œè¿™ä¸ªæ™ºèƒ½ä½“çµå·§åœ°åˆ‡æ¢åˆ°äº†ç»´åŸºç™¾ç§‘æœç´¢å·¥å…·â€”â€”æˆ‘éƒ½å¿˜äº†è‡ªå·±æ›¾èµ‹äºˆå®ƒè¿™é¡¹èƒ½åŠ›â€”â€”å¹¶æœ€ç»ˆä½¿ç”¨ç»´åŸºç™¾ç§‘è€Œä¸æ˜¯ç½‘ç»œæœç´¢å®Œæˆäº†ä»»åŠ¡ã€‚\n\nè¿™å¯¹æˆ‘æ¥è¯´å°±æ˜¯ä¸€ä¸ªå……æ»¡æƒŠå–œçš„ AI æ™ºèƒ½ä½“æ—¶åˆ»ã€‚æˆ‘ç›¸ä¿¡ï¼Œè®¸å¤šå°šæœªæœ‰è¿‡è¿™ç§ä½“éªŒçš„äººï¼Œåœ¨æœªæ¥å‡ ä¸ªæœˆå†…ä¹Ÿå°†è¿æ¥è¿™æ ·çš„æ—¶åˆ»ã€‚å½“ä½ çœ‹åˆ°ä¸€ä¸ªæ™ºèƒ½ä½“èƒ½è‡ªä¸»å†³å®šä»¥ä½ æ„æƒ³ä¸åˆ°çš„æ–¹å¼å®Œæˆä»»åŠ¡ï¼Œå¹¶ä¸”æœ€ç»ˆæˆåŠŸäº†ï¼Œé‚£æ„Ÿè§‰çœŸæ˜¯å¦™ä¸å¯è¨€ï¼\n\nå¾ˆå¤šä»»åŠ¡æ— æ³•ä¸€æ­¥åˆ°ä½ï¼Œä¹Ÿæ— æ³•é€šè¿‡å•ä¸€å·¥å…·è°ƒç”¨æ¥å®Œæˆï¼Œä½†æ™ºèƒ½ä½“å¯ä»¥è‡ªä¸»å†³å®šè¦é‡‡å–å“ªäº›æ­¥éª¤ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†ç®€åŒ– HuggingGPT è®ºæ–‡ï¼ˆå‚è§ä¸‹æ–‡å¼•ç”¨ï¼‰ä¸­çš„ä¸€ä¸ªä¾‹å­ï¼šå¦‚æœä½ æƒ³è®©ä¸€ä¸ªæ™ºèƒ½ä½“åˆ†æä¸€å¼ ç”·å­©çš„ç…§ç‰‡ï¼Œç„¶åç”»ä¸€å¼ ç›¸åŒå§¿åŠ¿çš„å¥³å­©çš„ç…§ç‰‡ï¼Œè¿™é¡¹ä»»åŠ¡å¯ä»¥åˆ†è§£æˆä¸¤ä¸ªæˆªç„¶ä¸åŒçš„æ­¥éª¤ï¼š(i) æ£€æµ‹ç”·å­©ç…§ç‰‡ä¸­çš„å§¿åŠ¿ï¼Œä»¥åŠ (ii) åŸºäºæ£€æµ‹åˆ°çš„å§¿åŠ¿æ¸²æŸ“ä¸€å¼ å¥³å­©çš„ç…§ç‰‡ã€‚ä¸€ä¸ª LLM å¯èƒ½ä¼šè¢«å¾®è°ƒï¼Œæˆ–è€…é€šè¿‡å°‘æ ·æœ¬ (Few-shot) æç¤ºæ¥è§„åˆ’æ­¥éª¤ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªç±»ä¼¼ \"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}\" çš„å­—ç¬¦ä¸²ã€‚\n\nè¿™ä¸ªç»“æ„åŒ–çš„è¾“å‡ºæ˜ç¡®äº†è¦æ‰§è¡Œçš„ä¸¤ä¸ªæ­¥éª¤ï¼Œéšåä¼šè§¦å‘è½¯ä»¶ä¾æ¬¡è°ƒç”¨å§¿åŠ¿æ£€æµ‹å·¥å…· (pose detection tool) å’Œå§¿åŠ¿è½¬å›¾åƒå·¥å…· (pose-to-image tool) æ¥å®Œæˆä»»åŠ¡ã€‚ï¼ˆæ­¤ç¤ºä¾‹ä»…ç”¨äºè¯´æ˜ç›®çš„ï¼›HuggingGPT ä½¿ç”¨çš„æ ¼å¼æœ‰æ‰€ä¸åŒã€‚ï¼‰\n\nå½“ç„¶ï¼Œè®¸å¤š AI æ™ºèƒ½ä½“å·¥ä½œæµ (workflow) å¹¶ä¸éœ€è¦è§„åˆ’ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½è®©ä¸€ä¸ªæ™ºèƒ½ä½“åœ¨å›ºå®šæ¬¡æ•°å†…åæ€ (Reflection) å¹¶ä¼˜åŒ–å…¶è¾“å‡ºã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ™ºèƒ½ä½“é‡‡å–çš„æ­¥éª¤åºåˆ—æ˜¯å›ºå®šä¸”ç¡®å®šæ€§çš„ã€‚ä½†å¯¹äºé‚£äº›ä½ æ— æ³•é¢„å…ˆæŒ‡å®šä»»åŠ¡åˆ†è§£æ­¥éª¤çš„å¤æ‚ä»»åŠ¡ï¼Œè§„åˆ’ (Planning) å°±å…è®¸æ™ºèƒ½ä½“åŠ¨æ€åœ°å†³å®šå¦‚ä½•è¡ŒåŠ¨ã€‚\n\nä¸€æ–¹é¢ï¼Œè§„åˆ’æ˜¯ä¸€é¡¹éå¸¸å¼ºå¤§çš„èƒ½åŠ›ï¼›å¦ä¸€æ–¹é¢ï¼Œå®ƒä¹Ÿä½¿å¾—ç»“æœçš„å¯é¢„æµ‹æ€§é™ä½ã€‚æ ¹æ®æˆ‘çš„ç»éªŒï¼Œè™½ç„¶æˆ‘èƒ½è®©åæ€ (Reflection) å’Œå·¥å…·ä½¿ç”¨ (Tool use) è¿™ä¸¤ç§æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼å¯é åœ°å‘æŒ¥ä½œç”¨ï¼Œå¹¶æå‡æˆ‘åº”ç”¨ç¨‹åºçš„æ€§èƒ½ï¼Œä½†è§„åˆ’ä»æ˜¯ä¸€é¡¹ç›¸å¯¹ä¸å¤Ÿæˆç†Ÿçš„æŠ€æœ¯ï¼Œæˆ‘å‘ç°å¾ˆéš¾æå‰é¢„æµ‹å®ƒçš„å…·ä½“è¡Œä¸ºã€‚ä¸è¿‡ï¼Œè¿™ä¸ªé¢†åŸŸæ­£åœ¨è¿…é€Ÿå‘å±•ï¼Œæˆ‘ç›¸ä¿¡è§„åˆ’èƒ½åŠ›ä¼šå¾ˆå¿«å¾—åˆ°æ˜¾è‘—æå‡ã€‚\n\nå¦‚æœæ‚¨å¯¹åˆ©ç”¨ LLM è¿›è¡Œè§„åˆ’ (Planning) æ„Ÿå…´è¶£ï¼Œæˆ‘æ¨èé˜…è¯»ä»¥ä¸‹æ–‡çŒ®ï¼š\n- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, Wei et al. (2022)\n- HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face, Shen et al. (2023)\n- Understanding the planning of LLM agents: A survey, by Huang et al. (2024)\n\n[Original text: https://t.co/pWmIR9wEki ]"
  },
  {
    "id": "1778075380886495676",
    "url": "https://x.com/AndrewYNg/status/1778075380886495676",
    "text": "Data preprocessing is critical for building effective RAG systems. Our new short course, Preprocessing Unstructured Data for LLM Applications, taught by @mrobinson0623 of @UnstructuredIO, demonstrates important but sometimes overlooked aspects of RAG systems:\n\n- How to extract and normalize content from diverse formats like PDF, Powerpoint, and HTML to expand your LLM's knowledge\n- Enriching data with metadata to enable more powerful retrieval and reasoning\n- Applying document layout analysis and vision transforms to process embedded images and tables\n\nThen youâ€™ll use all these skills and build a RAG bot that draws from a corpus that includes PDF, PowerPoint, and Markdown documents.\n\nPlease sign up here: https://t.co/AM3rmZJmNF",
    "createdAt": "Wed Apr 10 14:59:40 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 235,
    "replyCount": 24,
    "likeCount": 1190,
    "quoteCount": 21,
    "viewCount": 150023,
    "bookmarkCount": 814,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ•°æ®é¢„å¤„ç†å¯¹äºæ„å»ºé«˜æ•ˆçš„ RAG ç³»ç»Ÿ (Retrieval Augmented Generation systems) æ¥è¯´ä¸å¯æˆ–ç¼ºã€‚æˆ‘ä»¬æ–°æ¨å‡ºçš„çŸ­è¯¾ç¨‹â€œé¢å‘å¤§è¯­è¨€æ¨¡å‹ (Large Language Model) åº”ç”¨çš„éç»“æ„åŒ–æ•°æ®é¢„å¤„ç†â€ï¼Œç”± @UnstructuredIO çš„ @mrobinson0623 è€å¸ˆä¸»è®²ï¼Œå°†æ·±å…¥æ¢è®¨ RAG ç³»ç»Ÿä¸­ä¸€äº›è‡³å…³é‡è¦å´å¸¸è¢«å¿½è§†çš„ç¯èŠ‚ï¼š\n\n- å¦‚ä½•ä» PDFã€Powerpoint å’Œ HTML ç­‰å¤šç§æ ¼å¼ä¸­æå–å¹¶è§„èŒƒåŒ–å†…å®¹ï¼Œä»è€Œä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›æ›´å¹¿é˜”çš„çŸ¥è¯†åŸºç¡€ã€‚\n- åˆ©ç”¨å…ƒæ•°æ® (metadata) ä¸°å¯Œæ•°æ®ï¼Œä»¥å®ç°æ›´å¼ºå¤§çš„æ£€ç´¢å’Œæ¨ç†èƒ½åŠ›ã€‚\n- åº”ç”¨æ–‡æ¡£ç‰ˆé¢åˆ†æ (document layout analysis) å’Œè§†è§‰è½¬æ¢ (vision transforms) æŠ€æœ¯æ¥å¤„ç†æ–‡æ¡£ä¸­åµŒå…¥çš„å›¾åƒå’Œè¡¨æ ¼ã€‚\n\nå­¦å®Œæœ¬è¯¾ç¨‹ï¼Œæ‚¨å°†èƒ½å¤Ÿè¿ç”¨è¿™äº›æŠ€èƒ½ï¼Œäº²æ‰‹æ­å»ºä¸€ä¸ª RAG æœºå™¨äºº (Retrieval Augmented Generation bot)ï¼Œå®ƒèƒ½ä»åŒ…å« PDFã€PowerPoint å’Œ Markdown æ–‡æ¡£çš„è¯­æ–™åº“ (corpus) ä¸­æ™ºèƒ½æå–ä¿¡æ¯ã€‚\n\næ¬¢è¿ç‚¹å‡»æ­¤å¤„æŠ¥åå­¦ä¹ ï¼šhttps://t.co/AM3rmZJmNF"
  },
  {
    "id": "1776737961243218134",
    "url": "https://x.com/AndrewYNg/status/1776737961243218134",
    "text": "The Financial Times has a great article on Renate Nyborg @renate's work on @meeno_official , written by @madhumita29. \n\nThe article is paywalled, but I appreciate Renate (as well as Harvard's @ronivey)'s leadership speaking about the dangers of the AI fake girlfriend/boyfriend industry and the risk of this leading to greater loneliness. Renate says  \"Men didnâ€™t want to meet girls because they had virtual girlfriends who said exactly what they wanted to hear.\" To regulators wondering what are the risky applications of AI, I would urge taking a look at the fake gf/bf industry! \n\nIn contrast, Meeno gives advice for human relationships, and is working to bring people together. Working to reduce human loneliness is a wonderful goal! \n\nhttps://t.co/nB6dfkHaHn",
    "createdAt": "Sat Apr 06 22:25:14 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 56,
    "replyCount": 43,
    "likeCount": 279,
    "quoteCount": 7,
    "viewCount": 110658,
    "bookmarkCount": 97,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ã€Šé‡‘èæ—¶æŠ¥ã€‹åˆŠç™»äº†ä¸€ç¯‡ç”± @madhumita29 æ’°å†™çš„ç²¾å½©æ–‡ç« ï¼Œä»‹ç»äº† Renate Nyborg @renate åœ¨ @meeno_official æ–¹é¢çš„å·¥ä½œã€‚\n\nè¯¥æ–‡ç« è®¾æœ‰ä»˜è´¹å¢™ï¼Œä½†æˆ‘éå¸¸èµèµ Renate (ä»¥åŠå“ˆä½›å¤§å­¦çš„ @ronivey) å¸¦å¤´æŒ‡å‡º AI å‡å¥³å‹/ç”·å‹è¡Œä¸šçš„å±é™©ï¼Œä»¥åŠè¿™å¯èƒ½åŠ å‰§äººç±»å­¤ç‹¬æ„Ÿçš„é—®é¢˜ã€‚Renate è¡¨ç¤ºï¼šâ€œç”·æ€§ä¸æ„¿ä¸ç°å®ä¸­çš„å¥³å­©äº¤å¾€ï¼Œå› ä¸ºä»–ä»¬æ‹¥æœ‰è™šæ‹Ÿå¥³å‹ï¼Œè¿™äº›è™šæ‹Ÿå¥³å‹æ€»èƒ½è¯´å‡ºä»–ä»¬æƒ³å¬çš„ä¸€åˆ‡ã€‚â€ å¯¹äºé‚£äº›æ­£åœ¨æ¢å¯» AI (äººå·¥æ™ºèƒ½) æ½œåœ¨é«˜é£é™©åº”ç”¨çš„ç›‘ç®¡æœºæ„ï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä»–ä»¬å…³æ³¨å‡å¥³å‹/ç”·å‹è¡Œä¸šï¼\n\nä¸æ­¤å½¢æˆå¯¹æ¯”çš„æ˜¯ï¼ŒMeeno æ—¨åœ¨ä¸ºçœŸå®çš„äººé™…å…³ç³»æä¾›å»ºè®®ï¼Œå¹¶åŠªåŠ›å°†äººä»¬è”ç³»åœ¨ä¸€èµ·ã€‚è‡´åŠ›äºå‡å°‘äººç±»å­¤ç‹¬æ„Ÿï¼Œè¿™æ— ç–‘æ˜¯ä¸€ä¸ªç¾å¥½çš„ç›®æ ‡ï¼\n\nhttps://t.co/nB6dfkHaHn"
  },
  {
    "id": "1776363779141628369",
    "url": "https://x.com/AndrewYNg/status/1776363779141628369",
    "text": "The task-based analysis of how AI affects jobs is a powerful technique for creating business value. It was pioneered by Workhelixâ€™s @erikbryn et al. Now, Workhelix has developed technology to apply this at scale, by automatically examining a companyâ€™s job descriptions, professional social data, and other information, to give CEOs and Boards a roadmap to creating value. \n\nAI Fund is thrilled to support Workhelixâ€™s launch, coming Tuesday April 9th. To learn more, please join the conversation with @erikbryn, @amcafee, @danielrock and @JamesMilin and me at the webinar below! https://t.co/I6sVHhEGmV",
    "createdAt": "Fri Apr 05 21:38:22 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 90,
    "replyCount": 33,
    "likeCount": 519,
    "quoteCount": 8,
    "viewCount": 172487,
    "bookmarkCount": 316,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "é’ˆå¯¹ AI (Artificial Intelligence) å¦‚ä½•åŸºäºä»»åŠ¡å½±å“å·¥ä½œçš„åˆ†æï¼Œæ˜¯åˆ›é€ å•†ä¸šä»·å€¼çš„ä¸€ç§å¼ºå¤§æŠ€æœ¯ã€‚è¿™é¡¹æŠ€æœ¯æœ€åˆç”± Workhelix çš„ @erikbryn ç­‰äººå¼€åˆ›ã€‚ç°åœ¨ï¼ŒWorkhelix å·²ç»å¼€å‘å‡ºç›¸å…³æŠ€æœ¯ï¼Œèƒ½å¤Ÿå¤§è§„æ¨¡åº”ç”¨è¿™ä¸€åˆ†ææ–¹æ³•ï¼šé€šè¿‡è‡ªåŠ¨å®¡æŸ¥å…¬å¸çš„èŒä½æè¿°ã€ä¸“ä¸šç¤¾äº¤æ•°æ®åŠå…¶ä»–ä¿¡æ¯ï¼Œä¸º CEO (é¦–å¸­æ‰§è¡Œå®˜) å’Œè‘£äº‹ä¼š (Boards) æä¾›ä¸€ä»½åˆ›é€ ä»·å€¼çš„è·¯çº¿å›¾ã€‚\n\nAI Fund å¾ˆé«˜å…´èƒ½æ”¯æŒ Workhelix åœ¨ 4 æœˆ 9 æ—¥ï¼ˆæ˜ŸæœŸäºŒï¼‰ä¸Šçº¿ã€‚æƒ³è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹é“¾æ¥ï¼Œä¸ @erikbrynã€@amcafeeã€@danielrockã€@JamesMilin ä»¥åŠæˆ‘ä¸€èµ·å‚åŠ ç½‘ç»œç ”è®¨ä¼šï¼ŒåŠ å…¥æˆ‘ä»¬çš„è®¨è®ºï¼https://t.co/I6sVHhEGmV"
  },
  {
    "id": "1775951610059141147",
    "url": "https://x.com/AndrewYNg/status/1775951610059141147",
    "text": "Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design pattern of AI agentic workflows. You may be familiar with LLM-based systems that can perform a web search or execute code. Some of the large, consumer-facing LLMs already incorporate these features. But tool use goes well beyond these examples. \n\nIf you prompt an online LLM-based chat system, â€œWhat is the best coffee maker according to reviewers?â€, it might decide to carry out a web search and download one or more web pages to gain context. Early on, LLM developers realized that relying only on a pre-trained transformer to generate output tokens is limiting, and that giving an LLM a tool for web search lets it do much more. With such a tool, an LLM is either fine-tuned or prompted (perhaps with few-shot prompting) to generate a special string like {tool: web-search, query: \"coffee maker reviews\"} to request calling a search engine. (The exact format of the string depends on the implementation.) A post-processing step then looks for strings like these, calls the web search function with the relevant parameters when it finds one, and passes the result back to the LLM as additional input context for further processing.\n\nSimilarly, if you ask, â€œIf I invest $100 at compound 7% interest for 12 years, what do I have at the end?â€, rather than trying to generate the answer directly using a transformer network â€” which is unlikely to result in the right answer â€” the LLM might use a code execution tool to run a Python command to compute 100 * (1+0.07)**12 to get the right answer. The LLM might generate a string like this: {tool: python-interpreter, code: \"100 * (1+0.07)**12\"}.\n\nBut tool use in agentic workflows now goes much further. Developers are using functions to search different sources (web, Wikipedia, arXiv, etc.), to interface with productivity tools (send email, read/write calendar entries, etc.), generate or interpret images, and much more. We can prompt an LLM using context that gives detailed descriptions of many functions. These descriptions might include a text description of what the function does plus details of what arguments the function expects. And weâ€™d expect the LLM to automatically choose the right function to call to do a job.\n\nFurther, systems are being built in which the LLM has access to hundreds of tools. In such settings, there might be too many functions at your disposal to put all of them into the LLM context, so you might use heuristics to pick the most relevant subset to include in the LLM context at the current step of processing. This technique, which is described in the Gorilla paper cited below, is reminiscent of how, if there is too much text to include as context, retrieval augmented generation (RAG) systems offer heuristics for picking a subset of the text to include.\n\nEarly in the history of LLMs, before widespread availability of large multimodal models (LMMs)  like LLaVa, GPT-4V, and Gemini, LLMs could not process images directly, so a lot of work on tool use was carried out by the computer vision community. At that time, the only way for an LLM-based system to manipulate an image was by calling a function to, say, carry out object recognition or some other function on it. Since then, practices for tool use have exploded. GPT-4â€™s function calling capability, released in the middle of last year, was a significant step toward general-purpose tool use. Since then, more and more LLMs are being developed to similarly be facile with tool use.\n\nIf youâ€™re interested in learning more about tool use, I recommend:\n- Gorilla: Large Language Model Connected with Massive APIs, Patil et al. (2023)\n- MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action, Yang et al. (2023)\n- Efficient Tool Use with Chain-of-Abstraction Reasoning, Gao et al. (2024)\n\nBoth Tool Use and Reflection, which I posted about last week, are design patterns that I can get to work fairly reliably on my applications â€” both are capabilities well worth learning about. In the future, Iâ€™ll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable â€” albeit very exciting â€” technologies.\n\n[Original text:  https://t.co/gHCOYSsKQO ]",
    "createdAt": "Thu Apr 04 18:20:34 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 301,
    "replyCount": 80,
    "likeCount": 1588,
    "quoteCount": 33,
    "viewCount": 255763,
    "bookmarkCount": 1270,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å·¥å…·ä½¿ç”¨ï¼Œå³èµ‹äºˆå¤§è¯­è¨€æ¨¡å‹ (LLM) å¯ä¾›å…¶è¯·æ±‚è°ƒç”¨çš„åŠŸèƒ½ï¼Œç”¨äºæ”¶é›†ä¿¡æ¯ã€é‡‡å–è¡ŒåŠ¨æˆ–æ“çºµæ•°æ®ï¼Œæ˜¯ AI æ™ºèƒ½ä½“ (AI agent) å·¥ä½œæµä¸­çš„ä¸€ä¸ªå…³é”®è®¾è®¡æ¨¡å¼ã€‚ä½ å¯èƒ½å·²ç»ç†Ÿæ‚‰é‚£äº›èƒ½å¤Ÿæ‰§è¡Œç½‘é¡µæœç´¢æˆ–è¿è¡Œä»£ç çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç³»ç»Ÿã€‚ä¸€äº›å¤§å‹çš„ã€é¢å‘æ¶ˆè´¹è€…çš„çš„å¤§è¯­è¨€æ¨¡å‹å·²ç»å†…ç½®äº†è¿™äº›åŠŸèƒ½ã€‚ä½†å·¥å…·ä½¿ç”¨çš„èŒƒç•´è¿œä¸æ­¢äºæ­¤ã€‚\n\nå¦‚æœä½ å‘ä¸€ä¸ªåœ¨çº¿çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„èŠå¤©ç³»ç»Ÿæé—®ï¼šâ€œæ ¹æ®è¯„è®ºè€…ï¼Œæœ€å¥½çš„å’–å•¡æœºæ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼Œå®ƒå¯èƒ½ä¼šå†³å®šè¿›è¡Œä¸€æ¬¡ç½‘é¡µæœç´¢ï¼Œå¹¶ä¸‹è½½ä¸€ä¸ªæˆ–å¤šä¸ªç½‘é¡µæ¥è·å–ç›¸å…³èƒŒæ™¯ä¿¡æ¯ã€‚æ—©æœŸï¼Œå¤§è¯­è¨€æ¨¡å‹å¼€å‘è€…å°±æ„è¯†åˆ°ï¼Œä»…ä»…ä¾é é¢„è®­ç»ƒçš„ Transformer æ¥ç”Ÿæˆè¾“å‡º Token (æ ‡è®°) æ˜¯æœ‰å±€é™çš„ã€‚å¦‚æœèµ‹äºˆå¤§è¯­è¨€æ¨¡å‹ç½‘é¡µæœç´¢å·¥å…·ï¼Œå®ƒå°±èƒ½åšæ›´å¤šäº‹æƒ…ã€‚æœ‰äº†è¿™æ ·çš„å·¥å…·ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¼šç»è¿‡å¾®è°ƒæˆ–é€šè¿‡æç¤ºï¼ˆä¾‹å¦‚ å°‘æ ·æœ¬ (few-shot) æç¤ºï¼‰æ¥ç”Ÿæˆä¸€ä¸ªç‰¹æ®Šå­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ {tool: web-search, query: \"coffee maker reviews\"}ï¼Œä»è€Œè¯·æ±‚è°ƒç”¨æœç´¢å¼•æ“ã€‚ (è¯¥å­—ç¬¦ä¸²çš„å…·ä½“æ ¼å¼å–å†³äºå…·ä½“çš„å®ç°ã€‚) éšåï¼Œä¸€ä¸ªåå¤„ç†æ­¥éª¤ä¼šæŸ¥æ‰¾è¿™äº›ç‰¹æ®Šå­—ç¬¦ä¸²ï¼Œä¸€æ—¦æ‰¾åˆ°ï¼Œä¾¿ä¼šä½¿ç”¨ç›¸å…³å‚æ•°è°ƒç”¨ç½‘é¡µæœç´¢åŠŸèƒ½ï¼Œå¹¶å°†ç»“æœä½œä¸ºé¢å¤–çš„è¾“å…¥ä¸Šä¸‹æ–‡åé¦ˆç»™å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†ã€‚\n\nåŒæ ·ï¼Œå¦‚æœä½ é—®ï¼šâ€œå¦‚æœæˆ‘ä»¥ 7% çš„å¤åˆ©æŠ•èµ„ 100 ç¾å…ƒ 12 å¹´ï¼Œæœ€åæˆ‘èƒ½å¾—åˆ°å¤šå°‘é’±ï¼Ÿâ€ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¸ä¼šè¯•å›¾ç›´æ¥ä½¿ç”¨ Transformer ç½‘ç»œæ¥ç”Ÿæˆç­”æ¡ˆ â€” å› ä¸ºè¿™ä¸å¤ªå¯èƒ½å¾—å‡ºæ­£ç¡®ç»“æœ â€” è€Œæ˜¯å¯èƒ½è°ƒç”¨ä¸€ä¸ªä»£ç æ‰§è¡Œå·¥å…·ï¼Œè¿è¡Œåƒ 100 * (1+0.07)**12 è¿™æ ·çš„ Python å‘½ä»¤ï¼Œä»è€Œå¾—å‡ºæ­£ç¡®ç­”æ¡ˆã€‚å¤§è¯­è¨€æ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆä¸€ä¸ªç±»ä¼¼è¿™æ ·çš„å­—ç¬¦ä¸²ï¼š{tool: python-interpreter, code: \"100 * (1+0.07)**12\"}ã€‚\n\nç„¶è€Œï¼Œåœ¨æ™ºèƒ½ä½“å·¥ä½œæµä¸­ï¼Œå·¥å…·ä½¿ç”¨çš„èƒ½åŠ›å·²ç»å¤§å¤§æ‹“å±•ã€‚å¼€å‘è€…æ­£åˆ©ç”¨è¿™äº›åŠŸèƒ½æœç´¢ä¸åŒçš„ä¿¡æ¯æ¥æº (ä¾‹å¦‚ç½‘ç»œã€ç»´åŸºç™¾ç§‘ã€arXiv ç­‰)ï¼Œä¸ç”Ÿäº§åŠ›å·¥å…·å¯¹æ¥ (ä¾‹å¦‚å‘é€ç”µå­é‚®ä»¶ã€è¯»å†™æ—¥å†æ¡ç›®ç­‰)ï¼Œç”Ÿæˆæˆ–è§£é‡Šå›¾åƒï¼Œä»¥åŠå®ç°æ›´å¤šç›®æ ‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æä¾›è¯¦ç»†æè¿°ä¼—å¤šåŠŸèƒ½çš„ä¸Šä¸‹æ–‡æ¥æç¤ºå¤§è¯­è¨€æ¨¡å‹ã€‚è¿™äº›æè¿°å¯èƒ½åŒ…æ‹¬å¯¹åŠŸèƒ½ä½œç”¨çš„æ–‡æœ¬è¯´æ˜ï¼Œä»¥åŠè¯¥åŠŸèƒ½é¢„æœŸæ¥æ”¶å“ªäº›å‚æ•°çš„è¯¦ç»†ä¿¡æ¯ã€‚æˆ‘ä»¬æœŸæœ›å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n\næ­¤å¤–ï¼Œç›®å‰æ­£åœ¨å¼€å‘çš„ç³»ç»Ÿï¼Œèƒ½è®©å¤§è¯­è¨€æ¨¡å‹è®¿é—®æ•°ç™¾ç§å·¥å…·ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä¾›å¤§è¯­è¨€æ¨¡å‹ä½¿ç”¨çš„åŠŸèƒ½å¯èƒ½å¤ªå¤šï¼Œæ— æ³•å°†æ‰€æœ‰åŠŸèƒ½éƒ½çº³å…¥å…¶ä¸Šä¸‹æ–‡ (context)ï¼Œå› æ­¤ç³»ç»Ÿå¯èƒ½ä¼šé‡‡ç”¨å¯å‘å¼æ–¹æ³•æ¥æŒ‘é€‰æœ€ç›¸å…³çš„å­é›†ï¼Œä»¥ä¾¿åœ¨å½“å‰å¤„ç†æ­¥éª¤ä¸­åŒ…å«åœ¨å¤§è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å†…ã€‚è¿™é¡¹æŠ€æœ¯åœ¨ä¸‹é¢å¼•ç”¨çš„ Gorilla è®ºæ–‡ä¸­æœ‰æ‰€æè¿°ï¼Œå®ƒç±»ä¼¼äºå½“æœ‰å¤ªå¤šæ–‡æœ¬æ— æ³•å…¨éƒ¨ä½œä¸ºä¸Šä¸‹æ–‡æ—¶ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿå¦‚ä½•æä¾›å¯å‘å¼æ–¹æ³•æ¥é€‰æ‹©æ–‡æœ¬çš„ä¸€ä¸ªå­é›†ä»¥ä¾›åŒ…å«ã€‚\n\nåœ¨å¤§è¯­è¨€æ¨¡å‹å‘å±•æ—©æœŸï¼Œåœ¨ LLaVaã€GPT-4V å’Œ Gemini ç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ (LMM) å°šæœªå¹¿æ³›æ™®åŠä¹‹å‰ï¼Œå¤§è¯­è¨€æ¨¡å‹æ— æ³•ç›´æ¥å¤„ç†å›¾åƒã€‚å› æ­¤ï¼Œè®¡ç®—æœºè§†è§‰ç¤¾åŒºåœ¨å·¥å…·ä½¿ç”¨æ–¹é¢åšäº†å¤§é‡å·¥ä½œã€‚é‚£æ—¶ï¼ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç³»ç»Ÿæ“çºµå›¾åƒçš„å”¯ä¸€æ–¹å¼æ˜¯è°ƒç”¨ä¸€ä¸ªåŠŸèƒ½ï¼Œä¾‹å¦‚å¯¹å…¶æ‰§è¡Œç›®æ ‡è¯†åˆ«æˆ–è¿›è¡Œå…¶ä»–å¤„ç†ã€‚è‡ªé‚£æ—¶èµ·ï¼Œå·¥å…·ä½¿ç”¨çš„å®è·µå·²ç»è“¬å‹ƒå‘å±•ã€‚GPT-4 äºå»å¹´å¹´ä¸­å‘å¸ƒçš„åŠŸèƒ½è°ƒç”¨èƒ½åŠ›ï¼Œæ˜¯è¿ˆå‘é€šç”¨å·¥å…·ä½¿ç”¨çš„é‡è¦ä¸€æ­¥ã€‚æ­¤åï¼Œè¶Šæ¥è¶Šå¤šçš„çš„å¤§è¯­è¨€æ¨¡å‹æ­£åœ¨å¼€å‘ä¸­ï¼Œä»¥æœŸåŒæ ·æ“…é•¿å·¥å…·ä½¿ç”¨ã€‚\n\nå¦‚æœä½ æœ‰å…´è¶£äº†è§£æ›´å¤šå…³äºå·¥å…·ä½¿ç”¨çš„ä¿¡æ¯ï¼Œæˆ‘æ¨èä»¥ä¸‹è®ºæ–‡ï¼š\n- Gorilla: Large Language Model Connected with Massive APIs, Patil et al. (2023)\n- MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action, Yang et al. (2023)\n- Efficient Tool Use with Chain-of-Abstraction Reasoning, Gao et al. (2024)\n\nå·¥å…·ä½¿ç”¨å’Œåæ€ï¼Œæˆ‘åœ¨ä¸Šå‘¨çš„å¸–å­ä¸­æåˆ°äº†å®ƒä»¬ï¼Œè¿™äº›è®¾è®¡æ¨¡å¼åœ¨æˆ‘å¼€å‘çš„åº”ç”¨ç¨‹åºä¸­éƒ½èƒ½ç›¸å½“å¯é åœ°å‘æŒ¥ä½œç”¨ â€” ä¸¤è€…éƒ½æ˜¯éå¸¸å€¼å¾—å­¦ä¹ çš„èƒ½åŠ›ã€‚æœªæ¥ï¼Œæˆ‘å°†æè¿°è§„åˆ’å’Œå¤šæ™ºèƒ½ä½“åä½œè®¾è®¡æ¨¡å¼ã€‚å®ƒä»¬èƒ½è®© AI æ™ºèƒ½ä½“å®Œæˆæ›´å¤šä»»åŠ¡ï¼Œä½†ä½œä¸ºæŠ€æœ¯è€Œè¨€ï¼Œå®ƒä»¬æˆç†Ÿåº¦è¾ƒä½ã€å¯é¢„æµ‹æ€§è¾ƒå·® â€” å°½ç®¡å®ƒä»¬éå¸¸ä»¤äººå…´å¥‹ã€‚\n\n[åŸå§‹æ–‡æœ¬: https://t.co/gHCOYSsKQO ]"
  },
  {
    "id": "1775569875639116148",
    "url": "https://x.com/AndrewYNg/status/1775569875639116148",
    "text": "Learn to carry out red teaming attacks against your own LLM-based applications to spot and patch vulnerabilities! In our new short course, Red Teaming LLM Applications, Matteo Dora & Luca Martial of LLM testing company @giskard_ai teach how to simulate malicious actions to discover vulnerabilities, and improve security. We start with prompt injection, where you can trick an LLM into bypassing safeguards to reveal private information, or say something inappropriate. There is no one-size-fits-all approach to security, but this course will help you identify some scenarios to protect against.\n\nWe believe having red teaming capabilities widely known will result in greater transparency and safer LLM-based systems. However, we ask you to use the skills you gain from this course ethically.\n\nPlease sign up here: https://t.co/Y9ZANSldhG",
    "createdAt": "Wed Apr 03 17:03:41 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 129,
    "replyCount": 27,
    "likeCount": 734,
    "quoteCount": 7,
    "viewCount": 109324,
    "bookmarkCount": 319,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å­¦ä¹ å¦‚ä½•å¯¹æ‚¨è‡ªå·±çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„åº”ç”¨ç¨‹åºè¿›è¡Œçº¢é˜Ÿæ”»å‡» (red teaming attack)ï¼Œä»¥å‘ç°å¹¶ä¿®è¡¥å®‰å…¨æ¼æ´ï¼åœ¨æˆ‘ä»¬æ–°çš„çŸ­æœŸè¯¾ç¨‹ã€ŠLLM åº”ç”¨ç¨‹åºçš„çº¢é˜Ÿæ¼”ç»ƒã€‹ä¸­ï¼ŒLLM æµ‹è¯•å…¬å¸ @giskard_ai çš„ Matteo Dora å’Œ Luca Martial å°†æ•™æ‚¨å¦‚ä½•æ¨¡æ‹Ÿæ¶æ„è¡Œä¸ºï¼Œä»è€Œå‘ç°æ¼æ´å¹¶æé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚æˆ‘ä»¬å°†ä»æç¤ºæ³¨å…¥ (prompt injection) å¼€å§‹ï¼Œè¿™ç§æ”»å‡»æ–¹å¼å¯ä»¥æ¬ºéª— LLM ç»•è¿‡å®‰å…¨é˜²æŠ¤ï¼Œæ³„éœ²ç§äººä¿¡æ¯æˆ–å‘å‡ºä¸å½“è¨€è®ºã€‚è™½ç„¶å®‰å…¨é˜²æŠ¤æ²¡æœ‰ä¸‡èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œä½†æœ¬è¯¾ç¨‹å°†å¸®åŠ©æ‚¨è¯†åˆ«ä¸€äº›éœ€è¦é‡ç‚¹é˜²èŒƒçš„åœºæ™¯ã€‚\n\næˆ‘ä»¬ç›¸ä¿¡ï¼Œçº¢é˜Ÿèƒ½åŠ›å¦‚æœèƒ½è¢«å¹¿æ³›æŒæ¡ï¼Œå°†æœ‰åŠ©äºæé«˜é€æ˜åº¦ï¼Œå¹¶ä½¿åŸºäº LLM çš„ç³»ç»Ÿæ›´åŠ å®‰å…¨ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬è¦æ±‚æ‚¨ä»¥é“å¾·çš„æ–¹å¼ä½¿ç”¨ä»æœ¬è¯¾ç¨‹ä¸­è·å¾—çš„æŠ€èƒ½ã€‚\n\nè¯·åœ¨æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/Y9ZANSldhG"
  },
  {
    "id": "1775324778624397657",
    "url": "https://x.com/AndrewYNg/status/1775324778624397657",
    "text": "I hope everyone in Taiwan ğŸ‡¹ğŸ‡¼ is okay after the earthquake. My thoughts are with everyone affected. â¤ï¸",
    "createdAt": "Wed Apr 03 00:49:45 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 127,
    "replyCount": 47,
    "likeCount": 1866,
    "quoteCount": 5,
    "viewCount": 188744,
    "bookmarkCount": 28,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å¸Œæœ›å°æ¹¾ ğŸ‡¹ğŸ‡¼ çš„æ¯ä¸ªäººåœ¨åœ°éœ‡åéƒ½å¹³å®‰ã€‚æˆ‘çš„å¿ƒä¸æ‰€æœ‰å—å½±å“çš„äººåŒåœ¨ã€‚â¤ï¸"
  },
  {
    "id": "1773393357022298617",
    "url": "https://x.com/AndrewYNg/status/1773393357022298617",
    "text": "Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I'd like to discuss Reflection. For a design pattern thatâ€™s relatively quick to implement, I've seen it lead to surprising performance gains. \n\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection. \n\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. After that, we can prompt it to reflect on its own output, perhaps as follows:\n\nHereâ€™s code intended for task X:\n[previously generated code]\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\n\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\n\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\n\nFurther, we can implement Reflection using a multi-agent framework. I've found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent's output. The resulting discussion between the two agents leads to improved responses.\n\nReflection is a relatively basic type of agentic workflow, but I've been delighted by how much it improved my applicationsâ€™ results in a few cases. I hope you will try it in your own work. If youâ€™re interested in learning more about reflection, I recommend these papers:\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\n\nIâ€™ll discuss the other agentic design patterns as well in the future.\n\n[Original text: https://t.co/FtM2zOT2Lx ]",
    "createdAt": "Thu Mar 28 16:54:59 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 576,
    "replyCount": 101,
    "likeCount": 2801,
    "quoteCount": 76,
    "viewCount": 488223,
    "bookmarkCount": 2649,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ä¸Šå‘¨ï¼Œæˆ‘ä»‹ç»äº†å››ç§ AI æ™ºèƒ½ä½“å·¥ä½œæµçš„ è®¾è®¡æ¨¡å¼ï¼Œæˆ‘ç›¸ä¿¡å®ƒä»¬å°†åœ¨ä»Šå¹´æ¨åŠ¨æ˜¾è‘—çš„è¿›å±•ï¼š åæ€ (Reflection)ã€ å·¥å…·ä½¿ç”¨ (Tool use)ã€ è§„åˆ’ (Planning) å’Œ å¤šæ™ºèƒ½ä½“åä½œ (Multi-agent collaboration)ã€‚ä¸è®© å¤§è¯­è¨€æ¨¡å‹ (LLM) ç›´æ¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºä¸åŒï¼Œ AI æ™ºèƒ½ä½“å·¥ä½œæµä¼šå¤šæ¬¡æç¤º å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶æœ‰æœºä¼šé€æ­¥æ„å»ºå‡ºæ›´é«˜è´¨é‡çš„è¾“å‡ºã€‚ä»Šå¤©ï¼Œæˆ‘æƒ³æ·±å…¥æ¢è®¨ä¸€ä¸‹ åæ€ è¿™ç§æ¨¡å¼ã€‚å°½ç®¡å®ƒå®ç°èµ·æ¥ç›¸å¯¹å¿«é€Ÿï¼Œä½†å…¶å¸¦æ¥çš„ æ€§èƒ½æå‡ å´å¸¸å¸¸ä»¤äººæƒŠå–œã€‚\n\nä½ ä¹Ÿè®¸æœ‰è¿‡è¿™æ ·çš„ç»å†ï¼šå‘ ChatGPT/Claude/Gemini æé—®ï¼Œæ”¶åˆ°çš„ç­”æ¡ˆä¸å°½å¦‚äººæ„ï¼Œäºæ˜¯ä½ æä¾›äº† æ‰¹åˆ¤æ€§åé¦ˆï¼Œå¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ æ”¹è¿›å“åº”ï¼Œæœ€ç»ˆè·å¾—äº†æ›´å¥½çš„ç­”æ¡ˆã€‚é‚£ä¹ˆï¼Œå¦‚æœæˆ‘ä»¬å°†æä¾› æ‰¹åˆ¤æ€§åé¦ˆ çš„æ­¥éª¤è‡ªåŠ¨åŒ–ï¼Œè®©æ¨¡å‹è‡ªåŠ¨è¯„ä¼°è‡ªå·±çš„è¾“å‡ºå¹¶è¿›è¡Œæ”¹è¿›å‘¢ï¼Ÿè¿™æ­£æ˜¯ åæ€ çš„æ ¸å¿ƒæ€æƒ³ã€‚\n\nä»¥è¦æ±‚ å¤§è¯­è¨€æ¨¡å‹ ç¼–å†™ä»£ç çš„ä»»åŠ¡ä¸ºä¾‹ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥æç¤ºå®ƒç”Ÿæˆæ‰§è¡Œç‰¹å®šä»»åŠ¡ X çš„ä»£ç ã€‚ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥æç¤ºå®ƒå¯¹è‡ªå·±çš„è¾“å‡ºè¿›è¡Œåæ€å’Œè¯„ä¼°ï¼Œå…·ä½“å¯ä»¥è¿™æ ·å¼•å¯¼ï¼š\n\nè¿™æ˜¯ä¸ºä»»åŠ¡ X ç¼–å†™çš„ä»£ç ï¼š\n[ä»¥å‰ç”Ÿæˆçš„ä»£ç ]\nè¯·ä»”ç»†æ£€æŸ¥ä»£ç çš„æ­£ç¡®æ€§ã€é£æ ¼å’Œæ•ˆç‡ï¼Œå¹¶æå‡ºå»ºè®¾æ€§çš„æ”¹è¿›æ„è§ã€‚\n\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ å¤§è¯­è¨€æ¨¡å‹ æœ‰æ—¶ä¼šå‘ç°é—®é¢˜å¹¶æå‡ºå»ºè®¾æ€§å»ºè®®ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å°† (i) ä¹‹å‰ç”Ÿæˆçš„ä»£ç  å’Œ (ii) å»ºè®¾æ€§åé¦ˆ ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå†æ¬¡æç¤º å¤§è¯­è¨€æ¨¡å‹ï¼Œè¦æ±‚å®ƒæ ¹æ®åé¦ˆé‡å†™ä»£ç ã€‚è¿™é€šå¸¸èƒ½å¸¦æ¥æ›´å¥½çš„ç»“æœã€‚é‡å¤è¿™ç§è¯„ä¼°/é‡å†™è¿‡ç¨‹ï¼Œå¯èƒ½ä¼šè¿›ä¸€æ­¥æå‡ä»£ç è´¨é‡ã€‚è¿™ç§ è‡ªæˆ‘åæ€ è¿‡ç¨‹èƒ½å¸®åŠ© å¤§è¯­è¨€æ¨¡å‹ åœ¨å„ç§ä»»åŠ¡ä¸­å‘ç°ä¸è¶³å¹¶æ”¹è¿›è¾“å‡ºï¼Œæ— è®ºæ˜¯ç”Ÿæˆä»£ç ã€æ’°å†™æ–‡æœ¬è¿˜æ˜¯å›ç­”é—®é¢˜ã€‚\n\næˆ‘ä»¬è¿˜å¯ä»¥å°† åæ€ è¿‡ç¨‹æå‡ä¸€ä¸ªå±‚æ¬¡ï¼Œä¸º å¤§è¯­è¨€æ¨¡å‹ é…å¤‡æœ‰åŠ©äºè¯„ä¼°å…¶è¾“å‡ºçš„å·¥å…·ã€‚ä¾‹å¦‚ï¼Œè®©å®ƒé€šè¿‡å‡ ä¸ª å•å…ƒæµ‹è¯• æ¥è¿è¡Œç”Ÿæˆçš„ä»£ç ï¼Œæ£€æŸ¥åœ¨æµ‹è¯•ç”¨ä¾‹ä¸Šæ˜¯å¦å¾—åˆ°æ­£ç¡®ç»“æœï¼›æˆ–è€…æœç´¢ç½‘ç»œæ¥æ ¸å®æ–‡æœ¬å†…å®¹çš„å‡†ç¡®æ€§ã€‚è¿™æ ·ï¼Œ å¤§è¯­è¨€æ¨¡å‹ å°±èƒ½åæ€å®ƒå‘ç°çš„ä»»ä½•é”™è¯¯ï¼Œå¹¶æå‡ºæ”¹è¿›æ–¹æ¡ˆã€‚\n\næ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡ å¤šæ™ºèƒ½ä½“æ¡†æ¶ æ¥å®ç° åæ€ã€‚æˆ‘å‘ç°ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ˜¯åˆ›å»ºä¸¤ä¸ªä¸åŒçš„ AI æ™ºèƒ½ä½“ï¼šä¸€ä¸ªä¸“é—¨è´Ÿè´£ç”Ÿæˆä¼˜è´¨è¾“å‡ºï¼Œå¦ä¸€ä¸ªåˆ™è´Ÿè´£å¯¹ç¬¬ä¸€ä¸ª æ™ºèƒ½ä½“ çš„è¾“å‡ºæä¾› å»ºè®¾æ€§æ‰¹è¯„ã€‚è¿™ä¸¤ä¸ª æ™ºèƒ½ä½“ ä¹‹é—´çš„â€œè®¨è®ºâ€èƒ½å¤Ÿä¿ƒæˆå“åº”è´¨é‡çš„æå‡ã€‚\n\nåæ€ æ˜¯ä¸€ç§ç›¸å¯¹åŸºç¡€çš„ AI æ™ºèƒ½ä½“å·¥ä½œæµï¼Œä½†ä»¤æˆ‘æ¬£å–œçš„æ˜¯ï¼Œå®ƒåœ¨ä¸€äº›æƒ…å†µä¸‹æå¤§åœ°æ”¹å–„äº†æˆ‘çš„åº”ç”¨ç¨‹åºç»“æœã€‚æˆ‘é¼“åŠ±ä½ ä¹Ÿåœ¨è‡ªå·±çš„å·¥ä½œä¸­å°è¯•è¿™ç§æ–¹æ³•ã€‚å¦‚æœä½ å¯¹äº†è§£æ›´å¤šå…³äº åæ€ çš„ä¿¡æ¯æ„Ÿå…´è¶£ï¼Œæˆ‘æ¨èä»¥ä¸‹è®ºæ–‡ï¼š\n- Self-Refine: Iterative Refinement with Self-Feedbackï¼Œä½œè€… Madaan ç­‰äºº (2023)\n- Reflexion: Language Agents with Verbal Reinforcement Learningï¼Œä½œè€… Shinn ç­‰äºº (2023)\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquingï¼Œä½œè€… Gou ç­‰äºº (2024)\n\næœªæ¥ï¼Œæˆ‘å°†ç»§ç»­æ¢è®¨å…¶ä»–çš„ AI æ™ºèƒ½ä½“ è®¾è®¡æ¨¡å¼ã€‚\n\n[åŸæ–‡é“¾æ¥: https://t.co/FtM2zOT2Lx ]"
  },
  {
    "id": "1773006786058219889",
    "url": "https://x.com/AndrewYNg/status/1773006786058219889",
    "text": "New JavaScript short course: Build a full-stack web application that uses RAG in JavaScript RAG Web Apps with LlamaIndex, taught by @seldo, VP of Developer Relations at @llama_index and npm co-founder.\n- Build a RAG application for querying your own data\n- Develop tools to interact with multiple data sources using an agent that intelligently selects the right tool for your queries\n- Create a full-stack web app that can chat with your data\n- Dig further into production-ready techniques, like how to persist your data so you arenâ€™t constantly reindexing, and try the create-llama command line tool from LlamaIndex\nYou can sign up here: https://t.co/w2j0Mq2df1",
    "createdAt": "Wed Mar 27 15:18:53 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 241,
    "replyCount": 35,
    "likeCount": 1277,
    "quoteCount": 25,
    "viewCount": 218147,
    "bookmarkCount": 1046,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°çš„ JavaScript çŸ­æœŸè¯¾ç¨‹æ¥äº†ï¼šå­¦ä¹ å¦‚ä½•åœ¨ LlamaIndex çš„â€œJavaScript RAG Web Appsâ€ä¸­ï¼Œæ„å»ºä¸€ä¸ªä½¿ç”¨ RAG (Retrieval Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆ) æŠ€æœ¯çš„å…¨æ ˆç½‘ç»œåº”ç”¨ç¨‹åºã€‚æœ¬è¯¾ç¨‹ç”± @seldo äº²è‡ªæˆè¯¾ï¼Œä»–ä¸ä»…æ˜¯ @llama_index çš„å¼€å‘è€…å…³ç³»å‰¯æ€»è£ï¼Œè¿˜æ˜¯ npm çš„è”åˆåˆ›å§‹äººã€‚\n- æ„å»ºä¸€ä¸ªèƒ½å¤ŸæŸ¥è¯¢æ‚¨ä¸ªäººæ•°æ®çš„ RAG åº”ç”¨ç¨‹åº\n- å¼€å‘å·¥å…·ï¼Œé€šè¿‡ä¸€ä¸ªèƒ½æ™ºèƒ½é€‰æ‹©åˆé€‚å·¥å…·æ¥å¤„ç†æ‚¨æŸ¥è¯¢çš„ AI æ™ºèƒ½ä½“ (AI Agent)ï¼Œä¸å¤šä¸ªæ•°æ®æºè¿›è¡Œäº¤äº’\n- åˆ›å»ºä¸€ä¸ªå¯ä»¥ä¸æ‚¨çš„æ•°æ®è¿›è¡ŒèŠå¤©çš„å…¨æ ˆç½‘ç»œåº”ç”¨ç¨‹åº\n- æ·±å…¥æ¢ç´¢å¯ç”¨äºç”Ÿäº§ç¯å¢ƒçš„æŠ€æœ¯ï¼Œä¾‹å¦‚å¦‚ä½•æŒä¹…åŒ–å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œé¿å…é¢‘ç¹åœ°é‡å¤ç´¢å¼•ï¼Œå¹¶ä½“éªŒ LlamaIndex æä¾›çš„ create-llama å‘½ä»¤è¡Œå·¥å…·\næ‚¨å¯ä»¥åœ¨è¿™é‡Œæ³¨å†Œï¼šhttps://t.co/w2j0Mq2df1"
  },
  {
    "id": "1771297451506622741",
    "url": "https://x.com/AndrewYNg/status/1771297451506622741",
    "text": "Iâ€™ve been a fan of â¦@pyautogenâ© as a multiagent programming framework for awhile. It was great hosting two of its leaders â¦@Chi_Wang_â© and â¦@qingyun_wuâ© to discuss agent design patterns! https://t.co/1c2SrjLtj1",
    "createdAt": "Fri Mar 22 22:06:36 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 61,
    "replyCount": 28,
    "likeCount": 669,
    "quoteCount": 9,
    "viewCount": 107590,
    "bookmarkCount": 129,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä¸€ç›´æ˜¯ @pyautogen è¿™ä¸ªå¤šæ™ºèƒ½ä½“ç¼–ç¨‹æ¡†æ¶çš„å¿ å®æ‹¥è¶¸ï¼ˆç²‰ä¸ï¼‰ã€‚å¾ˆé«˜å…´èƒ½é‚€è¯·åˆ°å®ƒçš„ä¸¤ä½è´Ÿè´£äºº @Chi_Wang_ å’Œ @qingyun_wuï¼Œä¸€èµ·æ¢è®¨ AI æ™ºèƒ½ä½“ï¼ˆAgentï¼‰çš„è®¾è®¡æ¨¡å¼ï¼ˆDesign Patternsï¼‰ï¼ https://t.co/1c2SrjLtj1"
  },
  {
    "id": "1770969902452822519",
    "url": "https://x.com/AndrewYNg/status/1770969902452822519",
    "text": "Yes, with agentic workflows, super fast token generation (like @groq) becomes very important to overall system speed. \n\nIf an LLM were generating tokens only for human consumption, then there's not much value to generating much faster than human reading speed. But with agentic workflows, most of the generated tokens are consumed not by humans but instead by another part of the AI system, so very very high token generation throughput is a big help to speeding up the overall system.",
    "createdAt": "Fri Mar 22 00:25:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 16,
    "replyCount": 7,
    "likeCount": 117,
    "quoteCount": 10,
    "viewCount": 28549,
    "bookmarkCount": 32,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "æ˜¯çš„ï¼Œåœ¨ AI æ™ºèƒ½ä½“ (AI Agent) å·¥ä½œæµä¸­ï¼Œè¶…å¿«çš„ Token ç”Ÿæˆ (æ¯”å¦‚ @groq) å¯¹æå‡æ•´ä¸ªç³»ç»Ÿçš„é€Ÿåº¦è‡³å…³é‡è¦ã€‚\n\nå¦‚æœä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLM) ç”Ÿæˆ Token ä»…ä»…æ˜¯ä¸ºäº†ä¾›äººç±»é˜…è¯»å’Œç†è§£ï¼Œé‚£ä¹ˆç”Ÿæˆé€Ÿåº¦è¿œè¶…äººç±»é˜…è¯»é€Ÿåº¦çš„æ„ä¹‰å°±ä¸å¤§äº†ã€‚ç„¶è€Œï¼Œåœ¨ AI æ™ºèƒ½ä½“å·¥ä½œæµä¸­ï¼Œå¤§å¤šæ•°ç”Ÿæˆçš„ Token å¹¶éç”±äººç±»ç›´æ¥æ¶ˆè´¹ï¼Œè€Œæ˜¯ç”± AI ç³»ç»Ÿçš„å…¶ä»–éƒ¨åˆ†è¿›ä¸€æ­¥å¤„ç†ï¼Œå› æ­¤æé«˜çš„ Token ç”Ÿæˆååé‡ (throughput) å¯¹äºåŠ é€Ÿæ•´ä¸ªç³»ç»Ÿè¿è¡Œæœ‰ç€å·¨å¤§çš„å¸®åŠ©ã€‚"
  },
  {
    "id": "1770967731753677266",
    "url": "https://x.com/AndrewYNg/status/1770967731753677266",
    "text": "@erikbryn Yes, and the outcomes of task-based analysis of jobs is also changing, since the set of tasks that agentic workflows can do is much larger than the set of tasks that non-agentic LLMs can do!",
    "createdAt": "Fri Mar 22 00:16:24 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 6,
    "replyCount": 1,
    "likeCount": 35,
    "quoteCount": 0,
    "viewCount": 13692,
    "bookmarkCount": 7,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@erikbryn æ²¡é”™ï¼Œè€Œä¸”å¯¹å·¥ä½œçš„ä»»åŠ¡å¼åˆ†æç»“æœä¹Ÿåœ¨å‘ç”Ÿå˜åŒ–ã€‚åŸå› åœ¨äºï¼ŒAI æ™ºèƒ½ä½“ (AI Agent) å·¥ä½œæµèƒ½å¤Ÿå¤„ç†çš„ä»»åŠ¡èŒƒå›´ï¼Œæ¯”ä¸å…·å¤‡æ™ºèƒ½ä½“èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ (Large Language Model) æ‰€èƒ½å¤„ç†çš„ä»»åŠ¡èŒƒå›´è¦å¤§å¾—å¤šï¼"
  },
  {
    "id": "1770897666702233815",
    "url": "https://x.com/AndrewYNg/status/1770897666702233815",
    "text": "I think AI agentic workflows will drive massive AI progress this year â€” perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\n\nToday, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!\n\nWith an agentic workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:\n- Plan an outline.\n- Decide what, if any, web searches are needed to gather more information.\n- Write a first draft.\n- Read over the first draft to spot unjustified arguments or extraneous information.\n- Revise the draft taking into account any weaknesses spotted.\n- And so on.\n\nThis iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.\n\nDevinâ€™s splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithmâ€™s ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below. \n\nGPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. \n\nOpen source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, Iâ€™d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.\n\n- Reflection: The LLM examines its own work to come up with ways to improve it.\n- Tool use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.\n- Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).\n- Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n\nIâ€™ll elaborate on these design patterns and offer suggested readings for each next week. \n\n[Original text: https://t.co/y4McIAjD2m]",
    "createdAt": "Thu Mar 21 19:38:00 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 1251,
    "replyCount": 217,
    "likeCount": 5257,
    "quoteCount": 196,
    "viewCount": 832515,
    "bookmarkCount": 3902,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘è®¤ä¸º AI æ™ºèƒ½ä½“ (AI agent) å·¥ä½œæµå°†åœ¨ä»Šå¹´æ¨åŠ¨å·¨å¤§çš„ AI è¿›æ­¥â€”â€”å…¶å½±å“åŠ›ç”šè‡³å¯èƒ½è¶…è¶Šä¸‹ä¸€ä»£åŸºç¡€æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªå€¼å¾—é«˜åº¦å…³æ³¨çš„é‡è¦è¶‹åŠ¿ï¼Œæˆ‘å¼ºçƒˆå»ºè®®æ‰€æœ‰ä»äº‹ AI å·¥ä½œçš„äººå…³æ³¨å®ƒã€‚\n\nç›®å‰ï¼Œæˆ‘ä»¬ä¸»è¦ä»¥é›¶æ ·æœ¬ (zero-shot) æ¨¡å¼ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼šé€šè¿‡æç¤ºè¯æŒ‡ä»¤æ¨¡å‹é€ä¸ªç”Ÿæˆæœ€ç»ˆè¾“å‡º Token (Token)ï¼ŒæœŸé—´ä¸å…è®¸å…¶ä¿®æ”¹è‡ªå·±çš„å·¥ä½œã€‚è¿™å°±åƒæ˜¯è¦æ±‚ä¸€ä¸ªäººä»å¤´åˆ°å°¾å®Œæˆä¸€ç¯‡è®ºæ–‡ï¼Œä¸­é—´ä¸èƒ½å›æº¯æˆ–ä¿®æ”¹ï¼Œå´ä»ç„¶æœŸå¾…é«˜è´¨é‡çš„ç»“æœã€‚å°½ç®¡ä»»åŠ¡éš¾åº¦å¾ˆé«˜ï¼Œä½†å¤§è¯­è¨€æ¨¡å‹åœ¨è¿™ç§æ¨¡å¼ä¸‹ä¾ç„¶è¡¨ç°æƒŠäººï¼\n\nç„¶è€Œï¼Œå€ŸåŠ©æ™ºèƒ½ä½“å·¥ä½œæµï¼Œæˆ‘ä»¬å¯ä»¥è¦æ±‚å¤§è¯­è¨€æ¨¡å‹å¯¹ä¸€ä»½æ–‡æ¡£è¿›è¡Œå¤šæ¬¡è¿­ä»£ã€‚ä¾‹å¦‚ï¼Œå®ƒå¯èƒ½ä¼šéµå¾ªä¸€ç³»åˆ—æ­¥éª¤ï¼Œä¾‹å¦‚ï¼š\n- è§„åˆ’å¤§çº²ã€‚\n- å†³å®šæ˜¯å¦éœ€è¦è¿›è¡Œç½‘ç»œæœç´¢ä»¥æ”¶é›†æ›´å¤šä¿¡æ¯ã€‚\n- æ’°å†™åˆç¨¿ã€‚\n- å®¡é˜…åˆç¨¿ï¼Œæ‰¾å‡ºç¼ºä¹ä¾æ®çš„è®ºç‚¹æˆ–å¤šä½™çš„ä¿¡æ¯ã€‚\n- æ ¹æ®å‘ç°çš„ä»»ä½•å¼±ç‚¹ä¿®æ”¹è‰ç¨¿ã€‚\n- ä¾æ­¤ç±»æ¨ã€‚\n\nè¿™ç§è¿­ä»£è¿‡ç¨‹å¯¹äºå¤§å¤šæ•°äººç±»ä½œè€…æ¥è¯´ï¼Œæ˜¯å†™å‡ºä¼˜ç§€æ–‡æœ¬çš„å…³é”®ã€‚å¯¹äº AI è€Œè¨€ï¼Œè¿™ç§è¿­ä»£å·¥ä½œæµæ¯”ä¸€æ¬¡æ€§å†™ä½œèƒ½äº§ç”Ÿè¿œæ›´å¥½çš„ç»“æœã€‚\n\nDevin æœ€è¿‘é‚£åœºè½°åŠ¨ä¸€æ—¶çš„æ¼”ç¤ºåœ¨ç¤¾äº¤åª’ä½“ä¸Šå¼•å‘äº†å¹¿æ³›çƒ­è®®ã€‚æˆ‘çš„å›¢é˜Ÿä¸€ç›´åœ¨å¯†åˆ‡å…³æ³¨ AI ç¼–å†™ä»£ç çš„æ¼”å˜ã€‚æˆ‘ä»¬åˆ†æäº†æ¥è‡ªå¤šä¸ªç ”ç©¶å›¢é˜Ÿçš„ç»“æœï¼Œé‡ç‚¹å…³æ³¨ç®—æ³•åœ¨å¹¿æ³›ä½¿ç”¨çš„ HumanEval ç¼–ç åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å¦‚ä½•ã€‚æ‚¨å¯ä»¥åœ¨ä¸‹é¢çš„å›¾ä¸­çœ‹åˆ°æˆ‘ä»¬çš„å‘ç°ã€‚\n\nGPT-3.5 (é›¶æ ·æœ¬) çš„æ­£ç¡®ç‡ä¸º 48.1%ã€‚GPT-4 (é›¶æ ·æœ¬) è¡¨ç°æ›´å¥½ï¼Œè¾¾åˆ° 67.0%ã€‚ç„¶è€Œï¼Œä» GPT-3.5 åˆ° GPT-4 çš„æ”¹è¿›ï¼Œåœ¨æ•´åˆäº†è¿­ä»£æ™ºèƒ½ä½“å·¥ä½œæµä¹‹åå°±æ˜¾å¾—ç›¸å½¢è§ç»Œäº†ã€‚äº‹å®ä¸Šï¼Œå½“ GPT-3.5 å°è£…åœ¨æ™ºèƒ½ä½“å¾ªç¯ä¸­æ—¶ï¼Œå…¶æ­£ç¡®ç‡é«˜è¾¾ 95.1%ã€‚\n\nå¼€æºæ™ºèƒ½ä½“å·¥å…·å’Œå…³äºæ™ºèƒ½ä½“çš„å­¦æœ¯æ–‡çŒ®æ­£åœ¨è“¬å‹ƒå‘å±•ï¼Œè¿™ä½¿å¾—å½“å‰æ—¢æ˜¯æ¿€åŠ¨äººå¿ƒçš„æ—¶åˆ»ï¼Œä¹Ÿå¯èƒ½ä»¤äººæ„Ÿåˆ°å›°æƒ‘ã€‚ä¸ºäº†å¸®åŠ©å¤§å®¶æ›´å¥½åœ°ç†è§£è¿™é¡¹å·¥ä½œï¼Œæˆ‘æƒ³åˆ†äº«ä¸€ä¸ªç”¨äºå¯¹æ„å»ºæ™ºèƒ½ä½“çš„è®¾è®¡æ¨¡å¼è¿›è¡Œåˆ†ç±»çš„æ¡†æ¶ã€‚æˆ‘çš„å›¢é˜Ÿ AI Fund æ­£åœ¨è®¸å¤šåº”ç”¨ç¨‹åºä¸­æˆåŠŸè¿ç”¨è¿™äº›æ¨¡å¼ï¼Œå¸Œæœ›æ‚¨ä¹Ÿèƒ½ä»ä¸­å—ç›Šã€‚\n\n- åæ€ (Reflection)ï¼šå¤§è¯­è¨€æ¨¡å‹æ£€æŸ¥è‡ªå·±çš„å·¥ä½œï¼Œä»¥æ‰¾å‡ºæ”¹è¿›çš„æ–¹æ³•ã€‚\n- å·¥å…·ä½¿ç”¨ (Tool use)ï¼šå¤§è¯­è¨€æ¨¡å‹è¢«èµ‹äºˆå·¥å…·ï¼Œä¾‹å¦‚ç½‘ç»œæœç´¢ã€ä»£ç æ‰§è¡Œæˆ–ä»»ä½•å…¶ä»–åŠŸèƒ½ï¼Œä»¥å¸®åŠ©å®ƒæ”¶é›†ä¿¡æ¯ã€é‡‡å–è¡ŒåŠ¨æˆ–å¤„ç†æ•°æ®ã€‚\n- è§„åˆ’ (Planning)ï¼šå¤§è¯­è¨€æ¨¡å‹æå‡ºå¹¶æ‰§è¡Œä¸€ä¸ªå¤šæ­¥éª¤è®¡åˆ’ä»¥å®ç°ç›®æ ‡ (ä¾‹å¦‚ï¼Œä¸ºä¸€ç¯‡è®ºæ–‡æ’°å†™å¤§çº²ï¼Œç„¶åè¿›è¡Œåœ¨çº¿ç ”ç©¶ï¼Œç„¶åæ’°å†™åˆç¨¿ï¼Œä¾æ­¤ç±»æ¨)ã€‚\n- å¤šæ™ºèƒ½ä½“åä½œ (Multi-agent collaboration)ï¼šå¤šä¸ª AI æ™ºèƒ½ä½“ååŒå·¥ä½œï¼Œåˆ†æ‘Šä»»åŠ¡å¹¶è®¨è®ºå’Œè¾©è®ºæƒ³æ³•ï¼Œä»¥æå‡ºæ¯”å•ä¸ªæ™ºèƒ½ä½“æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚\n\næˆ‘å°†åœ¨ä¸‹å‘¨è¯¦ç»†é˜è¿°è¿™äº›è®¾è®¡æ¨¡å¼ï¼Œå¹¶ä¸ºæ¯ç§æ¨¡å¼æä¾›å»ºè®®çš„é˜…è¯»ææ–™ã€‚\n\n[åŸæ–‡é“¾æ¥ï¼š https://t.co/y4McIAjD2m]"
  },
  {
    "id": "1769761666143814122",
    "url": "https://x.com/AndrewYNg/status/1769761666143814122",
    "text": "Learn how to build an optimized LLM inference system from the ground up in our new short course, Efficiently Serving LLMs, built in collaboration with @predibase and taught by @TravisAddair.\n\nWhether you're serving your own LLM or using a model hosting service, this course will give you a deep understanding of the optimizations required to efficiently serve many users at once.\n- Learn how LLMs generate text one token at a time, and how techniques like KV caching, continuous batching, and quantization speed things up and optimize memory usage for serving multiple users.\n- Benchmark the performance of these LLM optimizations to explore the trade-offs between quickly responding to an individual userâ€™s request vs. serving many users at once.\n- Use techniques like low-rank adaptation (LoRA) to efficiently serve hundreds of unique, custom fine-tuned models on a single device, without sacrificing throughput.\n- Use Predibase's LoRAX framework to see optimization techniques in action on a real LLM server.\n\nSign up here: https://t.co/JgIvrJGf8G",
    "createdAt": "Mon Mar 18 16:23:56 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 130,
    "replyCount": 21,
    "likeCount": 756,
    "quoteCount": 14,
    "viewCount": 104458,
    "bookmarkCount": 413,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨æˆ‘ä»¬çš„æ–°çŸ­æœŸè¯¾ç¨‹ã€Šé«˜æ•ˆæœåŠ¡å¤§è¯­è¨€æ¨¡å‹ã€‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä»å¤´æ„å»ºä¸€å¥—ä¼˜åŒ–çš„å¤§è¯­è¨€æ¨¡å‹ (LLM) æ¨ç†ç³»ç»Ÿã€‚æœ¬è¯¾ç¨‹ç”± @TravisAddair æˆè¯¾ï¼Œå¹¶ä¸ @predibase åˆä½œå¼€å‘ã€‚\n\næ— è®ºæ‚¨æ˜¯éƒ¨ç½²è‡ªå·±çš„ å¤§è¯­è¨€æ¨¡å‹ ï¼Œè¿˜æ˜¯ä½¿ç”¨æ¨¡å‹æ‰˜ç®¡æœåŠ¡ï¼Œæœ¬è¯¾ç¨‹éƒ½å°†è®©æ‚¨æ·±å…¥ç†è§£ï¼Œå¦‚ä½•è¿›è¡Œå¿…è¦çš„ä¼˜åŒ–æ‰èƒ½é«˜æ•ˆåœ°åŒæ—¶æœåŠ¡å¤§é‡ç”¨æˆ·ã€‚\n- å­¦ä¹  å¤§è¯­è¨€æ¨¡å‹ æ˜¯å¦‚ä½•é€ä¸ª token ç”Ÿæˆæ–‡æœ¬çš„ï¼Œä»¥åŠ KV ç¼“å­˜ (KV caching)ã€è¿ç»­æ‰¹å¤„ç† (continuous batching) å’Œé‡åŒ– (quantization) ç­‰æŠ€æœ¯å¦‚ä½•åŠ é€Ÿæ¨ç†å¹¶ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œä»è€ŒæœåŠ¡å¤šä¸ªç”¨æˆ·ã€‚\n- å¯¹è¿™äº› å¤§è¯­è¨€æ¨¡å‹ ä¼˜åŒ–æŠ€æœ¯çš„æ€§èƒ½è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ¢ç´¢å¿«é€Ÿå“åº”å•ä¸ªç”¨æˆ·è¯·æ±‚ä¸åŒæ—¶æœåŠ¡ä¼—å¤šç”¨æˆ·ä¹‹é—´çš„æƒè¡¡ã€‚\n- è¿ç”¨ä½ç§©é€‚åº” (LoRA) ç­‰æŠ€æœ¯ï¼Œåœ¨å•ä¸ªè®¾å¤‡ä¸Šé«˜æ•ˆæœåŠ¡æ•°ç™¾ä¸ªç‹¬ç‰¹ä¸”å®šåˆ¶åŒ–çš„å¾®è°ƒæ¨¡å‹ï¼ŒåŒæ—¶ä¸ç‰ºç‰²ååé‡ã€‚\n- ä½¿ç”¨ Predibase çš„ LoRAX æ¡†æ¶ï¼Œåœ¨ä¸€ä¸ªçœŸå®çš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡å™¨ä¸Šäº²çœ¼è§è¯ä¼˜åŒ–æŠ€æœ¯åœ¨å®é™…ä¸­çš„åº”ç”¨ã€‚\n\nåœ¨æ­¤æ³¨å†Œï¼šhttps://t.co/JgIvrJGf8G"
  },
  {
    "id": "1767941813820862655",
    "url": "https://x.com/AndrewYNg/status/1767941813820862655",
    "text": "Our new short course, Knowledge Graphs for RAG, is now available! Knowledge graphs are a data structure that is great at capturing complex relationships between data of multiple types. By enabling more sophisticated retrieval of text than similarity search alone, knowledge graphs can improve the context you pass to the LLM and the performance of your RAG applications. \n\nIn this course, taught by @akollegger of @neo4j, youâ€™ll\n- Explore how knowledge graphs work by building a graph of public financial documents from scratch\n- Learn to write queries that retrieve text and data from the graph and use it to enhance the context you pass to an LLM chatbot\n- Combine a knowledge graph with a question-answer chain to build better RAG-powered chat systems\n\nSign up here! https://t.co/N3gceKrvib",
    "createdAt": "Wed Mar 13 15:52:29 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 408,
    "replyCount": 50,
    "likeCount": 2104,
    "quoteCount": 38,
    "viewCount": 242392,
    "bookmarkCount": 1660,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä»¬çš„æ–°çŸ­æœŸè¯¾ç¨‹â€œé¢å‘ RAG çš„çŸ¥è¯†å›¾è°±â€ç°å·²ä¸Šçº¿ï¼çŸ¥è¯†å›¾è°± (Knowledge Graphs) æ˜¯ä¸€ç§æ“…é•¿æ•è·å¤šç§ç±»å‹æ•°æ®ä¹‹é—´å¤æ‚å…³ç³»çš„æ•°æ®ç»“æ„ã€‚é€šè¿‡å®ç°æ¯”å•çº¯çš„ç›¸ä¼¼æ€§æœç´¢ (similarity search) æ›´å¤æ‚çš„æ–‡æœ¬æ£€ç´¢æ–¹å¼ï¼ŒçŸ¥è¯†å›¾è°±å¯ä»¥æ”¹å–„æ‚¨ä¼ é€’ç»™å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„ä¸Šä¸‹æ–‡ï¼Œä»è€Œæå‡æ‚¨çš„ RAG (Retrieval-Augmented Generation) åº”ç”¨ç¨‹åºçš„æ€§èƒ½ã€‚\n\nåœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œç”±æ¥è‡ª @neo4j çš„ @akollegger æ•™æˆï¼Œæ‚¨å°†ï¼š\n- é€šè¿‡ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå…³äºå…¬å…±è´¢åŠ¡æ–‡æ¡£çš„å›¾è°±ï¼Œæ¢ç´¢çŸ¥è¯†å›¾è°±çš„å·¥ä½œåŸç†\n- å­¦ä¹ ç¼–å†™æŸ¥è¯¢ï¼Œä»å›¾è°±ä¸­æ£€ç´¢æ–‡æœ¬å’Œæ•°æ®ï¼Œå¹¶åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥å¢å¼ºæ‚¨ä¼ é€’ç»™å¤§è¯­è¨€æ¨¡å‹èŠå¤©æœºå™¨äºº (chatbot) çš„ä¸Šä¸‹æ–‡\n- å°†çŸ¥è¯†å›¾è°±ä¸é—®ç­”é“¾ (question-answer chain) ç»“åˆï¼Œä»¥æ„å»ºæ›´ä¼˜ç§€çš„ç”± RAG æä¾›æ”¯æŒçš„èŠå¤©ç³»ç»Ÿ\n\nåœ¨æ­¤æŠ¥åï¼https://t.co/N3gceKrvib"
  },
  {
    "id": "1766589035781202423",
    "url": "https://x.com/AndrewYNg/status/1766589035781202423",
    "text": "@SiVola @RylanSchaeffer @BrandoHablando @sanmikoyejo The definition of AGI I use is \"AI that can perform any intellectual task that a human can.\"\n\nBut a few teams have come up with alternative definitions, so its meaning has become muddied and confusing, I now less it less esp in discussions that need technical precision.",
    "createdAt": "Sat Mar 09 22:17:02 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 15,
    "replyCount": 20,
    "likeCount": 103,
    "quoteCount": 4,
    "viewCount": 11793,
    "bookmarkCount": 21,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@SiVola @RylanSchaeffer @BrandoHablando @sanmikoyejo æˆ‘æ‰€ä½¿ç”¨çš„ AGI (é€šç”¨äººå·¥æ™ºèƒ½) å®šä¹‰æ˜¯â€œèƒ½å¤Ÿæ‰§è¡Œäººç±»å¯ä»¥å®Œæˆçš„ä»»ä½•æ™ºåŠ›ä»»åŠ¡çš„ AIâ€ã€‚\n\nç„¶è€Œï¼Œä¸€äº›å›¢é˜Ÿæå‡ºäº†å…¶ä»–çš„å®šä¹‰ï¼Œè¿™ä½¿å¾— AGI çš„å«ä¹‰å˜å¾—æ¨¡ç³Šä¸”å®¹æ˜“æ··æ·†ã€‚å› æ­¤ï¼Œæˆ‘ç°åœ¨è¾ƒå°‘ä½¿ç”¨è¿™ä¸ªè¯ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æŠ€æœ¯ç²¾ç¡®æ€§çš„è®¨è®ºä¸­ã€‚"
  },
  {
    "id": "1766554536192446957",
    "url": "https://x.com/AndrewYNg/status/1766554536192446957",
    "text": "When we get to AGI, it will have come slowly, not overnight. \n\nA NeurIPS Outstanding Paper award recipient, Are Emergent Abilities of Large Language Models a Mirage? (by @RylanSchaeffer, @BrandoHablando, @sanmikoyejo) studies emergent properties of LLMs, and concludes: \n\"... emergent abilities appear due the researcherâ€™s choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance.\" \n\nPublic perception goes through discontinuities when lots of people suddenly become aware of a technology -- maybe one that's been developing for a long time --  leading to a surprise. But growth in AI capabilities is  more continuous than one might think. \n\nThat's why I expect the path to AGI to be one involving numerous steps forward, leading to step-by-step improvements in how intelligent our systems are.",
    "createdAt": "Sat Mar 09 19:59:57 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 259,
    "replyCount": 91,
    "likeCount": 1598,
    "quoteCount": 37,
    "viewCount": 240773,
    "bookmarkCount": 648,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å½“æˆ‘ä»¬æŠµè¾¾é€šç”¨äººå·¥æ™ºèƒ½ (AGI) çš„å½¼å²¸æ—¶ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ªå¾ªåºæ¸è¿›çš„è¿‡ç¨‹ï¼Œè€Œéä¸€è¹´è€Œå°±ã€‚\n\nä¸€ç¯‡è£è· NeurIPS æ°å‡ºè®ºæ–‡å¥–çš„è®ºæ–‡â€”â€”ã€Šå¤§è¯­è¨€æ¨¡å‹ (Large Language Model) çš„æ¶Œç°èƒ½åŠ›æ˜¯æµ·å¸‚èœƒæ¥¼å—ï¼Ÿã€‹ (ä½œè€…ï¼š@RylanSchaeffer, @BrandoHablando, @sanmikoyejo) â€”æ·±å…¥ç ”ç©¶äº† å¤§è¯­è¨€æ¨¡å‹ çš„æ¶Œç°èƒ½åŠ›ï¼Œå¹¶å¾—å‡ºç»“è®ºï¼š\nâ€œ... æ¶Œç°èƒ½åŠ›ä¼¼ä¹æ˜¯ç”±äºç ”ç©¶äººå‘˜é€‰æ‹©çš„è¡¡é‡æŒ‡æ ‡é€ æˆçš„ï¼Œè€Œéæ¨¡å‹è¡Œä¸ºéšè§„æ¨¡å˜åŒ–è€Œäº§ç”Ÿçš„æ ¹æœ¬æ€§æ”¹å˜ã€‚å…·ä½“æ¥è¯´ï¼Œéçº¿æ€§æˆ–ä¸è¿ç»­çš„è¡¡é‡æŒ‡æ ‡ä¼šä½¿æ¶Œç°èƒ½åŠ›æ˜¾å¾—å°¤ä¸ºçªå‡ºï¼Œè€Œçº¿æ€§æˆ–è¿ç»­çš„è¡¡é‡æŒ‡æ ‡åˆ™å±•ç°å‡ºæ¨¡å‹æ€§èƒ½å¹³æ»‘ã€è¿ç»­ã€å¯é¢„æµ‹çš„å˜åŒ–ã€‚â€\n\nå½“ä¸€é¡¹æŠ€æœ¯â€”â€”ä¹Ÿè®¸æ˜¯å·²ç»å‘å±•äº†å¾ˆé•¿æ—¶é—´çš„æŠ€æœ¯â€”â€”çªç„¶è¢«å¤§ä¼—æ‰€çŸ¥æ—¶ï¼Œå…¬ä¼—çš„è®¤çŸ¥ä¼šç»å†è·³è·ƒå¼å˜åŒ–ï¼Œä»è€Œäº§ç”ŸæƒŠè®¶æ„Ÿã€‚ç„¶è€Œï¼Œäººå·¥æ™ºèƒ½èƒ½åŠ›çš„å‘å±•å®é™…ä¸Šæ¯”äººä»¬æƒ³è±¡çš„æ›´å…·æœ‰è¿ç»­æ€§ã€‚\n\nå› æ­¤ï¼Œæˆ‘é¢„è®¡é€šå¾€ é€šç”¨äººå·¥æ™ºèƒ½ çš„é“è·¯å°†æ˜¯æ­¥æ­¥ä¸ºè¥çš„ï¼Œæ¯ä¸€æ­¥çš„è¿›æ­¥éƒ½å°†ä½¿æˆ‘ä»¬ç³»ç»Ÿçš„æ™ºèƒ½ç¨‹åº¦é€æ­¥æå‡ã€‚"
  },
  {
    "id": "1765426218847949236",
    "url": "https://x.com/AndrewYNg/status/1765426218847949236",
    "text": "New short course: Open Source Models with Hugging Face ğŸ¤—, taught by @mariaKhalusova, @_marcsun, and Younes Belkada! @huggingface has been a game changer by letting you quickly grab any of hundreds of thousands of already-trained open source models to assemble into new applications. This course teaches you best practices for building this way, including how to search and choose among models.\n\nYouâ€™ll learn to use the Transformers library and walk through multiple models for text, audio, and image processing, including zero-shot image segmentation, zero-shot audio classification, and speech recognition. You'll also learn to use multimodal models for visual question answering, image search, and image captioning. Finally, youâ€™ll learn how to demo what you build locally, on the cloud, or via an API using Gradio and Hugging Face Spaces. \n\nYou can sign up here: https://t.co/KavDNQHCCY",
    "createdAt": "Wed Mar 06 17:16:25 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 185,
    "replyCount": 40,
    "likeCount": 1140,
    "quoteCount": 28,
    "viewCount": 224100,
    "bookmarkCount": 707,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…¨æ–°çŸ­æœŸè¯¾ç¨‹ï¼šç”± @mariaKhalusovaã€@_marcsun å’Œ Younes Belkada ä¸»è®²ï¼Œå¸¦ä½ ç©è½¬ Hugging Face ğŸ¤— çš„å¼€æºæ¨¡å‹ï¼@huggingface å¹³å°å ªç§°è¡Œä¸šé¢ è¦†è€…ï¼Œå®ƒå…è®¸ä½ å¿«é€Ÿè·å–æ•°åä¸‡ä¸ªé¢„è®­ç»ƒçš„å¼€æºæ¨¡å‹ï¼Œå¹¶å°†å®ƒä»¬é›†æˆåˆ°æ–°çš„åº”ç”¨ç¨‹åºä¸­ã€‚æœ¬è¯¾ç¨‹å°†æ•™æˆä½ é€šè¿‡è¿™ç§æ–¹å¼æ„å»ºé¡¹ç›®çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬å¦‚ä½•æœç´¢å’Œé€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚\n\nä½ å°†å­¦ä¹ ä½¿ç”¨ Transformers åº“ï¼Œå¹¶æ·±å…¥äº†è§£ç”¨äºæ–‡æœ¬ã€éŸ³é¢‘å’Œå›¾åƒå¤„ç†çš„å¤šç§æ¨¡å‹ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬å›¾åƒåˆ†å‰² (zero-shot image segmentation)ã€é›¶æ ·æœ¬éŸ³é¢‘åˆ†ç±» (zero-shot audio classification) å’Œè¯­éŸ³è¯†åˆ« (speech recognition)ã€‚æ­¤å¤–ï¼Œä½ è¿˜å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ (multimodal models) è¿›è¡Œè§†è§‰é—®ç­” (visual question answering)ã€å›¾åƒæœç´¢ (image search) å’Œå›¾åƒå­—å¹• (image captioning)ã€‚æœ€åï¼Œä½ å°†å­¦ä¼šå¦‚ä½•åˆ©ç”¨ Gradio å’Œ Hugging Face Spaces åœ¨æœ¬åœ°ã€äº‘ç«¯æˆ–é€šè¿‡ API (Application Programming Interface) å±•ç¤ºä½ æ„å»ºçš„åº”ç”¨æˆæœã€‚\n\nç‚¹å‡»è¿™é‡Œæ³¨å†Œï¼šhttps://t.co/KavDNQHCCY"
  },
  {
    "id": "1765059128190173202",
    "url": "https://x.com/AndrewYNg/status/1765059128190173202",
    "text": "There're now multiple, very well resourced companies that \"can't afford to lose\" spending billions to compete to build better LLMs. I expect this competition to go on for years. This is going to great for innovation, and also for everyone building applications on top of LLMs.",
    "createdAt": "Tue Mar 05 16:57:44 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 131,
    "replyCount": 67,
    "likeCount": 1306,
    "quoteCount": 25,
    "viewCount": 157065,
    "bookmarkCount": 145,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å½“å‰ï¼Œè®¸å¤šèµ„é‡‘é›„åšçš„å…¬å¸æ­£ä¸æƒœæŠ•å…¥æ•°åäº¿ç¾å…ƒï¼Œç«ç›¸æ„å»ºæ›´å‡ºè‰²çš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œå®ƒä»¬æ·±çŸ¥è¿™åœºç«äº‰â€œè¾“ä¸èµ·â€ã€‚æˆ‘é¢„è®¡è¿™ç§ç«äº‰å°†ä¼šæŒç»­æ•°å¹´ã€‚è¿™ä¸ä»…å°†æå¤§åœ°ä¿ƒè¿›åˆ›æ–°ï¼Œä¹Ÿå°†ä¸ºæ‰€æœ‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) å¼€å‘åº”ç”¨çš„äººå¸¦æ¥å·¨å¤§çš„ç›Šå¤„ã€‚"
  },
  {
    "id": "1762879627633287477",
    "url": "https://x.com/AndrewYNg/status/1762879627633287477",
    "text": "New short course: Prompt Engineering with Llama 2, built in collaboration with Meta @AIatMeta, and taught by @asangani7! Meta's Llama 2 has been game-changing for AI. Building with open source lets you control your own data, scrutinize errors, update (or not) the models as you please, and work alongside the global community advancing open models.\n\nLlama isn't a single model, it's a collection of models. In this course, you'll:\n- Learn the differences between different Llama 2 flavors, and when to use each.\n- Prompt the Llama chat models -- you'll also see how Llama's instruction tags work -- so they can help you with day-to-day tasks, like writing or summarization.\n- Use advanced prompting, like few-shot prompting for classification, and chain-of-thought prompting for solving logic problems.\n- Use specialized models in the Llama collection for specific tasks, like Code Llama to help you write, analyze, and improve code, and Llama Guard, which checks prompts and model responses for harmful content. \n\nThe course also touches on how to run Llama 2 locally on your own computer.\n\nI hope youâ€™ll take this course and try out these powerful, open models!\nhttps://t.co/kas7jmeCkj",
    "createdAt": "Wed Feb 28 16:37:10 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 260,
    "replyCount": 86,
    "likeCount": 1287,
    "quoteCount": 18,
    "viewCount": 162302,
    "bookmarkCount": 805,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æ–°çŸ­è¯¾ç¨‹ï¼šLlama 2 æç¤ºå·¥ç¨‹ (Prompt Engineering)ï¼Œç”± Meta @AIatMeta åˆä½œå¼€å‘ï¼Œå¹¶ç”± @asangani7 äº²è‡ªæˆè¯¾ï¼Meta çš„ Llama 2 å¯¹äººå·¥æ™ºèƒ½ (AI) é¢†åŸŸè€Œè¨€ï¼Œæ— ç–‘å¸¦æ¥äº†é©å‘½æ€§çš„æ”¹å˜ã€‚åŸºäºå¼€æºæ¨¡å‹è¿›è¡Œå¼€å‘ï¼Œä½ å°†èƒ½å¤Ÿæ›´å¥½åœ°æŒæ§è‡ªå·±çš„æ•°æ®ï¼Œä»”ç»†å®¡æŸ¥æ½œåœ¨é”™è¯¯ï¼Œæ ¹æ®éœ€è¦é€‰æ‹©æ›´æ–°æˆ–ä¸æ›´æ–°æ¨¡å‹ï¼Œå¹¶ä¸å…¨çƒç¤¾åŒºä¸€åŒæ¨åŠ¨å¼€æ”¾æ¨¡å‹çš„è¿›æ­¥ã€‚\n\nLlama å¹¶éå•ä¸€æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ä¸ªç”±å¤šç§æ¨¡å‹ç»„æˆçš„ç³»åˆ—ã€‚é€šè¿‡æœ¬è¯¾ç¨‹ï¼Œä½ å°†ï¼š\n- å­¦ä¹ ä¸åŒ Llama 2 å˜ä½“ä¹‹é—´çš„åŒºåˆ«ï¼Œå¹¶äº†è§£ä½•æ—¶é€‰æ‹©ä½¿ç”¨å®ƒä»¬ã€‚\n- å­¦ä¼šå¦‚ä½•å‘ Llama èŠå¤©æ¨¡å‹è¿›è¡Œæç¤º (Prompt)ï¼Œä½ è¿˜ä¼šäº†è§£ Llama çš„æŒ‡ä»¤æ ‡ç­¾ (instruction tags) æ˜¯å¦‚ä½•è¿ä½œçš„ï¼Œä»è€Œè®©å®ƒä»¬ååŠ©ä½ å®Œæˆæ—¥å¸¸ä»»åŠ¡ï¼Œä¾‹å¦‚å†™ä½œæˆ–å†…å®¹æ€»ç»“ã€‚\n- æŒæ¡é«˜çº§æç¤ºæŠ€å·§ï¼Œä¾‹å¦‚ç”¨äºåˆ†ç±»çš„å°‘æ ·æœ¬æç¤º (few-shot prompting)ï¼Œä»¥åŠç”¨äºè§£å†³é€»è¾‘é—®é¢˜çš„æ€ç»´é“¾æç¤º (chain-of-thought prompting)ã€‚\n- äº†è§£å¹¶ä½¿ç”¨ Llama ç³»åˆ—ä¸­é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„ä¸“ä¸šæ¨¡å‹ï¼Œä¾‹å¦‚ Code Llama å¯ä»¥å¸®åŠ©ä½ ç¼–å†™ã€åˆ†æå’Œæ”¹è¿›ä»£ç ï¼Œè€Œ Llama Guard åˆ™ç”¨äºæ£€æŸ¥æç¤ºå’Œæ¨¡å‹å“åº”ä¸­æ˜¯å¦å­˜åœ¨æœ‰å®³å†…å®¹ã€‚\n\næœ¬è¯¾ç¨‹è¿˜ä¼šæ¢è®¨å¦‚ä½•åœ¨ä½ è‡ªå·±çš„è®¡ç®—æœºä¸Šæœ¬åœ°è¿è¡Œ Llama 2ã€‚\n\nå¸Œæœ›ä½ èƒ½å¤Ÿé€šè¿‡è¿™é—¨è¯¾ç¨‹ï¼Œäº²èº«ä½“éªŒè¿™äº›åŠŸèƒ½å¼ºå¤§ä¸”å¼€æ”¾çš„æ¨¡å‹ï¼\nhttps://t.co/kas7jmeCkj"
  },
  {
    "id": "1761912346153521374",
    "url": "https://x.com/AndrewYNg/status/1761912346153521374",
    "text": "To all my Google friends: I know this week has been tough with a lot of criticism about Gemini's gaffes. \n\nJust wanted to say I love all of you and am rooting for you. I know everyone means well, and am grateful for your work &amp; eager to see where you next take this amazing tech!",
    "createdAt": "Mon Feb 26 00:33:32 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 204,
    "replyCount": 267,
    "likeCount": 3456,
    "quoteCount": 70,
    "viewCount": 445641,
    "bookmarkCount": 172,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "è‡´æˆ‘æ‰€æœ‰çš„ Google æœ‹å‹ä»¬ï¼š è¿™ä¸€å‘¨è¿‡å¾—ä¸å®¹æ˜“ï¼Œæˆ‘çŸ¥é“ Gemini çš„ä¸€äº›å¤±è¯¯å¼•æ¥äº†ä¸å°‘æ‰¹è¯„ã€‚\n\næˆ‘åªæƒ³è¯´ï¼Œæˆ‘çˆ±ä½ ä»¬æ¯ä¸€ä¸ªäººï¼Œå¹¶ä¼šä¸ºä½ ä»¬æ‰€æœ‰äººåŠ æ²¹æ‰“æ°”ï¼æˆ‘æ·±çŸ¥å¤§å®¶éƒ½æ˜¯å‡ºäºå¥½æ„ï¼Œéå¸¸æ„Ÿè°¢ä½ ä»¬æ‰€ä»˜å‡ºçš„åŠªåŠ›å’Œå·¥ä½œã€‚æˆ‘ä¹Ÿæ— æ¯”æœŸå¾…ï¼Œçœ‹åˆ°ä½ ä»¬æ¥ä¸‹æ¥ä¼šå°†è¿™é¡¹æƒŠäººçš„æŠ€æœ¯å¸¦å‘ä½•æ–¹ï¼"
  },
  {
    "id": "1759430085957111932",
    "url": "https://x.com/AndrewYNg/status/1759430085957111932",
    "text": "@roelofbotha @sequoia It's wonderful that @sequoia is putting this together to support Open Source to benefit everyone. Thank you @roelofbotha! \n\nAm also a huge fan of your first Open Source Fellow @tiangolo -- I was literally using his FastAPI framework today to deploy an app!",
    "createdAt": "Mon Feb 19 04:09:55 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 3,
    "replyCount": 5,
    "likeCount": 98,
    "quoteCount": 1,
    "viewCount": 33479,
    "bookmarkCount": 6,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@roelofbotha @sequoia å¾ˆé«˜å…´ @sequoia æ­£åœ¨ç€æ‰‹åšè¿™ä»¶äº‹æ¥æ”¯æŒå¼€æºï¼Œé€ ç¦æ‰€æœ‰äººã€‚è°¢è°¢ä½  @roelofbothaï¼\n\næˆ‘ä¹Ÿæ˜¯å…¶é¦–ä½å¼€æºç ”ç©¶å‘˜ @tiangolo çš„å¿ å®ç²‰ä¸â€”â€”æˆ‘ä»Šå¤©æ°å¥½å°±åœ¨ç”¨ä»–çš„ FastAPI æ¡†æ¶éƒ¨ç½²ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼"
  },
  {
    "id": "1758633108654711008",
    "url": "https://x.com/AndrewYNg/status/1758633108654711008",
    "text": "Congratulations @hwchase17 and the whole @LangChainAI team! Love the work you're doing to make it easy for others to build LLM apps.",
    "createdAt": "Fri Feb 16 23:23:01 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 40,
    "replyCount": 58,
    "likeCount": 393,
    "quoteCount": 0,
    "viewCount": 102764,
    "bookmarkCount": 63,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "ç¥è´º @hwchase17 å’Œæ•´ä¸ª @LangChainAI å›¢é˜Ÿï¼éå¸¸å–œæ¬¢ä½ ä»¬çš„å·¥ä½œï¼Œè®©å¤§å®¶èƒ½æ›´è½»æ¾åœ°å¼€å‘å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºã€‚"
  },
  {
    "id": "1757826615147704345",
    "url": "https://x.com/AndrewYNg/status/1757826615147704345",
    "text": "@fahadaziz It is our privilege at AI Fund to be working with you!",
    "createdAt": "Wed Feb 14 17:58:18 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 0,
    "replyCount": 0,
    "likeCount": 9,
    "quoteCount": 0,
    "viewCount": 7199,
    "bookmarkCount": 2,
    "source": "",
    "lang": "en",
    "isReply": true,
    "isPinned": false,
    "tranlastedContent": "@fahadaziz åœ¨ AI Fundï¼Œæˆ‘ä»¬éå¸¸è£å¹¸èƒ½ä¸æ‚¨åˆä½œï¼"
  },
  {
    "id": "1757821916843552842",
    "url": "https://x.com/AndrewYNg/status/1757821916843552842",
    "text": "New short course on Serverless LLM apps with Amazon Bedrock, taught by @AWS' @mikegchambers! A serverless architecture enables you to quickly deploy your applications without needing to set up and manage compute servers to run your applications on, the maintenance of which can be another full-time job. In this course, youâ€™ll learn how to do this by using an event-driven architecture to build complex AI workflows.\n\nMike illustrate these concepts by building a cool application that automatically detects incoming customer inquiries, transcribes them with ASR (automatic speech recognition), summarizes them with an LLM using Bedrock, and deploys serverless with AWS Lambda.\n\nI hope this course makes it much easier for you to build and deploy LLM applications requiring multi-step AI workflows.  Please sign up here: https://t.co/37hE71j3pT",
    "createdAt": "Wed Feb 14 17:39:38 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 181,
    "replyCount": 68,
    "likeCount": 900,
    "quoteCount": 8,
    "viewCount": 107782,
    "bookmarkCount": 406,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "@AWS çš„ @mikegchambers å¸¦æ¥äº†ä¸€é—¨å…³äºä½¿ç”¨ Amazon Bedrock æ„å»ºæ— æœåŠ¡å™¨å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨ç¨‹åºçš„æ–°çŸ­æœŸè¯¾ç¨‹ï¼æ— æœåŠ¡å™¨æ¶æ„ (Serverless Architecture) èƒ½è®©æ‚¨å¿«é€Ÿéƒ¨ç½²åº”ç”¨ç¨‹åºï¼Œè€Œæ— éœ€è€—è´¹ç²¾åŠ›å»è®¾ç½®å’Œç®¡ç†è¿è¡Œè¿™äº›åº”ç”¨çš„è®¡ç®—æœåŠ¡å™¨ï¼Œå› ä¸ºæœåŠ¡å™¨çš„ç»´æŠ¤æœ¬èº«å¯èƒ½å°±æ˜¯ä¸€ä»½å…¨èŒå·¥ä½œã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•é€šè¿‡äº‹ä»¶é©±åŠ¨æ¶æ„ (Event-driven Architecture) æ¥æ„å»ºå¤æ‚çš„ AI å·¥ä½œæµ (AI Workflows)ã€‚\n\nMike å°†é€šè¿‡æ„å»ºä¸€ä¸ªç²¾å½©çš„åº”ç”¨æ¥æ¼”ç¤ºè¿™äº›æ¦‚å¿µï¼šè¿™ä¸ªåº”ç”¨èƒ½å¤Ÿè‡ªåŠ¨æ£€æµ‹ä¼ å…¥çš„å®¢æˆ·å’¨è¯¢ï¼Œåˆ©ç”¨ ASR (è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ŒAutomatic Speech Recognition) æŠ€æœ¯å°†å…¶è½¬å½•ï¼Œå†é€šè¿‡ Bedrock ä¸Šçš„ å¤§è¯­è¨€æ¨¡å‹ (LLM) å¯¹å…¶è¿›è¡Œæ€»ç»“ï¼Œæœ€åä½¿ç”¨ AWS Lambda å®ç°æ— æœåŠ¡å™¨éƒ¨ç½²ã€‚\n\næˆ‘å¸Œæœ›è¿™é—¨è¯¾ç¨‹èƒ½è®©æ‚¨åœ¨æ„å»ºå’Œéƒ¨ç½²éœ€è¦å¤šæ­¥éª¤ AI å·¥ä½œæµçš„ LLM åº”ç”¨ç¨‹åºæ—¶ï¼Œå˜å¾—æ›´åŠ è½»æ¾ã€‚è¯·ç‚¹å‡»æ­¤å¤„æŠ¥åï¼šhttps://t.co/37hE71j3pT"
  },
  {
    "id": "1752763171042165183",
    "url": "https://x.com/AndrewYNg/status/1752763171042165183",
    "text": "New short course on Building Applications with Vector Databases, taught by @pineconeâ€™s @timt! At the heart of a vector database is the ability to store a collection of vectors and then query against that, meaning input a new vector and find similar ones. This is useful for many AI applications. In this course, you'll learn how to use vector databases to build:\n\n(i) Semantic Search: Create a text search tool that goes beyond keyword matching, and instead focuses on the meaning of content.\n(ii) RAG (retrieval augmented generation): Enhance your LLM output by incorporating context from sources the model wasn't trained on.\n(iii) Recommender System: Combine semantic search and RAG to recommend topics, and demonstrate it with a news article recommender.\n(iv) Hybrid Search: Build an application that finds items using both images and descriptive text -- by combining both sparse and dense vector representations of the data -- using an eCommerce dataset as an example.\n(v) Image Similarity: Use image vector embeddings to create an app to compare facial features, using a database of public figures to determine the likeness between them.\n(vi) Anomaly Detection: Build an anomaly detection app that identifies unusual patterns in network communication logs.\n\nI hope youâ€™ll enjoy learning how to build all these types of applications! Please sign up here: https://t.co/nginq45FAf",
    "createdAt": "Wed Jan 31 18:37:59 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 206,
    "replyCount": 65,
    "likeCount": 1150,
    "quoteCount": 14,
    "viewCount": 136721,
    "bookmarkCount": 654,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "ç”± @pinecone å…¬å¸çš„ @timt è®²æˆçš„â€œä½¿ç”¨å‘é‡æ•°æ®åº“æ„å»ºåº”ç”¨ç¨‹åºâ€æ–°çŸ­æœŸè¯¾ç¨‹å¼€è¯¾å•¦ï¼å‘é‡æ•°æ®åº“ (Vector Database) çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯å­˜å‚¨å¤§é‡å‘é‡ï¼Œå¹¶èƒ½é€šè¿‡è¾“å…¥ä¸€ä¸ªæ–°å‘é‡æ¥æŸ¥è¯¢å’Œæ£€ç´¢ä¸ä¹‹ç›¸ä¼¼çš„å‘é‡ã€‚è¿™åœ¨è®¸å¤š AI åº”ç”¨ç¨‹åºä¸­éƒ½éå¸¸æœ‰ç”¨ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å‘é‡æ•°æ®åº“æ„å»ºä»¥ä¸‹åº”ç”¨ï¼š\n\n(i) è¯­ä¹‰æœç´¢ (Semantic Search): åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æœç´¢å·¥å…·ï¼Œå®ƒä¸ä»…é™äºå…³é”®è¯åŒ¹é…ï¼Œæ›´ä¾§é‡äºå†…å®¹çš„æ·±å±‚å«ä¹‰ã€‚\n(ii) RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ, retrieval augmented generation): é€šè¿‡å¼•å…¥æ¨¡å‹æœªæ›¾è®­ç»ƒè¿‡çš„å¤–éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ¥å¢å¼ºæ‚¨çš„ å¤§è¯­è¨€æ¨¡å‹ (LLM) è¾“å‡ºã€‚\n(iii) æ¨èç³»ç»Ÿ (Recommender System): ç»“åˆè¯­ä¹‰æœç´¢å’Œ RAG æ¥æ¨èä¸»é¢˜ï¼Œå¹¶å°†é€šè¿‡ä¸€ä¸ªæ–°é—»æ–‡ç« æ¨èå™¨è¿›è¡Œæ¼”ç¤ºã€‚\n(iv) æ··åˆæœç´¢ (Hybrid Search): æ„å»ºä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œç»“åˆå›¾åƒå’Œæè¿°æ€§æ–‡æœ¬æ¥æŸ¥æ‰¾å•†å“ï¼ŒåŒæ—¶åˆ©ç”¨æ•°æ®çš„ç¨€ç–å’Œå¯†é›†å‘é‡è¡¨ç¤ºâ€”â€”æˆ‘ä»¬å°†ä»¥ä¸€ä¸ªç”µå­å•†åŠ¡æ•°æ®é›†ä¸ºä¾‹ã€‚\n(v) å›¾åƒç›¸ä¼¼æ€§ (Image Similarity): ä½¿ç”¨å›¾åƒå‘é‡åµŒå…¥ (Image Vector Embeddings) æ¥åˆ›å»ºä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œç”¨äºæ¯”è¾ƒé¢éƒ¨ç‰¹å¾ï¼Œé€šè¿‡ä¸€ä¸ªå…¬å…±äººç‰©æ•°æ®åº“æ¥åˆ¤æ–­ä¸åŒäººä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚\n(vi) å¼‚å¸¸æ£€æµ‹ (Anomaly Detection): æ„å»ºä¸€ä¸ªå¼‚å¸¸æ£€æµ‹åº”ç”¨ç¨‹åºï¼Œç”¨äºè¯†åˆ«ç½‘ç»œé€šä¿¡æ—¥å¿—ä¸­çš„å¼‚å¸¸æ¨¡å¼ã€‚\n\nå¸Œæœ›æ‚¨èƒ½äº«å—å­¦ä¹ å¦‚ä½•æ„å»ºè¿™äº›å¤šæ ·åŒ–åº”ç”¨ç¨‹åºçš„è¿‡ç¨‹ï¼è¯·åœ¨è¿™é‡Œæ³¨å†Œï¼šhttps://t.co/nginq45FAf"
  },
  {
    "id": "1750985019789873244",
    "url": "https://x.com/AndrewYNg/status/1750985019789873244",
    "text": "My takeaways from attending WEF at Davos last week:\n- There were lots of discussions on business implementation of AI. My top two tips: (i) Pretty much all knowledge workers can benefit from using GenAI now, but most will need training. (ii) Task-based analysis of jobs is helping businesses identify opportunities. \n- Also lots of AI regulation conversations. I'm happy to report that the conversation is much more sensible than 6 months ago. For example, the unnecessary fears and discussion on AI extinction risk is fading away. But some big companies are still pushing for stifling, anti-competitive regulations, and the fight to protect open-source is still far from won. \n- Attending climate sessions made me even more worried about the lack of action to change our planet's trajectory. Rather than 1.5 degrees Celsius of warming as the optimistic case and 2 degrees as the pessimistic case, I think 2 degrees is an optimistic case, and 4 degrees a more realistic pessimistic case. Decarbonization remains critical; and unfortunately, that we're talking about 1.5-2 degrees rather than 2-4 degrees means we're underinvesting in resilience, adaptation, and potentially game-changing technologies like geo-engineering.\n\nLonger writeup below in The Batch: https://t.co/ZkdsgeF6WU",
    "createdAt": "Fri Jan 26 20:52:15 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 264,
    "replyCount": 105,
    "likeCount": 1439,
    "quoteCount": 32,
    "viewCount": 723896,
    "bookmarkCount": 451,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä¸Šå‘¨å‚åŠ è¾¾æ²ƒæ–¯ä¸–ç•Œç»æµè®ºå› (WEF) çš„æ”¶è·ï¼š\n- ä¼šä¸Šé’ˆå¯¹äººå·¥æ™ºèƒ½ (AI) çš„å•†ä¸šåŒ–è½åœ°è¿›è¡Œäº†å¤§é‡è®¨è®ºã€‚æˆ‘çš„ä¸¤å¤§å»ºè®®æ˜¯ï¼š (i) å‡ ä¹æ‰€æœ‰çŸ¥è¯†å·¥ä½œè€…ç°åœ¨éƒ½èƒ½ä»ç”Ÿæˆå¼ AI (Generative AI) çš„ä½¿ç”¨ä¸­å—ç›Šï¼Œä½†å¤§å¤šæ•°äººä»éœ€è¦ä¸“ä¸šåŸ¹è®­ã€‚(ii) åŸºäºä»»åŠ¡çš„å·¥ä½œåˆ†ææ­£å¸®åŠ©ä¼ä¸šå‘ç°æ–°çš„æœºé‡ã€‚\n- å…³äº AI ç›‘ç®¡çš„æ¢è®¨ä¹Ÿå¾ˆå¤šã€‚æˆ‘å¾ˆé«˜å…´åœ°å‘Šè¯‰å¤§å®¶ï¼Œç›®å‰çš„è®¨è®ºæ¯”å…­ä¸ªæœˆå‰ç†æ€§å¾—å¤šã€‚ä¾‹å¦‚ï¼Œå¯¹ AI ç­ç»é£é™©é‚£äº›ä¸å¿…è¦çš„æ‹…å¿§å’Œäº‰è®ºæ­£åœ¨é€æ¸æ¶ˆé€€ã€‚ç„¶è€Œï¼Œä¸€äº›å¤§å‹ä¼ä¸šä»åœ¨åŠ›æ¨å…·æœ‰æŠ‘åˆ¶ä½œç”¨ã€åç«äº‰çš„ç›‘ç®¡æ”¿ç­–ï¼Œå› æ­¤ä¿æŠ¤å¼€æºï¼ˆOpen-sourceï¼‰çš„åŠªåŠ›è¿œæœªæˆåŠŸã€‚\n- å‚åŠ æ°”å€™è®®é¢˜ä¼šè®®è®©æˆ‘å¯¹ç›®å‰ç¼ºä¹æ”¹å˜åœ°çƒæ°”å€™èµ°å‘çš„è¡ŒåŠ¨æ„Ÿåˆ°æ›´åŠ æ‹…å¿§ã€‚æˆ‘è®¤ä¸ºï¼Œå°†å…¨çƒå‡æ¸© 1.5 æ‘„æ°åº¦è§†ä¸ºä¹è§‚æƒ…å†µã€2 æ‘„æ°åº¦è§†ä¸ºæ‚²è§‚æƒ…å†µï¼Œè¿™å¹¶ä¸å‡†ç¡®ã€‚å®é™…ä¸Šï¼Œ2 æ‘„æ°åº¦å‡æ¸©æˆ–è®¸å·²æ˜¯ä¹è§‚é¢„æœŸï¼Œè€Œ 4 æ‘„æ°åº¦å‡æ¸©å¯èƒ½æ‰æ˜¯æ›´ç°å®çš„æ‚²è§‚æƒ…æ™¯ã€‚è„±ç¢³ä¾ç„¶è‡³å…³é‡è¦ï¼›ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬ä»åœ¨è®¨è®º 1.5 åˆ° 2 æ‘„æ°åº¦çš„å‡æ¸©ï¼Œè€Œé 2 åˆ° 4 æ‘„æ°åº¦ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬åœ¨æŠµå¾¡æ°”å€™å˜åŒ–çš„èƒ½åŠ›ï¼ˆéŸ§æ€§ï¼‰ã€é€‚åº”æªæ–½ä»¥åŠåœ°çƒå·¥ç¨‹ç­‰å¯èƒ½æ”¹å˜å±€é¢çš„æŠ€æœ¯ä¸ŠæŠ•å…¥ä¸è¶³ã€‚\n\næ›´è¯¦ç»†çš„å†…å®¹å¯åœ¨ã€ŠThe Batchã€‹ä¸­æŸ¥çœ‹ï¼š https://t.co/ZkdsgeF6WU"
  },
  {
    "id": "1750200384600309872",
    "url": "https://x.com/AndrewYNg/status/1750200384600309872",
    "text": "New short course on Automated Testing for LLMOps, by @CircleCI's CTO Rob Zuber! This teaches you how to adapt some key ideas from CI (continuous integration), which has been a pillar of efficient software engineering, to building LLM-based applications.\n\nTweaking an LLM-based app to improve it -- say by modifying a prompt -- can have unexpected side effects. For example, what if a teammate updates a prompt to try to make the LLM output sound more interesting, but this causes it to hallucinate more? Automated testing, as part of your approach to LLMOps (LLM Operations), helps avoid these problems and lets you ship faster and with greater confidence.\n\nIn this course, youâ€™ll learn to:\n(i) Write LLM evaluations to cover common problems like hallucinations, data drift, and harmful or offensive output.\n(ii) Build a CI workflow to automatically evaluate each change to your application.\n(iii) Orchestrate your CI workflow to run specific evaluations at different stages of development.\n\nCI is especially important for AI applications given the iterative nature of AI development, which means we often want to make many incremental changes. \n\nPlease sign up for this course here!  https://t.co/eTfzX2dPjD",
    "createdAt": "Wed Jan 24 16:54:23 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 148,
    "replyCount": 67,
    "likeCount": 789,
    "quoteCount": 9,
    "viewCount": 100885,
    "bookmarkCount": 356,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "@CircleCI é¦–å¸­æŠ€æœ¯å®˜ (CTO) Rob Zuber æ¨å‡ºäº†ä¸€é—¨å…³äºå¤§è¯­è¨€æ¨¡å‹è¿ç»´ (LLMOps) è‡ªåŠ¨åŒ–æµ‹è¯•çš„å…¨æ–°çŸ­æœŸè¯¾ç¨‹ï¼æœ¬è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•æŠŠæŒç»­é›†æˆ (CI) ä¸­çš„ä¸€äº›å…³é”®ç†å¿µåº”ç”¨åˆ°åŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Model) çš„åº”ç”¨ç¨‹åºå¼€å‘ä¸­ã€‚æŒç»­é›†æˆ (CI) ä¸€ç›´æ˜¯é«˜æ•ˆè½¯ä»¶å·¥ç¨‹çš„æ”¯æŸ±ã€‚\n\nè°ƒæ•´ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„åº”ç”¨ç¨‹åºæ¥æ”¹è¿›å®ƒâ€”â€”æ¯”å¦‚é€šè¿‡ä¿®æ”¹ä¸€ä¸ªæç¤ºè¯ (prompt) â€”â€”å¯èƒ½ä¼šäº§ç”Ÿæ„æƒ³ä¸åˆ°çš„å‰¯ä½œç”¨ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœä¸€ä½é˜Ÿå‹æ›´æ–°äº†æç¤ºè¯ï¼Œè¯•å›¾è®©å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„è¾“å‡ºå¬èµ·æ¥æ›´æœ‰è¶£ï¼Œä½†è¿™å´å¯¼è‡´æ¨¡å‹äº§ç”Ÿæ›´å¤šå¹»è§‰ (hallucination)ï¼Œé‚£è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿè‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œä½œä¸ºä½ å¤§è¯­è¨€æ¨¡å‹è¿ç»´ (LLM Operations, LLMOps) ç­–ç•¥çš„ä¸€éƒ¨åˆ†ï¼Œæœ‰åŠ©äºé¿å…è¿™äº›é—®é¢˜ï¼Œè®©ä½ èƒ½æ›´å¿«ã€æ›´æœ‰ä¿¡å¿ƒåœ°äº¤ä»˜åº”ç”¨ã€‚\n\nåœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ ï¼š\n(i) ç¼–å†™å¤§è¯­è¨€æ¨¡å‹ (LLM) è¯„ä¼°ï¼Œä»¥åº”å¯¹å¹»è§‰ã€æ•°æ®æ¼‚ç§» (data drift) ä»¥åŠæœ‰å®³æˆ–å†’çŠ¯æ€§è¾“å‡ºç­‰å¸¸è§é—®é¢˜ã€‚\n(ii) æ„å»ºæŒç»­é›†æˆ (CI) å·¥ä½œæµï¼Œå¯¹ä½ åº”ç”¨ç¨‹åºçš„æ¯ä¸€æ¬¡æ›´æ”¹è¿›è¡Œè‡ªåŠ¨è¯„ä¼°ã€‚\n(iii) åè°ƒä½ çš„æŒç»­é›†æˆ (CI) å·¥ä½œæµï¼Œä»¥ä¾¿åœ¨å¼€å‘çš„ä¸åŒé˜¶æ®µè¿è¡Œç‰¹å®šçš„è¯„ä¼°ã€‚\n\né‰´äºäººå·¥æ™ºèƒ½ (AI) å¼€å‘çš„è¿­ä»£æ€§è´¨ï¼Œå³æˆ‘ä»¬é€šå¸¸éœ€è¦è¿›è¡Œè®¸å¤šå¢é‡æ›´æ”¹ï¼ŒæŒç»­é›†æˆ (CI) å¯¹äºäººå·¥æ™ºèƒ½ (AI) åº”ç”¨ç¨‹åºæ¥è¯´å°¤ä¸ºé‡è¦ã€‚\n\nè¯·åœ¨æ­¤å¤„æŠ¥åå‚åŠ æœ¬è¯¾ç¨‹ï¼š https://t.co/eTfzX2dPjD"
  },
  {
    "id": "1748005715237654528",
    "url": "https://x.com/AndrewYNg/status/1748005715237654528",
    "text": "New short course on LLMOps!\n\nLLMOps (large language model operations) is a rapidly developing field that takes ideas from MLOps (machine learning operations) and specializes them to building and deploying LLM-based applications. In this course, taught by @googlecloud's Erwin Huizenga, you'll learn to use automation to make building, tuning and deploying an LLM-based application less manual and more efficient. \n\nYou'll learn how to:\n- Apply supervised fine-tuning to tune an LLM to a specific task\n- Automate and orchestrate LLM-tuning and deployment by customizing a pre-built tuning pipeline\n- Apply best practices for preparing training data for supervised fine-tuning of an LLM\n- Create an LLMOps workflow you can adapt to other LLM-tuning jobs\n\nThis course doesn't assume any prior MLOps or LLMOps experience. Sign up here to learn about this emerging field! https://t.co/UlDEbI0DbK",
    "createdAt": "Thu Jan 18 15:33:33 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 281,
    "replyCount": 78,
    "likeCount": 1461,
    "quoteCount": 25,
    "viewCount": 221278,
    "bookmarkCount": 1014,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "å…³äº LLMOps çš„å…¨æ–°çŸ­æœŸè¯¾ç¨‹æ¥äº†ï¼\n\nLLMOps (å¤§è¯­è¨€æ¨¡å‹è¿è¥) æ˜¯ä¸€ä¸ªè¿…é€Ÿå‘å±•çš„é¢†åŸŸï¼Œå®ƒå€Ÿé‰´äº† MLOps (æœºå™¨å­¦ä¹ è¿è¥) çš„ç†å¿µï¼Œå¹¶å°†å…¶ä¸“é—¨åº”ç”¨äºæ„å»ºå’Œéƒ¨ç½²åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚åœ¨è¿™é—¨ç”± Google Cloud çš„ Erwin Huizenga ä¸»è®²çš„è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•è¿ç”¨è‡ªåŠ¨åŒ–ï¼Œè®©å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ„å»ºã€è°ƒä¼˜å’Œéƒ¨ç½²è¿‡ç¨‹å‡å°‘äººå·¥å¹²é¢„ï¼Œå˜å¾—æ›´åŠ é«˜æ•ˆã€‚\n\nä½ å°†æŒæ¡ä»¥ä¸‹æŠ€èƒ½ï¼š\n- è¿ç”¨ç›‘ç£å¾®è°ƒ (supervised fine-tuning) æŠ€æœ¯ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œä¼˜åŒ–ã€‚\n- é€šè¿‡å®šåˆ¶é¢„è®¾çš„è°ƒä¼˜æµç¨‹ï¼Œè‡ªåŠ¨åŒ–å’Œç¼–æ’å¤§è¯­è¨€æ¨¡å‹çš„è°ƒä¼˜ä¸éƒ¨ç½²ã€‚\n- æŒæ¡ä¸ºå¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒå‡†å¤‡è®­ç»ƒæ•°æ®çš„æœ€ä½³å®è·µã€‚\n- åˆ›å»ºä¸€ä¸ªå¯åº”ç”¨äºå…¶ä»–å¤§è¯­è¨€æ¨¡å‹è°ƒä¼˜ä»»åŠ¡çš„ LLMOps å·¥ä½œæµã€‚\n\næœ¬è¯¾ç¨‹ä¸è¦æ±‚ä½ å…·å¤‡ä»»ä½• MLOps æˆ– LLMOps ç»éªŒã€‚ç‚¹å‡»æ­¤å¤„æŠ¥åï¼Œæ¢ç´¢è¿™ä¸ªæ–°å…´é¢†åŸŸå§ï¼https://t.co/UlDEbI0DbK"
  },
  {
    "id": "1745516258697863259",
    "url": "https://x.com/AndrewYNg/status/1745516258697863259",
    "text": "It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing Direct Preference Optimization (DPO) by @rm_rafailov @archit_sharma97 @ericmitchellai @StefanoErmon @chrmanning and @chelseabfinn. This beautiful paper proposes a much simpler alternative to RLHF (reinforcement learning from human feedback) for aligning language models to human preferences. \n\nRLHF has been a key technique for training LLMs. In brief, RLHF (i) Gets humans to specify their preferences by ranking LLM outputs, (ii) Trains a reward model (used to score LLM outputs) -- typically represented using a transformer network -- to be consistent with the human rankings, (iii) Uses reinforcement learning to tune an LLM, also represented as a transformer, to maximize rewards. This requires two transformer networks, and RLHF is also finicky to the choice of hyperparameters.\n\nDPO simplifies the whole thing. Via clever mathematical insight, the authors show that given an LLM, there is a specific reward function for which that LLM is optimal. DPO then trains the LLM directly to make the reward function (thatâ€™s now implicitly defined by the LLM) consistent with the human rankings. So you no longer need to deal with a separately represented reward function, and you can train the LLM directly to optimize the same objective as RLHF. \n\nAlthough itâ€™s still too early to be sure, I am cautiously optimistic that DPO will have a huge impact on LLMs and beyond in the next few years.\n\nYou can read the paper here: https://t.co/m14qRYszVa I also write more about this in The Batch (linked to below).  \nhttps://t.co/8h2ag2plIa",
    "createdAt": "Thu Jan 11 18:41:20 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 764,
    "replyCount": 90,
    "likeCount": 5099,
    "quoteCount": 78,
    "viewCount": 694998,
    "bookmarkCount": 3694,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘å¾ˆå°‘åœ¨è¯»å®Œä¸€ç¯‡ç ”ç©¶è®ºæ–‡åï¼Œä¼šæ„Ÿåˆ°æƒ³ç»™ä½œè€…ä»¬èµ·ç«‹é¼“æŒã€‚ä½†åœ¨è¯»å®Œ Rafailovã€Sharmaã€Mitchellã€Ermonã€Manning å’Œ Finn å‡ ä½åˆè‘—çš„ã€Šç›´æ¥åå¥½ä¼˜åŒ–ã€‹( Direct Preference Optimization, DPO ) åï¼Œæˆ‘ç¡®å®æœ‰è¿™ç§æ„Ÿè§‰ã€‚è¿™ç¯‡ç²¾å½©çš„è®ºæ–‡æå‡ºäº†ä¸€ç§æ¯” RLHF ( reinforcement learning from human feedback ) ç®€å•å¾—å¤šçš„æ›¿ä»£æ–¹æ¡ˆï¼Œç”¨äºè®©è¯­è¨€æ¨¡å‹æ›´å¥½åœ°ç¬¦åˆäººç±»åå¥½ã€‚\n\nRLHF ä¸€ç›´æ˜¯è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ ( LLM ) çš„å…³é”®æŠ€æœ¯ã€‚ç®€è€Œè¨€ä¹‹ï¼ŒRLHF çš„æµç¨‹åŒ…æ‹¬ï¼š ( i ) è®©äººç±»é€šè¿‡å¯¹ LLM è¾“å‡ºè¿›è¡Œæ’åºæ¥è¡¨è¾¾ä»–ä»¬çš„åå¥½ï¼› ( ii ) è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ ( é€šå¸¸ä½¿ç”¨ Transformer ç½‘ç»œæ¥è¡¨ç¤ºï¼Œç”¨äºå¯¹ LLM è¾“å‡ºè¿›è¡Œè¯„åˆ† ) ï¼Œä½¿å…¶ä¸äººç±»çš„åå¥½æ’åºä¿æŒä¸€è‡´ï¼› ( iii ) ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥è°ƒæ•´ LLM ( åŒæ ·ä¹Ÿæ˜¯ä¸€ä¸ª Transformer ) ï¼Œä»¥æœ€å¤§åŒ–è¿™ä¸ªå¥–åŠ±ã€‚è¿™éœ€è¦ä¸¤ä¸ª Transformer ç½‘ç»œï¼Œè€Œä¸” RLHF å¯¹è¶…å‚æ•° ( hyperparameters ) çš„é€‰æ‹©ä¹Ÿéå¸¸æ•æ„Ÿï¼Œè°ƒä¼˜èµ·æ¥æ¯”è¾ƒæ£˜æ‰‹ã€‚\n\nDPO ç®€åŒ–äº†æ•´ä¸ªè¿‡ç¨‹ã€‚é€šè¿‡å·§å¦™çš„æ•°å­¦æ´å¯Ÿï¼Œä½œè€…ä»¬å‘ç°ï¼Œå¯¹äºä»»ä½•ä¸€ä¸ªç»™å®šçš„ LLMï¼Œéƒ½å­˜åœ¨ä¸€ä¸ªç‰¹å®šçš„å¥–åŠ±å‡½æ•°ï¼Œè€Œè¿™ä¸ª LLM å¯¹è¯¥å¥–åŠ±å‡½æ•°æ¥è¯´æ˜¯â€œæœ€ä¼˜â€çš„ã€‚ DPO éšåç›´æ¥è®­ç»ƒ LLMï¼Œä½¿ç”± LLM éšå¼å®šä¹‰çš„å¥–åŠ±å‡½æ•°ä¸äººç±»çš„åå¥½æ’åºä¿æŒä¸€è‡´ã€‚è¿™æ ·ä¸€æ¥ï¼Œä½ å°±ä¸å†éœ€è¦å•ç‹¬è®¾è®¡æˆ–æ˜¾å¼è¡¨ç¤ºä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥è®­ç»ƒ LLM æ¥ä¼˜åŒ–ä¸ RLHF ç›¸åŒçš„ç›®æ ‡ã€‚\n\nå°½ç®¡ç°åœ¨ä¸‹ç»“è®ºè¿˜ä¸ºæ—¶è¿‡æ—©ï¼Œä½†æˆ‘è°¨æ…ä¹è§‚åœ°è®¤ä¸º DPO å°†åœ¨æœªæ¥å‡ å¹´å¯¹ LLM ä»¥åŠæ›´å¹¿æ³›çš„é¢†åŸŸäº§ç”Ÿå·¨å¤§å½±å“ã€‚\n\nä½ å¯ä»¥åœ¨è¿™é‡Œé˜…è¯»è¿™ç¯‡è®ºæ–‡ï¼šhttps://t.co/m14qRYszVa æˆ‘è¿˜åœ¨ The Batch ( é“¾æ¥å¦‚ä¸‹ ) ä¸­å¯¹æ­¤å†™äº†æ›´å¤šå†…å®¹ã€‚\nhttps://t.co/8h2ag2plIa"
  },
  {
    "id": "1745127613742657887",
    "url": "https://x.com/AndrewYNg/status/1745127613742657887",
    "text": "Our first Generative AI short course in JavaScript!\n\nGitHub recently reported that JavaScript is again the worldâ€™s most popular programming language. To support web developers exploring and developing with generative AI, we just launched a new short course in JavaScript taught by @Hacubu, founding engineer at @LangChainAI. In â€‹â€‹Build LLM Apps with LangChain.js youâ€™ll learn elements common in AI development, including:\n\n(i) Using data loaders to pull data from common sources such as PDFs, websites, and databases\n(ii) Prompts, which are used to provide the LLM context\n(iii) Modules to support RAG such as text splitters and integrations with vector stores\n(iv) Working with different models to write applications that are not vendor-specific\n(v) Parsers, which extract and format the output for your downstream code to process\n\nYouâ€™ll also build with the LangChain Expression Language, which lets you easily compose  sequences (also called chains) of modules to perform complex tasks using LLMs. \n\nPutting all this together, youâ€™ll also work on a conversational question-answering LLM application capable of using external data as context.\n\nPlease sign up here: https://t.co/oVoFPKRBbW",
    "createdAt": "Wed Jan 10 16:57:00 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 332,
    "replyCount": 78,
    "likeCount": 1709,
    "quoteCount": 40,
    "viewCount": 283672,
    "bookmarkCount": 1126,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä»¬çš„é¦–ä¸ª JavaScript ç”Ÿæˆå¼ AI (Generative AI) çŸ­æœŸè¯¾ç¨‹ï¼\n\nGitHub æœ€è¿‘æŠ¥å‘Šç§°ï¼ŒJavaScript å†æ¬¡æˆä¸ºå…¨çƒæœ€å—æ¬¢è¿çš„ç¼–ç¨‹è¯­è¨€ã€‚ä¸ºäº†æ”¯æŒç½‘é¡µå¼€å‘è€…æ¢ç´¢å’Œä½¿ç”¨ç”Ÿæˆå¼ AI è¿›è¡Œå¼€å‘ï¼Œæˆ‘ä»¬åˆšåˆšæ¨å‡ºäº†ä¸€é—¨å…¨æ–°çš„ JavaScript çŸ­æœŸè¯¾ç¨‹ã€‚è¿™é—¨è¯¾ç¨‹ç”± @Hacubu è®²æˆï¼Œä»–æ˜¯ @LangChainAI çš„åˆ›å§‹å·¥ç¨‹å¸ˆã€‚åœ¨åä¸ºâ€œæ„å»º LangChain.js å¤§è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨â€çš„è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹  AI å¼€å‘ä¸­å¸¸è§çš„æ ¸å¿ƒè¦ç´ ï¼ŒåŒ…æ‹¬ï¼š\n\n(i) ä½¿ç”¨æ•°æ®åŠ è½½å™¨ä» PDFã€ç½‘ç«™å’Œæ•°æ®åº“ç­‰å¸¸è§æ¥æºæå–æ•°æ®\n(ii) æç¤ºè¯ (Prompts)ï¼Œå®ƒä»¬ç”¨æ¥ä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯\n(iii) æ”¯æŒæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) çš„æ¨¡å—ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†å‰²å™¨ (text splitters) ä»¥åŠä¸å‘é‡å­˜å‚¨ (vector stores) çš„é›†æˆ\n(iv) ä½¿ç”¨ä¸åŒçš„æ¨¡å‹æ¥ç¼–å†™ä¸å±€é™äºç‰¹å®šä¾›åº”å•†çš„åº”ç”¨ç¨‹åº\n(v) è§£æå™¨ (Parsers)ï¼Œå®ƒä»¬è´Ÿè´£æå–å¹¶æ ¼å¼åŒ–è¾“å‡ºï¼Œä»¥ä¾¿æ‚¨çš„åç»­ä»£ç è¿›è¡Œå¤„ç†\n\næ‚¨è¿˜å°†å­¦ä¹ å¹¶ä½¿ç”¨ LangChain è¡¨è¾¾å¼è¯­è¨€ (LangChain Expression Language) æ¥æ„å»ºåº”ç”¨ã€‚è¿™ç§è¯­è¨€èƒ½è®©æ‚¨è½»æ¾åœ°å°†ä¸€ç³»åˆ—æ¨¡å—ï¼ˆä¹Ÿç§°ä¸ºâ€œé“¾â€ (chains)ï¼‰ç»„åˆèµ·æ¥ï¼Œä»è€Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚\n\næ€»è€Œè¨€ä¹‹ï¼Œæ‚¨è¿˜å°†äº²æ‰‹å¼€å‘ä¸€ä¸ªå¯¹è¯å¼é—®ç­”çš„å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºï¼Œå®ƒèƒ½å¤Ÿåˆ©ç”¨å¤–éƒ¨æ•°æ®ä½œä¸ºä¸Šä¸‹æ–‡è¿›è¡Œäº¤äº’ã€‚\n\nè¯·ç‚¹å‡»æ­¤å¤„æ³¨å†Œï¼šhttps://t.co/oVoFPKRBbW"
  },
  {
    "id": "1744433663969022090",
    "url": "https://x.com/AndrewYNg/status/1744433663969022090",
    "text": "I said some things poorly in my previous tweet, so let me elaborate/clarify.\n\n1. I don't think it's okay for any company to regurgitate others' copyrighted content at scale without permission or a viable fair-use rationale. I should have said this more explicitly.\n\nAnd... I still think the link between training an LLM on someone's content to having the LLM regurgitate that content to users at scale is weaker than many would have thought from looking at the NYT lawsuit. It is possible that an LLM will regurgitate text using only the pre-trained weights (no RAG), but I believe only in very rare, corner cases, in response to particular prompts (that in practice are hardly ever used by normal users).\n\n2. When I try to replicate the \"worst\" looking examples of copyright violations in the lawsuit -- such as a user trying to use ChatGPT to get around a paywall, or get Wirecutter (an NYT property) results -- I end up triggering GPT-4's web browsing capability. (See two examples in attached screenshots.) That's why I said I suspect RAG was involved in the examples used in the NYT lawsuit.\n\nSpecifically, one of the cool features of GPT-4 is that it can browse the web to download additional information to generate its response. For example, one can prompt it to do a web search, or sometimes even to download a specific article. While it's not great that GPT-4 apparently used to be willing to download and display an article (nearly) verbatim, to OpenAI's credit, this loophole appears to have been closed.\n\nI believe the prominence given to these examples in the lawsuit made people think that it was training an LLM on NYT text that led directly to some of these examples of NYT text being regurgitated. But if RAG was involved, then the root cause of these examples of regurgitation is not that the LLM was trained on NYT text -- that's why I said I found the presentation of issues in the lawsuit muddied.\n\n3. It is also true that the NYT shows that you can get GPT-4 to regurgitate NYT text, by prompting it in a particular way. (I should have said this in my last tweet as well.) The prompts used seem to typically involve giving a large chunk of an article, and then getting the LLM to complete it.\n\nWhile it's not great that an LLM does this, I am skeptical that practically anyone uses an LLM this way.  Thatâ€™s why I said that given the rarity of such generations resulting in text regurgitation, I question how much harm to NYT this has actually caused. I'm also not sure if this works only on articles that have been syndicated and are all over the internet anyway (so that the article appears numerous times in the LLM training set). Further, it looks like the newer versions of ChatGPT have closed this loophole. \n\n@TonyW also makes this point well: https://t.co/KKYir0eFVV\n\nThanks for reading!",
    "createdAt": "Mon Jan 08 18:59:30 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 114,
    "replyCount": 112,
    "likeCount": 667,
    "quoteCount": 17,
    "viewCount": 265186,
    "bookmarkCount": 186,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isQuote": true,
    "isPinned": false,
    "tranlastedContent": "æˆ‘ä¹‹å‰çš„ä¸€äº›è¡¨è¿°æœ‰æ¬ å¦¥ä¹‹å¤„ï¼Œæ‰€ä»¥åœ¨æ­¤è¿›è¡Œè¯¦ç»†é˜è¿°å’Œæ¾„æ¸…ã€‚\n\n1.  æˆ‘è®¤ä¸ºä»»ä½•å…¬å¸åœ¨æœªç»è®¸å¯æˆ–ç¼ºä¹åˆç†ä½¿ç”¨ç†ç”±çš„æƒ…å†µä¸‹ï¼Œå¤§è§„æ¨¡å¤è¿°ä»–äººçš„ç‰ˆæƒå†…å®¹éƒ½æ˜¯ä¸å¦¥çš„ã€‚è¿™ä¸€ç‚¹æˆ‘æœ¬åº”æ›´æ˜ç¡®åœ°æŒ‡å‡ºã€‚\n\næ­¤å¤–â€¦â€¦æˆ‘ä»ç„¶è®¤ä¸ºï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ (LLM) åˆ©ç”¨ä»–äººçš„å†…å®¹è¿›è¡Œè®­ç»ƒï¼Œä¸è®©å¤§è¯­è¨€æ¨¡å‹å°†è¿™äº›å†…å®¹å¤§è§„æ¨¡å¤è¿°ç»™ç”¨æˆ·ä¹‹é—´ï¼Œå…¶è”ç³»çš„ç´§å¯†ç¨‹åº¦å¯èƒ½æ¯”è®¸å¤šäººåœ¨çœ‹è¿‡ã€Šçº½çº¦æ—¶æŠ¥ã€‹è¯‰è®¼åæ‰€æƒ³è±¡çš„è¦å¼±ã€‚å¤§è¯­è¨€æ¨¡å‹ç¡®å®æœ‰å¯èƒ½ä»…ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆä¸ä¾èµ–æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œå³ RAGï¼‰æ¥å¤è¿°æ–‡æœ¬ï¼Œä½†æˆ‘ç›¸ä¿¡è¿™ä»…å‘ç”Ÿåœ¨æå°‘æ•°è¾¹ç¼˜æ¡ˆä¾‹ä¸­ï¼Œå¹¶ä¸”æ˜¯å¯¹ç‰¹å®šæç¤ºçš„å“åº”ï¼ˆè€Œè¿™äº›æç¤ºåœ¨å®è·µä¸­å‡ ä¹ä¸ä¼šè¢«æ™®é€šç”¨æˆ·ä½¿ç”¨ï¼‰ã€‚\n\n2.  å½“æˆ‘å°è¯•å¤ç°è¯‰è®¼ä¸­é‚£äº›çœ‹ä¼¼â€œæœ€ç³Ÿç³•â€çš„ç‰ˆæƒä¾µæƒç¤ºä¾‹æ—¶â€”â€”ä¾‹å¦‚ç”¨æˆ·è¯•å›¾ä½¿ç”¨ ChatGPT ç»•è¿‡ä»˜è´¹å¢™ï¼Œæˆ–è·å– Wirecutterï¼ˆã€Šçº½çº¦æ—¶æŠ¥ã€‹æ——ä¸‹çš„åª’ä½“ï¼‰çš„å†…å®¹â€”â€”æˆ‘æœ€ç»ˆéƒ½ä¼šè°ƒç”¨ GPT-4 çš„ç½‘é¡µæµè§ˆåŠŸèƒ½ã€‚ï¼ˆè¯·å‚è§é™„å›¾ä¸­ä¸¤ä¸ªç¤ºä¾‹ã€‚ï¼‰è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘æ€€ç–‘ã€Šçº½çº¦æ—¶æŠ¥ã€‹è¯‰è®¼ä¸­æåˆ°çš„ç¤ºä¾‹æ¶‰åŠäº† RAGã€‚\n\nå…·ä½“æ¥è¯´ï¼ŒGPT-4 çš„ä¸€ä¸ªå‡ºè‰²åŠŸèƒ½æ˜¯å®ƒèƒ½å¤Ÿæµè§ˆç½‘é¡µä»¥ä¸‹è½½é¢å¤–ä¿¡æ¯æ¥ç”Ÿæˆå“åº”ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥æç¤ºå®ƒè¿›è¡Œç½‘ç»œæœç´¢ï¼Œç”šè‡³æœ‰æ—¶ç›´æ¥ä¸‹è½½æŸç¯‡æ–‡ç« ã€‚è™½ç„¶ GPT-4 ä»¥å‰æ˜¾ç„¶æ„¿æ„ä¸‹è½½å¹¶ï¼ˆå‡ ä¹ï¼‰é€å­—æ˜¾ç¤ºæ–‡ç« è¿™ä¸€è¡Œä¸ºå¹¶ä¸ç†æƒ³ï¼Œä½†å€¼å¾—ç§°èµçš„æ˜¯ï¼ŒOpenAI ä¼¼ä¹å·²ç»ä¿®è¡¥äº†è¿™ä¸€æ¼æ´ã€‚\n\næˆ‘ç›¸ä¿¡ï¼Œè¿™äº›ä¾‹å­åœ¨è¯‰è®¼ä¸­è¢«ç€é‡å¼ºè°ƒï¼Œä½¿å¾—äººä»¬è¯¯ä»¥ä¸ºæ˜¯ç”±äºç”¨ã€Šçº½çº¦æ—¶æŠ¥ã€‹çš„æ–‡æœ¬è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹æ‰ç›´æ¥å¯¼è‡´äº†è¿™äº›ã€Šçº½çº¦æ—¶æŠ¥ã€‹æ–‡æœ¬è¢«å¤è¿°çš„ä¾‹å­ã€‚ä½†å¦‚æœå…¶ä¸­æ¶‰åŠäº† RAGï¼Œé‚£ä¹ˆè¿™äº›å¤è¿°çš„æ ¹æœ¬åŸå› å°±ä¸åœ¨äºå¤§è¯­è¨€æ¨¡å‹æ˜¯ç”¨ã€Šçº½çº¦æ—¶æŠ¥ã€‹çš„æ–‡æœ¬è®­ç»ƒçš„â€”â€”è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘è¯´æˆ‘å‘ç°è¯‰è®¼ä¸­é—®é¢˜çš„å‘ˆç°æ–¹å¼æ¨¡ç³Šäº†ç„¦ç‚¹ã€‚\n\n3.  åŒæ ·ï¼Œäº‹å®æ˜¯ã€Šçº½çº¦æ—¶æŠ¥ã€‹å±•ç¤ºäº†ï¼Œé€šè¿‡ä»¥ç‰¹å®šæ–¹å¼æç¤º GPT-4ï¼Œç¡®å®å¯ä»¥ä½¿å…¶å¤è¿°ã€Šçº½çº¦æ—¶æŠ¥ã€‹çš„æ–‡æœ¬ã€‚ï¼ˆæˆ‘ä¸Šæ¬¡çš„æ¨æ–‡ä¸­ä¹Ÿåº”è¯¥æåŠè¿™ä¸€ç‚¹ã€‚ï¼‰æ‰€ä½¿ç”¨çš„æç¤ºé€šå¸¸ä¼¼ä¹æ¶‰åŠæä¾›æ–‡ç« çš„å¾ˆå¤§ä¸€éƒ¨åˆ†å†…å®¹ï¼Œç„¶åè®©å¤§è¯­è¨€æ¨¡å‹å®Œæˆå‰©ä½™éƒ¨åˆ†ã€‚\n\nå°½ç®¡å¤§è¯­è¨€æ¨¡å‹å­˜åœ¨è¿™ç§å¤è¿°èƒ½åŠ›å¹¶éå¥½äº‹ï¼Œä½†æˆ‘å¯¹æ­¤æŒæ€€ç–‘æ€åº¦ï¼Œå› ä¸ºåœ¨å®é™…åº”ç”¨ä¸­å‡ ä¹æ²¡æœ‰äººä¼šä»¥è¿™ç§æ–¹å¼ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘è¯´ï¼Œè€ƒè™‘åˆ°è¿™ç§ç”Ÿæˆæ–¹å¼å¯¼è‡´æ–‡æœ¬å¤è¿°çš„ç½•è§æ€§ï¼Œæˆ‘è´¨ç–‘è¿™å®é™…ä¸Šå¯¹ã€Šçº½çº¦æ—¶æŠ¥ã€‹é€ æˆäº†å¤šå¤§çš„æŸå®³ã€‚æˆ‘ä¹Ÿä¸ç¡®å®šè¿™æ˜¯å¦ä»…é€‚ç”¨äºé‚£äº›å·²è¢«å¹¿æ³›è”åˆå‘å¸ƒå¹¶éå¸ƒäº’è”ç½‘çš„æ–‡ç« ï¼ˆä»¥è‡³äºè¯¥æ–‡ç« åœ¨å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒé›†ä¸­å‡ºç°äº†æ— æ•°æ¬¡ï¼‰ã€‚æ­¤å¤–ï¼Œçœ‹èµ·æ¥æ›´æ–°ç‰ˆæœ¬çš„ ChatGPT å·²ç»è§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚\n\n@TonyW ä¹Ÿå¾ˆå¥½åœ°é˜è¿°äº†è¿™ä¸€è§‚ç‚¹ï¼š https://t.co/KKYir0eFVV\n\næ„Ÿè°¢é˜…è¯»ï¼"
  },
  {
    "id": "1744145064115446040",
    "url": "https://x.com/AndrewYNg/status/1744145064115446040",
    "text": "After reading the @nytimes lawsuit against @OpenAI and @Microsoft, I find my sympathies more with OpenAI and Microsoft than with the NYT. \n\nThe suit:\n(1) Claims, among other things, that OpenAI and Microsoft used millions of copyrighted NYT articles to train their models\n(2) Gives examples in which OpenAI models regurgitated NYT articles almost verbatim\n\nBut the presentation muddies (1) and (2), and I saw a lot of commentary on social media that -- because of what I believe is a muddied presentation -- draws a link between them that I'm not sure is what people think it is.\n\nOn (1): I understand why media companies don't like people training on their documents, but believe that just as humans are allowed to read documents on the open internet, learn from them, and synthesize brand new ideas, AI should be allowed to do so too. I would like to see training on the public internet covered under fair use -- society will be better off this way -- though whether it actually is will ultimately be up to legislators and the courts. \n\nOn (2): I suspect a lot of the examples of ChatGPT regurgitating articles nearly verbatim were due to a RAG-like mechanism where the user prompt causes the system to browse the web, retrieve a specific article and then print it out. (If my statement here isn't accurate, I would love to see the @nytimes clarify this.) If this is the case, then (i) To OpenAI's credit, they seem to have already updated their software to make this much less likely, and (ii) This is also a much easier problem to fix than if an LLM were to regurgitate text using only the pre-trained weights, which AFAIK very rarely happens (and which, given its rarity, also raises the question of how much harm to NYT this has actually caused). \n\nTo be clear, I believe independent media is important for democracy and must be protected. I also sympathize with media businesses worried about Generative AI disrupting their businesses. But I'm not convinced the NYT lawsuit is the right way to do this. \n\nUsual caveat: I am not a lawyer and am not giving legal advice or any other form of advice here. \n\nYou can also read more details of my take on this below. https://t.co/wkZSMHsvNA",
    "createdAt": "Sun Jan 07 23:52:42 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 550,
    "replyCount": 299,
    "likeCount": 3448,
    "quoteCount": 101,
    "viewCount": 945113,
    "bookmarkCount": 842,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "åœ¨é˜…è¯»äº† ã€Šçº½çº¦æ—¶æŠ¥ã€‹ (NYT) å¯¹ OpenAI å’Œ Microsoft çš„è¯‰è®¼ä¹‹åï¼Œæˆ‘å‘ç°è‡ªå·±å¯¹ OpenAI å’Œ Microsoft çš„åŒæƒ…å¤šäºå¯¹ NYT çš„åŒæƒ…ã€‚\n\nè¯‰è®¼æŒ‡å‡ºï¼š\n(1) OpenAI å’Œ Microsoft è¢«æŒ‡æ§ä½¿ç”¨äº†æ•°ç™¾ä¸‡ç¯‡å—ç‰ˆæƒä¿æŠ¤çš„ NYT æ–‡ç« æ¥è®­ç»ƒä»–ä»¬çš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œè¿™åªæ˜¯ä¼—å¤šä¸»å¼ ä¹‹ä¸€ã€‚\n(2) è¯‰è®¼ä¹Ÿåˆ—ä¸¾äº† OpenAI çš„æ¨¡å‹å‡ ä¹é€å­—é€å¥åœ°é‡å¤äº† NYT æ–‡ç« çš„ä¾‹å­ã€‚\n\nç„¶è€Œï¼Œè¿™ç§é™ˆè¿°æ–¹å¼å´å°†ä¸Šè¿° (1) å’Œ (2) ä¸¤ç‚¹æ··æ·†äº†ã€‚æˆ‘åœ¨ç¤¾äº¤åª’ä½“ä¸Šçœ‹åˆ°è®¸å¤šè¯„è®ºï¼Œç”±äºè¿™ç§åœ¨æˆ‘çœ‹æ¥æœ‰äº›æ¨¡ç³Šçš„å‘ˆç°æ–¹å¼ï¼Œè¿™äº›è¯„è®ºå°†ä¸¤è€…å…³è”èµ·æ¥ï¼Œä½†è¿™ç§å…³è”æ˜¯å¦å°±æ˜¯äººä»¬æ‰€è®¤ä¸ºçš„é‚£æ ·ï¼Œæˆ‘å¹¶ä¸ç¡®å®šã€‚\n\nå…³äºç¬¬ä¸€ç‚¹ï¼šæˆ‘ç†è§£åª’ä½“å…¬å¸ä¸ä¹æ„äººä»¬ä½¿ç”¨ä»–ä»¬çš„å†…å®¹è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚ä½†æˆ‘è®¤ä¸ºï¼Œå°±åƒäººç±»è¢«å…è®¸åœ¨å¼€æ”¾çš„äº’è”ç½‘ä¸Šé˜…è¯»èµ„æ–™ã€ä»ä¸­å­¦ä¹ å¹¶åˆ›é€ å‡ºå…¨æ–°çš„æƒ³æ³•ä¸€æ ·ï¼ŒAI ä¹Ÿåº”è¯¥è¢«å…è®¸è¿™æ ·åšã€‚æˆ‘å¸Œæœ›å°†åŸºäºå…¬å…±äº’è”ç½‘å†…å®¹çš„è®­ç»ƒçº³å…¥â€œåˆç†ä½¿ç”¨â€ (fair use) èŒƒç•´â€”â€”è¿™ä¼šä½¿ç¤¾ä¼šå—ç›ŠåŒªæµ…â€”â€”å°½ç®¡æœ€ç»ˆè¿™æ˜¯å¦èƒ½å®ç°ï¼Œä»å°†å–å†³äºç«‹æ³•è€…å’Œæ³•é™¢çš„è£å†³ã€‚\n\nå…³äºç¬¬äºŒç‚¹ï¼šæˆ‘çŒœæµ‹è®¸å¤š ChatGPT å‡ ä¹é€å­—é€å¥åœ°é‡å¤æ–‡ç« çš„ä¾‹å­ï¼Œæ˜¯ç”±äºä¸€ç§ç±»ä¼¼äºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) çš„æœºåˆ¶ã€‚åœ¨è¿™ç§æœºåˆ¶ä¸‹ï¼Œç”¨æˆ·çš„æç¤ºä¼šå¯¼è‡´ç³»ç»Ÿæµè§ˆç½‘é¡µï¼Œæ£€ç´¢ç‰¹å®šçš„æ–‡ç« ï¼Œç„¶åå°†å…¶è¾“å‡ºã€‚ï¼ˆå¦‚æœæˆ‘è¿™é‡Œçš„è¯´æ³•ä¸å‡†ç¡®ï¼Œæˆ‘å¸Œæœ› ã€Šçº½çº¦æ—¶æŠ¥ã€‹ èƒ½å¯¹æ­¤è¿›è¡Œæ¾„æ¸…ã€‚ï¼‰å¦‚æœæƒ…å†µç¡®å®å¦‚æ­¤ï¼Œé‚£ä¹ˆï¼š(i) å€¼å¾—ç§°èµçš„æ˜¯ï¼ŒOpenAI ä¼¼ä¹å·²ç»æ›´æ–°äº†ä»–ä»¬çš„è½¯ä»¶ï¼Œå¤§å¤§é™ä½äº†è¿™ç§æƒ…å†µå‘ç”Ÿçš„å¯èƒ½æ€§ï¼›(ii) è¿™ä¸ªé—®é¢˜ä¹Ÿæ¯”å¤§è¯­è¨€æ¨¡å‹ (LLM) ä»…ä½¿ç”¨é¢„è®­ç»ƒæƒé‡æ¥é‡å¤æ–‡æœ¬æ›´å®¹æ˜“è§£å†³ã€‚æ®æˆ‘æ‰€çŸ¥ï¼Œåè€…çš„æƒ…å†µéå¸¸ç½•è§ï¼ˆè€ƒè™‘åˆ°å…¶ç½•è§æ€§ï¼Œè¿™ä¹Ÿå¼•å‘äº†ä¸€ä¸ªé—®é¢˜ï¼šè¿™å®é™…ä¸Šå¯¹ NYT é€ æˆäº†å¤šå¤§çš„æŸå®³ï¼Ÿï¼‰ã€‚\n\néœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œæˆ‘è®¤ä¸ºç‹¬ç«‹åª’ä½“å¯¹æ°‘ä¸»è‡³å…³é‡è¦ï¼Œå¿…é¡»å—åˆ°ä¿æŠ¤ã€‚æˆ‘ä¹ŸåŒæƒ…é‚£äº›æ‹…å¿ƒç”Ÿæˆå¼ AI (Generative AI) ä¸šåŠ¡å‘å±•ä¼šå†²å‡»å…¶è¥æ”¶çš„åª’ä½“å…¬å¸ã€‚ä½†æˆ‘ä¸ç›¸ä¿¡ NYT çš„è¯‰è®¼æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„æ­£ç¡®æ–¹æ³•ã€‚\n\næƒ¯ä¾‹å£°æ˜ï¼šæˆ‘å¹¶éå¾‹å¸ˆï¼Œåœ¨æ­¤ä¸æä¾›ä»»ä½•æ³•å¾‹å»ºè®®æˆ–å…¶ä»–å½¢å¼çš„å»ºè®®ã€‚\n\næ‚¨ä¹Ÿå¯ä»¥ç‚¹å‡»ä¸‹æ–¹é“¾æ¥ï¼Œé˜…è¯»æˆ‘å¯¹æ­¤äº‹çš„æ›´å¤šè¯¦ç»†çœ‹æ³•ã€‚https://t.co/wkZSMHsvNA"
  },
  {
    "id": "1742943594242249023",
    "url": "https://x.com/AndrewYNg/status/1742943594242249023",
    "text": "New short course on advanced retrieval for RAG (retrieval augmented generation)! \n\nRAG fetches relevant documents to give context to an LLM. In Advanced Retrieval for AI with Chroma, taught by @trychroma founder @atroyn, youâ€™ll learn:\n(i) Query expansion using an LLM to rewrite and improve a query, by either generating either additional relevant queries or a hypothetical answer to the query.\n(ii) Reranking using a cross-encoder - a model trained to measure similarity between two inputs presented simultaneously. Reranking reorders retrieved documents based on the cross-encoder similarity measure. \n(iii) Constructing and training an Embedding Adaptor, which is a model that adapts the embedding values to be more relevant to your use case.\n\nEach of these techniques can help you build much better RAG systems. Please sign up for the course here: https://t.co/6N1H8agcYC",
    "createdAt": "Thu Jan 04 16:18:29 +0000 2024",
    "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
    "retweetCount": 258,
    "replyCount": 77,
    "likeCount": 1467,
    "quoteCount": 22,
    "viewCount": 190628,
    "bookmarkCount": 987,
    "source": "",
    "lang": "en",
    "isReply": false,
    "isPinned": false,
    "tranlastedContent": "RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) é«˜çº§æ£€ç´¢æ–°çŸ­è¯¾ç¨‹å¼€è®²å•¦ï¼\n\nRAG çš„ä½œç”¨æ˜¯è·å–ç›¸å…³æ–‡æ¡£ï¼Œä»è€Œä¸ºå¤§è¯­è¨€æ¨¡å‹ (LLM) æä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åœ¨ç”± @trychroma åˆ›å§‹äºº @atroyn äº²æˆçš„â€œChroma AI é«˜çº§æ£€ç´¢â€è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦åˆ°ï¼š\n(i) æŸ¥è¯¢æ‰©å±•ï¼šåˆ©ç”¨ å¤§è¯­è¨€æ¨¡å‹ é‡å†™å¹¶ä¼˜åŒ–åŸå§‹æŸ¥è¯¢ï¼Œæ–¹æ³•åŒ…æ‹¬ç”Ÿæˆé¢å¤–çš„ç›¸å…³æŸ¥è¯¢ï¼Œæˆ–è€…ç›´æ¥æä¾›ä¸€ä¸ªå‡è®¾æ€§çš„ç­”æ¡ˆæ¥å¸®åŠ©æ¨¡å‹ç†è§£ã€‚\n(ii) é‡æ’åºï¼šé€šè¿‡äº¤å‰ç¼–ç å™¨ (cross-encoder) è¿›è¡Œã€‚äº¤å‰ç¼–ç å™¨æ˜¯ä¸€ç§ç»è¿‡ä¸“é—¨è®­ç»ƒçš„æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶è¯„ä¼°å¹¶æµ‹é‡ä¸¤ä¸ªè¾“å…¥ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚å®ƒä¼šæ ¹æ®è¿™ç§ç›¸ä¼¼åº¦æ¥é‡æ–°æ’åˆ—æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œç¡®ä¿æœ€ç›¸å…³çš„æ’åœ¨å‰é¢ã€‚\n(iii) æ„å»ºå’Œè®­ç»ƒåµŒå…¥é€‚é…å™¨ (Embedding Adaptor) ï¼šè¿™æ˜¯ä¸€ç§æ¨¡å‹ï¼Œæ—¨åœ¨è°ƒæ•´åµŒå…¥å€¼ï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”æ‚¨çš„ç‰¹å®šåº”ç”¨åœºæ™¯å’Œç”¨ä¾‹ã€‚\n\næŒæ¡è¿™äº›æŠ€æœ¯ï¼Œæ‚¨å°±èƒ½æ„å»ºå‡ºè¿œè¶…ä»¥å¾€çš„ RAG ç³»ç»Ÿã€‚è¯·ç‚¹å‡»æ­¤é“¾æ¥æŠ¥åè¯¾ç¨‹ï¼šhttps://t.co/6N1H8agcYC"
  },
  {
    "id": -1,
    "text": "Since you are a free user, you can only access a maximum of 15 tweets. Please upgrade to a paid user to unlock access to all tweets.",
    "tranlastedContent": "ç”±äºæ‚¨æ˜¯å…è´¹ç”¨æˆ·ï¼Œæ‚¨æœ€å¤šåªèƒ½æŸ¥çœ‹ 15 æ¡æ¨æ–‡ã€‚è¯·å‡çº§ä¸ºä»˜è´¹ç”¨æˆ·ï¼Œå³å¯è§£é”æ‰€æœ‰æ¨æ–‡çš„è®¿é—®æƒé™ã€‚"
  }
]