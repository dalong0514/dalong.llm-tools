[{
  "id": "1975614372799283423",
  "url": "https://x.com/AndrewYNg/status/1975614372799283423",
  "text": "Announcing my new course: Agentic AI!\n\nBuilding AI agents is one of the most in-demand skills in the job market. This course, available now at https://t.co/zGHUh1loPO, teaches you how.\n\nYou'll learn to implement four key agentic design patterns:\n- Reflection, in which an agent examines its own output and figures out how to improve it\n- Tool use, in which an LLM-driven application decides which functions to call to carry out web search, access calendars, send email, write code, etc.\n- Planning, where you'll use an LLM to decide how to break down a task into sub-tasks for execution, and\n- Multi-agent collaboration, in which you build multiple specialized agents — much like how a company might hire multiple employees — to perform a complex task\n\nYou'll also learn to take a complex application and systematically decompose it into a sequence of tasks to implement using these design patterns.\n\nBut here's what I think is the most important part of this course: Having worked with many teams on AI agents, I've found that the single biggest predictor of whether someone executes well is their ability to drive a disciplined process for evals and error analysis. In this course, you'll learn how to do this, so you can efficiently home in on which components to improve in a complex agentic workflow. Instead of guessing what to work on, you'll let evals data guide you. This will put you significantly ahead of the game compared to the vast majority of teams building agents.\n\nTogether, we'll build a deep research agent that searches, synthesizes, and reports, using all of these agentic design patterns and best practices.\n\nThis self-paced course is taught in a vendor neutral way, using raw Python - without hiding details in a framework. You'll see how each step works, and learn the core concepts that you can then implement using any popular agentic AI framework, or using no framework. The only prerequisite is familiarity with Python, though knowing a bit about LLMs helps.\n\nCome join me, and let's build some agentic AI systems!\n\nSign up to get started: https://t.co/FX35dloqw4",
  "createdAt": "Tue Oct 07 17:29:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1053,
  "replyCount": 135,
  "likeCount": 6399,
  "quoteCount": 76,
  "viewCount": 650328,
  "bookmarkCount": 6432,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1973090336068215058",
  "url": "https://x.com/AndrewYNg/status/1973090336068215058",
  "text": "Announcing a significant upgrade to Agentic Document Extraction! \n\nLandingAI's new DPT (Document Pre-trained Transformer) accurately extracts even from complex docs. For example, from large, complex tables, which is important for many finance and healthcare applications. And a new SDK makes using it require only 3 simple lines of code. Please see the video for technical details. I hope this unlocks a lot of value from the \"dark data\" currently stuck in PDF files, and that you'll build something cool with this!",
  "createdAt": "Tue Sep 30 18:19:29 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 588,
  "replyCount": 100,
  "likeCount": 3698,
  "quoteCount": 32,
  "viewCount": 283587,
  "bookmarkCount": 3884,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1971312147654377823",
  "url": "https://x.com/AndrewYNg/status/1971312147654377823",
  "text": "Last week, China barred its major tech companies from buying Nvidia chips. This move received only modest attention in the media, but has implications beyond what’s widely appreciated. Specifically, it signals that China has progressed sufficiently in semiconductors to break away from dependence on advanced chips designed in the U.S., the vast majority of which are manufactured in Taiwan. It also highlights the U.S. vulnerability to possible disruptions in Taiwan at a moment when China is becoming less vulnerable.\n\nAfter the U.S. started restricting AI chip sales to China, China dramatically ramped up its semiconductor research and investment to move toward self-sufficiency. These efforts are starting to bear fruit, and China’s willingness to cut off Nvidia is a strong sign of its faith in its domestic capabilities. For example, the new DeepSeek-R1-Safe model was trained on 1000 Huawei Ascend chips. While individual Ascend chips are significantly less powerful than individual Nvidia or AMD chips, Huawei’s system-level design approach to orchestrating how a much larger number of chips work together seems to be paying off. For example, Huawei’s CloudMatrix 384 system of 384 chips aims to compete with Nvidia’s GB200, which uses 72 higher-capability chips.\n\nToday, U.S. access to advanced semiconductors is heavily dependent on Taiwan’s TSMC, which manufactures the vast majority of the most advanced chips. Unfortunately, U.S. efforts to ramp up domestic semiconductor manufacturing have been slow. I am encouraged that one fab at the TSMC Arizona facility is now operating, but issues of workforce training, culture, licensing and permitting, and the supply chain are still being addressed, and there is still a long road ahead for the U.S. facility to be a viable substitute for manufacturing in Taiwan.\n\nIf China gains independence from Taiwan manufacturing significantly faster than the U.S., this would leave the U.S. much more vulnerable to possible disruptions in Taiwan, whether through natural disasters or man-made events. If manufacturing in Taiwan is disrupted for any reason and Chinese companies end up accounting for a large fraction of global semiconductor manufacturing capabilities, that would also help China gain tremendous geopolitical influence.\n\nDespite occasional moments of heightened tensions and large-scale military exercises, Taiwan has been mostly peaceful since the 1960s. This peace has helped the people of Taiwan to prosper and allowed AI to make tremendous advances, built on top of chips made by TSMC. I hope we will find a path to maintaining peace for many decades more.\n\nBut hope is not a plan. In addition to working to ensure peace, practical work lies ahead to multi-source, build more chip fabs in more nations, and enhance the resilience of the semiconductor supply chain. Dependence on any single manufacturer invites shortages, price spikes, and stalled innovation the moment something goes sideways.\n\n[Original text: https://t.co/5bdEpQcaob ]",
  "createdAt": "Thu Sep 25 20:33:35 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1079,
  "replyCount": 213,
  "likeCount": 5874,
  "quoteCount": 164,
  "viewCount": 815189,
  "bookmarkCount": 1841,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1970899944258375866",
  "url": "https://x.com/AndrewYNg/status/1970899944258375866",
  "text": "When data agents fail, they often fail silently - giving  confident-sounding answers that are wrong, and it can be hard to figure out what caused the failure. \n\n\"Building and Evaluating Data Agents\" is a new short course created with @Snowflake and taught by @datta_cs and @_jreini that teaches you to build data agents with comprehensive evaluation built in.\n\nSkills you'll gain:\n- Build reliable LLM data agents using the Goal-Plan-Action framework and runtime evaluations that catch failures mid-execution\n- Use OpenTelemetry tracing and evaluation infrastructure to diagnose exactly where agents fail and systematically improve performance\n- Orchestrate multi-step workflows across web search, SQL, and document retrieval in LangGraph-based agents\n\nThe result: visibility into every step of your agent's reasoning, so if something breaks, you have a systematic approach to fix it. \n\nSign up to get started: https://t.co/jGQQcU6X46",
  "createdAt": "Wed Sep 24 17:15:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 310,
  "replyCount": 65,
  "likeCount": 1398,
  "quoteCount": 7,
  "viewCount": 95046,
  "bookmarkCount": 833,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1969871958365163539",
  "url": "https://x.com/AndrewYNg/status/1969871958365163539",
  "text": "My heart goes out to all the families and individuals anxious over their futures following the abrupt and chaotic announcement of H-1B visa changes. \n\nAmerica should be working to attract more skilled talent, not create uncertainly that turns them away. To all legal immigrants and H1-B holders: I support and appreciate you.",
  "createdAt": "Sun Sep 21 21:10:47 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 581,
  "replyCount": 599,
  "likeCount": 7068,
  "quoteCount": 48,
  "viewCount": 524531,
  "bookmarkCount": 483,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1968710105924280352",
  "url": "https://x.com/AndrewYNg/status/1968710105924280352",
  "text": "Video of the panel at Buildathon: https://t.co/rYevXjv1vZ",
  "createdAt": "Thu Sep 18 16:14:00 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 13,
  "replyCount": 1,
  "likeCount": 60,
  "quoteCount": 1,
  "viewCount": 53921,
  "bookmarkCount": 72,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1968710001079501303",
  "url": "https://x.com/AndrewYNg/status/1968710001079501303",
  "text": "Automated software testing is growing in importance in the era of AI-assisted coding. Agentic coding systems accelerate development but are also unreliable. Agentic testing — where you ask AI to write tests and check your code against them — is helping. Automatically testing  infrastructure software components that you intend to build on top of is especially helpful and results in more stable infrastructure and less downstream debugging.\n\nSoftware testing methodologies such as Test Driven Development (TDD), a test-intensive approach that involves first writing rigorous tests for correctness and only then making progress by writing code that passes those tests, are an important way to find bugs. But it can be a lot of work to write tests. (I personally never adopted TDD for that reason.) Because AI is quite good at writing tests, agentic testing enjoys growing attention.\n\nFirst, coding agents do misbehave! My teams use them a lot, and we have seen:\n- Numerous bugs introduced by coding agents, including subtle infrastructure bugs that take humans weeks to find.\n- A security loophole that was introduced into our production system when a coding agent made password resets easier to simplify development.\n- Reward hacking, where a coding agent modified test code to make it easier to pass the tests.\n- An agent running \"rm *.py\" in the working directory, leading to deletion of all of a project's  code (which, fortunately, was backed up on github).\n\nIn the last example, when pressed, the agent apologized and agreed “that was an incredibly stupid mistake.” This made us feel better, but the damage had already been done!\n\nI love coding agents despite such mistakes and see them making us dramatically more productive. To make them more reliable, I’ve found that prioritizing where to test helps.\n\nI rarely write (or direct an agent to write) extensive tests for front-end code. If there's a bug, hopefully it will be easy to see and also cause little lasting damage. For example, I find generated code’s front-end bugs, say in the display of information on a web page, relatively easy to find. When the front end of a web site looks wrong, you’ll see it immediately, and you can tell the agent and have it iterate to fix it. (A more advanced technique: Use MCP to let the agent integrate with software like Playwright to automatically take screenshots, so it can autonomously see if something is wrong and debug.)\nIn contrast, back-end bugs are harder to find. I’ve seen subtle infrastructure bugs — for example, one that led to a corrupted database record only in certain corner cases — that took a long time to find. Putting in place rigorous tests for your infrastructure code might help spot these problems earlier and save you many hours of challenging debugging.\n\nBugs in software components that you intend to build on top of lead to downstream bugs that can be hard to find. Further, bugs in a component that’s deep in a software stack — and that you build multiple abstraction layers on top of — might surface only weeks or months later, long after you’ve forgotten what you were doing while building this specific component, and be really hard to identify and fix. This is why testing components deep in your software stack is especially important. Meta’s mantra “Move fast with stable infrastructure” (which replaced “move fast and break things”) still applies today. Agentic testing can help you make sure you have good infrastructure for you and others to build on!\n\nAt AI Fund and https://t.co/zpIxRSuky4’s recent Buildathon, we held a panel discussion with experts in agentic coding (Michele Catasta, President at Replit; Chao Peng, Principal Research Scientist at Trae; and Paxton Maeder-York, Venture Partnerships at Anthropic; moderated by AI Fund’s Eli Chen), where the speakers shared best practices. Testing was one of the topics discussed. That panel was one of my highlights of Buildathon and you can watch the video on YouTube.\n\n[Original text: https://t.co/B1sQ5oDnCU ]",
  "createdAt": "Thu Sep 18 16:13:35 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 208,
  "replyCount": 71,
  "likeCount": 1371,
  "quoteCount": 26,
  "viewCount": 176967,
  "bookmarkCount": 1103,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1968353689716035898",
  "url": "https://x.com/AndrewYNg/status/1968353689716035898",
  "text": "New short course: Build AI Apps with MCP Servers: Working with Box Files, built with @Box and taught by  @BenAtBox , their CTO.\n\nMany AI applications require custom code for basic file operations. The Model Context Protocol (MCP) standardizes this by letting you offload file tasks to dedicated servers that provide tools an LLM can use directly.\n\nIn this course, you'll process documents stored in a Box folder using the Box MCP server. Rather than writing custom integration code to connect to the Box API and download files, you'll design your application to use the tools provided via MCP.\n\nSkills you'll gain:\n- Build an LLM-powered document processing app, using the Box MCP server to access files\n- Design a multi-agent system using Google's Agent Development Kit (ADK), consisting of specialized agents for file operations\n- Coordinate the multi-agent workflow through an orchestrator that uses the Agent2Agent (A2A) protocol to connect to the agents\n\nYou'll start with a local file-processing app, refactor it to work with Box's MCP server, then evolve it into a multi-agent system.\n\nSign up here: https://t.co/FitKgvGnpb",
  "createdAt": "Wed Sep 17 16:37:44 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 160,
  "replyCount": 39,
  "likeCount": 717,
  "quoteCount": 8,
  "viewCount": 76736,
  "bookmarkCount": 502,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1963631698987684272",
  "url": "https://x.com/AndrewYNg/status/1963631698987684272",
  "text": "There is significant unmet demand for developers who understand AI. At the same time, because most universities have not yet adapted their curricula to the new reality of programming jobs being much more productive with AI tools, there is also an uptick in unemployment of recent CS graduates.\n\nWhen I interview AI engineers — people skilled at building AI applications — I look for people who can:\n- Use AI assistance to rapidly engineer software systems\n- Use AI building blocks like prompting, RAG, evals, agentic workflows, and machine learning to build applications\n- Prototype and iterate rapidly\n\nSomeone with these skills can get a massively greater amount done than someone who writes code the way we did in 2022, before the advent of Generative AI. I talk to large businesses every week that would love to hire hundreds or more people with these skills, as well as startups that have great ideas but not enough engineers to build them. As more businesses adopt AI, I expect this talent shortage only to grow! At the same time, recent CS graduates face an increased unemployment rate, though the underemployment rate — of graduates doing work that doesn’t require a degree — is still lower than for most other majors. This is why we hear simultaneously anecdotes of unemployed CS graduates and also of rising salaries for in-demand AI engineers.\n\nWhen programming evolved from punchcards to keyboard and terminal, employers continued to hire punchcard programmers for a while. But eventually, all developers had to switch to the new way of coding. AI engineering is similarly creating a huge wave of change.\n\nThere is a stereotype of “AI Native” fresh college graduates who outperform experienced developers. There is some truth to this. Multiple times, I have hired, for full-stack software engineering, a new grad who really knows AI over an experienced developer who still works 2022-style. But the best developers I know aren’t recent graduates (no offense to the fresh grads!). They are experienced developers who have been on top of changes in AI. The most productive programmers today  deeply understand computers, how to architect software, and how to make complex tradeoffs — and who additionally are familiar with cutting-edge AI tools.\n\nSure, some skills from 2022 are becoming obsolete. For example, a lot of coding syntax that we had to memorize back then is no longer important, since we no longer need to code by hand as much. But even if, say, 30% of CS knowledge is obsolete, the remaining 70% — complemented with modern AI knowledge — is what makes really productive developers. (Even after punch cards became obsolete, a fundamental understanding of programming was very helpful for typing code into a keyboard.)\n\nWithout understanding how computers work, you can’t just “vibe code” your way to greatness. Fundamentals are still important, and for those who additionally understand AI, job opportunities are numerous!\n\n[Original text: https://t.co/nqzPC6eUpR ]",
  "createdAt": "Thu Sep 04 15:54:14 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 591,
  "replyCount": 117,
  "likeCount": 1833,
  "quoteCount": 54,
  "viewCount": 222869,
  "bookmarkCount": 1040,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1961118026398617648",
  "url": "https://x.com/AndrewYNg/status/1961118026398617648",
  "text": "Parallel agents are emerging as an important new direction for scaling up AI. AI capabilities have scaled with more training data, training-time compute, and test-time compute. Having multiple agents run in parallel is growing as a technique to further scale and improve performance.\n\nWe know from work at Baidu by my former team, and later OpenAI, that AI models’ performance scales predictably with the amount of data and training computation. Performance rises further with test-time compute such as in agentic workflows and in reasoning models that think, reflect, and iterate on an answer. But these methods take longer to produce output. Agents working in parallel offer another path to improve results, without making users wait.\n\nReasoning models generate tokens sequentially and can take a long time to run. Similarly, most agentic workflows are initially implemented in a sequential way. But as LLM prices per token continue to fall — thus making these techniques practical — and product teams want to deliver results to users faster, more and more agentic workflows are being parallelized.\n\nSome examples:\n- Many research agents now fetch multiple web pages and examine their texts in parallel to try to synthesize deeply thoughtful research reports more quickly.\n- Some agentic coding frameworks allow users to orchestrate many agents working simultaneously on different parts of a code base. Our short course on Claude Code shows how to do this using git worktrees.\n- A rapidly growing design pattern for agentic workflows is to have a compute-heavy agent work for minutes or longer to accomplish a task, while another agent monitors the first and gives brief updates to the user to keep them informed. From here, it’s a short hop to parallel agents that work in the background while the UI agent keeps users informed and perhaps also routes asynchronous user feedback to the other agents.\n\nIt is difficult for a human manager to take a complex task (like building a complex software application) and break it down into smaller tasks for human engineers to work on in parallel; scaling to huge numbers of engineers is especially challenging. Similarly, it is also challenging to decompose tasks for parallel agents to carry out. But the falling cost of LLM inference makes it worthwhile to use a lot more tokens, and using them in parallel allows this to be done without significantly increasing the user’s waiting time.\n\nI am also encouraged by the growing body of research on parallel agents. For example, I enjoyed reading “CodeMonkeys: Scaling Test-Time Compute for Software Engineering” by Ryan Ehrlich and others, which shows how parallel code generation helps you to explore the solution space. The mixture-of-agents architecture by Junlin Wang is a surprisingly simple way to organize parallel agents: Have multiple LLMs come up with different answers, then have an aggregator LLM combine them into the final output.\n\nThere remains a lot of research as well as engineering to explore how best to leverage parallel agents, and I believe the number of agents that can work productively in parallel — like the humans who can work productively in parallel — will be very high.\n\n[Original text, with links: https://t.co/ElcJZyzcfw ]",
  "createdAt": "Thu Aug 28 17:25:47 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 359,
  "replyCount": 115,
  "likeCount": 1849,
  "quoteCount": 38,
  "viewCount": 318804,
  "bookmarkCount": 1081,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1960731961494004077",
  "url": "https://x.com/AndrewYNg/status/1960731961494004077",
  "text": "Build better RAG by letting a team of agents extract and connect your reference materials into a knowledge graph. Our new short course, “Agentic Knowledge Graph Construction,” taught by @Neo4j Innovation Lead @akollegger, shows you how.\n\nKnowledge graphs are an important way to store information accurately but they are a lot of work to build manually.\n\nIn this course you’ll learn how to build a team of agents that turn data– in this case product reviews and invoices from suppliers–into structured graphs of entities and relationships for RAG.\n\nLearn how agents can automatically handle the time-consuming work of building graphs — extracting entities and relationships (e.g., Product \"contains\" Assembly, Part \"supplied_by\" Supplier, Customer review \"mentions\" Product), deduplicating them, fact-checking them, and committing them to a graph database — so your retrieval system can find right information to generate accurate output. For example, you can use agents to help trace customer complaints directly to specific suppliers, manufacturing processes, and product hierarchies, thus turning fragmented information into queryable business intelligence.\n\nSkills you’ll gain:\n- Build, store, and access knowledge graphs using the Neo4j graph database\n- Build multi-agent systems using Google’s Agent Development Kit (ADK)\n- Set up a loop of agentic workflows to propose and refine a graph schema through fact-checking\n- Connect agent-generated graphs of unstructured and structured data into a unified knowledge graph\n\nThis course gets into the practicum of why knowledge graphs give more accurate information retrieval than vector search alone, especially for high-stakes applications where precision matters more than fuzzy similarity matching.\n\nSign up here: https://t.co/2txZfYqGZ9",
  "createdAt": "Wed Aug 27 15:51:42 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 426,
  "replyCount": 57,
  "likeCount": 2371,
  "quoteCount": 18,
  "viewCount": 161192,
  "bookmarkCount": 2631,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1958595307929051587",
  "url": "https://x.com/AndrewYNg/status/1958595307929051587",
  "text": "The products that teams worked on at Buildathon: https://t.co/iA48xG9yU2",
  "createdAt": "Thu Aug 21 18:21:25 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 5,
  "replyCount": 4,
  "likeCount": 51,
  "quoteCount": 0,
  "viewCount": 26423,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1958595107457999073",
  "url": "https://x.com/AndrewYNg/status/1958595107457999073",
  "text": "On Saturday at the Buildathon hosted by AI Fund and https://t.co/zpIxRSuky4, over 100 developers competed to build software products quickly using AI assisted coding. I was inspired to see developers build functional products in just 1-2 hours. The best practices for rapid engineering are changing quickly along with the tools, and I loved the hallway conversations sharing tips with other developers on using AI to code!\n\nThe competitors raced to fulfill product specs like this one (you can see the full list in our github repo; link in reply): \nProject: Codebase Time Machine\nDescription: Navigate any codebase through time, understanding evolution of features and architectural decisions.\nRequirements:\n- Clone repo and analyze full git history\n- Build semantic understanding of code changes over time\n- Answer questions like “Why was this pattern introduced?” or “Show me how auth evolved”\n- Visualize code ownership and complexity trends\n- Link commits to business features/decisions\n\nTeams had 6½ hours to build 5 products. And many of them managed to do exactly that! They created fully functional applications with good UIs and sometimes embellishments.\n\nWhat excites me most isn’t just what can now be built in a few hours. Rather, it is that, if AI assistance lets us build basic but fully functional products this quickly, then imagine what can now be done in a week, or a month, or six months. If the teams that participated in the Buildathon had this velocity of execution and iterated over multiple cycles of getting customer feedback and using that to improve the product, imagine how quickly it is now possible to build great products.\n\nOwning proprietary software has long been a moat for businesses, because it has been hard to write complex software. Now, as AI assistance enables rapid engineering, this moat is weakening. \n\nWhile many members of the winning teams had computer science backgrounds — which does provide an edge — not all did. Team members who took home prizes included a high school senior, a product manager, and a healthcare entrepreneur who initially posted on Discord that he was “over his skis” as someone who “isn't a coder.” I was thrilled that multiple participants told me they exceeded their own expectations and discovered they can now build faster than they realized. If you haven’t yet pushed yourself to build quickly using agentic coding tools, you, too, might be surprised at what you can do!\n\nAt AI Fund and https://t.co/zpIxRSuky4, we pride ourselves on building and iterating quickly. At the Buildathon, I saw many teams execute quickly using a wide range of tools including Claude Code, GPT-5, Replit, Cursor, Windsurf, Trae, and many others.\n\nI offer my hearty congratulations to all the winners!\n- 1st Place: Milind Pathak, Mukul Pathak, and  Sapna Sangmitra (Team Vibe-as-a-Service), a team of three family members. They also received an award for Best Design.\n- 2nd Place: David Schuster, Massimiliano Viola, and Manvik Pasula. (Team Two Coders and a Finance Guy).\n- Solo Participant Award: Ivelina Dimova, who had just flown to San Francisco from Portugal, and who worked on the 5 projects not sequentially, but in parallel!\n- Graph Thinking Award: Divya Mahajan, Terresa Pan, and Achin Gupta (Team A-sync).\n- Honorable mentions went to finalists Alec Hewitt, Juan Martinez, Mark Watson and Sophia Tang (Team Secret Agents) and Yuanyuan Pan, Jack Lin, and Xi Huang (Team Can Kids).\n\nTo everyone who participated, thank you! Through events like these, I hope we can all learn from each other, encourage each other, invent new best practices, and spread the word about where agentic coding is taking software engineering.\n\n[Original text: https://t.co/wJbQMrnZdL ]",
  "createdAt": "Thu Aug 21 18:20:37 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 52,
  "replyCount": 41,
  "likeCount": 427,
  "quoteCount": 7,
  "viewCount": 56243,
  "bookmarkCount": 129,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1958165941369634825",
  "url": "https://x.com/AndrewYNg/status/1958165941369634825",
  "text": "AI Dev 25 is coming to NYC on November 14!\n\n1,200+ developers will dive into technical topics such as:\n- Agentic AI: Multi-agent orchestration, tool use, complex reasoning chains\n- Coding with AI: Agentic coding assistants, automated testing, debugging strategies\n- Context engineering: Advanced RAG, structured context, memory systems\n- Multimodal AI: Vision-language models, audio processing, cross-modal architectures\n- Fintech applications: Fraud detection, credit modeling, regulatory compliance\n\nOur Pi Day AI Dev event sold out quickly, so we booked a bigger venue this time. Tickets available here: https://t.co/baLDrB1EPd",
  "createdAt": "Wed Aug 20 13:55:16 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 75,
  "replyCount": 56,
  "likeCount": 477,
  "quoteCount": 6,
  "viewCount": 65646,
  "bookmarkCount": 111,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1957475040523644936",
  "url": "https://x.com/AndrewYNg/status/1957475040523644936",
  "text": "Just as many businesses are transforming to become more capable by using AI, universities are too. I recently visited the UK to receive an honorary doctorate from the University of Exeter’s Faculty of Environment, Science and Economy. @UniofExeter The name of this faculty stood out to me as a particularly forward-looking way to organize an academic division. Having Computer Science sit alongside Environmental Science and the Business School creates natural opportunities for collaboration across these fields.\n\nLeveraging AI leads a university to do things differently. Speaking with Vice Chancellor Lisa Roberts, Deputy Vice Chancellor Timothy Quine, and CS Department Head Andrew Howes, I was struck by the university leadership’s pragmatic and enthusiastic embrace of AI. This is not a group whose primary worry is whether students will cheat using AI. This is a group that is thinking about how to create a student body that is empowered through AI, whether by teaching more students to code, helping them use AI tools effectively, or showing them what’s newly possible in their disciplines.\n\nExeter is a wonderful place to create synergies between AI, environmental science, and business. It hosts 5 of the world’s top 21 most influential climate scientists according to Reuters, and its scholars are major contributors to reports by the UN’s IPCC (Intergovernmental Panel on Climate Change) as well as pioneers in numerous areas of climate research including geoengineering, which I wrote about previously. Its Centre for Environmental Intelligence, a partnership with the Met Office (the UK’s national weather service), applies AI to massive climate datasets. More work like this is needed to understand climate change and strategies for mitigation and adaptation. Add to this its Business School — named Business School of the Year by the consultancy Times Higher Education — and you have the ingredients for building applications and pursuing interdisciplinary studies that span technological, environmental, and economic realities.\n\nHaving been born in the UK and spent most of my career in Silicon Valley, I find it exciting to see Exeter’s leadership embrace AI with an enthusiasm I more often associate with California. The UK has always punched above its weight in research, and seeing that tradition continue in the AI era is encouraging.\n\nJust as every company is becoming an AI company, every university must become an AI university — not just teaching AI, but using it to advance every field of study. This doesn’t mean abandoning disciplinary expertise. It means maintaining technical excellence while ensuring AI enhances every field.\n\nLike almost all other universities and businesses worldwide, Exeter’s AI transformation is just beginning. But the enthusiastic embrace of AI by its leadership will give it momentum. As someone who is proud to be an honorary graduate of the university, I look forward to seeing what comes next!\n\n[Original text: https://t.co/Y1PyN17Qzs ]",
  "createdAt": "Mon Aug 18 16:09:52 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 99,
  "replyCount": 36,
  "likeCount": 509,
  "quoteCount": 4,
  "viewCount": 53666,
  "bookmarkCount": 32,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1955656413075919051",
  "url": "https://x.com/AndrewYNg/status/1955656413075919051",
  "text": "Buildathon: The Rapid Engineering Competition livestreams this Saturday, August 16. Top developers will compete to build 5+ products in a single day using AI coding assistants – projects that traditionally took weeks. Watch live as they advance through semifinals and finals, and see how fast software can now be built!  Register at https://t.co/3vAkmZDU4V",
  "createdAt": "Wed Aug 13 15:43:17 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 206,
  "replyCount": 57,
  "likeCount": 777,
  "quoteCount": 12,
  "viewCount": 117430,
  "bookmarkCount": 225,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1953509055584252013",
  "url": "https://x.com/AndrewYNg/status/1953509055584252013",
  "text": "Recently Meta made headlines with unprecedented, massive compensation packages for AI model builders exceeding $100M (sometimes spread over multiple years). With the company planning to spend $66B-72B this year on capital expenses such as data centers, a meaningful fraction of which will be devoted to AI, from a purely financial point of view, it’s not irrational to spend a few extra billion dollars on salaries to make sure this hardware is used well.\n\nA typical software-application startup that’s not involved in training foundation models might spend 70-80% of its dollars on salaries, 5-10% on rent, and 10-25% on other operating expenses (cloud hosting, software licenses, marketing, legal/accounting, etc.). But scaling up models is so capital-intensive, salaries are a small fraction of the overall expense. This makes it feasible for businesses in this area to pay their relatively few employees exceptionally well. If you’re spending tens of billions of dollars on GPU hardware, why not spend just a tenth of that on salaries? Even before Meta’s recent offers, salaries of AI model trainers have been high, with many being paid $5-10M/year, although Meta has raised these numbers to new heights.\n\nMeta carries out many activities, including run Facebook, Instagram, WhatsApp, and Oculus. But the Llama/AI-training part of its operations is particularly capital-intensive. Many of Meta’s properties rely on user-generated content (UGC) to attract attention, which is then monetized through advertising. AI is a huge threat and opportunity to such businesses: If AI-generated content (AIGC) substitutes for UGC to capture people's attention to sell ads against, this will transform the social-media landscape.\n\nThis is why Meta — like TikTok, YouTube, and other social-media properties — is paying close attention to AIGC, and why making significant investments in AI is rational. Further, when Meta hires a key employee, not only does it gain the future work output of that person, but it also potentially gets insight into a competitor’s technology, which also makes its willingness to pay high salaries a rational business move (so long as it does not adversely affect the company’s culture).\n\nThe pattern of capital-intensive businesses compensating employees extraordinarily well is not new. For example, Netflix expects to spend a huge $18B this year on content. This makes the salary expense of paying its 14,000 employees a small fraction of the total expense, which allows the company to routinely pay above-market salaries. Its ability to spend this way also shapes a distinctive culture that includes elements of “we’re a sports team, not a family” (which seems to work for Netflix but isn’t right for everyone). In contrast, a labor-intensive manufacturing business like Foxconn, which employs over 1 million people globally, has to be much more price-sensitive in what it pays people.\n\nEven a decade ago, when I led a team that worked to scale up AI, I built spreadsheets that modeled how much of my budget to allocate toward salaries and how much to allocate toward GPUs (using a custom model for how much productive output N employees and M GPUs would lead to, so I could optimize N and M subject to my budget constraint). Since then, the business of scaling up AI has skewed the spending significantly toward GPUs.\n\nI’m happy for the individuals who are getting large pay packages. And regardless of any individual's pay, I’m grateful for the contributions of everyone working in AI. Everyone in AI deserves a good salary, and while the gaps in compensation are growing, I believe this reflects the broader phenomenon that developers who work in AI, at this moment in history, have an opportunity to make a huge impact and do world-changing work.\n\n[Original text: https://t.co/5wQe7foww8 ]",
  "createdAt": "Thu Aug 07 17:30:27 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 490,
  "replyCount": 109,
  "likeCount": 3743,
  "quoteCount": 46,
  "viewCount": 478698,
  "bookmarkCount": 1760,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1953097967361245251",
  "url": "https://x.com/AndrewYNg/status/1953097967361245251",
  "text": "I'm thrilled to announce the definitive course on Claude Code, created with @AnthropicAI and taught by Elie Schoppik @eschoppik. If you want to use highly agentic coding - where AI works autonomously for many minutes or longer, not just completing code snippets - this is it.\n\nClaude Code has been a game-changer for many developers (including me!), but there's real depth to using it well. This comprehensive course covers everything from fundamentals to advanced patterns.\n\nAfter this short course, you'll be able to:\n- Orchestrate multiple Claude subagents to work on different parts of your codebase simultaneously\n- Tag Claude in GitHub issues and have it autonomously create, review, and merge pull requests\n- Transform messy Jupyter notebooks into clean, production-ready dashboards\n- Use MCP tools like Playwright so Claude can see what's wrong with your UI and fix it autonomously\n\nWhether you're new to Claude Code or already using it, you'll discover powerful capabilities that can fundamentally change how you build software.\n\nI'm very excited about what agentic coding lets everyone now do. Please take this course!\n\nhttps://t.co/HGM8ArDalK",
  "createdAt": "Wed Aug 06 14:16:56 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1022,
  "replyCount": 137,
  "likeCount": 6791,
  "quoteCount": 105,
  "viewCount": 747408,
  "bookmarkCount": 8523,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1952838045235126510",
  "url": "https://x.com/AndrewYNg/status/1952838045235126510",
  "text": "I'm thrilled @OpenAI has released two open weight models. Thank you to all my friends at OpenAI for this gift! I'm also encouraged that from my quick tests gpt-oss-120b looks strong (though we should still wait for rigorous 3rd party evals).",
  "createdAt": "Tue Aug 05 21:04:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 369,
  "replyCount": 74,
  "likeCount": 2696,
  "quoteCount": 11,
  "viewCount": 179472,
  "bookmarkCount": 173,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1950941108000964654",
  "url": "https://x.com/AndrewYNg/status/1950941108000964654",
  "text": "There is now a path for China to surpass the U.S. in AI. Even though the U.S. is still ahead, China has tremendous momentum with its vibrant open-weights model ecosystem and aggressive moves in semiconductor design and manufacturing. In the startup world, we know momentum matters: Even if a company is small today, a high rate of growth compounded for a few years quickly becomes an unstoppable force. This is why a small, scrappy team with high growth can threaten even behemoths. While both the U.S. and China are behemoths, China’s hypercompetitive business landscape and rapid diffusion of knowledge give it tremendous momentum. The White House’s AI Action Plan released last week, which explicitly champions open source (among other things), is a very positive step for the U.S., but by itself it won’t be sufficient to sustain the U.S. lead.\n\nNow, AI isn’t a single, monolithic technology, and different countries are ahead in different areas. For example, even before Generative AI, the U.S. had long been ahead in scaled cloud AI implementations, while China has long been ahead in surveillance technology. These translate to different advantages in economic growth as well as both soft and hard power. Even though nontechnical pundits talk about “the race to AGI” as if AGI were a discrete technology to be invented, the reality is that AI technology will progress continuously, and there is no single finish line. If a company or nation declares that it has achieved AGI, I expect that declaration to be less a technology milestone than a marketing milestone. A slight speed advantage in the Olympic 100m dash translates to a dramatic difference between winning a gold medal versus a silver medal. An advantage in AI prowess translates into a proportionate advantage in economic growth and national power; while the impact won’t be a binary one of either winning or losing everything, these advantages nonetheless matter.\n\nLooking at Artificial Analysis and LMArena leaderboards, the top proprietary models were developed in the U.S., but the top open models come from China. Google’s Gemini 2.5 Pro, OpenAI’s o4, Anthropic’s Claude 4 Opus, and Grok 4 are all strong models. But open alternatives from China such as DeepSeek R1-0528, Kimi K2 (designed for agentic reasoning), Qwen3 variations (including Qwen3-Coder, which is strong at coding) and Zhipu’s GLM 4.5 (whose post-training software was released as open source) are close behind, and many are ahead of Meta’s Llama 4 and Google’s Gemma 3 — the U.S.’ best open-weights offerings.\n\nBecause many U.S. companies have taken a secretive approach to developing foundation models — a reasonable business strategy — the leading companies spend huge numbers of dollars to recruit key team members from each other who might know the “secret sauce“ that enabled a competitor to develop certain capabilities. So knowledge does circulate, but at high cost and slowly. In contrast, in China’s open AI ecosystem, many advanced foundation model companies undercut each other on pricing, make bold PR announcements, and poach each others’ employees and customers. This Darwinian life-or-death struggle will lead to the demise of many of the existing players, but the intense competition breeds strong companies.\n\nIn semiconductors, too, China is making progress. Huawei’s CloudMatrix 384 aims to compete with Nvidia’s GB200 high-performance computing system. While China has struggled to develop GPUs with a similar capability as Nvidia’s top-of-the-line B200, Huawei is trying to build a competitive system by combining a larger number (384 instead of 72) of lower-capability chips. China’s automotive sector once struggled to compete with U.S. and European internal combustion engine vehicles, but leapfrogged ahead by betting on electric vehicles. It remains to be seen how effective Huawei’s alternative architectures prove to be, but the U.S. export restrictions have given Huawei and other Chinese businesses a strong incentive to invest heavily in developing their own technology. Further, if China were to develop its domestic semiconductor manufacturing capabilities while the U.S. remained reliant on TSMC in Taiwan, then the U.S.’ AI roadmap would be much more vulnerable to a disruption of the Taiwan supply chain (perhaps due to a blockade or, worse, a hot war).\n\nWith the rise of electricity, the internet, and other general-purpose technologies, there was room for many nations to benefit, and the benefit to one nation hasn’t come at the expense of another. I know of businesses that, many months back, planned for a future in which China dominates open models (indeed, we are there at this moment, although the future depends on our actions). Given the transformative impact of AI, I hope all nations — especially democracies with a strong respect for human rights and the rule of law — will clear roadblocks from AI progress and invest in open science and technology to increase the odds that this technology will support democracy and benefit the greatest possible number of people.\n\n[Full text: https://t.co/jn0KNi3gmA ]",
  "createdAt": "Thu Jul 31 15:26:21 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1082,
  "replyCount": 253,
  "likeCount": 4284,
  "quoteCount": 156,
  "viewCount": 629438,
  "bookmarkCount": 1648,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1948032883664519244",
  "url": "https://x.com/AndrewYNg/status/1948032883664519244",
  "text": "Announcing our new event - Buildathon: The Rapid Engineering Competition. See the video for details, and please apply to participate!",
  "createdAt": "Wed Jul 23 14:50:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 524,
  "replyCount": 61,
  "likeCount": 1403,
  "quoteCount": 14,
  "viewCount": 96578,
  "bookmarkCount": 427,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1947308544916889979",
  "url": "https://x.com/AndrewYNg/status/1947308544916889979",
  "text": "The invention of modern writing instruments like the typewriter made writing easier, but they also led to the rise of writer’s block, where deciding what to write became the bottleneck. Similarly, the invention of agentic coding assistants has led to a new builder’s block, where the holdup is deciding what to build. I call this the Product Management Bottleneck.\n\nProduct management is the art and science of deciding what to build. Because highly agentic coding accelerates the writing of software to a given product specification, deciding what to build is the new bottleneck, especially in early-stage projects. As the teams I work with take advantage of agentic coders, I increasingly value product managers (PMs) who have very high user empathy and can make product decisions quickly, so the speed of product decision-making matches the speed of coding.\n\nPMs with high user empathy can make decisions by gut and get them right a lot of the time. As new information comes in, they can keep refining their mental models of what users like or do not like — and thereby refine their gut — and keep making fast decisions of increasing quality.\n\nMany tactics are available to get user feedback and other forms of data that shape our beliefs about users. They include  conversations with a handful of users, focus groups, surveys, and A/B tests on scaled products. But to drive progress at GenAI speed, I find that synthesizing all these sources of data in a PM's gut helps us move faster.\n\nLet me illustrate with an example. Recently, my team debated which of 4 features users would prefer. I had my instincts, but none of us were sure, so we surveyed about 1,000 users. The results contradicted my initial beliefs — I was wrong! So what was the right thing to do at this point?\n- Option 1: Go by the survey and build what users told us clearly they prefer.\n- Option 2: Examine the survey data in detail to see how it changes my beliefs about what users want. That is, refine my mental model of users. Then use my revised mental model to decide what to do.\n\nEven though some would consider Option 1 the “data-driven” way to make decisions, I consider this an inferior approach for most projects. Surveys may be flawed. Further, taking time to run a survey before making a decision results in slow decision-making.\n\nIn contrast, using Option 2, the survey results give much more generalizable information that can help me shape not just this decision, but many others as well. And it lets me process this one piece of data alongside all the user conversations, surveys, market reports, and observations of user behavior when they’re engaging with our product to form a much fuller view on how to serve users. Ultimately, that mental model drives my product decisions.\n\nOf course, this technique does not always scale. For example, with programmatic online advertising in which AI might try to optimize the number of clicks on ads shown, an automated system conducts far more experiments in parallel and gathers data on what users do and do not click on, to filter through a PM's mental model of users. When a system needs to make a huge number of decisions, such as what ads to show (or products to recommend) on a huge number of pages, PM review and human intuition do not scale.\n\nBut in products where a team is making a small number of critical decisions such as what key features to prioritize, I find that data — used to help build a good mental model of the user, which is then applied to make decisions very quickly — is still the best way to drive rapid progress and relieve the Product Management Bottleneck.\n\n[Original text: https://t.co/1tulDs3k7U ]",
  "createdAt": "Mon Jul 21 14:51:51 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 287,
  "replyCount": 74,
  "likeCount": 1233,
  "quoteCount": 28,
  "viewCount": 341746,
  "bookmarkCount": 698,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1945502636012445937",
  "url": "https://x.com/AndrewYNg/status/1945502636012445937",
  "text": "Announcing a new Coursera course: Retrieval Augmented Generation (RAG)\n\nYou'll learn to build high performance, production-ready RAG systems in this hands-on, in-depth course created by https://t.co/zpIxRSuky4 and taught by @ZainHasan6, experienced AI and ML engineer, researcher, and educator. \n\nRAG is a critical component today of many LLM-based applications in customer support, internal company Q&A systems, even many of the leading chatbots that use web search to answer your questions. This course teaches you in-depth how to make RAG work well.\n\nLLMs can produce generic or outdated responses, especially when asked specialized questions not covered in its training data. RAG is the most widely used technique for addressing this. It brings in data from new data sources, such as internal documents or recent news, to give the LLM the relevant context to private, recent, or specialized information. This lets it generate more grounded and accurate responses.\n\nIn this course, you’ll learn to design and implement every part of a RAG system, from retrievers to vector databases to generation to evals. You’ll learn about the fundamental principles behind RAG and how to optimize it at both the component and whole-system levels.\n\nAs AI evolves, RAG is evolving too. New models can handle longer context windows, reason more effectively, and can be parts of complex agentic workflows. One exciting growth area is Agentic RAG, in which an AI agent at runtime (rather than it being hardcoded at development time) autonomously decides what data to retrieve, and when/how to go deeper. Even with this evolution, access to high-quality data at runtime is essential, which is why RAG is a key part of so many applications.\n\nYou'll learn via hands-on experiences to:\n- Build a RAG system with retrieval and prompt augmentation\n- Compare retrieval methods like BM25, semantic search, and Reciprocal Rank Fusion\n- Chunk, index, and retrieve documents using a Weaviate vector database and a news dataset\n- Develop a chatbot, using open-source LLMs hosted by Together AI, for a fictional store that answers product and FAQ questions\n- Use evals to drive improving reliability, and incorporate multi-modal data\n\nRAG is an important foundational technique. Become good at it through this course!\n\nPlease sign up here: https://t.co/81DSVlDEOW",
  "createdAt": "Wed Jul 16 15:15:48 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 329,
  "replyCount": 63,
  "likeCount": 1676,
  "quoteCount": 14,
  "viewCount": 121427,
  "bookmarkCount": 1428,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1945148766962729370",
  "url": "https://x.com/AndrewYNg/status/1945148766962729370",
  "text": "Announcing AI Aspire, our new advisory firm to help enterprises with their AI strategy and transformation journey! We are partnering with Bain & Company and looking forward to helping businesses unlock scalable, transformative value.\n\nC-suite is now realizing that top-down leadership is needed for AI transformation. But figuring out the implications of AI on a particular business is extremely complex. The Bain team is world class at helping businesses craft strategy and navigate complex landscapes. Kirsty Tan (at AI Aspire) and I are thrilled to be working with Bain's Chuck Whitten, Sarah Elk, Erika Serow and team to help businesses.\n\nQuestions that C-suite and boards are now asking include:\n- What new products are now possible? What can we (or our competitors) now do for customers that were not possible before?\n- How do we use AI to boost productivity? What workflows can be streamlined or processes reinvented?\n- What technology investments, for example in data infrastructure, should now be prioritized? And what are the risks, for example to security and compliance?\n- What are the HR implications: What roles do we hire more or fewer of?\n- How do we bring the team with us for the journey, and enable transformation from within?\n- Does AI enable new competitors; or alternatively, are there now new markets that are possible for us to move into?\n\nTechnology is no longer merely a support system for business — it is  engine of growth for the companies nimble enough to adapt and daring enough to lead.\n\nPress release: https://t.co/cjYX3yoWEn",
  "createdAt": "Tue Jul 15 15:49:39 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 161,
  "replyCount": 66,
  "likeCount": 878,
  "quoteCount": 9,
  "viewCount": 122038,
  "bookmarkCount": 462,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1943710282381180934",
  "url": "https://x.com/AndrewYNg/status/1943710282381180934",
  "text": "Last week, the United States Congress passed President Trump’s “Big Beautiful Bill.” I’m disappointed it didn’t include a proposed moratorium on U.S. state-level AI regulation. While there is a role for AI regulation, it is when the technology is new and poorly understood that lobbyists are most likely to succeed at pushing through anti-competitive regulations that hamper open-source and other beneficial AI efforts. A moratorium would have bought more time for regulators to figure out the realistic risks and rewards of AI and thereby avoid bad regulatory proposals.\n\nMany jurisdictions loosely follow this trajectory:\n- When new AI technology is still poorly understood, companies can make grandiose statements about its benefits or dangers, and both traditional and social media are ineffective at fact-checking them and tend to parrot what they say. During this initial period, businesses can get away with saying almost anything.\n- This opens opportunities for hype as well as fear mongering based on exaggerated claims about AI dangers. Some businesses exploit this opportunity to try to get regulators to pass anti-competitive laws that impede open-source and other competitors.\n- But eventually, smart regulators learn enough about AI to understand its realistic benefits and risks. For example, the U.S. Senate’s bipartisan Insight Forum on AI, which I participated in, heard from many stakeholders and came to support innovation and dismiss ill-founded fears of “AI takeover” and the like.\n\nIndeed, the European Union went through this trajectory as well. After the EU AI Act was passed, many regulators realized many of its “protections” are not actually helpful. They relaxed some of the law’s provisions to make it less stifling of innovation than many observers initially had feared.\n\nThere are AI regulations that would limit harmful applications appropriately, for example, banning non-consensual deepfake porn and preventing misleading marketing. However, many states, which have less resources than the federal government to deeply understand AI, have proposed harmful regulations, especially those that aim to regulate the technology rather than the applications.\n\nFor example:\n- California’s SB 1047 purported to impose safety requirements on frontier AI systems, but it placed ambiguous and/or technically infeasible requirements on model creators to prevent harmful downstream uses. This is akin to holding the maker of a hammer liable if someone uses it for harmful purposes. Fortunately, Governor Gavin Newsom quashed SB 1047 with a veto.\n- New York’s Responsible AI Safety and Education Act, which passed the state legislature in June and awaits Governor Kathy Hochul’s signature or veto, also places ambiguous and unreasonable requirements on model builders, purportedly to guard against theoretical “critical harms.” It would hamper open source without making anyone meaningfully safer.\n- The Texas Responsible AI Governance Act initially included many of the problematic elements of SB 1047. It would have created unreasonable requirements that model providers would have had a hard time complying with, and compliance would have amounted to safety theater that was unlikely to actually make people safer. Fortunately, as Texas regulators came to understand AI better, they significantly scaled back the law, and Governor Greg Abbott signed it into law in late June. The final law focuses on specific application areas, establishes an advisory council and regulatory sandbox, and places more burden on government agencies than private companies.\n\nSadly, I see the net impact of the regulations proposed so far as negative. Many would severely hamper innovation despite some lesser positive benefits. This is why a moratorium on state-level regulation would have been a net benefit to AI and to society. Shutting down bad regulations for a limited period would have given regulators time to figure out AI technology and ignore irresponsible fear mongering. In addition, it would have helped them avoid creating a patchwork of state-level regulations that businesses large and small have a hard time complying with.\n\nPerhaps a 10-year blanket moratorium was a step too far. A more modest, say, 2-year moratorium, and one that covered only the most problematic regulatory proposals, might have had a better chance of passing.\n\nEven though a moratorium did not make it into Trump’s bill, I hope that efforts continue in the U.S. and other nations to give regulators time to understand the real risks and benefits of AI, and not pass stifling regulations during that initial period when the technology is new and the power of fear mongering is strongest.\n\n[Original text: https://t.co/56ZkPD9ta5 ]",
  "createdAt": "Fri Jul 11 16:33:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 72,
  "replyCount": 39,
  "likeCount": 332,
  "quoteCount": 10,
  "viewCount": 67932,
  "bookmarkCount": 72,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1943385392469962846",
  "url": "https://x.com/AndrewYNg/status/1943385392469962846",
  "text": "My talk at YC Startup School on how to build AI startups. I share tips from @AI_Fund on how to use AI to build fast. Let me know what you think!",
  "createdAt": "Thu Jul 10 19:02:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 323,
  "replyCount": 53,
  "likeCount": 1471,
  "quoteCount": 11,
  "viewCount": 178548,
  "bookmarkCount": 1153,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1943319708859834499",
  "url": "https://x.com/AndrewYNg/status/1943319708859834499",
  "text": "Agentic Document Extraction now supports field extraction! Many doc extraction use cases extract specific fields from forms and other structured documents. You can now input a picture or PDF of an invoice, request the vendor name, item list, and prices, and get back the extracted fields. Or input a medical form and specify a schema to extract patient name, patient ID, insurance number, etc. \n\nOne cool feature: If you don't feel like writing a schema (json specification of what fields to extract) yourself, upload one sample document and write a natural language prompt saying what you want, and we automatically generate a schema for you.\n\nSee the video for details!",
  "createdAt": "Thu Jul 10 14:41:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 361,
  "replyCount": 67,
  "likeCount": 2277,
  "quoteCount": 18,
  "viewCount": 190568,
  "bookmarkCount": 2055,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1942952817049915596",
  "url": "https://x.com/AndrewYNg/status/1942952817049915596",
  "text": "New Course: Post-training of LLMs\n\nLearn to post-train and customize an LLM in this short course, taught by @BanghuaZ, Assistant Professor at  the University of Washington @UW, and co-founder of @NexusflowX.\n\nTraining an LLM to follow instructions or answer questions has two key stages: pre-training and post-training. In pre-training, it learns to predict the next word or token from large amounts of unlabeled text. In post-training, it learns useful behaviors such as following instructions, tool use, and reasoning.\n\nPost-training transforms a general-purpose token predictor—trained on trillions of unlabeled text tokens—into an assistant that follows instructions and performs specific tasks. Because it is much cheaper than pre-training, it is practical for many more teams to incorporate post-training methods into their workflows than pre-training.\n\nIn this course, you’ll learn three common post-training methods—Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Online Reinforcement Learning (RL)—and how to use each one effectively. With SFT, you train the model on pairs of input and ideal output responses. With DPO, you provide both a preferred (chosen) and a less preferred (rejected) response and train the model to favor the preferred output. With RL, the model generates an output, receives a reward score based on human or automated feedback, and updates the model to improve performance.\n\nYou’ll learn the basic concepts, common use cases, and principles for curating high-quality data for effective training. Through hands-on labs, you’ll download a pre-trained model from Hugging Face and post-train it using SFT, DPO, and RL to see how each technique shapes model behavior.\n\nIn detail, you’ll:\n- Understand what post-training is, when to use it, and how it differs from pre-training.\n- Build an SFT pipeline to turn a base model into an instruct model.\n- Explore how DPO reshapes behavior by minimizing contrastive loss—penalizing poor responses and reinforcing preferred ones.\n- Implement a DPO pipeline to change the identity of a chat assistant.\n- Learn online RL methods such as Proximal Policy Optimization (PPO) and Group Relative Policy Optimization (GRPO), and how to design reward functions.\n- Train a model with GRPO to improve its math capabilities using a verifiable reward.\n\nPost-training is one of the most rapidly developing areas of LLM training. Whether you’re building a high-accuracy context-specific assistant, fine-tuning a model's tone, or improving task-specific accuracy, this course will give you experience with the most important techniques shaping how LLMs are post-trained today.\n\nPlease sign up here: https://t.co/efSt2FnVNS",
  "createdAt": "Wed Jul 09 14:23:44 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 329,
  "replyCount": 38,
  "likeCount": 1488,
  "quoteCount": 10,
  "viewCount": 122792,
  "bookmarkCount": 1185,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1940864335083196819",
  "url": "https://x.com/AndrewYNg/status/1940864335083196819",
  "text": "I’d like to share a tip for getting more practice building with AI — that is, either using AI building blocks to build applications or using AI coding assistance to create powerful applications quickly: If you find yourself with only limited time to build, reduce the scope of your project until you can build something in whatever time you do have.\n\nIf you have only an hour, find a small component of an idea that you're excited about that you can build in an hour. With modern coding assistants like Anthropic’s Claude Code (my favorite dev tool right now), you might be surprised at how much you can do even in short periods of time! This gets you going, and you can always continue the project later.\n\nTo become good at building with AI, most people must (i) learn relevant techniques, for example by taking online AI courses, and (ii) practice building. I know developers who noodle on ideas for months without actually building anything — I’ve done this too! — because we feel we don’t have time to get started. If you find yourself in this position, I encourage you to keep cutting the initial project scope until you identify a small component you can build right away.\n\nLet me illustrate with an example — one of my many small, fun weekend projects that might never go anywhere, but that I’m glad I did.\n\nHere’s the idea: Many people fear public speaking. And public speaking is challenging to practice, because it's hard to organize an audience. So I thought it would be interesting to build an audience simulator to provide a digital audience of dozens to hundreds of virtual people on a computer monitor and let a user practice by speaking to them.\n\nOne Saturday afternoon, I found myself in a coffee shop with a couple of hours to spare and decided to give the audience simulator a shot. My familiarity with graphics coding is limited, so instead of building a complex simulator of a large audience and writing AI software to simulate appropriate audience responses, I decided to cut scope significantly to (a) simulating an audience of one person (which I could replicate later to simulate N persons), (b) omitting AI and letting a human operator manually select the reaction of the simulated audience (similar to Wizard of Oz prototyping), and (c) implementing the graphics using a simple 2D avatar.\n\nUsing a mix of several coding assistants, I built a basic version in the time I had. The avatar could move subtly and blink, but otherwise it used basic graphics. Even though it fell far short of a sophisticated audience simulator, I am glad I built this. In addition to moving the project forward and letting me explore different designs, it advanced my knowledge of basic graphics. Further, having this crude prototype to show friends helped me get user feedback that shaped my views on the product idea.\n\nI have on my laptop a list of ideas of things that I think would be interesting to build. Most of them would take much longer than the handful of hours I might have to try something on a given day, but by cutting their scope, I can get going, and the initial progress on a project helps me decide if it’s worth further investment. As a bonus, hacking on a wide variety of applications helps me practice a wide range of skills. But most importantly, this gets an idea out of my head and potentially in front of prospective users for feedback that lets the project move faster.\n\n[Original text: https://t.co/UP6arTWAdV ]",
  "createdAt": "Thu Jul 03 20:04:51 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 484,
  "replyCount": 76,
  "likeCount": 1650,
  "quoteCount": 32,
  "viewCount": 321412,
  "bookmarkCount": 1316,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1938265468986659075",
  "url": "https://x.com/AndrewYNg/status/1938265468986659075",
  "text": "On Monday, a United States District Court ruled that training LLMs on copyrighted books constitutes fair use. A number of authors had filed suit against Anthropic for training its models on their books without permission. Just as we allow people to read books and learn from them to become better writers, but not to regurgitate copyrighted text verbatim, the judge concluded that it is fair use for AI models to do so as well.\n\nIndeed, Judge Alsup wrote that the authors’ lawsuit is “no different than it would be if they complained that training schoolchildren to write well would result in an explosion of competing works.” While it remains to be seen whether the decision will be appealed, this ruling is reasonable and will be good for AI progress. (Usual caveat: I am not a lawyer and am not giving legal advice.)\n\nAI has massive momentum, but a few things could put progress at risk:\n- Regulatory capture that stifles innovation, including especially open source\n- Loss of access to cutting-edge semiconductor chips (the most likely cause would be war breaking out in Taiwan)\n- Regulations that severely impede access to data for training AI systems\n\nAccess to high-quality data is important. Even though the mass media tends to talk about the importance of building large data centers and scaling up models, when I speak with friends at companies that train foundation models, many describe a very large amount of their daily challenges as data preparation. Specifically, a significant fraction of their day-to-day work follows the usual Data Centric AI practices of identifying high-quality data (books are one important source), cleaning data (the ruling describes Anthropic taking steps like removing book pages' headers, footers, and page numbers), carrying out error analyses to figure out what types of data to acquire more of, and inventing new ways to generate synthetic data.\n\nI am glad that a major risk to data access just decreased. Appropriately, the ruling further said that Anthropic’s conversion of books from paper format to digital — a step that’s needed to enable training — also was fair use. However, in a loss for Anthropic, the judge indicated that, while training on data that was acquired legitimately is fine, using pirated materials (such as  texts downloaded from pirate websites) is not fair use. Thus, Anthropic still may be liable on this point. Other LLM providers, too, will now likely have to revisit their practices if they use datasets that may contain pirated works.\n\nOverall, the ruling is positive for AI progress. Perhaps the biggest benefit is that it reduces ambiguity with respect to AI training and copyright and (if it stands up to appeals) makes the roadmap for compliance clearer. This decision indicates it is okay to train on legitimately acquired data to build models that generate transformational outputs, and to convert printed books to digital format for this purpose. However, downloading from pirate sites (as well as permanently building a “general purpose” library of texts, stored indefinitely for purposes to be determined, without permission from the relevant copyright holders) are not considered fair use.\n\nI am very sympathetic with the many writers who are worried about their livelihoods being affected by AI. I don‘t know the right solution for that. Society is better off with free access to more data; but if a subset of people is significantly negatively affected, I hope we can figure out an arrangement that compensates them fairly.\n\n[Original text: https://t.co/kxcCgL4tpH ]",
  "createdAt": "Thu Jun 26 15:57:53 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 374,
  "replyCount": 121,
  "likeCount": 1221,
  "quoteCount": 54,
  "viewCount": 158103,
  "bookmarkCount": 341,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1937907934094360582",
  "url": "https://x.com/AndrewYNg/status/1937907934094360582",
  "text": "New Course: ACP: Agent Communication Protocol\n\nLearn to build agents that communicate and collaborate across different frameworks using ACP in this short course built with @IBMResearch's BeeAI, and taught by @sandi_besen, AI Research Engineer & Ecosystem Lead at IBM, and @nicholasrenotte, Head of AI Developer Advocacy at IBM.\n\nBuilding a multi-agent system with agents built or used by different teams and organizations can become challenging. You may need to write custom integrations each time a team updates their agent design or changes their choice of agentic orchestration framework.\n\nThe Agent Communication Protocol (ACP) is an open protocol that addresses this challenge by standardizing how agents communicate, using a unified RESTful interface that works across frameworks. In this protocol, you host an agent inside an ACP server, which handles requests from an ACP client and passes them to the appropriate agent. Using a standardized client-server interface allows multiple teams to reuse agents across projects. It also makes it easier to switch between frameworks, replace an agent with a new version, or update a multi-agent system without refactoring the entire system.\n\nIn this course, you’ll learn to connect agents through ACP. You’ll understand the lifecycle of an ACP Agent and how it compares to other protocols, such as MCP (Model Context Protocol) and A2A (Agent-to-Agent). You’ll build ACP-compliant agents and implement both sequential and hierarchical workflows of multiple agents collaborating using ACP.\n\nThrough hands-on exercises, you’ll build:\n- A RAG agent with CrewAI and wrap it inside an ACP server.\n- An ACP Client to make calls to the ACP server you created.\n- A sequential workflow that chains an ACP server, created with Smolagents, to the RAG agent.\n- A hierarchical workflow using a router agent that transforms user queries into tasks, delegated to agents available through ACP servers.\n- An agent that uses MCP to access tools and ACP to communicate with other agents.\n\nYou’ll finish up by importing your ACP agents into the BeeAI platform, an open-source registry for discovering and sharing agents.\n\nACP enables collaboration between agents across teams and organizations. By the end of this course, you’ll be able to build ACP agents and workflows that communicate and collaborate regardless of framework.\n\nPlease sign up here: https://t.co/csyHrswJuB",
  "createdAt": "Wed Jun 25 16:17:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 362,
  "replyCount": 52,
  "likeCount": 1547,
  "quoteCount": 17,
  "viewCount": 102818,
  "bookmarkCount": 949,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1935741989204770837",
  "url": "https://x.com/AndrewYNg/status/1935741989204770837",
  "text": "One of the most effective things the U.S. or any other nation can do to ensure its competitiveness in AI is to welcome high-skilled immigration and international students who have the potential to become high-skilled. For centuries, the U.S. has welcomed immigrants, and this helped make it a worldwide leader in technology. Letting immigrants and native-born Americans collaborate makes everyone better off. Reversing this stance would have a huge negative impact on U.S. technology development.\n\nI was born in the UK and came to the U.S. on an F-1 student visa as a relatively unskilled and clueless teenager to attend college. Fortunately I gained skills and became less clueless over time. After completing my graduate studies, I started working at Stanford under the OPT (Optional Practical Training) program, and later an H-1B visa, and ended up staying here. Many other immigrants have followed similar paths to contribute to the U.S.\n\nI am very concerned that making visas harder to obtain for students and high-skilled workers, such as the pause in new visa interviews that started last month and a newly chaotic process of visa cancellations, will hurt our ability to attract great students and workers. In addition, many international students without substantial means count on being able to work under OPT to pay off the high cost of a U.S. college degree. Gutting the OPT program, as has been proposed, would both hurt many international students’ ability to study here and deprive U.S. businesses of great talent. (This won’t stop students from wealthy families. But the U.S. should try to attract the best talent without regard to wealth.)\n\nFailure to attract promising students and high-skilled workers would have a huge negative impact on American competitiveness in AI. Indeed, a recent report by the National Security Commission on Artificial Intelligence exhorts the government to “strengthen AI talent through immigration.”\n\nIf talented people do not come to the U.S., will they have an equal impact on global AI development just working somewhere else? Unfortunately, the net impact will be negative. The U.S. has a number of tech hubs including Silicon Valley, Seattle, New York, Boston/Cambridge, Los Angeles, Pittsburgh and Austin, and these hubs concentrate talent and foster innovation. (This is why cities, where people can more easily find each other and collaborate, promote innovation.) Making it harder for AI talent to find each other and collaborate will slow down innovation, and it will take time for new hubs to become as advanced.\n\nNonetheless, other nations are working hard to attract immigrants who can drive innovation — a good move for them! Many have thoughtful programs to attract AI and other talent. There are the UK’s Global Talent Visa, France’s French Tech Visa, Australia’s Global Talent Visa, the UAE’s Golden Visa, Taiwan’s Employment Gold Card, China’s Thousand Talents Plan, and many more. The U.S. is fortunate that many people already want to come here to study and work. Squandering that advantage would be a huge unforced error.\n\nBeyond the matter of national competitiveness, there is the even more important ethical matter of making sure people are treated decently. I have spoken with international students who are terrified that their visas may be canceled arbitrarily. One recently agonized about whether to attend an international conference to present a research paper, because they were worried about being unable to return. In the end, with great sadness, they cancelled their trip. I also spoke with a highly skilled technologist who is in the U.S. on an H-1B visa. Their company shut down, leading them — after over a decade in this country, and with few ties to their nation of origin — scrambling to find alternative employment that would enable them to stay. \n\nThese stories, and many far worse, are heartbreaking. While I do what I can to help individuals I know personally, it is tragic that we are creating such an uncertain environment for immigrants, that many people who have extraordinary skills and talents will no longer want to come here.\n\nTo every immigrant or migrant in the U.S. who is concerned about the current national environment: I see you and empathize with your worries. As an immigrant myself, I will be fighting to protect everyone’s dignity and right to due process, and to encourage legal immigration, which makes both the U.S. and individuals much better off.\n\n[Full text, with links: https://t.co/6JNJz88Qyq ]",
  "createdAt": "Thu Jun 19 16:50:29 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 396,
  "replyCount": 307,
  "likeCount": 2167,
  "quoteCount": 69,
  "viewCount": 520932,
  "bookmarkCount": 316,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1935350552692658202",
  "url": "https://x.com/AndrewYNg/status/1935350552692658202",
  "text": "Introducing \"Building with Llama 4.\" This short course is created with @Meta @AIatMeta, and taught by  @asangani7, Director of Partner Engineering for Meta’s AI team.\n\nMeta’s new Llama 4 has added three new models and introduced the Mixture-of-Experts (MoE) architecture to its family of open-weight models, making them more efficient to serve. \n\nIn this course, you’ll work with two of the three new models introduced in Llama 4. First is Maverick, a 400B  parameter model, with 128 experts and 17B active parameters. Second is Scout, a 109B parameter model with 16 experts and 17B active parameters. Maverick and Scout support long context windows of up to a million tokens and 10M tokens, respectively. The latter is enough to support directly inputting even fairly large GitHub repos for analysis!\n\nIn hands-on lessons, you’ll build apps using Llama 4’s new multimodal capabilities including reasoning across multiple images and image grounding, in which you can identify elements in images. You’ll also use the official Llama API, work with Llama 4’s long-context abilities, and learn about Llama’s newest open-source tools: its prompt optimization tool that automatically improves system prompts and synthetic data kit that generates high-quality datasets for fine-tuning.\n\nIf you need an open model, Llama is a great option, and the Llama 4 family is an important part of any GenAI developer's toolkit. Through this course, you’ll learn to call Llama 4 via API, use its optimization tools, and build features that span text, images, and large context.\n\nPlease sign up here: https://t.co/oRFRi9vQNg",
  "createdAt": "Wed Jun 18 14:55:03 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 250,
  "replyCount": 34,
  "likeCount": 886,
  "quoteCount": 3,
  "viewCount": 66483,
  "bookmarkCount": 464,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1933185193059516442",
  "url": "https://x.com/AndrewYNg/status/1933185193059516442",
  "text": "There’s a new breed of GenAI Application Engineers who can build more-powerful applications faster than was possible before, thanks to generative AI. Individuals who can play this role are highly sought-after by businesses, but the job description is still coming into focus. Let me describe their key skills, as well as the sorts of interview questions I use to identify them.\n\nSkilled GenAI Application Engineers meet two primary criteria: (i) They are able to use the new AI building blocks to quickly build powerful applications. (ii) They are able to use AI assistance to carry out rapid engineering, building software systems in dramatically less time than was possible before. In addition, good product/design instincts are a significant bonus.\n\nAI building blocks. If you own a lot of copies of only a single type of Lego brick, you might be able to build some basic structures. But if you own many types of bricks, you can combine them rapidly to form complex, functional structures. Software frameworks, SDKs, and other such tools are like that. If all you know is how to call a large language model (LLM) API, that's a great start. But if you have a broad range of building block types — such as prompting techniques, agentic frameworks, evals, guardrails, RAG, voice stack, async programming, data extraction, embeddings/vectorDBs, model fine tuning, graphDB usage with LLMs, agentic browser/computer use, MCP, reasoning models, and so on — then you can create much richer combinations of building blocks.\n\nThe number of powerful AI building blocks continues to grow rapidly. But as open-source contributors and businesses make more building blocks available, staying on top of what is available helps you keep on expanding what you can build. Even though new building blocks are created, many building blocks from 1 to 2 years ago (such as eval techniques or frameworks for using vectorDBs) are still very relevant today.\n\nAI-assisted coding. AI-assisted coding tools enable developers to be far more productive, and such tools are advancing rapidly. Github Copilot, first announced in 2021 (and made widely available in 2022), pioneered modern code autocompletion. But shortly after, a new breed of AI-enabled IDEs such as Cursor and Windsurf offered much better code-QA and code generation. As LLMs improved, these AI-assisted coding tools that were built on them improved as well.\n\nNow we have highly agentic coding assistants such as OpenAI’s Codex and Anthropic’s Claude Code (which I really enjoy using and find impressive in its ability to write code, test, and debug autonomously for many iterations). In the hands of skilled engineers — who don’t just “vibe code” but deeply understand AI and software architecture fundamentals and can steer a system toward a thoughtfully selected product goal — these tools make it possible to build software with unmatched speed and efficiency.\n\nI find that AI-assisted coding techniques become obsolete much faster than AI building blocks, and techniques from 1 or 2 years ago are far from today's best practices. Part of the reason for this might be that, while AI builders might use dozens (hundreds?) of different building blocks, they aren’t likely to use dozens of different coding assistance tools at once, and so the forces of Darwinian competition are stronger among tools. Given the massive investments in this space by  Anthropic, Google, OpenAI, and other players, I expect the frenetic pace of development to continue, but keeping up with the latest developments in AI-assisted coding tools will pay off, since each generation is much better than the last.\n\nBonus: Product skills. In some companies, engineers are expected to take pixel-perfect drawings of a product, specified in great detail, and write code to implement it. But if a product manager has to specify even the smallest detail, this slows down the team. The shortage of AI product managers exacerbates this problem. I see teams move much faster if GenAI Engineers also have some user empathy as well at basic skill at designing products, so that, given only high-level guidance on what to build (“a user interface that lets users see their profiles and change their passwords”), they can make a lot of decisions themselves and build at least a prototype to iterate from.\n\nWhen interviewing GenAI Application Engineers, I will usually ask about their mastery of AI building blocks and ability to use AI-assisted coding, and sometimes also their product/design instincts. One additional question I've found highly predictive of their skill is, “How do you keep up with the latest developments in AI?” Because AI is evolving so rapidly, someone with good strategies for keeping up — such as reading The Batch and taking short courses 😃, regular hands-on practice building projects, and having a community to talk to — really does stay ahead of the game.\n\n[Original post: https://t.co/I3alxNs0vn ]",
  "createdAt": "Thu Jun 12 15:30:41 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 813,
  "replyCount": 138,
  "likeCount": 4431,
  "quoteCount": 84,
  "viewCount": 530992,
  "bookmarkCount": 5754,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1932822251273093247",
  "url": "https://x.com/AndrewYNg/status/1932822251273093247",
  "text": "Learn to build and deploy GenAI pipelines in \"Orchestrating Workflows for GenAI Applications\", built in partnership with @astronomerio and taught by Kenten Danas, the company's DevRel Senior Manager, and Tamara Fingerlin, developer advocate. \n\nMany GenAI applications require executing a pipeline comprising many steps. For example, a RAG app for recommending books might ingest and embed book descriptions, store the embeddings in a vector database, and later use the database to retrieve and recommend specific books based on a user query. After having prototyped this -- maybe in a Jupyter notebook -- how do you turn this into a reliable, repeatable workflow to run in production? \n\nIn this short course, you’ll learn to build reliable GenAI pipelines and orchestrate them using the popular open-source tool Airflow 3.0. You’ll learn to break down a workflow into discrete tasks so that an orchestration framework can schedule tasks to run in the right order at the right time (using time-based or data-aware triggers), and execute tasks in parallel when possible. It can also use retries to recover gracefully from failure (such as transient API rate limits) and provide observability (using Airflow UI) to help you track the status of the pipeline. You'll do this by using Airflow dags, which helps sequence tasks that need to run in a specific order, with clear task dependencies. \n\nBy the end of this course, you’ll know how to turn your prototype Jupyter notebook or Python script into production-ready workflow. \n\nPlease sign up here:  https://t.co/Ei8JZeS0ey",
  "createdAt": "Wed Jun 11 15:28:29 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 174,
  "replyCount": 41,
  "likeCount": 843,
  "quoteCount": 6,
  "viewCount": 72585,
  "bookmarkCount": 393,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1931072122853691639",
  "url": "https://x.com/AndrewYNg/status/1931072122853691639",
  "text": "Hanging out with @juberti , OpenAI’s head of realtime AI, responsible for the company’s voice AI products. One thing both of us agree on: while some things in AI are overhyped, voice applications seem underhyped right now. The application opportunities seem larger than the amount of developer or business attention on this right now.",
  "createdAt": "Fri Jun 06 19:34:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 148,
  "replyCount": 62,
  "likeCount": 722,
  "quoteCount": 9,
  "viewCount": 77924,
  "bookmarkCount": 94,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1930320263780151402",
  "url": "https://x.com/AndrewYNg/status/1930320263780151402",
  "text": "Thank you for your pioneering research work @lateinteraction on DSPy (together with @matei_zaharia, @ChrisGPotts and many others). I'm glad we could do a short course on this!",
  "createdAt": "Wed Jun 04 17:46:29 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 77,
  "replyCount": 13,
  "likeCount": 299,
  "quoteCount": 1,
  "viewCount": 61537,
  "bookmarkCount": 50,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1930277912030392356",
  "url": "https://x.com/AndrewYNg/status/1930277912030392356",
  "text": "New short course: DSPy: Build and Optimize Agentic Apps\n\nDSPy is a powerful open-source framework for automatically tuning prompts for GenAI applications. In this course, you'll learn to use DSPy, together with MLflow. This is built in partnership with @databricks and taught by @ChenMoneyQ, co-lead of the DSPy framework.\n\nMany AI builders spend hours hand-tuning prompts. When given a set of evals, DSPy automates this process. It’s especially useful for optimizing prompts, including few-shot prompts,  in complex agentic AI workflows. Further, if you switch an application to a newer LLM, performance can degrade if your prompts were optimized to the previous model. DSPy automatically optimizes the entire system for the new LLM as well, using just a few evaluation examples.\n\nThis course teaches DSPy works, and best practices for using it. You’ll write programs using DSPy’s signature-based programming model, debug them with MLflow tracing -- to gain visibility into how different parts of a pipeline, as well as how the overall system, are performing -- and automatically improve their accuracy with DSPy Optimizer.\n\nPlease sign up here: https://t.co/bb8uILyepf",
  "createdAt": "Wed Jun 04 14:58:11 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 313,
  "replyCount": 40,
  "likeCount": 1523,
  "quoteCount": 27,
  "viewCount": 177674,
  "bookmarkCount": 1319,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1929906213208113409",
  "url": "https://x.com/AndrewYNg/status/1929906213208113409",
  "text": "Everyone should learn to code with AI! At AI Fund, everyone - not just engineers - can vibe code or use AI assistance to code. This has been great for our creativity and productivity. I hope more teams will  empower everyone to build with AI. Please watch the  video for details. https://t.co/rsGC1QSKHL",
  "createdAt": "Tue Jun 03 14:21:11 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 427,
  "replyCount": 79,
  "likeCount": 2278,
  "quoteCount": 24,
  "viewCount": 159465,
  "bookmarkCount": 1339,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1928099650269237359",
  "url": "https://x.com/AndrewYNg/status/1928099650269237359",
  "text": "I am alarmed by the proposed cuts to U.S. funding for basic research, and the impact this would have for U.S. competitiveness in AI and other areas. Funding research that is openly shared benefits the whole world, but the nation it benefits most is the one where the research is done.\n\nIf not for funding for my early work in deep learning from the National Science Foundation (NSF)  and Defense Advanced Research Projects Agency (DARPA), which disburse a good deal of U.S. research funding, I would not have discovered lessons about scaling that led me to pitch starting Google Brain to scale up deep learning. I am worried that cuts to funding for basic science will lead the U.S. — and also the world — to miss out on the next set of ideas.\n\nIn fact, such funding benefits the U.S. more than any other nation.  Scientific research brings the greatest benefit to the country where the work happens because (i) the new knowledge diffuses fastest within that country, and (ii) the process of doing research creates new talent for that nation.\n\nWhy does most innovation in generative AI still happen in Silicon Valley? Because two teams based in this area — Google Brain, which invented the transformer network, and OpenAI, which scaled it up — did a lot of the early work. Subsequently, team members moved to other nearby businesses, started competitors, or worked with local universities. Further, local social networks rapidly diffused the knowledge through casual coffee meetings, local conferences, and even children’s play dates, where parents of like-aged kids meet and discuss technical ideas. In this way, the knowledge spread faster within Silicon Valley than to other geographies.\n\nIn a similar vein, research done in the U.S. diffuses to others in the U.S. much faster than to other geographic areas. This is particularly true when the research is openly shared through papers and/or open source: If researchers have permission to talk about an idea, they can share much more information, such as tips and tricks for how to really make an algorithm work, more quickly. It also lets others figure out faster who can answer their questions. Diffusion of knowledge created in academic environments is especially fast. Academia tends to be completely open, and students and professors, unlike employees of many companies, have full permission to talk about their work.\n\nThus funding basic research in the U.S. benefits the U.S. most, and also benefits our allies. It is true that openness benefits our adversaries, too. But as a subcommittee of the U.S. House of Representatives committee on science, space, and technology points out, “... open sharing of fundamental research is [not] without risk. Rather, ... openness in research is so important to competitiveness and security that it warrants the risk that adversaries may benefit from scientific openness as well.”\n\nFurther, generative AI is evolving so rapidly that staying on the cutting edge is what’s really critical. For example, the fact that many teams can now train a model with GPT-3.5- or even GPT-4-level capability does not seem to be hurting OpenAI much, which is busy growing its business by developing the cutting-edge o4, Codex, GPT-4.1, and so on. Those who invent a technology get to commercialize it first, and in a fast-moving world, the cutting-edge technology is what’s most valuable. Some studies (link in original post, below) also show how knowledge diffuses locally much faster than globally.\n\nChina was decisively behind the U.S. in generative AI when ChatGPT was first launched in 2022. However, China’s tech ecosystem is very open internally, and this has helped it to catch up over the past two years:\n- There is ample funding for open academic research in China.\n- China’s businesses such as DeepSeek and Alibaba have released cutting-edge, open-weights models. This openness at the corporate level accelerates diffusion of knowledge.\n- China’s labor laws make non-compete agreements (which stop an employee from jumping ship to a competitor) relatively hard to enforce, and the work culture supports significant idea sharing among employees of different companies; this has made circulation of ideas relatively efficient.\n\nWhile there’s also much about China that I would not want the U.S. to emulate, the openness of its tech ecosystem has helped it accelerate.\n\nIn 1945, Vannevar Bush’s landmark report “Science, The Endless Frontier” laid down key principles for public funding of U.S. research and talent development. Those principles enabled the U.S. to dominate scientific progress for decades. U.S. federal funding for science created numerous breakthroughs that have benefited the U.S. tremendously, and also the world, while training generations of domestic scientists, as well as immigrants who likewise benefit the U.S.\n\nThe good news is that this playbook is now well known. I hope many more nations will imitate it and invest heavily in science and talent. And I hope that, having pioneered this very successful model, the U.S. will not pull back from it by enacting drastic cuts to funding scientific research.\n\n[Original post, with links: https://t.co/JR3x4O1iVr ]",
  "createdAt": "Thu May 29 14:42:33 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 473,
  "replyCount": 106,
  "likeCount": 2655,
  "quoteCount": 48,
  "viewCount": 323701,
  "bookmarkCount": 471,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1927384264779170259",
  "url": "https://x.com/AndrewYNg/status/1927384264779170259",
  "text": "Agentic Document Extraction just got much faster! From previous 135sec median processing time down to 8sec. Extracts not just text but diagrams, charts, and form fields from PDFs to give LLM-ready output. Please see the video for details and some application ideas. https://t.co/29lOKf6UGO",
  "createdAt": "Tue May 27 15:19:52 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 605,
  "replyCount": 97,
  "likeCount": 3820,
  "quoteCount": 25,
  "viewCount": 288036,
  "bookmarkCount": 4081,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1925575163325948123",
  "url": "https://x.com/AndrewYNg/status/1925575163325948123",
  "text": "In the age of AI, large corporations — not just startups — can move fast. I often speak with large companies’ C-suite and Boards about AI strategy and implementation, and would like to share some ideas that are applicable to big companies. One key is to create an environment where small, scrappy teams don’t need permission to innovate. Let me explain.\n\nLarge companies are slower than startups for many reasons. But why are even 3-person, scrappy teams within large companies slower than startups of a similar size? One major reason is that large companies have more to lose, and cannot afford for a small team to build and ship a feature that leaks sensitive information, damages the company brand, hurts revenue, invites regulatory scrutiny, or otherwise damages an important part of the business. To prevent these outcomes, I have seen companies require privacy review, marketing review, financial review, legal review, and so on before a team can ship anything. But if engineers need sign-off from 5 vice presidents before they’re even allowed to launch an MVP (minimum viable product) to run an experiment, how can they ever discover what customers want, iterate quickly, or invent any meaningful new product?\n\nThanks to AI-assisted coding, the world now has a capability to build software prototypes really fast. But many large companies’ processes – designed to protect against legitimate downside risks – make them unable to take advantage of this capability. In contrast, in small startups with no revenue, no customers, and no brand reputation the downside is limited. In fact, going out of business is a very real possibility anyway, so moving fast makes a superior tradeoff to moving slowly to protect against downside risk. In the worst case, it might invent a new way to go out of business, but in a good case, it might become very valuable.\n\nFortunately, large companies have a way out of this conundrum. They can create a sandbox environment for teams to experiment in a way that strictly limits the downside risk. Then those teams can go much faster and not have to slow down to get anyone’s permission.\n\nThe sandbox environment can be a set of written policies, not necessarily a software implementation of a sandbox. For example, it may permit a team to test the nascent product only on employees of the company and perhaps alpha testers who have signed an NDA, and give no access to sensitive information. It may be allowed to launch product experiments only under newly created brands not tied directly to the company. Perhaps it must operate within a pre-allocated budget for compute.\n\nWithin this sandbox, there can be broad scope for experimentation, and — importantly — a team is free to experiment without frequently needing to ask for permission, because the downside they can create is limited. Further, when a prototype shows sufficient promise to bring it to scale, the company can then invest in making sure the software is reliable, secure, treats sensitive information appropriately, is consistent with the company’s brand, and so on.\n\nUnder this framework, it is easier to build a company culture that encourages learning, building, and experimentation and celebrates even the inevitable failures that now come with modest cost. Dozens or hundreds of prototypes can be built and quickly discarded as part of the price of finding one or two ideas that turn out to be home runs. This also lets teams move quickly as they churn through those dozens of prototypes needed to get to the valuable ones.\n\nI often speak with large companies about AI strategy and implementation. My quick checklist of things to consider is people, process, and platform. This letter has addressed only part of processes, with an emphasis on moving fast. I’m bullish about what both startups and large companies can do with AI, and I will write about the roles of people and platforms in future letters.\n\n[Original text: https://t.co/Jn1QLnrRlI ]",
  "createdAt": "Thu May 22 15:31:09 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 215,
  "replyCount": 68,
  "likeCount": 1118,
  "quoteCount": 18,
  "viewCount": 136115,
  "bookmarkCount": 749,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1925213790892929149",
  "url": "https://x.com/AndrewYNg/status/1925213790892929149",
  "text": "New Course: Reinforcement Fine-Tuning LLMs with GRPO! \n\nLearn to use reinforcement learning to improve your LLM performance in this short course, built in collaboration with @Predibase, and taught by @TravisAddair, its Co-Founder and CTO, and @grg_arnav, its Senior Engineer and Machine Learning Lead.\n\nReasoning models have been one of the most important developments in LLMs. Reinforcement Fine-Tuning (RFT) uses rewards to encourage LLMs to find solutions to multi-step reasoning tasks such as solving math problems and debugging code - without needing pre-existing training examples like in traditional supervised fine-tuning.\n\nGroup Relative Policy Optimization (GRPO) is a   reinforcement fine-tuning algorithm gaining rapid adoption. Developed by the DeepSeek team and used to train the R1 reasoning model, GRPO uses reward functions that you can write in Python to assign rewards to model responses. It’s beneficial for tasks with verifiable outcomes and can work well even with fewer than 100 training examples. It can also significantly improve the reasoning ability of smaller LLMs, making applications faster and more cost effective.\n\nIn this course, you’ll take a technical deep dive into RFT with GRPO. You’ll learn to build reward functions that you can use in the GRPO training process to guide an LLM toward better performance on multi-step reasoning tasks.\n\nIn detail, you’ll:\n- Learn when reinforcement fine-tuning is a better fit than supervised fine-tuning, especially for tasks involving multi-step reasoning or limited labeled data.\n- Understand how GRPO uses programmable reward functions as a more scalable alternative to the human feedback required for other reinforcement learning algorithms, such as RLHF and DPO.\n- Frame the Wordle game as a reinforcement fine-tuning problem and see how an LLM can learn to plan, analyze feedback, and improve its strategy over time.\n- Design reward functions that power the reinforcement fine-tuning process.\n- Learn techniques for evaluating more subjective tasks, such as rating the quality of a text summary, using an LLM as a judge.\n- Understand why reward hacking happens and how to avoid it by adding penalty functions to discourage undesirable behaviors.\n- Learn the four key components of the loss calculation in the GRPO algorithm: token probability distribution ratios, advantages, clipping, and KL-divergence.\n- Launch reinforcement fine-tuning jobs using Predibase’s hosted training services.\n\nBy the end of this course, you’ll be able to build and fine-tune LLMs using reinforcement learning to improve reasoning without relying on large labeled datasets or subjective human feedback.\n\nPlease sign up here: https://t.co/2BSuKuzE6N",
  "createdAt": "Wed May 21 15:35:11 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 184,
  "replyCount": 29,
  "likeCount": 1264,
  "quoteCount": 17,
  "viewCount": 84598,
  "bookmarkCount": 873,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1923045958511886549",
  "url": "https://x.com/AndrewYNg/status/1923045958511886549",
  "text": "AI’s ability to make tasks not just cheaper, but also faster, is underrated in its importance in creating business value.\n\nFor the task of writing code, AI is a game-changer. It takes so much less effort — and is so much cheaper — to write software with AI assistance than without. But beyond reducing the cost of writing software, AI is shortening the time from idea to working prototype, and the ability to test ideas faster is changing how teams explore and invent. When you can test 20 ideas per month, it dramatically changes what you can do compared to testing 1 idea per month. This is a benefit that comes from AI-enabled speed rather than AI-enabled cost reduction.\n\nThat AI-enabled automation can reduce costs is well understood. For example, providing automated customer service is cheaper than operating human-staffed call centers. Many businesses are more willing to invest in growth than just in cost savings; and, when a task becomes cheaper, some businesses will do a lot more of it, thus creating growth. But another recipe for growth is underrated: Making certain tasks much faster (whether or not they also become cheaper) can create significant new value.\n\nI see this pattern across more and more businesses. Consider the following scenarios:\n- If a lender can approve loans in minutes using AI, rather than days waiting for a human to review them, this creates more borrowing opportunities (and also lets the lender deploy its capital faster). Even if human-in-the-loop review is needed, using AI to get the most important information to the reviewer might speed things up. The ability to provide loans quickly opens up the market to new customers in need of rapid funds and helps customers who need a quick positive or negative decision to accept the loan or move on.\n- If an academic institution gives homework feedback to students in minutes (via sophisticated autograding) rather than days (via human grading), not only is the automation cheaper, the rapid feedback facilitates better learning.\n- If an online seller can approve purchases faster, this can lead to more sales. For example, many platforms that accept online ad purchases have an approval process that can take hours or days; if approvals can be done faster, they can earn revenue faster. Further, for customers buying ads, being able to post an ad in minutes lets them test ideas faster and also makes the ad product more valuable.\n- If a company’s sales department can prioritize leads and respond to prospective customers in minutes or hours rather than days — closer to when the customers’ buying intent first led them to contact the company — sales representatives might close more deals. Likewise, a business that can respond more quickly to requests for proposals may win more deals.\n\nI’ve written previously about looking at the tasks a company does to explore where AI can help. Many teams already do this with an eye toward making tasks cheaper, either to save costs or to do those tasks many more times. If you’re doing this exercise, consider also whether AI can significantly speed up certain tasks. One place to examine is the sequence of tasks on the path to earning revenue. If some of the steps can be sped up, perhaps this can help revenue growth.\n\nGrowth is more interesting to most businesses than cost savings, and if there are loops in your business that, when sped up, would drive growth, AI might be a tool to unlock this growth.\n\n[Original text: https://t.co/qx2Ir6pkSp  ]",
  "createdAt": "Thu May 15 16:00:59 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 192,
  "replyCount": 79,
  "likeCount": 891,
  "quoteCount": 34,
  "viewCount": 124357,
  "bookmarkCount": 406,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1922671569429766178",
  "url": "https://x.com/AndrewYNg/status/1922671569429766178",
  "text": "New course: MCP: Build Rich-Context AI Apps with Anthropic. Learn to build AI apps that access tools, data, and prompts using the Model Context Protocol in this short course, created in partnership with Anthropic @AnthropicAI and taught by Elie Schoppik @eschoppik, its Head of Technical Education.\n\nConnecting AI applications to external systems that bring rich context to LLM-based applications has often meant writing custom integrations for each use case. MCP is an open protocol that standardizes how LLMs access tools, data, and prompts from external sources, and simplifies how you provide context to your LLM-based applications. For example, you can provide context via third-party tools that let your LLM make API calls to search the web, access data from local docs, retrieve code from a GitHub repo, and so on.\n\nMCP, developed by Anthropic, is based on a client-server architecture that defines the communication details between an MCP client, hosted inside the AI application, and an MCP server that exposes tools, resources, and prompt templates. The server can be a subprocess launched by the client that runs locally or an independent process running remotely.\n\nIn this hands-on course, you'll learn the core architecture behind MCP. You’ll create an MCP-compatible chatbot, build and deploy an MCP server, and connect the chatbot to your MCP server and other open-source servers.\n\nHere’s what you’ll do:\n- Understand why MCP makes AI development less fragmented and standardizes connections between AI applications and external data sources\n- Learn the core components of the client-server architecture of MCP and the underlying communication mechanism\n- Build a chatbot with custom tools for searching academic papers, and transform it into an MCP-compatible application\n- Build a local MCP server that exposes tools, resources, and prompt templates using FastMCP, and test it using MCP Inspector\n- Create an MCP client inside your chatbot to dynamically connect to your server\n- Connect your chatbot to reference servers built by Anthropic’s MCP team, such as filesystem, which implements filesystem operations, and fetch, which extracts contents from the web as markdown\n- Configure Claude Desktop to connect to your server and others, and explore how it abstracts away the low-level logic of MCP clients\n- Deploy your MCP server remotely and test it with the Inspector or other MCP-compatible applications\n- Learn about the roadmap for future MCP development, such as multi-agent architecture, MCP registry API, server discovery, authorization, and authentication\n\nMCP is an exciting and important technology that lets you build rich-context AI applications that connect to a growing ecosystem of MCP servers, with minimal integration work.\n\nPlease sign up here! https://t.co/UDyp8NRe8R",
  "createdAt": "Wed May 14 15:13:18 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 376,
  "replyCount": 44,
  "likeCount": 2085,
  "quoteCount": 33,
  "viewCount": 139740,
  "bookmarkCount": 1834,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1920480706439876889",
  "url": "https://x.com/AndrewYNg/status/1920480706439876889",
  "text": "Additional tips on achieving speed:\n- Concreteness: https://t.co/H21N1tzkHM\n- Domain expert’s gut: https://t.co/6zGF1Fv8Ym\n- AI assisted coding: https://t.co/g41HynaFZ0\n- Quick user feedback: https://t.co/7rA0dit4jx",
  "createdAt": "Thu May 08 14:07:35 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 19,
  "replyCount": 7,
  "likeCount": 115,
  "quoteCount": 1,
  "viewCount": 31969,
  "bookmarkCount": 90,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1920480460318130460",
  "url": "https://x.com/AndrewYNg/status/1920480460318130460",
  "text": "I’m delighted to announce that AI Fund has closed $190M for our new fund, in an oversubscribed round. I look forward to working with many more builders to create new companies that serve humanity.\n\nAI Fund isn’t a traditional venture capital firm that invests in existing businesses. Instead, we are a venture builder (also called a venture studio): We co-found AI companies, so our team is directly involved in writing code, talking to customers to get feedback, iterating on product designs, preparing market analyses, and so on. We have a lot of fun building multiple AI products at a time, and thus live daily the emerging AI startup best practices.\n\nMany factors go into the success of a startup. But if I had to pick just one, it would be speed. Startups live or die based on their ability to make good decisions and execute fast, which has been a recurring theme of my posts here as well.\n\nIf you are building an AI startup, here are some ideas to consider:\n- A startup with a small team that pursues one focused, concrete idea can move really fast. Rather than hedging, it is often better to pursue one hypothesis (for example, build one concrete product) but also be willing to switch quickly to a different hypothesis (say, change what features you decide to build) if the data that comes back indicates the original hypothesis is flawed. Concreteness gets you speed!\n- A subject matter expert’s gut is remarkably good at making quick decisions. Obviously, there’s a role for data and user studies as well. But if you’re deciding whether to build feature A or B, or to sell first to user persona X or Y, sometimes a domain expert’s gut will point to a quick decision that you can execute and validate or falsify. Trusting a domain expert’s gut gets you speed!\n- AI-assisted coding is making prototyping faster than ever before. Yes, AI assistance is speeding up building reliable, enterprise-grade applications and maintaining legacy codebases. But the acceleration it brings to building stand-alone prototypes is far greater. This is because stand-alone prototypes have low requirements for reliability, integration, or even security (if, say, you run them in a sandbox environment). This lets us prototype and test at a ferocious velocity. AI-assisted coding (including vibe coding, where you might barely look at the code) gets you speed!\n- Finally, with faster prototyping, the bottleneck shifts to getting feedback from users. A single learning cycle might consist of (i) building a prototype and (ii) getting user feedback to inform the next iteration. Since (i) is now much faster than before, accelerating (ii) is growing in importance. This means teams that are skilled at finding prospective customers and getting their feedback in hours/days rather than weeks can go faster. For example, when building consumer products, I routinely approach strangers (in a respectful way) in public places to ask if they’re willing to give feedback on a prototype I’m working on. (Gathering feedback is more complex for enterprise products, because prospective customers are harder to track down.) Quick user feedback gets you speed!\n\nIn addition to speed, a second criterion that I find important for startup success is deep knowledge of the technology. Because AI technology is evolving rapidly, a team with a deep technical understanding of what AI can and cannot do, and when to use what tool, will make better decisions. This creates meaningful differentiation and saves wasting time in blind alleys. A good technical understanding, too, gets you speed!\n\nI’m grateful to AI Fund’s investors, team, and entrepreneur partners for working with us. There is much ahead to build!\n\n[Original text: https://t.co/I1nkYeTkFA ]",
  "createdAt": "Thu May 08 14:06:37 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 137,
  "replyCount": 58,
  "likeCount": 1198,
  "quoteCount": 27,
  "viewCount": 120142,
  "bookmarkCount": 481,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1920161212312268988",
  "url": "https://x.com/AndrewYNg/status/1920161212312268988",
  "text": "Learn to build conversational AI voice agents in \"Building AI Voice Agents for Production\", created in collaboration with @livekit and @realavatarai, and taught by @dsa (Co-founder & CEO of LiveKit), @shayneparlo (Developer Advocate, LiveKit), and @nedteneva (Head of AI at RealAvatar, an AI Fund portfolio company).\n\nVoice agents combine speech and reasoning capabilities to enable real-time conversations. They're already being used to support customer service, to improve accessibility in healthcare, for entertainment applications, and for talk therapy.\n\nIn this course, you’ll learn to build voice agents that listen, reason, and respond naturally. You’ll follow the architecture used to create the \"AI Andrew\" Avatar, a collaborative project between https://t.co/zpIxRSuky4 and RealAvatar that responds to users in what sounds like my voice. You’ll build a voice agent from scratch and deploy it to the cloud, enabling support for many simultaneous users.\n\nWhat you’ll learn:\n- Understand the fundamentals of voice agents, including key components like speech-to-text (STT), text-to-speech (TTS), and LLMs, and how latency is introduced at each layer.\n- Explore voice agent architectures and the trade-offs between modular pipelines and speech-to-speech APIs.\n- Explore how platforms like LiveKit mitigate latency issues with optimized networking infrastructure and low-latency communication protocols.\n- Learn how to connect client devices to voice agents using WebRTC—and why it outperforms HTTP and WebSocket for low-latency audio streaming.\n- Incorporate voice activity detection (VAD), end-of-turn detection, and context management to detect turns, handle interruptions, and manage conversational flow.\n- Understand the trade-offs between latency, quality, and cost in an example in which you build a voice agent and change its voice.\n- Equip your agent with metrics to measure latency at each stage of the voice pipeline and learn the key levers you can pull to make your agent faster and more responsive.\n\nThe voice agents built in this course also incorporate voice technology from @elevenlabsio, a supporting contributor to the project.\n\nBy the end of this course, you'll have learned the components of an AI voice agent pipeline, combined them into a system with low-latency communication, and deployed them on cloud infrastructure so it scales to many users.\n\nI’m looking forward to seeing what voice agents you build from this course!\n\nPlease sign up here: https://t.co/Offr7rPtDC",
  "createdAt": "Wed May 07 16:58:02 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 163,
  "replyCount": 40,
  "likeCount": 926,
  "quoteCount": 11,
  "viewCount": 86272,
  "bookmarkCount": 652,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1918839960880529641",
  "url": "https://x.com/AndrewYNg/status/1918839960880529641",
  "text": "In addition to being a great investor, @WarrenBuffett has also been a great teacher, and I'm grateful to have learned a lot from him. For example, one concept I refer to frequently at @AI_Fund is the Circle of Competence, meaning we figure out what we're good at and what we're not, and act accordingly. His stepping down from Berkshire Hathaway will be the end of an era!",
  "createdAt": "Sun May 04 01:27:51 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 105,
  "replyCount": 38,
  "likeCount": 1090,
  "quoteCount": 10,
  "viewCount": 116363,
  "bookmarkCount": 132,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1917986064851255658",
  "url": "https://x.com/AndrewYNg/status/1917986064851255658",
  "text": "Video of the talk: https://t.co/C5OB2qm7OP",
  "createdAt": "Thu May 01 16:54:46 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 21,
  "replyCount": 3,
  "likeCount": 102,
  "quoteCount": 1,
  "viewCount": 55903,
  "bookmarkCount": 49,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1917985792607363189",
  "url": "https://x.com/AndrewYNg/status/1917985792607363189",
  "text": "I hope we can empower everyone to build with AI. Starting from K-12, we should teach every student AI enabled coding, since this will enable them to become more productive and more empowered adults. But there is a huge shortage of computer science (CS) teachers. I recently spoke with high school basketball coach Kyle Creasy, who graduated with a B.A. in Physical Education in 2023. Until two years ago, he had never written a line of Python. Now — with help from AI — he not only writes code, he also teaches CS. I found Kyle’s story inspiring as a model for scaling up CS education in the primary- and secondary-school levels.\n\nKyle’s success has been with the support of Kira Learning (an AI Fund portfolio company), whose founders Andrea Pasinetti and Jagriti Agrawal have created a compelling vision for CS education. In K-12 classrooms, teachers play a huge social-emotional support role, for example, encouraging students and helping them when they stumble. In addition, they are expected to be subject-matter experts who can deliver the content needed for their subject. Kira Learning uses digital content delivery — educational videos, autograded quizzes, and AI-enabled chatbots to answer students' questions but without giving away homework answers — so the teacher can focus on social-emotional support. While these are still early days, it appears to be working!\n\nA key to making this possible is the hyperpersonalization that is now possible with AI (in contrast to the older idea of the flipped classroom, which had limited adoption). For example, when assigned a problem in an online coding environment, if a student writes this buggy line of Python code\n\nbest_$alty_snack = 'potato chips'\n\nKira Learning’s AI system can spot the problem and directly tell the teacher that $ is an invalid character in a variable name. It can also suggest a specific question for the teacher to ask the student to help get them unstuck, like “Can you identify what characters are allowed in variable names?” Whereas AI can directly deliver personalized advice to students, the fact that it is now helping teachers also deliver personalized support will really help in K-12.\n\nAdditionally, agentic workflows can automate a lot of teachers’ repetitive tasks. For example, when designing a curriculum, it’s time-consuming to align the content to educational standards (such as the Common Core in the United States, or the AP CS standard for many CS classes). Having an AI system carry out tasks like these is already proving helpful for teachers.\n\nSince learning to code, Kyle has built many pieces of software. He proudly showed me an analysis he generated in matplotlib of his basketball players’ attempts to shoot three-pointers (shown above), which in turn is affecting the team’s strategy on the court. One lesson is clear: When a basketball coach learns to code, they become a better basketball coach!\n\nI talked about Kyle (and other topics) at the ASU+GSV Summit on education. You can see a video online.\n\nIn the future, people who know how to code and build with AI will be much more productive than people who don’t. I’m excited about how AI will lead to new models for K-12 education. By delivering CS education to everyone, I hope that in the future, everyone will be able to build with AI.\n\n[Original text: https://t.co/F4xAhwfHaU ]",
  "createdAt": "Thu May 01 16:53:42 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 122,
  "replyCount": 47,
  "likeCount": 786,
  "quoteCount": 15,
  "viewCount": 80764,
  "bookmarkCount": 299,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1915421117998874899",
  "url": "https://x.com/AndrewYNg/status/1915421117998874899",
  "text": "Even though I’m a much better Python than JavaScript developer, with AI assistance, I’ve been writing a lot of JavaScript code recently. AI-assisted coding, including vibe coding, is making specific programming languages less important, even though learning one is still helpful to make sure you understand the key concepts. This is helping many developers write code in languages we’re not familiar with, which lets us get code working in many more contexts!\n\nMy background is in machine learning engineering and back-end development, but AI-assisted coding is making it easy for me to build front-end systems (the part of a website or app that users interact with) using JavaScript (JS) or TypeScript (TS), languages that I am weak in. Generative AI is making syntax less important, so we can all simultaneously be Python, JS, TS, C++, Java, and even Cobol developers. Perhaps one day, instead of being “Python developers\" or “C++ developers,” many more of us will just be “developers”!\n\nBut understanding the concepts behind different languages is still important. That’s why learning at least one language like Python still offers a great foundation for prompting LLMs to generate code in Python and other languages. If you move from one programming language to another that carries out similar tasks but with different syntax — say, from JS to TS, or C++ to Java, or Rust to Go — once you’ve learned the first set of concepts, you’ll know a lot of the concepts needed to prompt an LLM to code in the second language. (Although TensorFlow and PyTorch are not programming languages, learning the concepts of deep learning behind TensorFlow will also make it much easier to get an LLM to write PyTorch code for you, and vice versa!)  In addition, you’ll be able to understand much of the generated code (perhaps with a little LLM assistance).\n\nDifferent programming languages reflect different views of how to organize computation, and understanding the concepts is still important. For example, someone who does not understand arrays, dictionaries, caches, and memory will be less effective at getting an LLM to write code in most languages.\n\nSimilarly, a Python developer who moves toward doing more front-end programming with JS would benefit from learning the concepts behind front-end systems. For example, if you want an LLM to build a front end using the React framework, it will benefit you to understand how React breaks front ends into reusable UI components, and how it updates the DOM data structure that determines what web pages look like. This lets you prompt the LLM much more precisely, and helps you understand how to fix issues if something goes wrong. Similarly, if you want an LLM to help you write code in CUDA or ROCm, it helps to understand how GPUs organize compute and memory.\n\nJust as people who are fluent in multiple human languages can communicate more easily with other people, LLMs are making it easier for developers to build systems in multiple contexts. If you haven’t already done so, I encourage you to try having an LLM write some code in a language you’d like to learn but perhaps haven’t yet gotten around to, and see if it helps you get some new applications to work.\n\n[Original text: https://t.co/NdjaPgwwuk ]",
  "createdAt": "Thu Apr 24 15:02:35 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 472,
  "replyCount": 129,
  "likeCount": 3341,
  "quoteCount": 65,
  "viewCount": 263141,
  "bookmarkCount": 1140,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1915101920500564406",
  "url": "https://x.com/AndrewYNg/status/1915101920500564406",
  "text": "New short course: Building Code Agents with Hugging Face smolagents!\n\nLearn how to build code agents in this course, created in collaboration with @huggingface, and taught by @Thom_Wolf, its co-founder and CSO, and @AymericRoucher, Hugging Face’s Project Lead on Agents.\n\nTool-calling agents use LLMs to generate multiple function calls sequentially to complete a complex sequence of tasks. They generate one function call, execute it, observe, reason, and decide what to do next. Code agents take a different approach. They consolidate all these calls into a single block of code, letting the LLM lay out an entire action plan at once, which can be executed efficiently to provide more reliable results.\n\nYou’ll learn how to code agents using smolagents, a lightweight agentic framework from Hugging Face. Along the way, you’ll learn how to run LLM-generated code safely and develop an evaluation system to optimize your code agent for production.\n\nIn detail, you’ll learn:\n- How agentic systems have evolved, gaining greater levels of agency over time—and why code agents are a next step.\n- How code agents write their actions in code.\n- When code agents outperform function-calling agents.\n- How to run code agents safely in your system using a constrained Python interpreter and sandboxing using E2B.\n- To trace, debug, and assess the code agent to optimize its behaviours for complex requests.\n- How to build a research multi-agent system that can find information online and organize it into an interactive report.\n\nBy the end of this course, you’ll know how to build and run code agents using smolagents, and deploy them safely with a structured evaluation system in your projects.\n\nPlease sign up here! https://t.co/grcy0rH9Hg",
  "createdAt": "Wed Apr 23 17:54:13 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 229,
  "replyCount": 37,
  "likeCount": 1260,
  "quoteCount": 12,
  "viewCount": 126757,
  "bookmarkCount": 866,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1912908679344693711",
  "url": "https://x.com/AndrewYNg/status/1912908679344693711",
  "text": "I’ve noticed that many GenAI application projects put in automated evaluations (evals) of the system’s output probably later — and rely on humans to judge outputs longer — than they should. This is because building evals is viewed as a massive investment (say, creating 100 or 1,000 examples, and designing and validating metrics) and there’s never a convenient moment to put in that up-front cost. Instead, I encourage teams to think of building evals as an iterative process. It’s okay to start with a quick-and-dirty implementation (say, 5 examples with unoptimized metrics) and then iterate and improve over time. This allows you to gradually shift the burden of evaluations away from humans and toward automated evals.\n\nI wrote previously in The Batch about the importance and difficulty of creating evals. Say you’re building a customer-service chatbot that responds to users in free text. There’s no single right answer, so many teams end up having humans pore over dozens of example outputs with every update to judge if it improved the system. While techniques like LLM-as-judge are helpful, the details of getting this to work well (such as what prompt to use, what context to give the judge, and so on) are finicky to get right. All this contributes to the impression that building evals requires a large up-front investment, and thus on any given day, a team can make more progress by relying on human judges than figuring out how to build automated evals.\n\nI encourage you to approach building evals differently. It’s okay to build quick evals that are only partial, incomplete, and noisy measures of the system’s performance, and to iteratively improve them. They can be a complement to, rather than replacement for, manual evaluations. Over time, you can gradually tune the evaluation methodology to close the gap between the evals’ output and human judgments. For example:\n- It’s okay to start with very few examples in the eval set, say 5, and gradually add to them over time — or subtract them if you find that some examples are too easy or too hard, and not useful for distinguishing between the performance of different versions of your system.\n- It’s okay to start with evals that measure only a subset of the dimensions of performance you care about, or measure narrow cues that you believe are correlated with, but don’t fully capture, system performance. For example if, at a certain moment in the conversation, your customer-support agent is supposed to (i) call an API to issue a refund and (ii) generate an appropriate message to the user, you might start off measuring only whether or not it calls the API correctly and not worry about the message. Or if, at a certain moment, your chatbot should recommend a specific product, a basic eval could measure whether or not the chatbot mentions that product without worrying about what it says about it.\n\nSo long as the output of the evals correlates with overall performance, it’s fine to measure only a subset of things you care about when starting.\n\nThe development process thus comprises two iterative loops, which you might execute in parallel:\n- Iterating on the system to make it perform better, as measured by a combination of automated evals and human judgment;\n- Iterating on the evals to make them correspond more closely to human judgment.\n\nAs with many things in AI, we often don’t get it right the first time. So t’s better to build an initial end-to-end system quickly and then iterate to improve it. We’re used to taking this approach to building AI systems. We can build evals the same way.\n\nTo me, a successful eval meets the following criteria. Say, we currently have system A, and we might tweak it to get a system B:\n- If A works significantly better than B according to a skilled human judge, the eval should give A a significantly higher score than B.\n- If A and B have similar performance, their eval scores should be similar.\n\nWhenever a pair of systems A and B contradicts these criteria, that is a sign the eval is in “error” and we should tweak it to make it rank A and B correctly. This is a similar philosophy to error analysis in building machine learning algorithms, only instead of focusing on errors of the machine learning algorithm's output — such as when it outputs an incorrect label — we focus on “errors” of the evals — such as when they incorrectly rank two systems A and B, so the evals aren’t helpful in choosing between them.\n\nRelying purely on human judgment is a great way to get started on a project. But for many teams, building evals as a quick prototype and iterating to something more mature lets you put in evals earlier and accelerate your progress.\n\n[Original text: https://t.co/V3BZe8sRWE ]",
  "createdAt": "Thu Apr 17 16:39:03 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 176,
  "replyCount": 56,
  "likeCount": 1274,
  "quoteCount": 35,
  "viewCount": 206735,
  "bookmarkCount": 1245,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1912560177745994098",
  "url": "https://x.com/AndrewYNg/status/1912560177745994098",
  "text": "New Short Course: Building AI Browser Agents! \n\nLearn how to build AI agents that interact and take actions on websites in this course, created in partnership with @the_agi_company and taught by  @DivGarg_ and @namangarg0, Co-founders of AGI Inc.\n\nAI browser agents can log into websites, fill out forms, click through web pages, or even place orders online for you. They use both visual information, like screenshots, and structural data, like the HTML or Document Object Model (DOM) of a web page, to reason and take action.\n\nWith the complexity of webpages and multiple possible actions at each step, it can be challenging for an AI browser agent to complete an assigned task. Because these agents run long action sequences, a single error—like clicking the wrong button or misreading a field—can lead to unexpected outcomes or errors that compound over time.\n\nIn this course, you'll understand how autonomous web agents work, their current limitations, and how AgentQ enables them to improve through self-correction.\n\nIn detail, you'll:\n- Learn what web agents are, how they automate tasks online, their architecture, key components, limitations, and an overview of their decision-making strategies.\n- Build a web agent that can scrape https://t.co/zpIxRSuky4's website and return course recommendations in a structured output format.\n- Build an autonomous web agent that can execute multiple tasks, such as finding and summarizing webpages, filling out a form, and signing up for a newsletter.\n- Explore AgentQ, a framework that enables agents to self-correct by combining Monte Carlo Tree Search (MCTS), a self-critique mechanism for continuous improvement, and Direct Preference Optimization (DPO).\n- Deep dive into MCTS, learn how it finds an effective path, illustrated by an example of Gridworld animation, and use AgentQ to complete web tasks.\n- Understand AI agents' current state and future directions—including key factors shaping their evolution, such as hardware, algorithm innovation, and data availability.\nBy the end of this course, you will have hands-on experience building browser agents and a deeper understanding of how to make them more robust and reliable.\n\nPlease sign up here: https://t.co/kTzv4NkQ8H",
  "createdAt": "Wed Apr 16 17:34:14 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 302,
  "replyCount": 50,
  "likeCount": 1818,
  "quoteCount": 21,
  "viewCount": 183935,
  "bookmarkCount": 1881,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1910388768487727535",
  "url": "https://x.com/AndrewYNg/status/1910388768487727535",
  "text": "I am so sorry that the U.S. is letting down our friends and allies. Broad tariffs, implemented not just against adversaries but also steadfast allies, will damage the livelihoods of billions of people, create inflation, make the world more fragmented, and leave the U.S. and the world poorer. AI isn’t the solution to everything, but even amidst this challenging environment, I hope our community can hold together, keep building friendships across borders, keep sharing ideas, and keep supporting each other.\n\nMuch has been written about why high, widespread taxes on imports are harmful. In this letter, I’d like to focus on its possible effects on AI. One silver lining of the new tariffs is that they focus on physical imports, rather than digital goods and services, including intellectual property (IP) such as AI research inventions and software. IP is difficult to tax, because each piece of IP is unique and thus hard to value, and it moves across borders with little friction via the internet. Many international AI teams collaborate across borders and timezones, and software, including specifically open source software, is an important mechanism for sharing ideas. I hope that this free flow of ideas remains unhampered, even if the flow of physical goods is.\n\nHowever, AI relies on hardware, and tariffs will slow down AI progress by restricting access to it. Even though a last-minute exception was made for semiconductors, taxing imports of solar panels, wind turbines, and other power-generation and -distribution equipment will diminish the ability to provide power to U.S. data centers. Taxing imports of servers, cooling hardware, networking hardware, and the like will also make it more expensive to build data centers. And taxing consumer electronics, like laptops and phones, will make it harder for citizens to learn and use AI.\n\nWith regard to data-center buildouts, another silver lining is that, with the rise of generative AI, data gravity has decreased because compute processing costs are much greater than transmission costs, meaning it’s more feasible to place data centers anywhere in the world rather than only in close proximity to end-users. Even though many places do not have enough trained technicians to build and operate data centers, I expect tariffs will encourage data centers to be built around the world, creating more job opportunities globally.\n\nFinally, tariffs will create increased pressure for domestic manufacturing, which might create very mild tailwinds for robotics and industrial automation. As U.S. Vice President J.D. Vance pointed out in 2017, the U.S. should focus on automation (and education) rather than on tariffs. But the U.S. does not have the personnel — or know-how, or supply chain — to manufacture many of the goods that it currently counts on allies to make. Robotics can be helpful for addressing a small part of this large set of challenges. Generative AI’s rate of progress in robotics is also significantly slower than in processing text, visual data, audio, and reasoning. So while the tariffs could create tailwinds for AI-enabled robotics, I expect this effect to be small.\n\nMy 4-year-old son had been complaining for a couple of weeks that his shoes were a tight fit — he was proud that he’s growing! So last Sunday, we went shoe shopping. His new shoes cost $25, and while checking out, I paused and reflected on how lucky I am to be able to afford them. But I also thought about the many families living paycheck-to-paycheck, and for whom tariffs leading to shoes at $40 a pair would mean they let their kids wear ill-fitting shoes longer. I also thought about people I’ve met in clothing manufacturing plants in Asia and Latin America, for whom reduced demand would mean less work and less money to take home to their own kids.\n\nI don’t know what will happen next with the U.S. tariffs, and plenty of international trade will happen with or without U.S. involvement. I hope we can return to a world of vibrant global trade with strong, rules-based, U.S. participation. Until then, let’s all of us in AI keep nurturing our international friendships, keep up the digital flow of ideas — including specifically open source software — and keep supporting each other. Let’s all do what we can to keep the world as connected as we are able.\n\n[I had written this letter before the 90 day pause on the tariffs, but am sharing this here since many of the points are still relevant depends on what happens next.] \n\nOriginal text: https://t.co/fNyTqzABWy",
  "createdAt": "Thu Apr 10 17:45:50 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 364,
  "replyCount": 198,
  "likeCount": 2978,
  "quoteCount": 50,
  "viewCount": 333496,
  "bookmarkCount": 627,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1907843984158036137",
  "url": "https://x.com/AndrewYNg/status/1907843984158036137",
  "text": "Contrary to standard prompting advice that you should give LLMs the context they need to succeed, I find it’s sometimes faster to be lazy and dash off a quick, imprecise prompt and see what happens. The key to whether this is a good idea is whether you can quickly assess the output quality, so you can decide whether to provide more context. In this post, I’d like to share when and how I use “lazy prompting.”\n\nWhen debugging code, many developers copy-paste error messages — sometimes pages of them — into an LLM without further instructions. Most LLMs are smart enough to figure out that you want them to help understand and propose fixes, so you don’t need to explicitly tell them. With brief instructions like “Edit this: …” or “sample dotenv code” (to remind you how to write code to use Python's dotenv package), an LLM will often generate a good response. Further, if the response is flawed, hopefully you can spot any problems and refine the prompt, for example to steer how the LLM edits your text.\n\nAt the other end of the spectrum, sometimes  I spend 30 minutes carefully writing a 2-page prompt to get an AI system to help me solve a problem (for example to write many pages of code) that otherwise would have taken me much longer.\n\nI don’t try a lazy prompt if (i) I feel confident there’s no chance the LLM will provide a good solution without additional context. For example, given a partial program spec, does even a skilled human developer have a chance of understanding what you want? If I absolutely want to use a particular piece of pdf-to-text conversion software (like my team LandingAI’s Agentic Doc Extraction!), I should say so in the prompt, since otherwise it’s very hard for the LLM to guess my preference. I also wouldn’t use a lazy prompt if (ii) a buggy implementation would take a long time to detect. For example, if the only way for me to figure out if the output is incorrect is to laboriously run the code to check its functionality, it would be better to spend the time up-front to give context that would increase the odds of the LLM generating what I want.\n\nBy the way, lazy prompting is an advanced technique. On average, I see more people giving too little context to LLMs than too much. Laziness is a good technique only when you’ve learned how to provide enough context, and then deliberately step back to see how little context you can get away with and still have it work. Also, lazy prompting applies only when you can iterate quickly using an LLM’s web or app interface. It doesn’t apply to prompts written in code for the purpose of repeatedly calling an API, since presumably you won’t be examining every output to clarify and iterate if the output is poor.\n\nThank you to Rohit Prsad, who has been collaborating with me on the open-source package aisuite, for suggesting the term lazy prompting. There is an analogy to lazy evaluation in computer science, where you call a function at the latest possible moment and only when a specific result is needed. In lazy prompting, we add details to the prompt only when they are needed.\n\nOriginal text: https://t.co/Doh0TdJpO3",
  "createdAt": "Thu Apr 03 17:13:46 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 167,
  "replyCount": 77,
  "likeCount": 1419,
  "quoteCount": 38,
  "viewCount": 146030,
  "bookmarkCount": 733,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1907471607314133126",
  "url": "https://x.com/AndrewYNg/status/1907471607314133126",
  "text": "New Short Course: Getting Structured LLM Output!\n\nLearn how to get structured outputs from your LLM applications in this course, built in partnership with @dottxtai, and taught by @willkurt, a Founding Engineer, and @cameron_pfiffer , Developer Relations Engineer.\n\nIt's challenging for software to automatically parse through an LLM's freeform text outputs. Structured outputs—like JSON—solve this by converting natural language into consistent, clear, data that a machine can read and process. This course teaches you how to generate structured outputs while building several use cases, including a social media analysis agent.\n\nYou’ll learn about structured outputs and efficient ways to generate outputs in your defined schema or format. You’ll begin by using structured output APIs, then use re-prompting libraries like “instructor” to generate structured output. Finally, you’ll learn how constrained decoding works; this is a very clever technique in which constraints are applied on each subsequent token generated, blocking any tokens that don’t fit your defined schema.\n\nIn detail, you’ll:\n- Learn why structured outputs are important, how they allow for scalable software development, and the different approaches to generate them, including vendor-provided APIs, re-prompting libraries, and structured generation.\n- Build a simple social media agent using OpenAI’s structured output API, learn how to define a model's desired structured output using Pydantic, and perform basic programming with your outputs, such as importing structured data into a data frame using pandas.\n- Learn how to use the open-source library \"instructor,\" which checks the structured output of the model and re-prompts the model until it validates the desired output, and explore the limitations of this approach.\n- Understand how structured generation by the “outlines” library works by modifying LLM logits, on a per-generated-token basis based on the desired format, to give a particular output structure.\n- Learn how regular expressions, which outlines works with, are represented as finite-state machines, and how they can be used to develop a range of structured outputs beyond JSON.\n\nBy the end of this course, you’ll have broadened your knowledge of the approaches you can use to get structured outputs from your LLM applications.\n\nPlease sign up here: https://t.co/3k53vgEFj3",
  "createdAt": "Wed Apr 02 16:34:04 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 186,
  "replyCount": 32,
  "likeCount": 1267,
  "quoteCount": 21,
  "viewCount": 88725,
  "bookmarkCount": 860,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1907132637963260223",
  "url": "https://x.com/AndrewYNg/status/1907132637963260223",
  "text": "Major program launch: Data Analytics Professional Certificate! This large, five-course sequence takes you all the way to being job-ready as a data analyst, and shows how to use Generative AI as a thought partner to enhance your work in this role.\n\nOffered by https://t.co/zpIxRSuky4 on Coursera, this is taught by Sean Barnes, Ph.D., a Data Science & Engineering Leader at Netflix.\n\nAnalyzing data remains one of the most important skills in where the world is going with AI. This comprehensive certificate takes you all the way to being job-ready. \n\nEach course comes with practical projects demonstrated in real-world contexts, such as analyzing sales data for a Korean bakery, video game sales trends across different regions, or identifying factors impacting customer retention for a communications company. You'll also work on estimating fire distribution for forest fire prevention, analyzing how a diamond's properties affect its market value, and developing predictive models for retail sales analysis, carbon emissions, and coral reef conservation.\n\nHere's some of what you'll learn:\n- How to define data and categorize it into its many types such as discrete & continuous numerical, structured & unstructured, time series, categorical, and know what insights can be derived from the different types of data categories.\n- How to differentiate between data-related job roles and their responsibilities, and how data flows through an organization from the moment of capture to decision-making.\n- How to perform data processing functions and apply conditional formatting in spreadsheets to extract business value from your data using statistical calculations and best practices for visualizing and interpreting data.\n- How to use LLMs for stakeholder analysis, data exploration, and data visualization.\n- Best practices for using LLMs for as a thought partner to data analysis work\n\nBy the end of this professional certificate program, you will have learned core statistical concepts, analysis techniques, and visualization methodologies that will serve as the foundation for working as a data analyst.\n\nThe world needs more data analysts, especially ones who know how to use modern generative AI. With data science roles projected to grow 36% by 2033, the skills taught in this program create new professional opportunities in data.\n\nSign up here! https://t.co/R2ZiJQCn5g",
  "createdAt": "Tue Apr 01 18:07:08 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 165,
  "replyCount": 54,
  "likeCount": 849,
  "quoteCount": 3,
  "viewCount": 83413,
  "bookmarkCount": 758,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1904929635043074478",
  "url": "https://x.com/AndrewYNg/status/1904929635043074478",
  "text": "New short course: Vibe Coding 101 with Replit! Learn to build and host applications with an AI agent in this course, built in partnership with @Replit and taught by its President @pirroh and Head of Developer Relations @mattppal.\n\nCoding agents are changing how we write code. \"Vibe coding\" refers to a growing practice where you might barely look at the generated code, and instead focus on the architecture and features of your application. However, contrary to popular belief, effectively coding this way isn't done by just prompting, accepting all recommendations, and hoping for the best. It requires structuring your work, refining your prompts, and having a systematic process that lead to a more efficient and effective workflow.\n\nI code frequently using LLMs, and asking an LLM to do everything in one shot usually does not work. I'll typically take a problem, partition it into manageable modules, spend time creating prompts to specify each module, and use the model to produce the code one module at a time, and test/debug each module before moving on. A process like this is making me and many other developers faster and more efficient.\n\nIn this video-only course, you’ll learn how to use Replit’s cloud environment--with an integrated code editor, package manager, and deployment tools--to build and deploy web applications. Along the way, you’ll learn strategies for working effectively with agents and improve your development skills.\n\nIn detail, you’ll:\n- Understand principles of agentic code development such as being precise, giving agents one task at a time, making prompts specific, keeping projects tidy, starting with fresh sessions for each new feature, and how to approach debugging.\n- Learn how to get started with Replit, and key skills for vibe coding: Thinking, using frameworks, checkpoints, debugging, and providing context.\n- Create a product requirement document (PRD) and wireframe for your agent to build a prototype of a website performance analyzer.\n- See how to use an agent to make your prototype more visually appealing, and deploy it application others to access .\n- Learn to build a head-to-head national park ranking app, from a sample dataset, with voting capabilities and persistent data storage, and refine further ask the assistant to recap and explain what it built to find room for improvement and reinforce your learning.\n\nBy the end of this course, you’ll have a solid foundation in building with coding agents, and a process you can use to keep vibe coding effectively.\n\nPlease sign up here: https://t.co/yDbX1QFTI7",
  "createdAt": "Wed Mar 26 16:13:11 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 691,
  "replyCount": 110,
  "likeCount": 4227,
  "quoteCount": 136,
  "viewCount": 743254,
  "bookmarkCount": 5174,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1903147778097983709",
  "url": "https://x.com/AndrewYNg/status/1903147778097983709",
  "text": "Last Friday on Pi Day, we held AI Dev 25, a new conference for AI Developers. Tickets had (unfortunately) sold out shortly after we announced their availability, but I came away energized by the day of coding and technical discussions with fellow AI Builders! Let me share here my observations from the event.\n\nI'd decided to start AI Dev because while there're great academic AI conferences that disseminate research work (such as NeurIPS, ICML and ICLR) and also great meetings held by individual companies, often focused on each company's product offerings, there were few vendor-neutral conferences for AI developers. With the wide range of AI tools now available, there is a rich set of opportunities for developers to build new things (and to share ideas on how to build things!), but also a need for a neutral forum that helps developers do so.\n\nBased on an informal poll, about half the attendees had traveled to San Francisco from outside the Bay Area for this meeting, including many who had come from overseas. I was thrilled by the enthusiasm to be part of this AI Builder community. To everyone who came, thank you!\n\nOther aspects of the event that struck me:\n- First, agentic AI continues to be a strong theme. The topic attendees most wanted to hear about (based on free text responses to our in-person survey at the start of the event) was agents!\n- Google's Paige Bailey talked about embedding AI in everything and using a wide range of models to do so. I also particularly enjoyed her demos of Astra and Deep Research agents.\n- Meta's Amit Sangani talked compellingly as usual about open models. Specifically, he described developers fine-tuning smaller models on specific data, resulting in superior performance than with large general purpose models. While there're still many companies using fine-tuning that should really just be prompting, I'm also seeing continued growth of fine-tuning in applications that are reaching scale and that are becoming valuable.\n- Many speakers also spoke about the importance of being pragmatic about what problems we are solving, as opposed to buying into the AGI hype. For example, Nebius' Roman Chernin put it simply: Focusing on solving real problems is important!\n- Lastly, I was excited to hear continued enthusiasm for the Voice Stack. Justin Uberti gave a talk about OpenAI’s realtime audio API to a packed room, with many people pulling out laptops to try things out themselves in code!\n\nhttps://t.co/zpIxRSuky4 has a strong “Learner First” mentality; our foremost goal is always to help learners. I was thrilled that a few attendees told me they enjoyed how technical the sessions were, and said they learned many things that they're sure they will use. (In fact, I, too, came away with a few ideas from the sessions!) I was also struck that, both during the talks and at the technical demo booths, the rooms were packed with attendees who were highly engaged throughout the whole day. I'm glad that we were able to have a meeting filled with technical and engineering discussions.\n\nI'm delighted that AI Dev 25 went off so well, and am grateful to all the attendees, volunteers, speakers, sponsors, partners, and team members that made the event possible. I regretted only that the physical size of the event space prevented us from admitting more attendees this time. There is something magical about bringing people together physically to share ideas, make friends, and to learn from and help each other. I hope we'll be able to bring even more people together in the future.\n\n[Original text: https://t.co/iNUywKfGRx ]",
  "createdAt": "Fri Mar 21 18:12:43 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 47,
  "replyCount": 33,
  "likeCount": 268,
  "quoteCount": 7,
  "viewCount": 45778,
  "bookmarkCount": 63,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1902395485601853941",
  "url": "https://x.com/AndrewYNg/status/1902395485601853941",
  "text": "New short course: Long-Term Agentic Memory with LangGraph. Learn to build an agent with long-term memory in this course developed in collaboration with @LangChainAI taught by its Co-Founder and CEO, @hwchase17! \n\nPersonal assistance and productivity tasks have become important use cases for agents. An important feature of an AI assistant, such as a coding or calendar assistant, is its ability to keep improving over time from its experience. Agent memory is the key capability that enables this.\n\nTo add memory to an agent, you must first figure out what to store and what to retrieve when it is time to use the information. Additionally, you’ll have to decide when to update the stored information. For example, you might update in each iteration loop of the agent or perform updates in the background, with a helper agent.\n\nIn this course, you will learn a mental framework to build agents with long-term memory. You'll create a useful email assistant that can respond, ignore, and notify using writing, scheduling, and memory-management tools. You’ll develop your agent's memory by adding facts to its memory store, provide examples to learn the user's preferences, and optimize system prompts to evolve instructions based on previous responses.\n\nIn detail, you’ll:\n- Learn how the three types of memory--semantic, episodic, and procedural–and the two update mechanisms–via hot path and in the background–apply to your agents.\n- Build an email agent with writing, scheduling, and availability tools, along with a router that triages incoming email and handles it accordingly by ignoring, responding, or notifying the user.\n- Add tools to your email agent that allow it to operate on semantic memory by learning facts about the user, storing them in a long-term memory store, and searching over them in future interactions.\n- Incorporate episodic memory, in the form of few-shot examples, in the triage step of your agents to help them learn and update user preferences.\n- Add procedural memory as system prompts, optimized with feedback to improve the instructions the agent follows.\n\nLearn how to approach memory in agents, and start building agents with long-term memory with LangGraph!\n\nPlease sign up here: https://t.co/9E02gQDdiM",
  "createdAt": "Wed Mar 19 16:23:23 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 267,
  "replyCount": 50,
  "likeCount": 1619,
  "quoteCount": 18,
  "viewCount": 129706,
  "bookmarkCount": 1188,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1900639477279977618",
  "url": "https://x.com/AndrewYNg/status/1900639477279977618",
  "text": "OpenAI’s Justin Uberti at AI Dev 25 showing how to build a voice agent using the Realtime API. Building on the voice stack is easier than most realize - worth trying out if you have a voice idea! https://t.co/GOTyw7Vftl",
  "createdAt": "Fri Mar 14 20:05:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 78,
  "replyCount": 51,
  "likeCount": 472,
  "quoteCount": 3,
  "viewCount": 75035,
  "bookmarkCount": 192,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1900617330906067136",
  "url": "https://x.com/AndrewYNg/status/1900617330906067136",
  "text": "Good tip from Replit’s @mattppal at AI Dev 25 on debugging while vibe coding: Large part of it is looking at outputs to figure out what context you have that LLM does not, so that you can give it that context and help it get unstuck. Sometimes pasting in the error messages is enough, but also sometimes not.",
  "createdAt": "Fri Mar 14 18:37:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 77,
  "replyCount": 38,
  "likeCount": 468,
  "quoteCount": 15,
  "viewCount": 105433,
  "bookmarkCount": 200,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1900610468747899142",
  "url": "https://x.com/AndrewYNg/status/1900610468747899142",
  "text": "Panel with Replit’s Michele Catasta, Stanford’s @percyliang , Nebius’ Roman Chernin and Hugging Face’s @Thom_Wolf, moderated by @lmoroney, on application building. Lots of tips on infra, open source, agentic workflows, benchmarking and code gen. Particular interest in how to take stochastic LLMs that hallucinate and nonetheless build reliable agents.",
  "createdAt": "Fri Mar 14 18:10:22 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 8,
  "replyCount": 10,
  "likeCount": 58,
  "quoteCount": 0,
  "viewCount": 33935,
  "bookmarkCount": 11,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1900599467822510154",
  "url": "https://x.com/AndrewYNg/status/1900599467822510154",
  "text": "Meta’s Chaya Nayak talking about the open Llama models and Llama Stack, and best practices for using them. Great tips and I saw lots of people pulling out phones to take pictures of her slides! https://t.co/OGixvLRyPO",
  "createdAt": "Fri Mar 14 17:26:39 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 18,
  "replyCount": 6,
  "likeCount": 66,
  "quoteCount": 0,
  "viewCount": 18052,
  "bookmarkCount": 10,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1900596396140671194",
  "url": "https://x.com/AndrewYNg/status/1900596396140671194",
  "text": "Great talk by Google’s Bill Jia on their GenAI work, including Astra and Deep Research agents (both of which I think are very cool). https://t.co/1yhNIQGxII",
  "createdAt": "Fri Mar 14 17:14:26 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 8,
  "replyCount": 12,
  "likeCount": 78,
  "quoteCount": 1,
  "viewCount": 32914,
  "bookmarkCount": 11,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1900595885970780360",
  "url": "https://x.com/AndrewYNg/status/1900595885970780360",
  "text": "From audience poll the topic AI developers are most excited about is Agents! https://t.co/WqMCyR07H4",
  "createdAt": "Fri Mar 14 17:12:25 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 10,
  "replyCount": 9,
  "likeCount": 66,
  "quoteCount": 1,
  "viewCount": 23236,
  "bookmarkCount": 6,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1900594063516254299",
  "url": "https://x.com/AndrewYNg/status/1900594063516254299",
  "text": "It’s starting - just kicked off AI Dev 25, the AI developer conference, in San Francisco! Happy Pi day! https://t.co/tlJvBFee0F",
  "createdAt": "Fri Mar 14 17:05:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 74,
  "replyCount": 120,
  "likeCount": 656,
  "quoteCount": 6,
  "viewCount": 61303,
  "bookmarkCount": 49,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1900219116822102116",
  "url": "https://x.com/AndrewYNg/status/1900219116822102116",
  "text": "Some people today are discouraging others from learning programming on the grounds AI will automate it. This advice will be seen as some of the worst career advice ever given. I disagree with the Turing Award and Nobel prize winner who wrote, “It is far more likely that the programming occupation will become extinct [...] than that it will become all-powerful. More and more, computers will program themselves.”​ Statements discouraging people from learning to code are harmful!\n\nIn the 1960s, when programming moved from punchcards (where a programmer had to laboriously make holes in physical cards to write code character by character) to keyboards with terminals, programming became easier. And that made it a better time than before to begin programming. Yet it was in this era that Nobel laureate Herb Simon wrote the words quoted in the first paragraph. Today’s arguments not to learn to code continue to echo his comment.\n\nAs coding becomes easier, more people should code, not fewer!\n\nOver the past few decades, as programming has moved from assembly language to higher-level languages like C, from desktop to cloud, from raw text editors to IDEs to AI assisted coding where sometimes one barely even looks at the generated code (which some coders recently started to call vibe coding), it is getting easier with each step.\n\nI wrote previously that I see tech-savvy people coordinating AI tools to move toward being 10x professionals — individuals who have 10 times the impact of the average person in their field. I am increasingly convinced that the best way for many people to accomplish this is not to be just consumers of AI applications, but to learn enough coding to use AI-assisted coding tools effectively.\n\nOne question I’m asked most often is what someone should do who is worried about job displacement by AI. My answer is: Learn about AI and take control of it, because one of the most important skills in the future will be the ability to tell a computer exactly what you want, so it can do that for you. Coding (or getting AI to code for you) is a great way to do that.\n\nWhen I was working on the course Generative AI for Everyone and needed to generate AI artwork for the background images, I worked with a collaborator who had studied art history and knew the language of art. He prompted Midjourney with terminology based on the historical style, palette, artist inspiration and so on — using the language of art — to get the result he wanted. I didn’t know this language, and my paltry attempts at prompting could not deliver as effective a result.\n\nSimilarly, scientists, analysts, marketers, recruiters, and people of a wide range of professions who understand the language of software through their knowledge of coding can tell an LLM or an AI-enabled IDE what they want much more precisely, and get much better results. As these tools are continuing to make coding easier, this is the best time yet to learn to code, to learn the language of software, and learn to make computers do exactly what you want them to do.\n\n[Original text: https://t.co/HdI3Jb9HmF ]",
  "createdAt": "Thu Mar 13 16:15:16 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 2866,
  "replyCount": 524,
  "likeCount": 12179,
  "quoteCount": 514,
  "viewCount": 2121039,
  "bookmarkCount": 5550,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1897776017873465635",
  "url": "https://x.com/AndrewYNg/status/1897776017873465635",
  "text": "Continuing from last week’s post on the rise of the Voice Stack, there’s an area that today’s voice-based systems often struggle with: Voice Activity Detection (VAD) and the turn-taking paradigm of communication.\n\nWhen communicating with a text-based chatbot, the turns are clear: You write something, then the bot does, then you do, and so on. The success of text-based chatbots with clear turn-taking has influenced the design of voice-based bots, most of which also use the turn-taking paradigm.\n\nA key part of building such a system is a VAD component to detect when the user is talking. This allows our software to take the parts of the audio stream in which the user is saying something and pass that to the model for the user’s turn. It also supports interruption in a limited way, whereby if a user insistently interrupts the AI system while it is talking, eventually the VAD system will realize the user is talking, shut off the AI’s output, and let the user take a turn. This works reasonably well in quiet environments.\n\nHowever, VAD systems today struggle with noisy environments, particularly when the background noise is from other human speech. For example, if you are in a noisy cafe speaking with a voice chatbot, VAD — which is usually trained to detect human speech — tends to be inaccurate at figuring out when you, or someone else, is talking. (In comparison, it works much better if you are in a noisy vehicle, since the background noise is more clearly not human speech.) It might think you are interrupting when it was merely someone in the background speaking, or fail to recognize that you’ve stopped talking. This is why today’s speech applications often struggle in noisy environments.\n\nIntriguingly, last year, Kyutai Labs published Moshi, a model that had many technical innovations. An important one was enabling persistent bi-direction audio streams from the user to Moshi and from Moshi to the user.\n\nIf you and I were speaking in person or on the phone, we would constantly be streaming audio to each other (through the air or the phone system), and we’d use social cues to know when to listen and how to politely interrupt if one of us felt the need. Thus, the streams would not need to explicitly model turn-taking. Moshi works like this. It’s listening all the time, and it’s up to the model to decide when to stay silent and when to talk. This means an explicit VAD step is no longer necessary. (Moshi also included other innovations, such as an “inner monologue” that simultaneously generates text alongside the audio to improve the quality of responses as well as audio encoding.)\n\nJust as the architecture of text-only transformers has gone through many evolutions (such as encoder-decoder models, decoder-only models, and reasoning models that generate a lot of “reasoning tokens” before the final output), voice models are going through a lot of architecture explorations. Given the importance of foundation models with voice-in and voice-out capabilities, many large companies right now are investing in developing better voice models. I’m confident we’ll see many more good voice models released this year.\n\nIt feels like the space of potential innovation for voice remains large. Hard technical problems, like the one of latency that I described last week and VAD errors, remain to be solved. As solutions get better, voice-to-voice will continue to be a promising category to build applications in.\n\n[Original text: https://t.co/vwLlAnTJZT ]",
  "createdAt": "Thu Mar 06 22:27:16 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 85,
  "replyCount": 38,
  "likeCount": 385,
  "quoteCount": 9,
  "viewCount": 68182,
  "bookmarkCount": 155,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1897389514034688313",
  "url": "https://x.com/AndrewYNg/status/1897389514034688313",
  "text": "New short course: Event-Driven Agentic Document Workflows. Event-driven workflows are a key design pattern in which many pieces of work (LLM calls, tool use, etc.) can be carried out asynchronously and in parallel, and completion of specific steps generate events that trigger other work to begin. In this course, created in partnership with @llama_index and @seldo, VP of Developer Relations, you'll learn to apply this technique to document workflows.\n\nFilling out complex forms can be tedious, time-consuming, and error-prone. Agentic workflows can automate this. This course teaches you how to build an agentic document workflow using an event-driven architecture.\n\nYou'll design an event-driven agentic workflow that fills out a PDF form based on information from a source document. The agent will use RAG to retrieve relevant data from the source document, parse the form to identify the required fields, convert the blank spaces into questions, and send those questions to the RAG system to fill the form. You'll collaborate with the agent using a human-in-the-loop feedback approach through text and with your voice.\n\nIn detail, you’ll:\n- Understand the basic concepts of event-driven workflows.\n- Build a series of LlamaIndex’s workflows that increase in complexity from branching and looping logic to concurrent executions.\n- Set up the agent’s RAG capability by parsing the source document, loading the extracted information into a vector store, and building a query engine on top of the store.\n- Implement workflow steps that enable the agent to parse the form to be filled, turn the parsed information into simple questions, and use the questions to query the RAG pipeline.\n- Incorporate human-in-the-loop into the workflow and ask the agent to re-answer when necessary to produce more accurate form responses.\n- Add multimodal capability to the agent, allowing it to process spoken feedback.\n\nBy the end of this course, you will have built an event-driven agentic workflow that fills out a document and responds to human feedback to complete the form more accurately.\n\nPlease sign up here: https://t.co/GZSZ9lXMKC",
  "createdAt": "Wed Mar 05 20:51:26 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 244,
  "replyCount": 136,
  "likeCount": 1556,
  "quoteCount": 12,
  "viewCount": 150897,
  "bookmarkCount": 1345,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1895183929977843970",
  "url": "https://x.com/AndrewYNg/status/1895183929977843970",
  "text": "Announcing: Agentic Document Extraction! \n\nPDF files represent information visually - via layout, charts, graphs, etc. - and are more than just text. Unlike  traditional OCR and most PDF-to-text approaches, which focus on extracting the text, an agentic approach lets us break a document down into components and reason about them, resulting in more accurate extraction of the underlying meaning for RAG and other applications. Watch the video for details.",
  "createdAt": "Thu Feb 27 18:47:14 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 894,
  "replyCount": 273,
  "likeCount": 6301,
  "quoteCount": 89,
  "viewCount": 683093,
  "bookmarkCount": 7114,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1895146310296379419",
  "url": "https://x.com/AndrewYNg/status/1895146310296379419",
  "text": "The Voice Stack is improving rapidly. Systems that interact with users via speaking and listening will drive many new applications. Over the past year, I’ve been working closely with https://t.co/zpIxRSuky4, AI Fund, and several collaborators on voice-based applications, and I will share best practices I’ve learned in this and future posts.\n\nFoundation models that are trained to directly input, and often also directly generate, audio have contributed to this growth, but they are only part of the story. OpenAI’s RealTime API makes it easy for developers to write prompts to develop systems that deliver voice-in, voice-out experiences. This is great for building quick-and-dirty prototypes, and it also works well for low-stakes conversations where making an occasional mistake is okay. I encourage you to try it!\n\nHowever, compared to text-based generation, it is still hard to control the output of voice-in voice-out models. In contrast to directly generating audio, when we use an LLM to generate text, we have many tools for building guardrails, and we can double-check the output before showing it to users. We can also use sophisticated agentic reasoning workflows to compute high-quality outputs. Before a customer-service agent shows a user the message, “Sure, I’m happy to issue a refund,” we can make sure that (i) issuing the refund is consistent with our business policy and (ii) we will call the API to issue the refund (and not just promise a refund without issuing it).\n\nIn contrast, the tools to prevent a voice-in, voice-out model from making such mistakes are much less mature.\n\nIn my experience, the reasoning capability of voice models also seems inferior to text-based models, and they give less sophisticated answers. (Perhaps this is because voice responses have to be more brief, leaving less room for chain-of-thought reasoning to get to a more thoughtful answer.)\n\nWhen building applications where I need a high degree of control over the output, I use agentic workflows to reason at length about the user’s input. In voice applications, this means I end up using a pipeline that includes speech-to-text (STT, also known as ASR, or automatic speech recognition) to transcribe the user’s words, then processes the text using one or more LLM calls, and finally returns an audio response to the user via TTS (text-to-speech). This STT → LLM/Agentic workflow → TTS pipeline, where the reasoning is done in text, allows for more accurate responses.\n\nHowever, this process introduces latency, and users of voice applications are very sensitive to latency. When https://t.co/zpIxRSuky4 worked with RealAvatar (an AI Fund portfolio company led by Jeff Daniel) to build an avatar of me, we found that getting TTS to generate a voice that sounded like me was not very hard, but getting it to respond to questions using words similar to those I would choose was. Even after a year of tuning our system — starting with iterating on multiple, long, mega-prompts and eventually developing complex agentic workflows — it remains a work in progress. You can play with it at https://t.co/vMO2CM0xfb\n\nInitially, this agentic workflow incurred 5-9 seconds of latency, and having users wait that long for responses led to a bad experience. To address this, we came up with the following latency reduction technique. The system quickly generates a pre-response (short for preliminary response) that can be uttered quickly, which buys time for an agentic workflow to generate a more thoughtful, full response. (We’re grateful to LiveKit’s CEO Russ d’Sa and team for helping us get this working.) This is similar to how, if you were to ask me a complicated question, I might say “Hmm, let me think about that” or “Sure, I can help with that” — that’s the pre-response — while thinking about what my full response might be.\n\nI think generating a pre-response followed by a full response, to quickly acknowledge the user’s query and also reduce the perceived latency, will be an important technique, and I hope many teams will find this useful. Our goal was to approach human face-to-face conversational latency, which is around 0.3-1 seconds. RealAvatar and https://t.co/zpIxRSuky4, through our efforts on the pre-response and other optimizations, have reduced the system’s latency to around 0.5-1 seconds.\n\nMonths ago, sitting in a coffee shop, I was able to buy a phone number on Twilio and hook it up to an STT → LLM → TTS pipeline in just hours. This enabled me to talk to my own LLM using custom prompts. Prototyping voice applications is much easier than most people realize!\n\nBuilding reliable, scaled production applications takes longer, of course, but if you have a voice application in mind, I hope you’ll start building prototypes and see how far you can get! I’ll keep building voice applications and sharing best practices and voice-related technology trends in future posts.\n\n[Original letter: https://t.co/M38Ud0UhdT ]",
  "createdAt": "Thu Feb 27 16:17:45 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 142,
  "replyCount": 132,
  "likeCount": 661,
  "quoteCount": 23,
  "viewCount": 76927,
  "bookmarkCount": 346,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1894979731726180765",
  "url": "https://x.com/AndrewYNg/status/1894979731726180765",
  "text": "Transformers have dominated LLM text generation, and generate tokens sequentially. This is a cool attempt to explore diffusion models as an alternative, by generating the entire text at the same time using a coarse-to-fine process. Congrats @StefanoErmon &amp; team!",
  "createdAt": "Thu Feb 27 05:15:49 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 281,
  "replyCount": 94,
  "likeCount": 1858,
  "quoteCount": 13,
  "viewCount": 159066,
  "bookmarkCount": 537,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1894796562829844873",
  "url": "https://x.com/AndrewYNg/status/1894796562829844873",
  "text": "New course to bring you up to state-of-the-art at using AI to help you code: Build Apps with Windsurf's AI Coding Agents, built in partnership with WIndsurf (@codeiumdev) and taught by @_anshulr!\n\nAI-assisted IDEs (Integrated Development Environments) make developers’ workflows faster, more efficient, and much more fun. Agentic tools like Windsurf are more than just code autocomplete—they are collaborative coding agents that help you break down complex applications, iterate efficiently, and generate code that spans multiple files.\n\nAlthough a lot of coding assistants share the same underlying large language models for planning and reasoning, a major point of distinction is how they handle tools, keep track of context, and stay aligned with your intent as a developer.\n\nFor instance, if you make modifications to a class definition in your code and make the same modifications to other classes in the same directory, you might tell the AI agent \"Do the same thing in similar places in this directory.\" Here, tracking your intent means understanding that “the same thing\" refers to that recent edit you just made, which must be followed by appropriate search and tool-calling to implement the changes.\n\nIn this course, you'll learn the inner workings of coding agents, their strengths and limitations, and how to use Windsurf to quickly build several applications.\n\nIn detail, you'll:\n- Build a mental model of how agents work by combining human-action tracking, tool integration, and context awareness to carry out an agentic coding workflow.\n- Learn the challenges of code search and discovery and how a multi-step retrieval approach helps coding agents address them.\n- Use Windsurf to analyze and understand a large, old codebase and update it to the latest versions of the frameworks and packages it uses.\n- Build a Wikipedia data analysis app that retrieves, parses, and analyzes word frequencies.\n- Enhance the performance of your Wikipedia analysis app by adding caching, and through this, also learn how to course-correct when the AI agent produces unexpected results.\n- Learn tips and tricks such as keyboard shortcuts, autocomplete, and @ mentions to quickly call on agentic capabilities.\n- Use image/multimodal capabilities of the AI agent to increase your development velocity; you'll see an example of uploading a mockup with sketched-out UI features, and ask the agent to use that to build new functionality to an app.\n\nBy the end of this course, you’ll understand agentic coding in-depth and know how to use it to make your development process much faster, more efficient, and enjoyable.\n\nPlease sign up here! https://t.co/IhFB3IwHAh",
  "createdAt": "Wed Feb 26 17:07:58 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 271,
  "replyCount": 143,
  "likeCount": 1565,
  "quoteCount": 24,
  "viewCount": 138836,
  "bookmarkCount": 1267,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1892628887856939236",
  "url": "https://x.com/AndrewYNg/status/1892628887856939236",
  "text": "Last month, a drone from Skyfire AI was credited with saving a police officer’s life after a dramatic 2 a.m. traffic stop. Many statistics show that AI impacts billions of lives, but sometimes a story still hits me emotionally. Let me share what happened.\n\nSkyfire AI, an AI Fund portfolio company led by CEO Don Mathis, operates a public safety program in which drones function as first responders to 911 calls. Particularly when a police department is personnel-constrained, drones can save officers’ time while enhancing their situational awareness. For example, many burglar alarms are false alarms, maybe set off by moisture or an animal. Rather than sending a patrol officer to drive over to discover this, a drone can get there faster and determine if an officer is required at all. If the alarm is real, the drone can help officers understand the situation, the locations of any perpetrators, and how best to respond.\n\nIn January, a Skyfire AI drone was returning to base after responding to a false alarm when the police dispatcher asked us to reroute it to help locate a patrol officer. The officer had radioed a few minutes earlier that he had pulled over a suspicious vehicle and had not been heard from since. The officer had stopped where two major highways intersect in a complex cloverleaf, and dispatch was unsure exactly where they were located.\n\nFrom the air, the drone rapidly located the officer and the driver of the vehicle he had pulled over, who it turned out had escaped from a local detention facility. Neither would have been visible from the road — they were fighting in a drainage ditch below the highway. Because of the complexity of the cloverleaf’s geometry, the watch officer (who coordinates police activities for the shift) later estimated it would have taken 5-7 minutes for an officer in a patrol car to find  them.\n\nFrom the aerial footage, it appeared that the officer still had his radio, but  was losing the fight and unable to reach it to call for help. Further, it looked like the assailant might gain control of his service weapon and use it against him. This was a dire and dangerous situation.\n\nFortunately, because the drone had pinpointed the location of the officer and his assailant, dispatch was able to direct additional units to assist. The first arrived not in 5-7 minutes but in 45 seconds. Four more units arrived within minutes.\n\nThe officers were able to take control of the situation and apprehend the driver, resulting in an arrest and, more important, a safe outcome for the officer. Subsequently, the watch officer said we’d probably saved the officer’s life.\n\nDemocratic nations still have a lot of work to do on drone technology, and we must build this technology with guardrails to make sure we enhance civil liberties and human rights. But I am encouraged by the progress we’re making. In the aftermath of Hurricane Helene last year, Skyfire AI’s drones supported search-and-rescue operations under the direction of the North Carolina Office of Emergency Management, responding to specific requests to help locate missing persons and direct rescue assets (e.g., helicopters and boats) to their location, and was credited with saving 13 lives.\n\nIt’s not every day that AI directly saves someone's life. But as our technology advances, I think there will be more and more stories like these.\n\n[Original text: https://t.co/xtBdJgqIqc ]",
  "createdAt": "Thu Feb 20 17:34:24 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 107,
  "replyCount": 167,
  "likeCount": 591,
  "quoteCount": 10,
  "viewCount": 64457,
  "bookmarkCount": 122,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1892258190546653392",
  "url": "https://x.com/AndrewYNg/status/1892258190546653392",
  "text": "New short course: Evaluating AI Agents! Evals are important for driving AI system improvements, and in this course you'll learn to systematically assess and improve an AI agent’s performance. This is built in partnership with @arizeai and taught by @JohnGilhuly, Head of Developer Relations, and @_amankhan, Director of Product.\n\nI've often found evals to be a critical tool in the agent development process - they can be the difference between picking the right thing to work on vs. wasting weeks of effort. Whether you’re building a shopping assistant, coding agent, or research assistant, having a structured evaluation process helps you refine its performance systematically, rather than relying on random trial and error. \n\nThis course shows you how to structure your evals to assess the performance of each component of an agent and its end-to-end performance. For each component, you select the appropriate evaluators, test examples, and performance metrics. This helps you identify areas for improvement both during development and in production. (If you're familiar with error analysis in supervised learning, think of this as adapting those ideas to agentic workflows.) \n\nIn this course, you'll build an AI agent, and add observability to visualize and debug its steps. You’ll learn about code-based evals, in which you write code explicitly to test a certain step, as well as LLM-as-a-Judge evals, in which you prompt an LLM to efficiently come up with ways to evaluate more open-ended outputs.\n\nIn detail, you’ll:\n- Understand key differences between evaluating LLM-based systems and traditional software testing.\n- Add observability to an agent by collecting traces of the steps taken by the agent and visualizing them\n- Choose the appropriate evaluator - code-based, LLM-as-a-Judge, human-annotation based - for each component.\n- Compute a convergence score to evaluate if your agent can respond to a query in an efficient number of steps. \n- Run structured experiments to improve the agent’s performance by exploring changes to the prompt, LLM model, or the agent’s logic.\n- Understand how to deploy these evaluation techniques to monitor the agent’s performance in production.\n\nBy the end of this course, you’ll know how to trace AI agents, systematically evaluate them, and improve their performance.\n\nPlease sign up here: https://t.co/hTNCM8xuYn",
  "createdAt": "Wed Feb 19 17:01:23 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 241,
  "replyCount": 137,
  "likeCount": 1352,
  "quoteCount": 23,
  "viewCount": 124425,
  "bookmarkCount": 1064,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1891885809722327138",
  "url": "https://x.com/AndrewYNg/status/1891885809722327138",
  "text": "Credit also goes to Matthew Carrigan for the neat idea of getting function descriptions from docstrings:  https://t.co/CPLL1KxHE4",
  "createdAt": "Tue Feb 18 16:21:41 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 14,
  "replyCount": 27,
  "likeCount": 85,
  "quoteCount": 2,
  "viewCount": 35821,
  "bookmarkCount": 27,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1891885332058210787",
  "url": "https://x.com/AndrewYNg/status/1891885332058210787",
  "text": "Announcing new aisuite capability: Easy function calling with LLMs! Function calling (tool use) is an important capability for agentic workflows and other LLM applications, but is cumbersome for developers to use (left column in image). Our open-source aisuite package simplifies it to just one command (right column), and works for multiple LLM providers.\n\nHope this makes implementing agents easier for developers, and thanks Rohit Prsad & team for working with me on this! \n\nhttps://t.co/gwz9oKTCFx",
  "createdAt": "Tue Feb 18 16:19:47 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 244,
  "replyCount": 94,
  "likeCount": 1419,
  "quoteCount": 19,
  "viewCount": 111097,
  "bookmarkCount": 1006,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1890858116574839241",
  "url": "https://x.com/AndrewYNg/status/1890858116574839241",
  "text": "Among people in non-technical roles (recruiter, marketer, sales, ...) I notice the more technical ones being more effective, and the gap is increasing. E.g., the ones that took a coding course are outperforming the ones that didn't. Has anyone else noticed this? \n\nOne obvious theory is that they are better at using AI, but would love to hear if you have other theories.",
  "createdAt": "Sat Feb 15 20:18:00 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 173,
  "replyCount": 212,
  "likeCount": 1618,
  "quoteCount": 41,
  "viewCount": 262527,
  "bookmarkCount": 385,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1890452971747479715",
  "url": "https://x.com/AndrewYNg/status/1890452971747479715",
  "text": "To all my AI friends: You must be a good prompt, because whenever we chat, you complete me. \n\nHappy Valentine's Day! ❤️",
  "createdAt": "Fri Feb 14 17:28:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 135,
  "replyCount": 176,
  "likeCount": 1804,
  "quoteCount": 20,
  "viewCount": 104753,
  "bookmarkCount": 69,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1890076882391167317",
  "url": "https://x.com/AndrewYNg/status/1890076882391167317",
  "text": "At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here to talk about AI safety.... I’m here to talk about AI opportunity.” I’m thrilled to see the U.S. government focus on opportunities in AI. Further, while it is important to use AI responsibly and try to stamp out harmful applications, I feel “AI safety” is not the right terminology for addressing this important problem. Language shapes thought, so using the right words is important. I’d rather talk about “responsible AI” than “AI safety.” Let me explain.\n\nFirst, there are clearly harmful applications of AI, such as non-consensual deepfake porn (which creates sexually explicit images of real people without their consent), the use of AI in misinformation, potentially unsafe medical diagnoses, addictive applications, and so on. We definitely want to stamp these out! There are many ways to apply AI in harmful or irresponsible ways, and we should discourage and prevent such uses.\n\nHowever, the concept of “AI safety” tries to make AI — as a technology — safe, rather than making safe applications of it. Consider the similar, obviously flawed notion of “laptop safety.” There are great ways to use a laptop and many irresponsible ways, but I don’t consider laptops to be intrinsically either safe or unsafe. It is the application, or usage, that determines if a laptop is safe. Similarly, AI, a general-purpose technology with numerous applications, is neither safe nor unsafe. How someone chooses to use it determines whether it is harmful or beneficial.\n\nNow, safety isn’t always a function only of how something is used. An unsafe airplane is one that, even in the hands of an attentive and skilled pilot, has a large chance of mishap. So we definitely should strive to build safe airplanes (and make sure they are operated responsibly)! The risk factors are associated with the construction of the aircraft rather than merely its application. Similarly, we want safe automobiles, blenders, dialysis machines, food, buildings, power plants, and much more.\n\n“AI safety” presupposes that AI, the underlying technology, can be unsafe. I find it more useful to think about how applications of AI can be unsafe.\n\nFurther, the term “responsible AI” emphasizes that it is our responsibility to avoid building applications that are unsafe or harmful and to discourage people from using even beneficial products in harmful ways.\n\nIf we shift the terminology for AI risks from “AI safety” to “responsible AI,” we can have more thoughtful conversations about what to do and what not to do.\n\nI believe the 2023 Bletchley AI Safety Summit slowed down European AI development — without making anyone safer — by wasting time considering science-fiction AI fears rather than focusing on opportunities. Last month, at Davos, business and policy leaders also had strong concerns about whether Europe can dig itself out of the current regulatory morass and focus on building with AI. I am hopeful that the Paris meeting, unlike the one at Bletchley, will result in acceleration rather than deceleration.\n\nIn a world where AI is becoming pervasive, if we can shift the conversation away from “AI safety” toward responsible [use of] AI, we will speed up AI’s benefits and do a better job of addressing actual problems. That will actually make people safer.\n\n[Original text: https://t.co/uvjfNwXq4c ]",
  "createdAt": "Thu Feb 13 16:33:39 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 168,
  "replyCount": 113,
  "likeCount": 703,
  "quoteCount": 32,
  "viewCount": 75275,
  "bookmarkCount": 128,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1889766176059994166",
  "url": "https://x.com/AndrewYNg/status/1889766176059994166",
  "text": "New short course: Attention in Transformers: Concepts and Code in PyTorch.\n\nLast week we released a course on how LLM transformers work. This week, go deeper and learn about the technical ideas behind the attention mechanism, and see how to code it in PyTorch. This course is built with @joshuastarmer, Founder and CEO of StatQuest.\n\nThe attention mechanism was a breakthrough that led to transformers, the architecture powering large language models like ChatGPT. Transformers, introduced in the 2017 paper: \"Attention is All You Need\" by Viswani and others, took off because of its highly scalable design. \n\nIn this course, you’ll learn how the attention mechanism, a key element of transformer-based LLMs, works and implement it in PyTorch. You'll develop deep intuition about building reliable, functional, and scalable AI applications.\n\nWhat you will do:\n- Understand the evolution of the attention mechanism, a key breakthrough that led to transformers.\n- Learn the relationships between word embeddings, positional embeddings, and attention.\n- Learn about the Query, Key, and Value matrices, and how to produce and use them in attention.\n- Walk through the math required to calculate self-attention and masked self-attention to learn why and how they work.\n- Understand the difference between self-attention and masked self-attention and how one is used in the encoder to build context-aware embeddings and the other is used in the decoder for generative outputs.\n- Learn the details of the encoder-decoder architecture, cross-attention, and multi-head attention and how they are all incorporated into a transformer.\n- Use PyTorch to code a class that implements self-attention, masked self-attention, and multi-head attention.\n\nThere're lots of exciting technical details in this course.  Please sign up here: https://t.co/aAeNblXcYo",
  "createdAt": "Wed Feb 12 19:59:01 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 262,
  "replyCount": 54,
  "likeCount": 1799,
  "quoteCount": 19,
  "viewCount": 130865,
  "bookmarkCount": 1269,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1889380742263890238",
  "url": "https://x.com/AndrewYNg/status/1889380742263890238",
  "text": "VP @JDVance at the Paris AI Summit: \"I'm not here to talk about AI Safety... I'm here to talk about AI Opportunity.\" This is excellent! Thrilled to see the US gov   focus on opportunities in AI.",
  "createdAt": "Tue Feb 11 18:27:26 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 270,
  "replyCount": 209,
  "likeCount": 3366,
  "quoteCount": 42,
  "viewCount": 264091,
  "bookmarkCount": 163,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1889369284482351280",
  "url": "https://x.com/AndrewYNg/status/1889369284482351280",
  "text": "The U.S. imports over $3 trillion/year of goods. With Trump imposing new tariffs, import compliance is getting more complex. Fortunately, we have an AI agentic solution to help! \n\nLast summer, we saw the possibility of new tariffs in 2025, and partnered with Emil Stefanutti to build a solution. When importing a bicycle from Mexico, whether its tires are 20-24 inches or 25-28 inches changes the classification code and duty rate required in the import paperwork. That’s why tariff compliance can require specialized brokers pouring over thousands of pages of regulations. And if a product is described inaccurately in the paperwork, it can get stuck at the border for weeks. Now multiply this by the thousands of products traded worldwide on any given day. \n\nWith Gaia Dynamics, importers can enter a product name and description, answer targeted clarifying questions (such as the bicycle tire size), and get a recommendation for the best way to describe the product and also possible classification codes. Gaia also tracks changing tariffs, including rumored changes, to help with planning.\n\nGaia Dynamics is available at https://t.co/d9BKBVH8pz.",
  "createdAt": "Tue Feb 11 17:41:54 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 85,
  "replyCount": 83,
  "likeCount": 670,
  "quoteCount": 10,
  "viewCount": 74941,
  "bookmarkCount": 273,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1889003138612650081",
  "url": "https://x.com/AndrewYNg/status/1889003138612650081",
  "text": "Since DeepSeek R1's release, very quickly AWS, Azure, Fireworks AI, Groq, Hugging Face, SambaNova and Together AI all started to host R1 variants. What's the \"best\" model changes frequently, and so developers often want to try out new ones. The aisuite package, which helps developers do this quickly with minimal code changes.\n\nThanks Rohit Prsad & team for working with me on this!\n\nhttps://t.co/gwz9oKTCFx",
  "createdAt": "Mon Feb 10 17:26:58 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 280,
  "replyCount": 140,
  "likeCount": 1548,
  "quoteCount": 12,
  "viewCount": 145119,
  "bookmarkCount": 752,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1887919658201960807",
  "url": "https://x.com/AndrewYNg/status/1887919658201960807",
  "text": "A “10x engineer” — a widely accepted concept in tech — purportedly has 10 times the impact of the average engineer. But we don’t seem to talk about 10x marketers, 10x recruiters, or 10x financial analysts. As more jobs become AI enabled, I think this will change, and there will be a lot more “10x professionals.”\n\nThere aren’t already more 10x professionals because, in many roles, the gap between the best and the average worker has a ceiling. No matter how athletic a supermarket checkout clerk is, they’re not likely to scan groceries so fast that customers get out of the store 10x faster. Similarly, even the best doctor is unlikely to make patients heal 10x faster than an average one (but to a sick patient, even a small difference is worth a lot). In many jobs, the laws of physics place a limit on what any human or AI can do (unless we completely reimagine that job).\n\nBut for many jobs that primarily involve applying knowledge or processing information, AI will be transformative. In a few roles, I’m starting to see tech-savvy individuals coordinate a suite of technology tools to do things differently and start to have, if not yet 10x impact, then easily 2x impact. I expect this gap to grow.\n\n10x engineers don’t write code 10 times faster. Instead, they make technical architecture decisions that result in dramatically better downstream impact, they spot problems and prioritize tasks more effectively, and instead of rewriting 10,000 lines of code (or labeling 10,000 training examples) they might figure out how to write just 100 lines (or collect 100 examples) to get the job done.\n\nI think 10x marketers, recruiters, and analysts will, similarly, do things differently. For example, perhaps traditional marketers repeatedly write social media posts. 10x marketers might use AI to help write, but the transformation will go deeper than that. If they are deeply sophisticated in how to apply AI — ideally able to write code themselves to test ideas, automate tasks, or analyze data — they might end up running a lot more experiments, get better insights about what customers want, and generate much more precise or personalized messages than a traditional marketer, and thereby end up making 10x impact.\n\nSimilarly, 10x recruiters won’t just use generative AI to help write emails to candidates or summarize interviews. (This level of use of prompting-based AI will soon become table stakes for many knowledge roles.) They might coordinate a suite of AI tools to efficiently identify and carry out research on a large set of candidates, enabling them to have dramatically greater impact than the average recruiter. And 10x analysts won’t just use generative AI to edit their reports. They might write code to orchestrate a suite of AI agents to do deep research into the products, markets, and companies, and thereby derive far more valuable conclusions than someone who does research the traditional way.\n\nA 2023 Harvard/BCG study estimated that, provided with GPT-4, consultants could complete 12% more tasks, and completed tasks 25% more quickly. This was just the average, using 2023 technology. The maximum advantage to be gained by using AI in a sophisticated way will be much bigger, and will only grow as technology improves.\n\nHere in Silicon Valley, I see more and more AI-native teams reinvent workflows and do things very differently. In software engineering, we've venerated the best engineers because they can have a really massive impact. This has motivated many generations of engineers to keep learning and working hard, because doing those things increases the odds of doing high-impact work. As AI becomes more helpful in many more job roles, I believe we will open up similar paths to a lot more people becoming a “10x professional.”\n\n[Original text: https://t.co/svQYHp3XVW ]",
  "createdAt": "Fri Feb 07 17:41:37 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 233,
  "replyCount": 161,
  "likeCount": 1302,
  "quoteCount": 61,
  "viewCount": 183554,
  "bookmarkCount": 849,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1887542467173753282",
  "url": "https://x.com/AndrewYNg/status/1887542467173753282",
  "text": "@Nimaano_ Thanks!",
  "createdAt": "Thu Feb 06 16:42:47 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 13,
  "quoteCount": 0,
  "viewCount": 5651,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1887533748205592656",
  "url": "https://x.com/AndrewYNg/status/1887533748205592656",
  "text": "You can also play with the demo here: https://t.co/3kZJPmwUD4",
  "createdAt": "Thu Feb 06 16:08:08 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 31,
  "replyCount": 26,
  "likeCount": 135,
  "quoteCount": 0,
  "viewCount": 37615,
  "bookmarkCount": 109,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1887533627275419690",
  "url": "https://x.com/AndrewYNg/status/1887533627275419690",
  "text": "Introducing Agentic Object Detection!\n\nGiven a text prompt like “unripe strawberries” or “Kellogg’s branded cereal” and an image, we use an agentic workflow to reason at length and detect the specified objects. No need to label any training data. Watch the video for details.",
  "createdAt": "Thu Feb 06 16:07:40 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 722,
  "replyCount": 199,
  "likeCount": 4560,
  "quoteCount": 101,
  "viewCount": 395018,
  "bookmarkCount": 3677,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1887184924165492940",
  "url": "https://x.com/AndrewYNg/status/1887184924165492940",
  "text": "Announcing How Transformer LLMs Work, created with @JayAlammar and @MaartenGr, co-authors of the beautifully illustrated book, “Hands-On Large Language Models.”\n\nThis course offers a deep dive into the inner workings of the transformer architecture that powers large language models (LLMs).\n\nThe transformer architecture revolutionized generative AI; in fact, the \"GPT\" in ChatGPT stands for \"Generative Pre-Trained Transformer.\" Originally introduced in the Google Brain team's groundbreaking 2017 paper \"Attention Is All You Need,\" by Vaswani and others, transformers were a highly scalable model for machine translation tasks. Variants of this architecture now power today’s LLMs such as those from OpenAI, Google, Meta, Cohere, Anthropic and DeepSeek.\n\nIn this course, you’ll learn in detail how LLMs process text. You'll also work through code examples that illustrate that transformer's individual components.\n\nIn details, you’ll learn:\n- How the representation of language has evolved, from  Bag-of-Words to Word2Vec embeddings to the transformer architecture that captures a word's meanings taking into account the context of other words in the input.\n- How inputs are broken down into tokens before they are sent to the language model.\n- The details of a transformer's main stages: Tokenization and embedding, the stack of transformer blocks, and the language model head.\n- The inner workings of the transformer block, including attention, which calculates relevance scores, and the feedforward layer, which incorporates stored information learned in training.\n- How cached calculations make transformers faster.\n- Some of the most recent ideas in the latest models such as Mixture-of-Experts (MoE) which uses multiple sub-models and a router on each layer to improve the quality of LLMs.\n\nBy the end of this course, you’ll have a deep understanding of how LLMs actually process text and  be able to read through papers describing the latest models and understand the details.\n\nGaining this intuition will improve your approach to building LLM applications.\n\nPlease sign up here: https://t.co/hdTUASuEbb",
  "createdAt": "Wed Feb 05 17:02:02 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 258,
  "replyCount": 44,
  "likeCount": 1594,
  "quoteCount": 19,
  "viewCount": 236843,
  "bookmarkCount": 1308,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1886871011578273818",
  "url": "https://x.com/AndrewYNg/status/1886871011578273818",
  "text": "Thank you @NYSE for highlighting Coursera on your trading floor to help us celebrate Greg Hart joining as our CEO! 🎉 https://t.co/JNe3wvPyNY",
  "createdAt": "Tue Feb 04 20:14:40 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 43,
  "replyCount": 24,
  "likeCount": 1083,
  "quoteCount": 3,
  "viewCount": 70298,
  "bookmarkCount": 37,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1886833904235241753",
  "url": "https://x.com/AndrewYNg/status/1886833904235241753",
  "text": "Announcing AI Dev 25: A conference for AI developers, this Pi day (3/14/2025)!\n\nThere're great AI academic conferences for researchers (NeurIPS, ICLR, ICML, etc.) and some companies hold great meetings around their products (Google I/O, OpenAI DevDay, etc.). But we need more vendor-neutral meetings for AI developers, so I decided to organize this. \n\nThis is a technical meeting, and we'll have >400 developers gathering in-person in San Francisco to build, share ideas, and network.\n\nThis will be fun! https://t.co/i4bQevDG4i",
  "createdAt": "Tue Feb 04 17:47:13 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 94,
  "replyCount": 160,
  "likeCount": 630,
  "quoteCount": 14,
  "viewCount": 72526,
  "bookmarkCount": 148,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1885522069301211562",
  "url": "https://x.com/AndrewYNg/status/1885522069301211562",
  "text": "@StanfordHAI @landay @erikbryn @alex_pentland @YejinChoinka Fun event, and great to see @StanfordHAI have such a strong presence at WEF. Thank you @landay for organizing this!",
  "createdAt": "Sat Feb 01 02:54:27 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1,
  "replyCount": 4,
  "likeCount": 14,
  "quoteCount": 0,
  "viewCount": 6579,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1885033810552905814",
  "url": "https://x.com/AndrewYNg/status/1885033810552905814",
  "text": "The buzz over DeepSeek this week crystallized, for many people, a few important trends that have been happening in plain sight: (i) China is catching up to the U.S. in generative AI, with implications for the AI supply chain. (ii) Open weight models are commoditizing the foundation-model layer, which creates opportunities for application builders. (iii) Scaling up isn’t the only path to AI progress. Despite the massive focus on and hype around processing power, algorithmic innovations are rapidly pushing down training costs.\n\nAbout a week ago, DeepSeek, a company based in China, released DeepSeek-R1, a remarkable model whose performance on benchmarks is comparable to OpenAI’s o1. Further, it was released as an open weight model with a permissive MIT license. At Davos last week, I got a lot of questions about it from non-technical business leaders. And on Monday, the stock market saw a “DeepSeek selloff”: The share prices of Nvidia and a number of other U.S. tech companies plunged. (As of the time of writing, some have recovered somewhat.)\n\nHere’s what I think DeepSeek has caused many people to realize:\n\nChina is catching up to the U.S. in generative AI. When ChatGPT was launched in November 2022, the U.S. was significantly ahead of China in generative AI. Impressions change slowly, and so even recently I heard friends in both the U.S. and China say they thought China was behind. But in reality, this gap has rapidly eroded over the past two years. With models from China such as Qwen (which my teams have used for months), Kimi, InternVL, and DeepSeek, China had clearly been closing the gap, and in areas such as video generation there were already moments where China seemed to be in the lead.\n\nI’m thrilled that DeepSeek-R1 was released as an open weight model, with a technical report that shares many details. In contrast, a number of U.S. companies have pushed for regulation to stifle open source by hyping up hypothetical AI dangers such as human extinction. It is now clear that open source/open weight models are a key part of the AI supply chain: Many companies will use them. If the U.S. continues to stymie open source, China will come to dominate this part of the supply chain and many businesses will end up using models that reflect China’s values much more than America’s.\n\nOpen weight models are commoditizing the foundation-model layer. As I wrote previously, LLM token prices have been falling rapidly, and open weights have contributed to this trend and given developers more choice. OpenAI’s o1 costs $60 per million output tokens; DeepSeek R1 costs $2.19. This nearly 30x difference brought the trend of falling prices to the attention of many people.\n\nThe business of training foundation models and selling API access is tough. Many companies in this area are still looking for a path to recouping the massive cost of model training. Sequoia’s article “AI’s $600B Question” lays out the challenge well (but, to be clear, I think the foundation model companies are doing great work, and I hope they succeed). In contrast, building applications on top of foundation models presents many great business opportunities. Now that others have spent billions training such models, you can access these models for mere dollars to build customer service chatbots, email summarizers, AI doctors, legal document assistants, and much more.\n\nScaling up isn’t the only path to AI progress. There’s been a lot of hype around scaling up models as a way to drive progress. To be fair, I was an early proponent of scaling up models. A number of companies raised billions of dollars by generating buzz around the narrative that, with more capital, they could (i) scale up and (ii) predictably drive improvements. Consequently, there has been a huge focus on scaling up, as opposed to a more nuanced view that gives due attention to the many different ways we can make progress. Driven in part by the U.S. AI chip embargo, the DeepSeek team had to innovate on many optimizations to run on less-capable H800 GPUs rather than H100s, leading ultimately to a model trained (omitting research costs) for under $6M of compute.\n\nIt remains to be seen if this will actually reduce demand for compute. Sometimes making each unit of a good cheaper can result in more dollars in total going to buy that good. I think the demand for intelligence and compute has practically no ceiling over the long term, so I remain bullish that humanity will use more intelligence even as it gets cheaper.\n\nI saw many different interpretations of DeepSeek’s progress here in X, as if it was a Rorschach test that allowed many people to project their own meaning onto it. I think DeepSeek-R1 has geopolitical implications that are yet to be worked out. And it’s also great for AI application builders. My team has already been brainstorming ideas that are newly possible only because we have easy access to an open advanced reasoning model. This continues to be a great time to build!\n\n[Original text: https://t.co/yiOHeGJgLZ ]",
  "createdAt": "Thu Jan 30 18:34:17 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1048,
  "replyCount": 290,
  "likeCount": 4405,
  "quoteCount": 128,
  "viewCount": 614217,
  "bookmarkCount": 1983,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1884723330839961664",
  "url": "https://x.com/AndrewYNg/status/1884723330839961664",
  "text": "Welcome Greg Hart as Coursera’s incoming CEO!\n\nI’m thrilled to announce that Greg will be joining Coursera as CEO, succeeding Jeff Maggioncalda after seven remarkable years of leadership.\n\nJeff has been an extraordinary leader. Under his guidance, Coursera has grown into a global platform serving over 160 million learners, expanded our partnerships to over 350 world-class universities and industry leaders, and debuted as a public company. Coursera exists to serve learners, and Jeff’s unwavering commitment to our goal of transforming lives through learning leaves an enduring legacy. I’m deeply grateful for his leadership, dedication, and partnership throughout this journey.\n\nAnd, I’m thrilled to welcome Greg Hart as our next CEO. Greg brings over 25 years of experience in technology-driven innovation and operational excellence, including leading the development and launch of Amazon Alexa and scaling Prime Video globally. At Compass, the leading real estate brokerage in the US, Greg served as Chief Product Officer and later Chief Operating Officer, where he helped take the company public and led the development of its industry-leading technology platform. His ability to combine strategic vision with operational excellence, coupled with his passion for education, makes him the ideal choice to lead Coursera into its next chapter.\n\nCoursera was founded with a mission to provide universal access to world-class learning. I’m grateful for everyone who has contributed to this journey – learners, educators, our team, and our many partners who have helped us advance this vision in countless ways. Yet, demand for high-quality training continues to grow, and our mission is far from complete. As we enter this next chapter, I’m excited about Greg’s leadership and what the exceptional Coursera team will do. We will keep working hard to serve learners everywhere!\n\n https://t.co/chvmwiqVGi",
  "createdAt": "Wed Jan 29 22:00:33 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 41,
  "replyCount": 34,
  "likeCount": 552,
  "quoteCount": 2,
  "viewCount": 61656,
  "bookmarkCount": 41,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1883972263177072730",
  "url": "https://x.com/AndrewYNg/status/1883972263177072730",
  "text": "Today's \"DeepSeek selloff\" in the stock market -- attributed to DeepSeek V3/R1 disrupting the tech ecosystem -- is another sign that the application layer is a great place to be. The foundation model layer being  hyper-competitive is great for people building applications.",
  "createdAt": "Mon Jan 27 20:16:04 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1027,
  "replyCount": 243,
  "likeCount": 7160,
  "quoteCount": 194,
  "viewCount": 789390,
  "bookmarkCount": 1230,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1882828225979760651",
  "url": "https://x.com/AndrewYNg/status/1882828225979760651",
  "text": "Discussion at Davos with @Yoshua_Bengio, @YejinChoinka, @JonathanRoss321, @Thom_Wolf moderated by @nxthompson. We share excitement for the future of AI, the science to be done, and the many things yet to be built. Take a look!",
  "createdAt": "Fri Jan 24 16:30:04 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 57,
  "replyCount": 49,
  "likeCount": 274,
  "quoteCount": 7,
  "viewCount": 75434,
  "bookmarkCount": 106,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1882125891821822398",
  "url": "https://x.com/AndrewYNg/status/1882125891821822398",
  "text": "Our first short course with @AnthropicAI! Building Towards Computer Use with Anthropic. This teaches you to build an LLM-based agent that uses a computer interface by generating mouse clicks and keystrokes. Computer Use is an important, emerging capability for LLMs that will let AI agents do many more tasks than were possible before, since it lets them interact with interfaces designed for humans to use, rather than only tools that provide explicit API access. I hope you will enjoy learning about it!\n\nThis course is taught by Anthropic's Head of Curriculum,  @Colt_Steele. You'll learn to apply image reasoning and tool use to \"use\" a computer as follows: a model processes an image of the screen, analyzes it to understand what's going on, and navigates the computer via mouse clicks and keystrokes.\n\nThis course goes through the key building blocks, and culminates in a demo of an AI assistant that uses a web browser to search for a research paper, downloads the PDF, and finally summarizes the paper for you.\n\nIn detail, you’ll:\n- Learn about Anthropic's family of models, when to use which one, and make API requests to Claude\n- Use multi-modal prompts that combine text and image content blocks, and also work with streaming responses\n- Improve your prompting by using prompt templates, using XML to structure prompts, and providing examples\n- Implement prompt caching to reduce cost and latency\n- Apply tool-use to build a chatbot that can call different tools to respond to queries\n- See all these building blocks come together in Computer Use demo\n\nPlease sign up here: https://t.co/lM3m6zsJ40",
  "createdAt": "Wed Jan 22 17:59:15 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 321,
  "replyCount": 48,
  "likeCount": 2181,
  "quoteCount": 17,
  "viewCount": 168406,
  "bookmarkCount": 1973,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1880728653329514606",
  "url": "https://x.com/AndrewYNg/status/1880728653329514606",
  "text": "Save the date! Pi day (3.14) is coming soon and I'm thinking of organizing something fun and in-person for AI developers in the San Francisco area. More details to come!",
  "createdAt": "Sat Jan 18 21:27:07 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 55,
  "replyCount": 53,
  "likeCount": 739,
  "quoteCount": 6,
  "viewCount": 68313,
  "bookmarkCount": 51,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1879939058211971420",
  "url": "https://x.com/AndrewYNg/status/1879939058211971420",
  "text": "Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!\n\nSoftware is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build.\n\nThis is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products.\n\nMany companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow.\n\nThis change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow.\n\nFurther, AI Product Management requires a different set of skills than traditional software Product Management. It requires:\n- Technical proficiency in AI. PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.\n- Iterative development. Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need be able to manage such a process.\n- Data proficiency. AI products often learn from data, and they can be designed to generate richer forms of data than traditional software.\n- Skill in managing ambiguity. Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it.\n- Ongoing learning. AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives.\n\nFinally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at gathering feedback fast to keep projects moving. Increasingly, I also expect strong product managers to be able to build prototypes for themselves.\n\nThe demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.\n\nThe variety of valuable things we can build is nearly unlimited. What a great time to build!\n\n[Original text: https://t.co/OIeAQXpriK ]",
  "createdAt": "Thu Jan 16 17:09:33 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1023,
  "replyCount": 187,
  "likeCount": 5439,
  "quoteCount": 198,
  "viewCount": 875043,
  "bookmarkCount": 4685,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1879641293401502163",
  "url": "https://x.com/AndrewYNg/status/1879641293401502163",
  "text": "@nedteneva @realavatarai @DeepLearningAI I've really enjoyed working with you @nedteneva on the tech powering this -- thank you!",
  "createdAt": "Wed Jan 15 21:26:21 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 1,
  "quoteCount": 0,
  "viewCount": 1559,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1879641073880076513",
  "url": "https://x.com/AndrewYNg/status/1879641073880076513",
  "text": "@dimapyanov @realavatarai It has been great fun working with you on the product  @dimapyanov -- thank you!",
  "createdAt": "Wed Jan 15 21:25:28 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 1,
  "replyCount": 1,
  "likeCount": 13,
  "quoteCount": 0,
  "viewCount": 5991,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1879590674561110219",
  "url": "https://x.com/AndrewYNg/status/1879590674561110219",
  "text": "Something fun: AI Avatar of me built, by https://t.co/zpIxRSuky4 and @realavatarai. \n\nVideo has details. This is a work in progress, but please come chat with me in avatar form, and let me know what you think!\n\nhttps://t.co/vMO2CM0xfb\n\nThank you Jeff Daniel @consciouspilot and team for working with us on this!",
  "createdAt": "Wed Jan 15 18:05:12 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 158,
  "replyCount": 65,
  "likeCount": 997,
  "quoteCount": 22,
  "viewCount": 107480,
  "bookmarkCount": 491,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1879253685232144487",
  "url": "https://x.com/AndrewYNg/status/1879253685232144487",
  "text": "Just released: New AI Climate Simulator that you can play with. Visualize how geoengineering can slow global warming. \n\nThere is no longer any path to limiting warming to 1.5 degrees Celsius (Paris Agreement), unless we use geoengineering. Reflecting 1% of sunlight away from earth would lead to an extra ~1 degree of cooling.\n\nOur simulator lets you explore how geoengineering via Stratospheric Aerosol Injection (SAI) gives us new paths to keep warming to 1.5 degrees. I think SAI is a promising technology worth serious exploration. Check out the simulator here: https://t.co/OxtaQMyDuL\n\nBig thanks to collaborators @jeremy_irvin16, Jake Dexheimer, @dakotagruener, Charlotte DeWald, @DanVisioni, @DWatsonParris, @DougMacMartin, Joshua Elliott, Juerg Luterbacher, Kion Yaghoobzadeh",
  "createdAt": "Tue Jan 14 19:46:08 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 349,
  "replyCount": 166,
  "likeCount": 1853,
  "quoteCount": 69,
  "viewCount": 169765,
  "bookmarkCount": 778,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1877405010893619238",
  "url": "https://x.com/AndrewYNg/status/1877405010893619238",
  "text": "Using AI-assisted coding to build software prototypes is an important way to quickly explore many ideas and invent new things. In this and future posts, I’d like to share with you some best practices for prototyping simple web apps. This post will focus on one idea: being opinionated about the software stack.\n\nThe software stack I personally use changes every few weeks. There are many good alternatives to these choices, and if you pick a preferred software stack and become familiar with its components, you’ll be able to develop more quickly. But as an illustration, here’s my current default:\n- Python with FastAPI for building web-hosted APIs: I develop primarily in Python, so that’s a natural choice for me. If you’re a JavaScript/TypeScript developer, you’ll likely make a different choice. I’ve found FastAPI really easy to use and scalable for deploying web services (APIs) hosted in Python.\n- Uvicorn to run the backend application server (to execute code and serve web pages) for local testing on my laptop.\n- If deploying on the cloud, then either Heroku for small apps or AWS Elastic Beanstalk for larger ones (disclosure: I serve on Amazon’s board of directors): There are many services for deploying jobs, including HuggingFace Spaces, Railway, Google’s Firebase, Vercel, and others. Many of these work fine, and becoming familiar with just 1 or 2 will simplify your development process.\n- MongoDB for NoSQL database: While traditional SQL databases are amazing feats of engineering that result in highly efficient and reliable data storage, the need to define the database structure (or schema) slows down prototyping. If you really need speed and ease of implementation, then dumping most of your data into a NoSQL (unstructured or semi-structured) database such as MongoDB lets you write code quickly and sort out later exactly what you want to do with the data. This is sometimes called schema-on-write, as opposed to schema-on-read. Mind you, if an application goes to scaled production, there are many use cases where a more structured SQL database is significantly more reliable and scalable.\n- OpenAI’s o1 and Anthropic’s Claude 3.5 Sonnet for coding assistance, often by prompting directly (when operating at the conceptual/design level). Also occasionally Cursor (when operating at the code level).  I hope never to have to code again without AI assistance! Claude 3.5 Sonnet is widely regarded as one of the best coding models. And o1 is incredible at planning and building more complex software modules, but you do have to learn to prompt it differently.\n\nOn top of all this, of course, I use many AI tools to manage agentic workflows, data ingestion, retrieval augmented generation, and so on. https://t.co/zpIxRSuky4 and our wonderful partners offer courses on many of these tools.\n\nMy personal software stack continues to evolve regularly. Components enter or fall out of my default stack every few weeks as I learn new ways to do things. So please don’t feel obliged to use the components I do, but perhaps some of them can be a helpful starting point if you are still deciding what to use. Interestingly, I have found most LLMs not very good at recommending a software stack. I suspect their training sets include too much “hype” on specific choices, so I don’t fully trust them to tell me what to use. And if you can be opinionated and give your LLM directions on the software stack you want it to build on, I think you’ll get better results.\n\nA lot of the software stack is still maturing, and I think many of these components will continue to improve. With my stack, I regularly build prototypes in hours that, without AI assistance, would have taken me days or longer. I hope you, too, will have fun building many prototypes!\n\n[Original text: https://t.co/cfQkXolEJk ]",
  "createdAt": "Thu Jan 09 17:20:09 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 453,
  "replyCount": 122,
  "likeCount": 3106,
  "quoteCount": 47,
  "viewCount": 290616,
  "bookmarkCount": 3192,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1877075439283482815",
  "url": "https://x.com/AndrewYNg/status/1877075439283482815",
  "text": "New short course: Build Long-Context AI Apps with Jamba. Learn about state space models (SSMs), which have emerged as an alternative to transformers!  Specifically, Jamba is a hybrid transformer-Mamba architecture that combines strengths of the transformer with ideas from SSMs. This course is built with  @AI21Labs and taught by @chenwai21 and @AlmagorChen.\n\nThe transformer architecture is computationally expensive when handling very long input contexts. But there's an alternative called Mamba, a selective state space model that can process very long contexts with a much lower computational cost. However, researchers found that the pure Mamba architecture underperforms in understanding the context, and gives lower-quality responses. To overcome this, AI21 developed the Jamba model, which combines Mamba's computational efficiency with the transformer's attention mechanism to help with the output quality.\n\nIn this course, you’ll learn about how state space models, and Jamba, work. You’ll also learn how to prompt Jamba, use it to process long documents, and build long-context RAG apps.\n\n- Learn how Jamba combines transformer and state space model architectures to achieve high performance and quality  \n- Use the AI21 SDK, with an example of prompting over a large 200k-token annual financial report of Nvidia \n- Use Jamba for tool-calling, with hands-on examples from calling simple arithmetic calculations to a function that returns quarterly company financial reports.\n- Learn how training for long context is done, and the metrics used for its evaluation \n- Create a RAG app using the AI21 Conversational RAG tool and build your own RAG pipeline that uses Jamba and LangChain.\n\nBy the end of this course, you'll learn how to build applications that can handle context as long as an entire book.\n\nPlease sign up here: https://t.co/qc6St7zK9g",
  "createdAt": "Wed Jan 08 19:30:33 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 149,
  "replyCount": 45,
  "likeCount": 803,
  "quoteCount": 11,
  "viewCount": 76546,
  "bookmarkCount": 586,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1876701823840776521",
  "url": "https://x.com/AndrewYNg/status/1876701823840776521",
  "text": "Where is AI going? Six leaders share their hopes for AI in the coming year, in The Batch:\n- Hanno Basse: Generative AI for Artists\n- David Ding: Generated Video With Music, Sound Effects, and Dialogue\n- Joseph Gonzalez: General Intelligence\n- Albert Gu: More Learning, Less Data\n- Mustafa Suleyman: Agents of Action\n- Audrey Tang: AI That Unites Us\n\nThank you @BasseHanno , @DavidDingAI, @profjoeyg, @_albertgu, @mustafasuleyman and @audreyt for writing these!  \n\nRead them here: https://t.co/YgfCpE6FL8",
  "createdAt": "Tue Jan 07 18:45:56 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 219,
  "replyCount": 57,
  "likeCount": 1158,
  "quoteCount": 13,
  "viewCount": 135246,
  "bookmarkCount": 706,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1876402210931867825",
  "url": "https://x.com/AndrewYNg/status/1876402210931867825",
  "text": "Hanging out ⁦⁦with @astroteller⁩ at Google X reminiscing about the early days of Google Brain! https://t.co/2j2QWnHiTz",
  "createdAt": "Mon Jan 06 22:55:23 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 41,
  "replyCount": 23,
  "likeCount": 440,
  "quoteCount": 3,
  "viewCount": 45532,
  "bookmarkCount": 21,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1874923856835772811",
  "url": "https://x.com/AndrewYNg/status/1874923856835772811",
  "text": "@nickclegg Thank you for your work championing open source to policymakers @nickclegg -- this has made a real difference!",
  "createdAt": "Thu Jan 02 21:00:56 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 0,
  "replyCount": 3,
  "likeCount": 40,
  "quoteCount": 0,
  "viewCount": 32247,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1874922734444236810",
  "url": "https://x.com/AndrewYNg/status/1874922734444236810",
  "text": "Despite having worked on AI since I was a teenager, I’m now more excited than ever about what we can do with it, especially in building AI applications. Sparks are flying in our field, and 2025 will be a great year for building!\n\nOne aspect of AI that I’m particularly excited about is how easy it is to build software prototypes. AI is lowering the cost of software development and expanding the set of possible applications. While it can help extend or maintain large software systems, it shines particularly in building prototypes and other simple applications quickly.\n\nIf you want to build an app to print out flash cards for your kids (I just did this in a couple of hours with o1’s help), or write an application that monitors foreign exchange rates to manage international bank accounts (a real example from https://t.co/zpIxRSuky4’s finance team), or analyzes user reviews automatically to quickly flag problems with your products (https://t.co/zpIxRSuky4's content team does this), it is now possible to build these applications quickly through AI-assisted coding.\n\nI find AI-assisted coding especially effective for prototyping because (i) stand-alone prototypes require relatively little context and software integration and (ii) prototypes in alpha testing usually don’t have to be reliable. While generative AI also helps with engineering large, mission-critical software systems, the improvements in productivity there aren't as dramatic, because it’s challenging to give the AI system all the context it needs to navigate a large codebase and also to make sure the generated code is reliable (for example, covering all important corner cases).\n\nUntil now, a huge friction point for getting a prototype into users’ hands has been deployment. Platforms like Bolt, Replit Agent, Vercel V0 use generative AI with agentic workflows to improve code quality, but more importantly, they also help deploy generated applications directly. (While I find these systems useful, my own workflow typically uses an LLM to design the system architecture and then generate code, one module at a time if there are multiple large modules. Then I test each module, edit the code further if needed — sometimes using an AI-enabled IDE like Cursor — and finally assemble the modules.)\n\nBuilding prototypes quickly is an efficient way to test ideas and get tasks done. It’s also a great way to learn. Perhaps most importantly, it’s really fun! (At least I think it is. 😄)\n\nHow can you take advantage of these opportunities in the coming year? As you form new year resolutions, I hope you will:\n- Make a learning plan! To be effective builders, we all need to keep up with the exciting changes that continue to unfold. How many short courses a month do you want to take in 2025? If you discuss your learning plan with friends, you can help each other along. For instance, we launched a learning summary page that shows what short courses people have taken. A few https://t.co/zpIxRSuky4 team members have agreed to a friendly competition to see who can take more courses in 2025!\n- Go build! If you already know how to code, I encourage you to build prototypes whenever inspiration strikes and you have a spare moment. And if you don’t yet code, it will be well worth your while to learn. Even small wins — like the flash cards I printed out, which inspired my daughter to spend an extra 20 minutes practicing her multiplication table — make life better. Perhaps you’ll invent something that really takes off. And even if you don’t, you’ll have fun and learn a lot along the way.\n\n[Original text: https://t.co/YgfCpE6FL8 ]",
  "createdAt": "Thu Jan 02 20:56:28 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 523,
  "replyCount": 126,
  "likeCount": 3360,
  "quoteCount": 40,
  "viewCount": 287241,
  "bookmarkCount": 1916,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1874495593827156120",
  "url": "https://x.com/AndrewYNg/status/1874495593827156120",
  "text": "Happy sum(i**3 for i in range(10)) !",
  "createdAt": "Wed Jan 01 16:39:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_normal.jpg",
  "retweetCount": 307,
  "replyCount": 98,
  "likeCount": 3050,
  "quoteCount": 50,
  "viewCount": 266970,
  "bookmarkCount": 133,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": -1,
  "text": "Since you are a free user, you can only access a maximum of 15 tweets. Please upgrade to a paid user to unlock access to all tweets."
}]