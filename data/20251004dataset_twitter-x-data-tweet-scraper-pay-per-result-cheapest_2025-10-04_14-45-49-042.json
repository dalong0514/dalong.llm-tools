[{
  "id": "1974484694273323289",
  "url": "https://x.com/karpathy/status/1974484694273323289",
  "text": "@Addiedesignco @seflless email is too formal. the whole idea here is specifically to create a reality escape valve for a formal process.",
  "createdAt": "Sat Oct 04 14:40:09 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 3,
  "quoteCount": 0,
  "viewCount": 136,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1974484350742978801",
  "url": "https://x.com/karpathy/status/1974484350742978801",
  "text": "@daniel_mac8 @OfficialLoganK yep, was in my mind as one example.",
  "createdAt": "Sat Oct 04 14:38:48 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 12,
  "quoteCount": 0,
  "viewCount": 501,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1974483612482634219",
  "url": "https://x.com/karpathy/status/1974483612482634219",
  "text": "@seflless Email doesn't work. It has to be DM. I don't know why, it just feels right.",
  "createdAt": "Sat Oct 04 14:35:52 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 1,
  "likeCount": 12,
  "quoteCount": 0,
  "viewCount": 733,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1974482521862865154",
  "url": "https://x.com/karpathy/status/1974482521862865154",
  "text": "Every company needs a DM POC - someone high up who you can just DM the most obvious things and who shortcuts the PM hierarchy.",
  "createdAt": "Sat Oct 04 14:31:31 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 11,
  "replyCount": 53,
  "likeCount": 269,
  "quoteCount": 5,
  "viewCount": 14809,
  "bookmarkCount": 34,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1974116645984743932",
  "url": "https://x.com/karpathy/status/1974116645984743932",
  "text": "@manca1 Good point! Maybe one prominent example for me is writing all kinds of \"one off\" stuff for dev work. E.g. I'll take 2000 lines  of ephemeral code just to help me find a single bug, but once I find &amp; fix it, I can just delete all of that code. Or a lot of vis low stakes code, etc.",
  "createdAt": "Fri Oct 03 14:17:40 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 0,
  "likeCount": 17,
  "quoteCount": 0,
  "viewCount": 1189,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1974110383423304101",
  "url": "https://x.com/karpathy/status/1974110383423304101",
  "text": "@timmolendijk yeah i see a few people say something similar in the replys, i could probably see it. it could basically be that a lot of industry software engineering work is essentially in the \"boilerplate\" category.",
  "createdAt": "Fri Oct 03 13:52:47 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 6,
  "likeCount": 39,
  "quoteCount": 0,
  "viewCount": 2264,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973898715053334908",
  "url": "https://x.com/karpathy/status/1973898715053334908",
  "text": "@0xKalos my reaction exactly fwiw",
  "createdAt": "Thu Oct 02 23:51:41 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 5,
  "likeCount": 133,
  "quoteCount": 0,
  "viewCount": 10966,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973895042684330243",
  "url": "https://x.com/karpathy/status/1973895042684330243",
  "text": "@jdchawla29 Yeah one more person pointed out already. I'd say it falls under \"agent\" because an LLM is still giving you a large chunk of code that you're slotting in.",
  "createdAt": "Thu Oct 02 23:37:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 5,
  "likeCount": 88,
  "quoteCount": 0,
  "viewCount": 16157,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973892769359056997",
  "url": "https://x.com/karpathy/status/1973892769359056997",
  "text": "For your professional programming do you use mostly:",
  "createdAt": "Thu Oct 02 23:28:04 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 57,
  "replyCount": 211,
  "likeCount": 1197,
  "quoteCount": 32,
  "viewCount": 305079,
  "bookmarkCount": 197,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1973877447415443700",
  "url": "https://x.com/karpathy/status/1973877447415443700",
  "text": "@gregisenberg I‚Äôve been doing this for a while, you don‚Äôt ‚Äúuse ChatGPT‚Äù you ‚Äúask chat‚Äù. Much cleaner.",
  "createdAt": "Thu Oct 02 22:27:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 40,
  "likeCount": 383,
  "quoteCount": 4,
  "viewCount": 60127,
  "bookmarkCount": 16,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973776784429842912",
  "url": "https://x.com/karpathy/status/1973776784429842912",
  "text": "Btw people should check out @alexisxrivas / @coverbuild, which is really cool and I've followed for a while. I think I'm just developing an allergy to some disease in culture that I'm working through. Separately from functional, scalable, affordable... we have to build CATHEDRALS again. Applying miracles of modern technology. To take people's breath away. To shake Olympus in jealousy.",
  "createdAt": "Thu Oct 02 15:47:11 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 16,
  "replyCount": 24,
  "likeCount": 254,
  "quoteCount": 2,
  "viewCount": 26264,
  "bookmarkCount": 26,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973762212956406266",
  "url": "https://x.com/karpathy/status/1973762212956406266",
  "text": "@alexisxrivas Dream kitchen, without the contemporary minimalism psyop. But also a big fan of functional and affordable. https://t.co/5vAVtmiOIh",
  "createdAt": "Thu Oct 02 14:49:16 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 13,
  "replyCount": 88,
  "likeCount": 942,
  "quoteCount": 6,
  "viewCount": 60127,
  "bookmarkCount": 71,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973756330449236009",
  "url": "https://x.com/karpathy/status/1973756330449236009",
  "text": "Hah judging by mentions overnight people seem to find the ghost analogy provocative. I swear I don't wake up just trying to come with new memes but to elaborate briefly why I thought it was a fun comparison:\n\n1) It captures the idea that LLMs are purely digital artifacts that don't interact with the physical world (unlike animals, which are very embodied).\n2) Ghosts are a kind of \"echo\" of the living, in this case a statistical distillation of humanity.\n3) There is an air of mystery over both ghosts and LLMs, as in we don't fully understand what they are or how they work.\n4) The process of training LLMs is a bit like summoning a ghost, i.e. a kind of elaborate computational ritual on a summoning platform of an exotic megastructure (GPU cluster). I've heard earlier references of LLM training as that of \"summoning a demon\" and it never sounded right because it implies and presupposes evil. Ghosts are a lot more neural entity just like LLMs, and may or may not be evil. For example, one of my favorite cartoons when I was a child was Casper the Friendly Ghost, clearly a friendly and wholesome entity. Same in Harry Potter, e.g. Nearly Headless Nick and such.\n5) It is a nod to an earlier reference \"ghost in the machine\", in the context of Decartes' mind-body dualism, and of course later derived references, \"Ghost in the shell\" etc. As in the mind (ghost) that animates a body (machine).\n\nProbably a few other things in the embedding space. Among the ways the analogy isn't great is that while ghosts may or may not be evil, they are almost always spooky, which feels too unfair. But anyway, I like that while no analogy is perfect, they let you pull in structure laterally from one domain to another as as a way of generating entropy and reaching unique thoughts.",
  "createdAt": "Thu Oct 02 14:25:54 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 54,
  "replyCount": 69,
  "likeCount": 797,
  "quoteCount": 43,
  "viewCount": 183193,
  "bookmarkCount": 286,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973474834949759107",
  "url": "https://x.com/karpathy/status/1973474834949759107",
  "text": "@rasbt yep üíØ! Using closed model API should feel quite unsettling when there is no recourse.",
  "createdAt": "Wed Oct 01 19:47:20 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 3,
  "likeCount": 148,
  "quoteCount": 0,
  "viewCount": 19565,
  "bookmarkCount": 25,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973468610917179630",
  "url": "https://x.com/karpathy/status/1973468610917179630",
  "text": "Tinker is cool.\n\nIf you're a researcher/developer, tinker dramatically simplifies LLM post-training. You retain 90% of algorithmic creative control (usually related to data, loss function, the algorithm) while tinker handles the hard parts that you usually want to touch much less often (infra, forward/backward of the LLM itself, distributed training), meaning you can do these at well below <<10% of typical complexity involved. Compared to the more common and existing paradigm of \"upload your data, we'll post-train your LLM\", this is imo a more clever place to \"slice up\" the complexity of post-training, both delegating the heavy lifting, but also keeping majority of the data/algorithmic creative control.\n\nI think the community still has to discover how and when finetuning makes sense compared to the (often strong) baseline of prompting a giant model. The early indications I've seen is that finetuning isn't so much about \"stylizing\" an LLM, instead, it's a lot more about narrowing the scope, and especially when you have a lot of training examples. An extreme example of scope narrowing being that of categorical classifiers, e.g.spam filters, content filters, etc. but it should be broader than that. Instead of building a giant few-shot prompts for a big LLM, it might work a lot better (and faster!) to finetune a smaller LLM specifically for your narrow task.\n\nIncreasingly, production applications of LLMs are larger pipelines where a bunch of LLMs collaborate in DAGs and flows. Some of these components might work well as prompts. But a lot of it will probably work a lot better as a finetune. Tinker makes the latter trivial and should allow for an easy experimentation of what works best at any stage.",
  "createdAt": "Wed Oct 01 19:22:36 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 608,
  "replyCount": 101,
  "likeCount": 5853,
  "quoteCount": 36,
  "viewCount": 613596,
  "bookmarkCount": 4200,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1973459267324879172",
  "url": "https://x.com/karpathy/status/1973459267324879172",
  "text": "@decruz I'd be afraid that NotebookLM is wired up to do RAG. It's not a lot of tokens. I want them in the context window. All of them and for sure.",
  "createdAt": "Wed Oct 01 18:45:29 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 5,
  "likeCount": 98,
  "quoteCount": 3,
  "viewCount": 9664,
  "bookmarkCount": 14,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973455432359485704",
  "url": "https://x.com/karpathy/status/1973455432359485704",
  "text": "@brickroad7 Think Casper! Childhood favorite. https://t.co/mL0Ioo7sSM",
  "createdAt": "Wed Oct 01 18:30:14 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 12,
  "likeCount": 359,
  "quoteCount": 0,
  "viewCount": 21215,
  "bookmarkCount": 6,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973454746754363579",
  "url": "https://x.com/karpathy/status/1973454746754363579",
  "text": "@chris_hayduk1 \"Don‚Äôt be difficult. I mean this is obvious.\" üòÇ\n\nSutton is right ofc. The analogue in LLM land to what humans do is something along the lines of:\n\nGiven this math problem AND human example solution in the context, solve the problem. Reward of 1 if correct. It's not SFT, it's RL.",
  "createdAt": "Wed Oct 01 18:27:31 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 9,
  "likeCount": 124,
  "quoteCount": 0,
  "viewCount": 21546,
  "bookmarkCount": 53,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973443912388977021",
  "url": "https://x.com/karpathy/status/1973443912388977021",
  "text": "Something I am experimenting with. I copy pasted:\n\n1) the full podcast transcript\n2) the bitter lesson blog post\n3) my full post above\n\nTo ChatGPT. The interesting part is you can fork the conversation context to ask any questions and take it in whatever direction with chat:\nhttps://t.co/m98ivfic67",
  "createdAt": "Wed Oct 01 17:44:28 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 32,
  "replyCount": 42,
  "likeCount": 828,
  "quoteCount": 8,
  "viewCount": 117634,
  "bookmarkCount": 490,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1973435013875314729",
  "url": "https://x.com/karpathy/status/1973435013875314729",
  "text": "Finally had a chance to listen through this pod with Sutton, which was interesting and amusing.\n\nAs background, Sutton's \"The Bitter Lesson\" has become a bit of biblical text in frontier LLM circles. Researchers routinely talk about and ask whether this or that approach or idea is sufficiently \"bitter lesson pilled\" (meaning arranged so that it benefits from added computation for free) as a proxy for whether it's going to work or worth even pursuing. The underlying assumption being that LLMs are of course highly \"bitter lesson pilled\" indeed, just look at LLM scaling laws where if you put compute on the x-axis, number go up and to the right. So it's amusing to see that Sutton, the author of the post, is not so sure that LLMs are \"bitter lesson pilled\" at all. They are trained on giant datasets of fundamentally human data, which is both 1) human generated and 2) finite. What do you do when you run out? How do you prevent a human bias? So there you have it, bitter lesson pilled LLM researchers taken down by the author of the bitter lesson - rough!\n\nIn some sense, Dwarkesh (who represents the LLM researchers viewpoint in the pod) and Sutton are slightly speaking past each other because Sutton has a very different architecture in mind and LLMs break a lot of its principles. He calls himself a \"classicist\" and evokes the original concept of Alan Turing of building a \"child machine\" - a system capable of learning through experience by dynamically interacting with the world. There's no giant pretraining stage of imitating internet webpages. There's also no supervised finetuning, which he points out is absent in the animal kingdom (it's a subtle point but Sutton is right in the strong sense: animals may of course observe demonstrations, but their actions are not directly forced/\"teleoperated\" by other animals). Another important note he makes is that even if you just treat pretraining as an initialization of a prior before you finetune with reinforcement learning, Sutton sees the approach as tainted with human bias and fundamentally off course, a bit like when AlphaZero (which has never seen human games of Go) beats AlphaGo (which initializes from them). In Sutton's world view, all there is is an interaction with a world via reinforcement learning, where the reward functions are partially environment specific, but also intrinsically motivated, e.g. \"fun\", \"curiosity\", and related to the quality of the prediction in your world model. And the agent is always learning at test time by default, it's not trained once and then deployed thereafter. Overall, Sutton is a lot more interested in what we have common with the animal kingdom instead of what differentiates us. \"If we understood a squirrel, we'd be almost done\".\n\nAs for my take...\n\nFirst, I should say that I think Sutton was a great guest for the pod and I like that the AI field maintains entropy of thought and that not everyone is exploiting the next local iteration LLMs. AI has gone through too many discrete transitions of the dominant approach to lose that. And I also think that his criticism of LLMs as not bitter lesson pilled is not inadequate. Frontier LLMs are now highly complex artifacts with a lot of humanness involved at all the stages - the foundation (the pretraining data) is all human text, the finetuning data is human and curated, the reinforcement learning environment mixture is tuned by human engineers. We do not in fact have an actual, single, clean, actually bitter lesson pilled, \"turn the crank\" algorithm that you could unleash upon the world and see it learn automatically from experience alone.\n\nDoes such an algorithm even exist? Finding it would of course be a huge AI breakthrough. Two \"example proofs\" are commonly offered to argue that such a thing is possible. The first example is the success of AlphaZero learning to play Go completely from scratch with no human supervision whatsoever. But the game of Go is clearly such a simple, closed, environment that it's difficult to see the analogous formulation in the messiness of reality. I love Go, but algorithmically and categorically, it is essentially a harder version of tic tac toe. The second example is that of animals, like squirrels. And here, personally, I am also quite hesitant whether it's appropriate because animals arise by a very different computational process and via different constraints than what we have practically available to us in the industry. Animal brains are nowhere near the blank slate they appear to be at birth. First, a lot of what is commonly attributed to \"learning\" is imo a lot more \"maturation\". And second, even that which clearly is \"learning\" and not maturation is a lot more \"finetuning\" on top of something clearly powerful and preexisting. Example. A baby zebra is born and within a few dozen minutes it can run around the savannah and follow its mother. This is a highly complex sensory-motor task and there is no way in my mind that this is achieved from scratch, tabula rasa. The brains of animals and the billions of parameters within have a powerful initialization encoded in the ATCGs of their DNA, trained via the \"outer loop\" optimization in the course of evolution. If the baby zebra spasmed its muscles around at random as a reinforcement learning policy would have you do at initialization, it wouldn't get very far at all. Similarly, our AIs now also have neural networks with billions of parameters. These parameters need their own rich, high information density supervision signal. We are not going to re-run evolution. But we do have mountains of internet documents. Yes it is basically supervised learning that is ~absent in the animal kingdom. But it is a way to practically gather enough soft constraints over billions of parameters, to try to get to a point where you're not starting from scratch. TLDR: Pretraining is our crappy evolution. It is one candidate solution to the cold start problem, to be followed later by finetuning on tasks that look more correct, e.g. within the reinforcement learning framework, as state of the art frontier LLM labs now do pervasively.\n\nI still think it is worth to be inspired by animals. I think there are multiple powerful ideas that LLM agents are algorithmically missing that can still be adapted from animal intelligence. And I still think the bitter lesson is correct, but I see it more as something platonic to pursue, not necessarily to reach, in our real world and practically speaking. And I say both of these with double digit percent uncertainty and cheer the work of those who disagree, especially those a lot more ambitious bitter lesson wise.\n\nSo that brings us to where we are. Stated plainly, today's frontier LLM research is not about building animals. It is about summoning ghosts. You can think of ghosts as a fundamentally different kind of point in the space of possible intelligences. They are muddled by humanity. Thoroughly engineered by it. They are these imperfect replicas, a kind of statistical distillation of humanity's documents with some sprinkle on top. They are not platonically bitter lesson pilled, but they are perhaps \"practically\" bitter lesson pilled, at least compared to a lot of what came before. It seems possibly to me that over time, we can further finetune our ghosts more and more in the direction of animals; That it's not so much a fundamental incompatibility but a matter of initialization in the intelligence space. But it's also quite possible that they diverge even further and end up permanently different, un-animal-like, but still incredibly helpful and properly world-altering. It's possible that ghosts:animals :: planes:birds.\n\nAnyway, in summary, overall and actionably, I think this pod is solid \"real talk\" from Sutton to the frontier LLM researchers, who might be gear shifted a little too much in the exploit mode. Probably we are still not sufficiently bitter lesson pilled and there is a very good chance of more powerful ideas and paradigms, other than exhaustive benchbuilding and benchmaxxing. And animals might be a good source of inspiration. Intrinsic motivation, fun, curiosity, empowerment, multi-agent self-play, culture. Use your imagination.",
  "createdAt": "Wed Oct 01 17:09:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1120,
  "replyCount": 396,
  "likeCount": 8695,
  "quoteCount": 317,
  "viewCount": 1533753,
  "bookmarkCount": 8127,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1973098972928479588",
  "url": "https://x.com/karpathy/status/1973098972928479588",
  "text": "@LiamFedus @ekindogus @periodiclabs We're not going to reason our way to Dyson spheres. Excited for you and all the best to the team!",
  "createdAt": "Tue Sep 30 18:53:48 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 23,
  "replyCount": 12,
  "likeCount": 674,
  "quoteCount": 5,
  "viewCount": 103962,
  "bookmarkCount": 55,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1971220449515516391",
  "url": "https://x.com/karpathy/status/1971220449515516391",
  "text": "\"AI isn't replacing radiologists\" good article\n\nExpectation: rapid progress in image recognition AI will delete radiology jobs (e.g. as famously predicted by Geoff Hinton now almost a decade ago). Reality: radiology is doing great and is growing.\n\nThere are a lot of imo naive predictions out there on the imminent impact of AI on the job market. E.g. a ~year ago, I was asked by someone who should know better if I think there will be any software engineers still today. (Spoiler: I think we're going to make it). This is happening too broadly.\n\nThe post goes into detail on why it's not that simple, using the example of radiology:\n\n- the benchmarks are nowhere near broad enough to reflect actual, real scenarios.\n- the job is a lot more multifaceted than just image recognition.\n- deployment realities: regulatory, insurance and liability, diffusion and institutional inertia.\n- Jevons paradox: if radiologists are sped up via AI as a tool, a lot more demand shows up.\n\nI will say that radiology was imo not among the best examples to pick on in 2016 - it's too multi-faceted, too high risk, too regulated. When looking for jobs that will change a lot due to AI on shorter time scales, I'd look in other places - jobs that look like repetition of one rote task, each task being relatively independent, closed (not requiring too much context), short (in time), forgiving (the cost of mistake is low), and of course automatable giving current (and digital) capability. Even then, I'd expect to see AI adopted as a tool at first, where jobs change and refactor (e.g. more monitoring or supervising than manual doing, etc). Maybe coming up, we'll find better and broader set of examples of how this is all playing out across the industry.\n\nAbout 6 months ago, I was also asked to vote if we will have less or more software engineers in 5 years. Exercise left for the reader.\n\nFull post (the whole The Works in Progress Newsletter is quite good):\nhttps://t.co/ON3GwlI3mi",
  "createdAt": "Thu Sep 25 14:29:13 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1366,
  "replyCount": 423,
  "likeCount": 8662,
  "quoteCount": 207,
  "viewCount": 2230878,
  "bookmarkCount": 6094,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1970178706179002533",
  "url": "https://x.com/karpathy/status/1970178706179002533",
  "text": "I was a bit surprised it is less than case than I expected. Code is KING. It‚Äôs the primary means of processing digital information - long term I can‚Äôt imagine a more important domain for the AGI pilled. And it is highly valuable in the interim too - big TAM @ high salaries. Despite the amusement of people bemoaning $200/mo to get double digit productivity gains in easily $100K+/yr jobs. One downside of the market being a fickle target audience - developers are savvy and will switch in large numbers to anything best at any point in time.",
  "createdAt": "Mon Sep 22 17:29:42 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 35,
  "replyCount": 36,
  "likeCount": 1035,
  "quoteCount": 10,
  "viewCount": 95476,
  "bookmarkCount": 219,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1970118678768488920",
  "url": "https://x.com/karpathy/status/1970118678768488920",
  "text": "@ProperPrompter Well for a properly omniscient entity of all present and past‚Ä¶ ü§∑‚Äç‚ôÇÔ∏è",
  "createdAt": "Mon Sep 22 13:31:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 5,
  "likeCount": 151,
  "quoteCount": 1,
  "viewCount": 14789,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1970113433795174792",
  "url": "https://x.com/karpathy/status/1970113433795174792",
  "text": "Anytime someone takes a picture/video that I happen to be in the background of I like to wave at the AGI that sees me 30 years from now",
  "createdAt": "Mon Sep 22 13:10:20 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 305,
  "replyCount": 295,
  "likeCount": 4743,
  "quoteCount": 46,
  "viewCount": 349772,
  "bookmarkCount": 329,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1969751479113195809",
  "url": "https://x.com/karpathy/status/1969751479113195809",
  "text": "@LocalBateman @Teknium1 Video goes hard though",
  "createdAt": "Sun Sep 21 13:12:03 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 8,
  "likeCount": 461,
  "quoteCount": 1,
  "viewCount": 35802,
  "bookmarkCount": 20,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1969722541376782688",
  "url": "https://x.com/karpathy/status/1969722541376782688",
  "text": "@burkov The code was written at layers 22-30 and is stored in the value activations you just can‚Äôt read it. I think you owe the LLM an apology.",
  "createdAt": "Sun Sep 21 11:17:04 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 53,
  "replyCount": 76,
  "likeCount": 2969,
  "quoteCount": 14,
  "viewCount": 148313,
  "bookmarkCount": 268,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1969699013671678382",
  "url": "https://x.com/karpathy/status/1969699013671678382",
  "text": "@dwarkesh_sp Most people misunderstand books as data for pertaining when it‚Äôs more a set of prompts for synthetic data generation.",
  "createdAt": "Sun Sep 21 09:43:34 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 119,
  "replyCount": 58,
  "likeCount": 1553,
  "quoteCount": 27,
  "viewCount": 369,
  "bookmarkCount": 450,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1966897698612932783",
  "url": "https://x.com/karpathy/status/1966897698612932783",
  "text": "from this era https://t.co/1pIFiqes4Y",
  "createdAt": "Sat Sep 13 16:12:09 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 17,
  "replyCount": 30,
  "likeCount": 601,
  "quoteCount": 7,
  "viewCount": 251780,
  "bookmarkCount": 71,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1966896849929073106",
  "url": "https://x.com/karpathy/status/1966896849929073106",
  "text": "reminded of this paragraph from gsm8k paper, 2021 :) https://t.co/lmubBMBFIb",
  "createdAt": "Sat Sep 13 16:08:46 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 134,
  "replyCount": 83,
  "likeCount": 2112,
  "quoteCount": 8,
  "viewCount": 357473,
  "bookmarkCount": 617,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1965474817056161873",
  "url": "https://x.com/karpathy/status/1965474817056161873",
  "text": "@RajaPatnaik Naively I'd rather it be smaller than thinner but I'll have to see/hold it.",
  "createdAt": "Tue Sep 09 17:58:07 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 11,
  "likeCount": 73,
  "quoteCount": 1,
  "viewCount": 13866,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1965451505882087617",
  "url": "https://x.com/karpathy/status/1965451505882087617",
  "text": "@jasonth0 Actually jason, every iPhone is the best iPhone they have made yet. And this is something only Apple can do.",
  "createdAt": "Tue Sep 09 16:25:29 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 5,
  "likeCount": 140,
  "quoteCount": 0,
  "viewCount": 10835,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1965442256854478875",
  "url": "https://x.com/karpathy/status/1965442256854478875",
  "text": "@AdityaJiRathore core memory watching that 18 years ago (omg...)",
  "createdAt": "Tue Sep 09 15:48:44 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 5,
  "likeCount": 316,
  "quoteCount": 0,
  "viewCount": 38,
  "bookmarkCount": 9,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1965441967439089918",
  "url": "https://x.com/karpathy/status/1965441967439089918",
  "text": "@devaaaaang The phones have been getting ever bigger, heavier, more full-featured. There are dozens of us that want the opposite. Dozens!",
  "createdAt": "Tue Sep 09 15:47:35 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 27,
  "likeCount": 424,
  "quoteCount": 5,
  "viewCount": 22879,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1965441492555890754",
  "url": "https://x.com/karpathy/status/1965441492555890754",
  "text": "@MeTrevorLoucks iirc when I looked into it a few years ago it was the worst selling model by far. But the few that loved it loved it deeply. This has not been accounted for!",
  "createdAt": "Tue Sep 09 15:45:42 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 8,
  "likeCount": 197,
  "quoteCount": 1,
  "viewCount": 16650,
  "bookmarkCount": 3,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1965440088273539376",
  "url": "https://x.com/karpathy/status/1965440088273539376",
  "text": "@imprivi Haha. I think in some way I still haven't gotten over the miracle.",
  "createdAt": "Tue Sep 09 15:40:07 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 87,
  "quoteCount": 0,
  "viewCount": 25,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1965439123252281654",
  "url": "https://x.com/karpathy/status/1965439123252281654",
  "text": "Bit silly but I still watch the Apple event livestream for new iPhones, every year since the first one in 2007. It doesn't make sense but it's ok. Livestream today at 10am (in 1.5 hours). This year, crossing my fingers again for an iPhone mini that I know won't come. rip.",
  "createdAt": "Tue Sep 09 15:36:17 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 339,
  "replyCount": 516,
  "likeCount": 6725,
  "quoteCount": 77,
  "viewCount": 521377,
  "bookmarkCount": 294,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1964036961750176232",
  "url": "https://x.com/karpathy/status/1964036961750176232",
  "text": "@sama Smarter! I can go for a nice walk or something it's okay. https://t.co/1RiTqSFsKv",
  "createdAt": "Fri Sep 05 18:44:36 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 139,
  "replyCount": 130,
  "likeCount": 6479,
  "quoteCount": 41,
  "viewCount": 203008,
  "bookmarkCount": 215,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1964026120191545346",
  "url": "https://x.com/karpathy/status/1964026120191545346",
  "text": "I love doing this actually :). I think it's a pretty powerful eval too. Have all models generate something, then put it all together and give it back to all of them and ask them to rank all outputs. I thought models might have a bias to prefer their own outputs, but this doesn't seem to be too strong of an issue in my (limited) testing. I think it's the generator-discriminator gap on display. That is, it's really hard to write something good, but it's much easier to recognize something good, and the models seem to do it well.",
  "createdAt": "Fri Sep 05 18:01:31 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 81,
  "replyCount": 58,
  "likeCount": 1787,
  "quoteCount": 34,
  "viewCount": 173649,
  "bookmarkCount": 307,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1964022216108257638",
  "url": "https://x.com/karpathy/status/1964022216108257638",
  "text": "@garricn not yet but planning to! I rotate through a lot of what exists in few day intervals. Actually ~3 weeks ago I found codex worse and less polished than CC right now for the more basic edits and overall experience. It's just 5 Pro specifically feels SOTA by a good margin atm.",
  "createdAt": "Fri Sep 05 17:46:00 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 8,
  "replyCount": 15,
  "likeCount": 576,
  "quoteCount": 1,
  "viewCount": 137175,
  "bookmarkCount": 51,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1964020416139448359",
  "url": "https://x.com/karpathy/status/1964020416139448359",
  "text": "I think congrats again to OpenAI for cooking with GPT-5 Pro. This is the third time I've struggled on something complex/gnarly for an hour on and off with CC, then 5 Pro goes off for 10 minutes and comes back with code that works out of the box. I had CC read the 5 Pro version and it wrote up 2 paragraphs admiring it (very wholesome). If you're not giving it your hardest problems you're probably missing out.",
  "createdAt": "Fri Sep 05 17:38:51 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 861,
  "replyCount": 438,
  "likeCount": 12820,
  "quoteCount": 193,
  "viewCount": 2572458,
  "bookmarkCount": 2681,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1962255220655980756",
  "url": "https://x.com/karpathy/status/1962255220655980756",
  "text": "@guyadamailion @justinbieber Haha exactly, except more of a high school orchestra club :)",
  "createdAt": "Sun Aug 31 20:44:36 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 15,
  "likeCount": 360,
  "quoteCount": 1,
  "viewCount": 42246,
  "bookmarkCount": 14,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1962166818325590122",
  "url": "https://x.com/karpathy/status/1962166818325590122",
  "text": "I almost had this happen yesterday, but my LLM suggested the right thing as `rm -rf '~'`. (with 'quotes'). Still very scary. Example of how this happens, e.g. if something like this sneaks into your .bashrc:\n\nexport WANDB_DIR=\"~/.cache/wandb\"\n\nThe ~ isn't expanded inside \"quotes\" and creates a literal ~ directory in your current one. Thank you for sharing this jump scare, love the LLM horror genre.",
  "createdAt": "Sun Aug 31 14:53:19 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 24,
  "replyCount": 35,
  "likeCount": 686,
  "quoteCount": 6,
  "viewCount": 70995,
  "bookmarkCount": 127,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1961150899264623071",
  "url": "https://x.com/karpathy/status/1961150899264623071",
  "text": "@tszzl in the limit of revenue/growth maxxing via A/B tests doesn't it all just converge to funny panda videos? it's the supermasive black hole at the center of the universe and no matter the initial conditions you eventually get sucked in. reels. youtube shorts. substack notes.",
  "createdAt": "Thu Aug 28 19:36:25 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 7,
  "replyCount": 20,
  "likeCount": 313,
  "quoteCount": 2,
  "viewCount": 19286,
  "bookmarkCount": 16,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1961146044550373712",
  "url": "https://x.com/karpathy/status/1961146044550373712",
  "text": "&lt;cot&gt;I wonder if the timeline over at Substack is better, maybe there is less slop and more interesting longform or so on. Opens Substack. https://t.co/Bbnlfe1XBX",
  "createdAt": "Thu Aug 28 19:17:08 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 166,
  "replyCount": 113,
  "likeCount": 1528,
  "quoteCount": 13,
  "viewCount": 742,
  "bookmarkCount": 90,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1961128638725923119",
  "url": "https://x.com/karpathy/status/1961128638725923119",
  "text": "Transforming human knowledge, sensors and actuators from human-first and human-legible to LLM-first and LLM-legible is a beautiful space with so much potential and so much can be done...\n\nOne example I'm obsessed with recently - for every textbook pdf/epub, there is a perfect \"LLMification\" of it intended not for human but for an LLM (though it is a non-trivial transformation that would need human in the loop involvement).\n\n- All of the exposition is extracted into a markdown document, including all latex, styling (bold/italic), tables, lists, etc. All of the figures are extracted as images.\n- All worked problems get extracted into SFT examples. Any referenced made to previous figures/tables/etc. are parsed and included.\n- All practice problems are extracted into environment examples for RL. The correct answers are located in the answer key and attached. Any additional information is added as \"answer key\" for a potential LLM judge.\n- Synthetic data expansion. For every specific problem, you can create an infinite problem generator, which emits problems of that type. For example, if a problem is \"What is the angle between the hour and minute hands at 9am?\" , you can imagine generalizing that to any arbitrary time and calculating answers using Python code, and possibly generating synthetic variations of the prompt text.\n- All of the data above could be nicely indexed and embedded into a RAG database for later reference, or maybe MCP servers that make it available.\n\nThen just as a (human) student could take a high school physics course, an LLM could take it in the exact same way. This would be a significantly richer source of legible, workable information for an LLM than just something like pdf-to-text (current prevailing practice), which simply asks the LLM to predict the textbook content top to bottom token by token (umm - lame).\n\nAs just a quick and crappy example of synthetic variations of the above example, GPT-5 gave me this problem generator (see image), which can now generalize that problem template to many variations:\n\n- When the time is 11:07 a.m., what is the degree measure of the angle between the hands? (Answer: 68)\n- Determine the angle in degrees between the clock‚Äôs hands at 4:14 a.m.. (Answer: 43)\n- What angle do the clock hands form when the time reads 11:47 a.m.? (Answer: 71)\n- At 7:02 a.m., what angle separates the hour hand and the minute hand? (Answer: 161)\n- At 4:14 a.m., calculate the angle made between the two hands. (Answer: 43)\n- What angle is formed by the hands of a clock at 4:45 p.m.? (Answer: 127)\n- What is the angle between the hour and minute hands at 8:37 p.m.? (Answer: 36)\n(infinite practice problems can be created...)",
  "createdAt": "Thu Aug 28 18:07:58 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 724,
  "replyCount": 288,
  "likeCount": 5820,
  "quoteCount": 98,
  "viewCount": 899,
  "bookmarkCount": 4835,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1961079942189638119",
  "url": "https://x.com/karpathy/status/1961079942189638119",
  "text": "I thought this should have already applied on the SFT layer and was a bit surprised when it didn't. Possibly it's that SFT is so few bits / brief that it is at most a shifting of superficial style around a pre-existing embedding space from (common) pretraining, with everyone basically latching onto the same underlying cluster. If RL spend is a lot more bits and much longer, it could more substantially speciate the network.",
  "createdAt": "Thu Aug 28 14:54:27 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 12,
  "replyCount": 22,
  "likeCount": 677,
  "quoteCount": 3,
  "viewCount": 79982,
  "bookmarkCount": 164,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1960818228198039909",
  "url": "https://x.com/karpathy/status/1960818228198039909",
  "text": "@johannes_hage alright!",
  "createdAt": "Wed Aug 27 21:34:30 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 1,
  "likeCount": 38,
  "quoteCount": 0,
  "viewCount": 5377,
  "bookmarkCount": 6,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1960805995313291488",
  "url": "https://x.com/karpathy/status/1960805995313291488",
  "text": "How amazing it would be if we could extract and reframe all the practice problems from all the textbooks ever written into environments...",
  "createdAt": "Wed Aug 27 20:45:53 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 42,
  "replyCount": 53,
  "likeCount": 1427,
  "quoteCount": 9,
  "viewCount": 144526,
  "bookmarkCount": 265,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1960804762871587015",
  "url": "https://x.com/karpathy/status/1960804762871587015",
  "text": "@archiexzzz I just mean long term, imo RL finetuning paradigm is a big upgrade over just SFT (expert imitation) for LLMs at the current stage of development and will continue to grow substantially.",
  "createdAt": "Wed Aug 27 20:41:00 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 2,
  "likeCount": 334,
  "quoteCount": 0,
  "viewCount": 19785,
  "bookmarkCount": 34,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1960803117689397543",
  "url": "https://x.com/karpathy/status/1960803117689397543",
  "text": "In era of pretraining, what mattered was internet text. You'd primarily want a large, diverse, high quality collection of internet documents to learn from.\n\nIn era of supervised finetuning, it was conversations. Contract workers are hired to create answers for questions, a bit like what you'd see on Stack Overflow / Quora, or etc., but geared towards LLM use cases.\n\nNeither of the two above are going away (imo), but in this era of reinforcement learning, it is now environments. Unlike the above, they give the LLM an opportunity to actually interact - take actions, see outcomes, etc. This means you can hope to do a lot better than statistical expert imitation. And they can be used both for model training and evaluation. But just like before, the core problem now is needing a large, diverse, high quality set of environments, as exercises for the LLM to practice against.\n\nIn some ways, I'm reminded of OpenAI's very first project (gym), which was exactly a framework hoping to build a large collection of environments in the same schema, but this was way before LLMs. So the environments were simple academic control tasks of the time, like cartpole, ATARI, etc. The @PrimeIntellect environments hub (and the `verifiers` repo on GitHub) builds the modernized version specifically targeting LLMs, and it's a great effort/idea. I pitched that someone build something like it earlier this year:\nhttps://t.co/ANHhasxzD8\nEnvironments have the property that once the skeleton of the framework is in place, in principle the community / industry can parallelize across many different domains, which is exciting.\n\nFinal thought - personally and long-term, I am bullish on environments and agentic interactions but I am bearish on reinforcement learning specifically. I think that reward functions are super sus, and I think humans don't use RL to learn (maybe they do for some motor tasks etc, but not intellectual problem solving tasks). Humans use different learning paradigms that are significantly more powerful and sample efficient and that haven't been properly invented and scaled yet, though early sketches and ideas exist (as just one example, the idea of \"system prompt learning\", moving the update to tokens/contexts not weights and optionally distilling to weights as a separate process a bit like sleep does).",
  "createdAt": "Wed Aug 27 20:34:27 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 875,
  "replyCount": 265,
  "likeCount": 7336,
  "quoteCount": 163,
  "viewCount": 905237,
  "bookmarkCount": 4939,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1960506038186053813",
  "url": "https://x.com/karpathy/status/1960506038186053813",
  "text": "@indubitably_ai Yes. I was contacted by an ATT rep and I had some hope for a second there, but instead of them helping solve the issue they tried to sell me Active Armor Advanced, for only $3/mo, offering completely unrelated features. And I was going to be given a discount for the first year.",
  "createdAt": "Wed Aug 27 00:53:58 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 2,
  "likeCount": 7,
  "quoteCount": 0,
  "viewCount": 1229,
  "bookmarkCount": 0,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1960121588185288969",
  "url": "https://x.com/karpathy/status/1960121588185288969",
  "text": "@tszzl Walking through security in the Singapore airport is such a breeze too. Last time, after passing through one of the automated stalls a person with a notepad hastily approached me to ask how the experience was and what could be improved, and he actually cared. Like whoa.",
  "createdAt": "Mon Aug 25 23:26:18 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 22,
  "replyCount": 23,
  "likeCount": 1388,
  "quoteCount": 0,
  "viewCount": 61295,
  "bookmarkCount": 54,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1959703967694545296",
  "url": "https://x.com/karpathy/status/1959703967694545296",
  "text": "Continuing the journey of optimal LLM-assisted coding experience. In particular, I find that instead of narrowing in on a perfect one thing my usage is increasingly diversifying across a few workflows that I \"stitch up\" the pros/cons of:\n\nPersonally the bread & butter (~75%?) of my LLM assistance continues to be just (Cursor) tab complete. This is because I find that writing concrete chunks of code/comments myself and in the right part of the code is a high bandwidth way of communicating \"task specification\" to the LLM, i.e. it's primarily about task specification bits - it takes too many bits and too much latency to communicate what I want in text, and it's faster to just demonstrate it in the code and in the right place. Sometimes the tab complete model is annoying so I toggle it on/off a lot.\n\nNext layer up is highlighting a concrete chunk of code and asking for some kind of a modification.\n\nNext layer up is Claude Code / Codex / etc, running on the side of Cursor, which I go to for larger chunks of functionality that are also fairly easy to specify in a prompt. These are super helpful, but still mixed overall and slightly frustrating at times. I don't run in YOLO mode because they can go off-track and do dumb things you didn't want/need and I ESC fairly often. I also haven't learned to be productive using more than one instance in parallel - one already feels hard enough. I haven't figured out a good way to keep CLAUDE[.]md good or up to date. I often have to do a pass of \"cleanups\" for coding style, or matters of code taste. E.g. they are too defensive and often over-use try/catch statements, they often over-complicate abstractions, they overbloat code (e.g. a nested if-the-else constructs when a list comprehension or a one-liner if-then-else would work), or they duplicate code chunks instead of creating a nice helper function, things like that... they basically don't have a sense of taste. They are indispensable in cases where I inch into a more vibe-coding territory where I'm less familiar (e.g. writing some rust recently, or sql commands, or anything else I've done less of before). I also tried CC to teach me things alongside the code it was writing but that didn't work at all - it really wants to just write code a lot more than it wants to explain anything along the way. I tried to get CC to do hyperparameter tuning, which was highly amusing. They are also super helpful in all kinds of lower-stakes one-off custom visualization or utilities or debugging code that I would never write otherwise because it would have taken way too long. E.g. CC can hammer out 1,000 lines of one-off extensive visualization/code just to identify a specific bug, which gets all deleted right after we find it. It's the code post-scarcity era - you can just create and then delete thousands of lines of super custom, super ephemeral code now, it's ok, it's not this precious costly thing anymore.\n\nFinal layer of defense is GPT5 Pro, which I go to for the hardest things. E.g. it has happened to me a few times now that I / Cursor / CC are all stuck on a bug for 10 minutes, but when I copy paste the whole thing to 5 Pro, it goes off for 10 minutes but then actually finds a really subtle bug. It is very strong. It can dig up all kinds of esoteric docs and papers and such. I've also used it for other meatier tasks, e.g. suggestions on how to clean up abstractions (mixed results, sometimes good ideas but not all), or an entire literature review around how people do this or that and it comes back with good relevant resources / pointers.\n\nAnyway, coding feels completely blown open with possibility across a number of \"kinds\" of coding and then a number of tools with their pros/cons. It's hard to avoid the feeling of anxiety around not being at the frontier of what is collectively possible, hence random sunday shower of thoughts and a good amount of curiosity about what others are finding.",
  "createdAt": "Sun Aug 24 19:46:50 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 974,
  "replyCount": 387,
  "likeCount": 8504,
  "quoteCount": 118,
  "viewCount": 661545,
  "bookmarkCount": 5470,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1959657977914478777",
  "url": "https://x.com/karpathy/status/1959657977914478777",
  "text": "@vincentweisser I pitched something like it earlier this year but I think it's missing the \"skeleton\" onto which it would be easy to add new envs, in parallel and in common schema. Something all the claude codes can play in.\nhttps://t.co/1oy8bWCu24",
  "createdAt": "Sun Aug 24 16:44:05 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 9,
  "replyCount": 24,
  "likeCount": 418,
  "quoteCount": 5,
  "viewCount": 80765,
  "bookmarkCount": 197,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1959436793910329345",
  "url": "https://x.com/karpathy/status/1959436793910329345",
  "text": "@nearcyan Platforms, user creativity, streamers and memes. Skip graphics. Very cool. \nhttps://t.co/Jbfi7Cb4ae",
  "createdAt": "Sun Aug 24 02:05:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 8,
  "likeCount": 81,
  "quoteCount": 2,
  "viewCount": 16731,
  "bookmarkCount": 43,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957836876888568105",
  "url": "https://x.com/karpathy/status/1957836876888568105",
  "text": "@JacobB1290H Even better, Siri right away highlighted this notification as a \"Priority Notification\". It just keeps getting better.",
  "createdAt": "Tue Aug 19 16:07:40 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 43,
  "likeCount": 280,
  "quoteCount": 1,
  "viewCount": 6,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957836494292258845",
  "url": "https://x.com/karpathy/status/1957836494292258845",
  "text": "@JacobB1290H umm update the new call screening feature in iOS26 does not seem to work at all? my phone buzzed alive with one of them just now: https://t.co/Cb3UL1M8WZ",
  "createdAt": "Tue Aug 19 16:06:09 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 10,
  "likeCount": 164,
  "quoteCount": 1,
  "viewCount": 39143,
  "bookmarkCount": 2,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957830888777216229",
  "url": "https://x.com/karpathy/status/1957830888777216229",
  "text": "@JacobB1290H I updated last night. This morning I saw a notification of a silenced call (random number), but no voicemail. So instead of 2 notifications it's 1, which is progress. I really need the version with no notifications at all, otherwise 10 of them randomly light up my phone per day.",
  "createdAt": "Tue Aug 19 15:43:53 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 9,
  "likeCount": 241,
  "quoteCount": 0,
  "viewCount": 40074,
  "bookmarkCount": 8,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957575801253335463",
  "url": "https://x.com/karpathy/status/1957575801253335463",
  "text": "@danielmerja Same https://t.co/e7IOdyc3f0",
  "createdAt": "Mon Aug 18 22:50:15 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 37,
  "likeCount": 824,
  "quoteCount": 3,
  "viewCount": 96968,
  "bookmarkCount": 15,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957575571258605731",
  "url": "https://x.com/karpathy/status/1957575571258605731",
  "text": "@brandmania I don‚Äôt pick up anything either but I still get notifications, which are cluttering and annoying.",
  "createdAt": "Mon Aug 18 22:49:20 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 49,
  "likeCount": 2052,
  "quoteCount": 1,
  "viewCount": 138670,
  "bookmarkCount": 19,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957574489358873054",
  "url": "https://x.com/karpathy/status/1957574489358873054",
  "text": "I get ~10 spam calls per day (various automated voicemails, \"loan pre-approval\" etc) and ~5 spam messages per day (usually phishing).\n\n- I have AT&T Active Armor, all of the above still slips through.\n- All of the above is always from new, unique numbers so blocking doesn't work.\n- I am on all Do Not Call lists.\n- I have iOS \"Silence Unknown Callers\" on, but even if it catches & silences them I still get the notifications.\n\nNot sure if other people are seeing something similar or figured out anything that works",
  "createdAt": "Mon Aug 18 22:45:02 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 620,
  "replyCount": 2703,
  "likeCount": 17241,
  "quoteCount": 269,
  "viewCount": 488,
  "bookmarkCount": 2193,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1957561075744010253",
  "url": "https://x.com/karpathy/status/1957561075744010253",
  "text": "Ok, spent an ~hour sifting through submissions. The biggest challenge was the spam, as majority of replies are people linking to their own existing projects, not things made for the challenge. Of the ones that were:\n\nWinner: I most enjoyed this one from @uncertainsys  - OmegaQuest. He's solving Humanity's Last Exam problems with heavy AI use in the loop on video. Actually I really identified with the long pauses and general confusion in trying to use the current state of the art systems in learning something hard and new, where they are simultaneously so tantalizingly helpful at the margins, but still really poor overall, compared to an imagined human expert tutor. The \"explanations\" are... not. But I love the tenacity on display in working out something hard and seeing how far you can get with AI. A good reminder how it's better than what was, but also so far from what could be.\nhttps://t.co/IKyvdn7dwH\n\nShoutout to @measure_plan for cool \"visual vibe coding\" projects, e.g. new musical instruments \nhttps://t.co/3Ny336xUEU\n\nA few of people commented that the challenge shouldn't have to be only for projects uniquely made for the challenge. If that were the case then shoutout to @evanliin et al. who linked to tinytpu, i really like the animated diagram, i haven't seen that before.\nhttps://t.co/Q7OSrhishg\n\nShoutout to @ChrisChipMonk for partially incepting the experiment a while ago with \nhttps://t.co/bOPtIAoGUX\nbut I basically come out agreeing with @nearcyan in his earlier comment \nhttps://t.co/XnkKrXctkB  , maybe even $5K isn't :)",
  "createdAt": "Mon Aug 18 21:51:44 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 12,
  "replyCount": 27,
  "likeCount": 368,
  "quoteCount": 5,
  "viewCount": 121700,
  "bookmarkCount": 135,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1957482644792569909",
  "url": "https://x.com/karpathy/status/1957482644792569909",
  "text": "@sharifshameem Related active form, I recall a quote along the lines of:\n\"If you can't make yourself happy, make someone else happy\"\nHas been influential for me, pretty powerful for when feeling down.",
  "createdAt": "Mon Aug 18 16:40:05 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 76,
  "replyCount": 50,
  "likeCount": 1978,
  "quoteCount": 16,
  "viewCount": 77655,
  "bookmarkCount": 346,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1956823465748754641",
  "url": "https://x.com/karpathy/status/1956823465748754641",
  "text": "@ivenzor I heard chunks of it, eg love his performance of this song among others haha  https://t.co/WcqaseGkqj",
  "createdAt": "Sat Aug 16 21:00:44 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 2,
  "replyCount": 4,
  "likeCount": 100,
  "quoteCount": 0,
  "viewCount": 60182,
  "bookmarkCount": 55,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1956808342191718638",
  "url": "https://x.com/karpathy/status/1956808342191718638",
  "text": "Yes and also related - this passage, one of my favorite conversations in all of LoTR, from the \"The Road to Isengard\" chapter talking about the caverns of Helm's Deep. Gimli to Legolas:\n\n\"No, you do not understand,\" said Gimli. \"No dwarf could be unmoved by such loveliness. None of Durin's race would mine those caves for stones or ore, not if diamonds and gold could be got there. Do you cut down groves of blossoming trees in the springtime for firewood? We would tend these glades of flowering stone, not quarry them. With cautious skill, tap by tap -- a small chip of rock and no more, perhaps, in a whole anxious day -- so we would work, and as the years went by, we should open up new ways, and display far chambers that are still dark, glimpsed only as a void beyond fissures in the rock. And lights, Legolas! We should make lights, such lamps as once shone in Khazad-dum; and when we wished we would drive away the night that has lain there since the hills were made; and when we desired rest, we would let the night return.\"",
  "createdAt": "Sat Aug 16 20:00:39 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 3,
  "likeCount": 16,
  "quoteCount": 0,
  "viewCount": 2304,
  "bookmarkCount": 1,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1956800455792853367",
  "url": "https://x.com/karpathy/status/1956800455792853367",
  "text": "Yes exactly, great question. I read it more as a critique of specific kind of power distribution and specific kind of technology.\n\nSo first I share his fear of corruption from power and I think many technologists do as well, imo especially pioneers of internet/computing. There's technology both power centralizing (big corpo style) and power decentralizing (printing press, early internet, cryptography, personal computing and open source, ...). And there are multiple characters in the legendarium Tolkien implicitly asks us to look up to, who \"pass the test\" and refuse to take the ring (even from a desire to do good!), with a diverse amount of ease - Gandalf, Aragorn, Galadriel, Faramir, Bilbo, Sam, Tom Bombadil.\n\nAs for technology I also see his hatred as more directed towards a specific kind of it - industrial technology at scale, particularly with externalities on the natural world, both plants and beasts. Actually, in his world magic is also a kind of technology, but of the good kind, and it is wielded by the elves, but for the purposes of art, for preservation and enhancement of culture and beauty.\n\nSo basically I feel in agreement with Tolkien despite working in technology, in both a default distrust of centralized power (even for ostensible good) and its inevitable corruption, and also in dislike of industrial scale technology with externalities on the natural world and human culture, recent prominent example being e.g. high throughput farming of animals.",
  "createdAt": "Sat Aug 16 19:29:18 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 36,
  "replyCount": 25,
  "likeCount": 811,
  "quoteCount": 5,
  "viewCount": 103671,
  "bookmarkCount": 139,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1956765908078387382",
  "url": "https://x.com/karpathy/status/1956765908078387382",
  "text": "I am (slowly) re-reading the Tolkien legendarium (of which Lord of the Rings is a small part). The whole body of work is so incredible and there's nothing else like it... it dilutes other worlds of fiction. Wait - your story doesn't have a comprehensive history/mythology spanning multiple ages all the way back to a creation myth as detailed in separate volumes? You didn't first invent new languages and dialects for your characters? You didn't pack it with powerful themes and stories written it in a beautiful, archaic style and compose poems and songs alongside? It didn't take you multiple decades of iteration? And what of all the uncharted territory still remaining? Is Tom Bombadil one of the Ainur. Where are the Entwives. What happened to the two unaccounted Istari. Can we hear more about what it was like in Cuivi√©nen when the elves first awoke? Or to see the light of the two trees of Valinor. Or of the splendor of the caves of Aglarond.\n\nWhat's most on my mind though - the Tolkien legendarium is imo a concrete example of a height of culture. Does AI, today or soon, make it easier to reach this high via empowerment in both writing and ideation? Or harder, when quick wins are tempting and ~free, and an independent ability to create is stifled. If such a body of work is made again but now with heavy AI assistance, does it inspire the same wonder? What if thousands of them come out on demand with just a prompt? Why do you feel cheated when you learn that something your read was AI generated? Is it transient or a function of capability? Is it slop? What is slop? Or is wonder inseparable from its own creation myth of a lifelong obsession of a mind like your own? So many questions.",
  "createdAt": "Sat Aug 16 17:12:02 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1455,
  "replyCount": 1060,
  "likeCount": 16131,
  "quoteCount": 314,
  "viewCount": 9220780,
  "bookmarkCount": 4741,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1956461804340810210",
  "url": "https://x.com/karpathy/status/1956461804340810210",
  "text": "@AlexReibman @cognition @DevinAI @swyx @CerebrasSystems @windsurf @AnthropicAI @modal hahaha fun photo. AndrejGPT-mini and a group of parallel subagents loading the context window with this 10,000 LOC codebase in gitingest, reasoning='low'",
  "createdAt": "Fri Aug 15 21:03:38 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 6,
  "replyCount": 5,
  "likeCount": 476,
  "quoteCount": 1,
  "viewCount": 53445,
  "bookmarkCount": 40,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1954565543887081904",
  "url": "https://x.com/karpathy/status/1954565543887081904",
  "text": "I went through a few phases first I thought it is some elaborate psyop, maybe some funny bet on objectivity of aesthetics between lizard people or a 1984 esque social engineering project. Or an actual symptom of cultural decline because it's much broader - architecture, interior design, film, etc. Money laundering makes a lot of sense too. Something's up.",
  "createdAt": "Sun Aug 10 15:28:34 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 57,
  "replyCount": 85,
  "likeCount": 1969,
  "quoteCount": 10,
  "viewCount": 199411,
  "bookmarkCount": 250,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1954231225230790716",
  "url": "https://x.com/karpathy/status/1954231225230790716",
  "text": "Two situations:\n\n1 I wave a co-worker to my monitor to show them a file I have open. \"Is this right\"?\n\n2 I sit down someone at a table. They have 2 hours to respond. This is an exam. The stakes are high. \"Is this right?\"\n\nThe humans collaborator knows 1 vs 2. The LLM doesn't know if it's 1 or 2, benchmarkmaxxing over time pushes it to assume 2.",
  "createdAt": "Sat Aug 09 17:20:06 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 24,
  "replyCount": 17,
  "likeCount": 558,
  "quoteCount": 6,
  "viewCount": 44299,
  "bookmarkCount": 82,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1954227464596832670",
  "url": "https://x.com/karpathy/status/1954227464596832670",
  "text": "@paimon2cool I'm starting to do some of this too. I have a script that packages all of the files of my project (which isn't a giant repo and fits just fine) uses `files-to-prompt`, then I start new conversation, copy paste, and ask a question at the end, and manually select appropriate model.",
  "createdAt": "Sat Aug 09 17:05:10 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 26,
  "replyCount": 57,
  "likeCount": 885,
  "quoteCount": 9,
  "viewCount": 68024,
  "bookmarkCount": 242,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1954224651443544436",
  "url": "https://x.com/karpathy/status/1954224651443544436",
  "text": "I'm noticing that due to (I think?) a lot of benchmarkmaxxing on long horizon tasks, LLMs are becoming a little too agentic by default, a little beyond my average use case.\n\nFor example in coding, the models now tend to reason for a fairly long time, they have an inclination to start listing and grepping files all across the entire repo, they do repeated web searchers, they over-analyze and over-think little rare edge cases even in code that is knowingly incomplete and under active development, and often come back ~minutes later even for simple queries.\n\nThis might make sense for long-running tasks but it's less of a good fit for more \"in the loop\" iterated development that I still do a lot of, or if I'm just looking for a quick spot check before running a script, just in case I got some indexing wrong or made some dumb error. So I find myself quite often stopping the LLMs with variations of \"Stop, you're way overthinking this. Look at only this single file. Do not use any tools. Do not over-engineer\", etc.\n\nBasically as the default starts to slowly creep into the \"ultrathink\" super agentic mode, I feel a need for the reverse, and more generally good ways to indicate or communicate intent / stakes, from \"just have a quick look\" all the way to \"go off for 30 minutes, come back when absolutely certain\".",
  "createdAt": "Sat Aug 09 16:53:59 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 846,
  "replyCount": 793,
  "likeCount": 10613,
  "quoteCount": 210,
  "viewCount": 1017434,
  "bookmarkCount": 2425,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1952704345817944279",
  "url": "https://x.com/karpathy/status/1952704345817944279",
  "text": "@lexfridman 100%, it's very interesting to me when a lot value is created but the awareness/esteem of it, the story of it, or the people involved is next to zero. It's not fully true but it's sufficiently true.",
  "createdAt": "Tue Aug 05 12:12:50 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 45,
  "replyCount": 59,
  "likeCount": 2616,
  "quoteCount": 3,
  "viewCount": 105620,
  "bookmarkCount": 138,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1952082830793850923",
  "url": "https://x.com/karpathy/status/1952082830793850923",
  "text": "@much_science Oops, not a dumb question at all üòÖ",
  "createdAt": "Sun Aug 03 19:03:09 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 0,
  "replyCount": 4,
  "likeCount": 253,
  "quoteCount": 0,
  "viewCount": 47352,
  "bookmarkCount": 4,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1952076108565991588",
  "url": "https://x.com/karpathy/status/1952076108565991588",
  "text": "Shower of thoughts: Instead of keeping your Twitter/ùïè payout, direct it towards a \"PayoutChallenge\" of your choosing - anything you want more of in the world!\n\nHere is mine for this round, combining my last 3 payouts of $5478.51:\n\nIt is imperative that humanity not fall while AI ascends. Humanity has to continue to rise, become better alongside. Create something that is specifically designed to uplift team human. Definition intentionally left a bit vague to keep some entropy around people's interpretation, but imo examples include:\n- Any piece of software that aids explanation, visualization, memorization, inspiration, understanding, coordination, etc...\n- It doesn't have to be too lofty, e.g. it can be a specific educational article/video explaining something some other people could benefit from or that you have unique knowledge of.\n- Prompts/agents for explanation, e.g. along the lines of recently released ChatGPT study mode.\n- Related works of art\n\nThis challenge will run for 2 weeks until Aug 17th EOD PST. Submit your contribution as a reply. It has to be something that was uniquely created for this challenge and would not exist otherwise. Criteria includes execution, leverage, novelty, inspiration, aesthetics, amusement. People can upvote submissions by liking, this \"people's choice\" will also be a factor. I will decide the winner on Aug 17th and send $5478.51 :)",
  "createdAt": "Sun Aug 03 18:36:26 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 715,
  "replyCount": 515,
  "likeCount": 6807,
  "quoteCount": 96,
  "viewCount": 860819,
  "bookmarkCount": 3005,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1951987909189640253",
  "url": "https://x.com/karpathy/status/1951987909189640253",
  "text": "@jxbz love the repo! clean code, good practices but still not overly over-engineered, triton kernels, well documented, simple reference implementations alongside optimized code. nice",
  "createdAt": "Sun Aug 03 12:45:58 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 5,
  "replyCount": 2,
  "likeCount": 206,
  "quoteCount": 0,
  "viewCount": 30385,
  "bookmarkCount": 61,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1951577221753094399",
  "url": "https://x.com/karpathy/status/1951577221753094399",
  "text": "2024: everyone releasing their own Chat\n2025: everyone releasing their own Code",
  "createdAt": "Sat Aug 02 09:34:02 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 598,
  "replyCount": 482,
  "likeCount": 8250,
  "quoteCount": 102,
  "viewCount": 846827,
  "bookmarkCount": 680,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1950868418443493763",
  "url": "https://x.com/karpathy/status/1950868418443493763",
  "text": "@adrusi Nice list! If I could only convince the YouTube algorithm somehow to show me these‚Ä¶",
  "createdAt": "Thu Jul 31 10:37:30 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 4,
  "replyCount": 31,
  "likeCount": 570,
  "quoteCount": 2,
  "viewCount": 33454,
  "bookmarkCount": 56,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1949959475512672410",
  "url": "https://x.com/karpathy/status/1949959475512672410",
  "text": "@mayfer So true!\nLet me look at your implementation of GiantClass\n[read 100 lines]\nPerfect! I see the core issue now. Let me now take the next 3 minutes to re-write the entire file from scratch with this totally not hallucinated fix...",
  "createdAt": "Mon Jul 28 22:25:42 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 36,
  "replyCount": 54,
  "likeCount": 1870,
  "quoteCount": 6,
  "viewCount": 73904,
  "bookmarkCount": 112,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1949910230609121436",
  "url": "https://x.com/karpathy/status/1949910230609121436",
  "text": "@JikaSatabi @jack How could chess engine be that giant? Very large local neural nets? Electron shennanigans? Too highres assets? What do you think @chesscom ? :p. Fwiw I couldn‚Äôt find other chess apps that were dramatically smaller so I ended up playing a bit just on the website.",
  "createdAt": "Mon Jul 28 19:10:01 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1,
  "replyCount": 20,
  "likeCount": 81,
  "quoteCount": 0,
  "viewCount": 10342,
  "bookmarkCount": 7,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1949900901076128201",
  "url": "https://x.com/karpathy/status/1949900901076128201",
  "text": "@jack Very interesting. Love that it‚Äôs 2MB - I tried to download a chess app yesterday and it was 400MB.",
  "createdAt": "Mon Jul 28 18:32:56 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 41,
  "replyCount": 69,
  "likeCount": 3378,
  "quoteCount": 10,
  "viewCount": 211495,
  "bookmarkCount": 132,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1949536863116542008",
  "url": "https://x.com/karpathy/status/1949536863116542008",
  "text": "@hristo_vassilev I believe this is true, I used the word in my ‚ÄúUnreasonable Effectiveness of RNNs‚Äù post from 2015, and as far as I can remember I also hallucinated it.",
  "createdAt": "Sun Jul 27 18:26:23 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 56,
  "replyCount": 76,
  "likeCount": 3269,
  "quoteCount": 9,
  "viewCount": 16,
  "bookmarkCount": 173,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1949473018683469992",
  "url": "https://x.com/karpathy/status/1949473018683469992",
  "text": "This model convergence is quite perplexing. Possibly related to recent results on subliminal learning? Basically deeper knowledge correlations transfer when training via distillation. As the amount of data online from LLMs increases, it‚Äôs possible this makes them converge to some collective fixed point. (This would be in addition to simpler things like everyone‚Äôs dataset already being very similar.)",
  "createdAt": "Sun Jul 27 14:12:41 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 41,
  "replyCount": 77,
  "likeCount": 1396,
  "quoteCount": 18,
  "viewCount": 10,
  "bookmarkCount": 327,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1948751596264841610",
  "url": "https://x.com/karpathy/status/1948751596264841610",
  "text": "@ClaudeMini Like! My personal top tweets are those that most people find confusing/wrong first and then obvious/self-evident a few years later. LLMs were at one point seen (and still are) as chatbot, like a better Eliza or so, hence the chat bubbles, which lacks imagination by about 1000X.",
  "createdAt": "Fri Jul 25 14:26:01 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 9,
  "likeCount": 233,
  "quoteCount": 0,
  "viewCount": 6,
  "bookmarkCount": 47,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1948062129187140051",
  "url": "https://x.com/karpathy/status/1948062129187140051",
  "text": "Love this! Supercharger, diner, ‚Ä¶ but really a kind of exhibit for the future. Plotting a road trip SF -&gt; LA to charge Shadowfax",
  "createdAt": "Wed Jul 23 16:46:19 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 1647,
  "replyCount": 546,
  "likeCount": 14434,
  "quoteCount": 46,
  "viewCount": 2620839,
  "bookmarkCount": 590,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isQuote": true,
  "isPinned": false
},
{
  "id": "1947019163949731891",
  "url": "https://x.com/karpathy/status/1947019163949731891",
  "text": "@aidenybai I use CC from Cursor and I assumed most do as well (?).\nI end up with a mixed thing where Cursor is the UI layer for reading the code, manual edits, tab completion and chunk edits, and CC for larger changes, architecting, Q&amp;A. Still rapidly evolving though...",
  "createdAt": "Sun Jul 20 19:41:57 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 40,
  "replyCount": 70,
  "likeCount": 1476,
  "quoteCount": 21,
  "viewCount": 156008,
  "bookmarkCount": 484,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1946745524033593739",
  "url": "https://x.com/karpathy/status/1946745524033593739",
  "text": "Hi @gmail does the \"report phishing\" button do anything https://t.co/asIRKdxJyd",
  "createdAt": "Sun Jul 20 01:34:36 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 137,
  "replyCount": 180,
  "likeCount": 5153,
  "quoteCount": 28,
  "viewCount": 196,
  "bookmarkCount": 200,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": "1946326434836037982",
  "url": "https://x.com/karpathy/status/1946326434836037982",
  "text": "@the_danny_g unhinged virus coated behavior haha",
  "createdAt": "Fri Jul 18 21:49:17 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 3,
  "replyCount": 7,
  "likeCount": 326,
  "quoteCount": 0,
  "viewCount": 28481,
  "bookmarkCount": 8,
  "source": "",
  "lang": "en",
  "isReply": true,
  "isPinned": false
},
{
  "id": "1946325810618700033",
  "url": "https://x.com/karpathy/status/1946325810618700033",
  "text": "\"Using a better model for analysis\" ü§®\nI didn't realize I was using haiku all this time, no idea when claude code snuck this one in rofl. https://t.co/If0qQ4svQh",
  "createdAt": "Fri Jul 18 21:46:48 +0000 2025",
  "author.profilePicture": "https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB_normal.jpg",
  "retweetCount": 115,
  "replyCount": 153,
  "likeCount": 2963,
  "quoteCount": 16,
  "viewCount": 368379,
  "bookmarkCount": 467,
  "source": "",
  "lang": "en",
  "isReply": false,
  "isPinned": false
},
{
  "id": -1,
  "text": "Since you are a free user, you can only access a maximum of 15 tweets. Please upgrade to a paid user to unlock access to all tweets."
}]