The field of Artificial Intelligence (AI) really came into existence with the birth of computers in and around the 1940s and 1950s. For the earlier period of its development, attention was clearly focused on getting computers to do things that, if a human did them, would be regarded as intelligent. Essentially, this involved trying to get computers to copy humans in some or all aspects of their behaviour. In the 1960s and 1970s this opened up a philosophical discussion as to just how close to a human brain a computer could be, and whether any differences that arose were really important. This period – referred to as ‘classical AI’ in this book – was, however, rather limited in its potential.  

In the 1980s and 1990s we saw a whole new approach, a sort of bottom-­up attack on the problem, effectively building artificial brains to bring about AI. This completely opened up the possibilities and created a whole new set of questions. No longer was AI restricted to merely copying human intelligence – now it could be intelligent in its own way. In some cases it could still be brought about by mimicking the way a human brain performed, but now it had the potential to be bigger, faster and better. The philosophical consequence of this was that now an artificial brain could potentially outperform a human brain.  

In more recent years the field has really taken off. Real-­world applications of AI, particularly in the finance, manufacturing and military sectors, are performing in ways with which the human brain simply cannot compete. Artificial brains are now being given their own body, with which to perceive the world in their own way and to move around in it and modify it as they see fit. They are being given the ability to learn, adapt and carry out their wishes with regard to humans. This raises all sorts of issues for the future.  